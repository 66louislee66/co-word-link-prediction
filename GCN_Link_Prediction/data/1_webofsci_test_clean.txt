Type 2 diabetes (T2D) is a long-term, highly prevalent disease that provides extensive data support in spatial-temporal user case data mining studies. In this paper, we present a novel T2D food access early risk warning model that aims to emphasize health management awareness among susceptible populations. This model incorporates the representation of T2D-related food categories with graph convolutional networks (GCN), enabling the diet risk visualization from the geotagged Twitter visit records on a map. A long short-term memory (LSTM) module is used to enhance the performance of the case temporal feature extraction and location approximate predictive approach. Through an analysis of the resulting data set, we highlight the food effect category has on T2D early risk visualization and user food access management on the map. Moreover, our proposed method can provide suggestions to T2D susceptible patients on diet management.
This paper proposes a new Quantum Spatial Graph Convolutional Neural Network (QSGCNN) model that can directly learn a classification function for graphs of arbitrary sizes. Unlike state-of-the-art Graph Convolutional Neural Network (GCNN) models, the proposed QSGCNN model incorporates the process of identifying transitive aligned vertices between graphs and transforms arbitrary sized graphs into fixed-sized aligned vertex grid structures. In order to learn representative graph characteristics, a new quantum spatial graph convolution is proposed and employed to extract multi-scale vertex features, in terms of quantum information propagation between grid vertices of each graph. Since the quantum spatial convolution preserves the grid structures of the input vertices (i.e., the convolution layer does not alter the original spatial position of vertices), the proposed QSGCNN model allows to directly employ the traditional convolutional neural network architecture to further learn from the global graph topology, providing an end-to-end deep learning architecture that integrates the graph representation and learning in the quantum spatial graph convolution layer and the traditional convolutional layer for graph classifications. We indicate the effectiveness of the proposed QSGCNN model in relation to existing state-of-the-art methods. Experiments on benchmark graph classification datasets demonstrate the effectiveness of the proposed QSGCNN model.
In recent years, skeleton-based action recognition has become increasingly popular in the field of human action recognition, and graph convolutional networks (GCNs) have shown better advantages in this task. Many GCN-based methods are insufficient in the latent relationship between features, which affects the discriminability of features being not rich enough. These potential feature relationships can manifest as feature differences that change due to actions and feature correlations that interact with each other. Therefore, we propose a feature difference and feature correlation learning mechanism to learn discriminative augmentation features, including feature differences in actions and feature correlations between joints. First, we propose a temporal feature difference and correlation learning module (FDCL) (TFDCL). In adjacent temporal frames, we extract feature correlations between related parts. Feature differences are captured through changes in joints over the overall long-term timeline. Second, we propose a channel FDCL module. Different channels contain different types of features for actions. We use convolution operations to interact between channels, continuously extracting the strongest features to obtain feature maps. Third, we propose a temporal channel context topology (TCCT) module to dynamically learn global contextual features of all joints during motion. Finally, experiments are conducted on the NTU-RGBD 60 dataset and the kinetics-skeleton 400 dataset to verify the effectiveness of the network.
With the rapid growth of population, more diverse crowd activities, and the rapid development of socialization process, group scenes are becoming more common, so the demand for modeling, analyzing, and understanding group behavior data in video is increasing. Compared with the previous work on video content analysis, factors such as the increasing number of people in the group video and the more complex scene make the analysis of group behavior in video face great challenges. Therefore, a group behavior pattern recognition algorithm based on spatio-temporal graph convolutional network is proposed in this paper, aiming at group density analysis and group behavior recognition in the video. A crowd detection and location method based on density map regression-guided classification was designed. Finally, a crowd behavior analysis method based on density grade division was designed to complete crowd density analysis and video group behavior detection. In addition, this paper also proposes to extract spatio-temporal features of crowd posture and density by using the double-flow spatio-temporal map network model, so as to effectively capture the differentiated movement information among different groups. Experimental results on public datasets show that the proposed method has high accuracy and can effectively predict group behavior.
Recent progress in spectral classification is dominated by the use of deep learning models. While various learning architectures have been developed, they all extract spectral features from a single-view input. In this article, we investigate a different perspective and develop a unified multiview spectral feature learning framework, which extracts discriminative spectral features from multiple views of inputs. To our knowledge, this is the first reported multiview spectral feature learning method based on deep learning. In this framework, we introduce a multiview spectrum construction method by transforming the input spectral vector into multiple 3-D image patches with different sizes, termed multiview spectrum. This multiview spectrum is fed to a well-designed triple-stream architecture, where global and two local spectral feature learning networks operate in parallel, thus capturing both global and local spectral contextual features simultaneously. Another important contribution of this work is a novel interactive attention mechanism to identify the most informative spectral contextual features. The model is trained in an end-to-end fashion from scratch with a joint loss. Experimental results on four datasets demonstrate excellent performance compared to the current state of the art.
Hyperspectral image (HSI) clustering is a challenging task due to the high complexity of HSI data. Subspace clustering has been proven to be powerful for exploiting the intrinsic relationship between data points. Despite the impressive performance in the HSI clustering, traditional subspace clustering methods often ignore the inherent structural information among data. In this article, we revisit the subspace clustering with graph convolution and present a novel subspace clustering framework called graph convolutional subspace clustering (GCSC) for robust HSI clustering. Specifically, the framework recasts the self-expressiveness property of the data into the non-Euclidean domain, which results in a more robust graph embedding dictionary. We show that traditional subspace clustering models are the special forms of our framework with the Euclidean data. On the basis of the framework, we further propose two novel subspace clustering models by using the Frobenius norm, namely efficient GCSC (EGCSC) and efficient kernel GCSC (EKGCSC). Each model has a globally optimal closed-form solution, making it easier to implement, train, and apply in practice. Extensive experiments strongly evidence that EGCSC and EKGCSC dramatically outperform current models on three popular HSI data sets consistently.
Alzheimer's disease (AD) is a progressive and irreversible neurodegenerative disease. Neuroimaging based on magnetic resonance imaging (MRI) is one of the most intuitive and reliable methods to perform AD screening and diagnosis. Clinical head MRI detection generates multimodal image data, and to solve the problem of multimodal MRI processing and information fusion, this paper proposes a structural and functional MRI feature extraction and fusion method based on generalized convolutional neural networks (gCNN). The method includes a three-dimensional residual U-shaped network based on hybrid attention mechanism (3D HA-ResUNet) for feature representation and classification for structural MRI, and a U-shaped graph convolutional neural network (U-GCN) for node feature representation and classification of brain functional networks for functional MRI. Based on the fusion of the two types of image features, the optimal feature subset is selected based on discrete binary particle swarm optimization, and the prediction results are output by a machine learning classifier. The validation results of multimodal dataset from the AD Neuroimaging Initiative (ADNI) open-source database show that the proposed models have superior performance in their respective data domains. The gCNN framework combines the advantages of these two models and further improves the performance of the methods using single-modal MRI, improving the classification accuracy and sensitivity by 5.56% and 11.11%, respectively. In conclusion, the gCNN-based multimodal MRI classification method proposed in this paper can provide a technical basis for the auxiliary diagnosis of Alzheimer's disease.阿尔茨海默病（AD）是一种进行性、不可逆的神经系统退行性疾病，基于磁共振成像（MRI）的神经影像学检查是进行AD筛查与诊断最直观、可靠的方法之一 。临床上头颅MRI检测会产生多模态影像数据，为解决多模态MRI处理与信息融合的问题，本文提出基于广义卷积神经网络（gCNN）的结构MRI和功能M RI特征提取与融合方法。该方法针对结构MRI提出基于混合注意力机制的三维残差U型网络（3D HA-ResUNet）进行特征表示与分类；针对功能MRI提出U型图卷积神经网络（U-GCN）进行脑功能网络的节点特征表示与分类。在两类影像特征融 合的基础上，基于离散二进制粒子群优化算法筛选最优特征子集，并使用机器学习分类器输出预测结果。来自AD神经影像学计划（ADNI）开源数据库的多模态 数据集验证结果表明，本文所提出的模型在各自数据域内都有优秀的表现，而gCNN框架结合了两类模型的优势，进一步提高使用单一模态MRI的方法性能，将 分类准确率和敏感性分别提升了5.56%和11.11%。综上，本文所提出的基于gCNN的多模态MRI分类方法可以为AD的辅助诊断提供技术基础。.
Graph representation learning aims at mapping a graph into a lower-dimensional feature space. Deep attributed graph representation, utilizing deep learning models on the graph structure and attributes, shows its significance in mining complex relational data. Most existing deep attributed graph representation models assume graph attributes in a single-attributed view. However, rich information in real-world applications demands the ability to handle multiple attributed views. For example, in social network users' profiles and posts represent two distinct attributed views. A single-attributed view or a simple ensemble of them fails to represent the rich information and complex relations therein. To confront this challenge, this paper proposes a novel deep unsupervised graph representation learning model, called Multi-attributed-view graph Convolutional AutoEncoder (MagCAE). MagCAE learns the node-pairwise proximity among multi-attributed views and node embeddings, across which a novel loss function is designed to preserve the node-pairwise likelihood. An aggregation layer is specially developed in MagCAE to optimize the weights of embeddings on multi-attributed views. The extensive experiments on four datasets demonstrate the superiority of MagCAE over twelve baselines.
Distributed resources at a grid's end cannot upload operational power data to local centers due to data transmission and privacy issues. This leaves the centers with incomplete information, thus impacting decision making. This paper presents a virtual aggregation-based model for such scenarios. We define four virtual aggregate types based on resource response characteristics. Using characteristic coefficients, we identify these aggregates' categories and proportions from bus power. To address blind source separation in single-channel power signals, we apply the Ensemble Empirical Mode Decomposition-Fast Independent Component Analysis (EEMD-FastICA) method. This helps extract and analyze bus power, thereby deriving power curves for different aggregates. Moreover, we use a graph convolutional network to explore how factors like date, time, weather, and pricing intertwine with aggregate power. We develop a predictive model with an advanced SpatioTemporal Graph Convolutional Network (STGCN), thus facilitating proactive power forecasting for virtual aggregates. Case studies show our method's efficacy in extracting power curves under limited information, with the STGCN ensuring accurate, forward-looking predictions.
Parameter identification plays an important role in power system. The existing parameter identification methods usually have two limitations: 1) the existing methods only consider the information of single branch and ignore the influence of adjacent branch information, and do not effectively use the topological structure constraints of the power grid; 2) the measurement data has the problems of poor numerical stability, numerical divergence and noise interference. Data contamination has become an important factor restricting the prediction accuracy of branch parameters. In order to solve these problems, this work proposes an automatic weighted loss-graph convolution networks model combined with the spatial structure of power grid. Based on the graphical modeling, the correlation between power grid branches is effectively used, and the adjacent branches are used to provide more effective information for the parameter identification of a branch, which improves the identification accuracy. In addition, the model enhances the local characteristics through the power grid structure information constraints, realizes the local optimal fitting, and constructs a self tradeoff loss function to weaken the impact of pollution data (data noise and data loss) on the model. The test results show that compared with the traditional method, this method has higher accuracy and stronger robustness.
Distantly supervised relation extraction is the most popular technique for identifying semantic relation between two entities. Most prior models only focus on the supervision information present in training sentences. In addition to training sentences, external lexical resource and knowledge graphs often contain other relevant prior knowledge. However, relation extraction models usually ignore such readily available information. Moreover, previous works only utilize a selective attention mechanism over sentences to alleviate the impact of noise, they lack the consideration of the implicit interaction between sentences with relation facts. In this paper, (1) a knowledge-guided graph convolutional network is proposed based on the word-level attention mechanism to encode the sentences. It can capture the key words and cue phrases to generate expressive sentence-level features by attending to the relation indicators obtained from the external lexical resource. (2) A knowledge-guided sentence selector is proposed, which explores the semantic and structural information of triples from knowledge graph as sentence-level knowledge attention to distinguish the importance of each individual sentence. Experimental results on two widely used datasets, NYT-FB and GDS, show that our approach is able to efficiently use the prior knowledge from the external lexical resource and knowledge graph to enhance the performance of distantly supervised relation extraction.
Ergonomic risk assessment (ERA) is commonly used to identify and analyze postures that are detrimental to the health of workers in industrial workplaces, which is vital to prevent work -related musculoskeletal disorders (WMSDs). Among the automatic approaches, algorithms based on graph convolutional networks (GCNs) have shown promising results in ERA using skeleton sequence as input. However, previous GCNbased methods still have certain limitations. First, the separated modeling of spatial and temporal information and the manually pre -defined topology of graph may restrict the representation diversity of the networks. Additionally, RNN-based temporal modeling often incurs high computational costs and fails to capture longrange temporal dependencies, thereby reducing flexibility in describing long videos. To overcome these challenges, in this study, we propose an attention -based adaptive spatial-temporal graph convolutional network (AAST-GCN), aiming to achieve effective and efficient action representation for ERA in long video. First, we employ an alternate modeling strategy to effectively capture the spatial-temporal information, and propose an improved adaptive adjacency matrix scheme to learn various coordination and relations of body -joints, thus enhancing the flexibility to model diverse postures. Furthermore, we introduce an efficient multi -scale temporal convolutional network as a replacement for RNN-based algorithms, enabling the network to extract various granularities of temporal features. Moreover, to make the network focuses on more valuable information, we employ a spatial-temporal interaction attention (STIA) module. Finally, the aforementioned modules are aggregated within a multi -task learning framework, with the action segmentation serving as the auxiliary task to further improve the accuracy of ERA. We conducted the ergonomic risk assessment on the UW-IOM and TUM Kitchen datasets using our network. Extensive experiments conducted on the most popular datasets UW-IOM and TUM Kitchen demonstrated that our proposed AAST-GCN outperforms other GCN-based methods. Ablation studies and visualization also prove the effectiveness of the individual sub -modules.
Skeleton-based human action recognition aims to recognize human actions from given skeleton sequences. The literature utilizes fixed-stride sampling and uniform aggregations, which are independent of the input data and do not focus on representative motion frames. In this paper, to overcome the challenge of the fixed uniform aggregation strategy being unable to focus on discriminative motion information, a novel non-uniform motion aggregation embedded with a graph convolutional network (NMA-GCN) is proposed for skeleton-based human action recognition. Based on the skeleton quality and motion-salient regions, NMA is able to focus on the discriminative motion information of human motion-salient regions. Finally, the aggregated skeleton sequences are embedded with the GCN backbone for skeleton-based human action recognition. Experiments were conducted on three large benchmarks: NTU RGB+D, NTU RGB+D 120, and FineGym. The results show that our method achieves 93.4% (Xsub) and 98.2% (Xview) on NTU RGB+D dataset, 87.0% (Xsub) and 90.0% (Xset) on the NTU RGB+D 120 dataset, and 90.3% on FineGym dataset. Ablation studies and evaluations across various GCN-based backbones further support the effectiveness and generalization of NMA-GCN.
Aspect-based Sentiment Analysis (ABSA) aims to automatically predict the sentiment polarity of the written text based on the analysis of specific aspects. By applying various pre-trained language encoders, recent studies have achieved great success in modeling aspect and context features and measuring the word-level correlations. However, the pre-trained language models (PLM) were usually employed as the feature representations generator without any task-oriented guidance. And the syntax dependency tree is also not fully utilized. Besides, simply concatenating usually fails to exploit deep semantic features from multi-source spaces and weakens the representation of context features. In this study, we propose a novel model, namely PRoGCN (Prompted RoBERTa & Graph Convolution Network), which directly tells RoBERTa the goal of the present task by inserting the task-oriented specific prompting word to the raw text. Moreover, the prompted feature representation is also utilized to help generate textual knowledge graph, and strongly enhances the syntactic feature representation. In addition, we first introduce cross attention into our study to integrate semantic representation and syntactic representation, which has been proven to be successful in implementing and fusing multi-source information. Experimental results on five publicly available ABSA datasets validate the effectiveness of our method, and the proposed method achieves state-of-the-art performance on mentioned ABSA benchmarks.
Facial expression recognition (FER) in the wild is challenging due to various unconstrained conditions, i.e., occlusions and head pose variations. Previous methods tend to improve the performance of facial expression recognition through resorting to holistic methods or coarse local-based methods, while ignoring the local fine-grained feature structure knowledge and the correlation between features. In this paper, we propose a Fine-Grained Association Graph Representation (FG-AGR) framework which can capture the local fine-grained facial expression representation. Firstly, an Adaptive Salient Region Induction (ASRI) is designed for adaptively highlighting the local saliency regions of facial expressions combined with spatial location information. Based on this, a Local Fine-grained Feature Extraction (LFFE) based on Visual Transformers is introduced to further extract fine but discriminative fine-grained features of saliency regions. Thirdly, an Adaptive Graph Association Reasoning (AGAR) based on Graph Convolutional Network is constructed to learn associated fine-grained feature combinations. Extensive experiments demonstrate that our FG-AGR achieves superior performance compared to the state-of-the-art methods with 90.81% on RAF-DB, 64.91% on AffectNet-7, 60.69% on AffectNet-8 and 91.09% on FERPlus.
Human motion recognition is of great value in the fields of intelligent monitoring systems, driver assistance system, advanced human-computer interaction, human motion analysis, image and video processing. However, the current human motion recognition methods have the problem of poor recognition effect. Therefore, we propose a human motion recognition method based on Nano complementary metal oxide semiconductor (CMOS) image sensor. First, using the Nano-CMOS image sensor to transform and process the human motion image, and combines the background mixed model of pixels in the human motion image to extract the human motion features, and feature selection is conducted. Second, according to the three-dimensional scanning features of Nano-CMOS image sensor, the human joint coordinate information data is collected, the state variables of human motion are sensed by the sensor, and the human motion model is constructed according to the measurement matrix of human motions. Finally, the foreground features of human motion images are obtained by calculating the feature parameters of each motion gesture. According to the posterior conditional probability of human motion images, the recognition objective function of human motion is obtained to realize human motion recognition. The results show that the human motion recognition effect of the proposed method is good, the extraction accuracy is high, the average human motion recognition rate is 92%, the classification accuracy is high, and the recognition speed is up to 186 frames/s.
Mineral prospectivity mapping (MPM) aims to reduce the areas for searching of mineral deposits. Various statistical models that have been successfully adopted to delineate prospecting regions for a specific type of mineral deposit can be divided into pixel-wise, image- (or pixel-patch), and graph-based approaches. The pixel-wise models, which frequently integrate multiple prospecting information (or evidence layers) at a single pixel, do not adequately consider the spatial associations among neighboring pixels and may ignore the spatial patterns linked to mineralization or the spatial distribution characteristics of mineral deposits to some extent. Image-based models such as convolutional neural networks (CNNs) can extract local meaningful features and capture the spatial patterns of prospecting information in MPM because the input data of image-based models are images composed of regular pixels in the Euclidean space. However, CNNs also have limitations in MPM, such as the requirement for regular input data and non-rotationally invariant spatial features. Graphs that are typically composed of nodes and edges have a strong abstraction to capture the complex and nonlinear spatial relationships among multiple nodes and their edges. Prospecting information or evidence layers can be regarded as graphs in which pixels are connected by their adjacent pixels. In this study, graph deep learning algorithms, including graph convolutional networks and graph attention networks, were employed to produce mineral potential maps. A comparative study of graph deep learning algorithms with a CNN demonstrated the advantage of graph deep learning algorithms for MPM in terms of the cumulative areas versus the cumulative number of mineral deposits and the true/false prediction rate plot. These results suggest that the graph-based models, such as graph neutral networks, can effectively capture mineralization information and the spatial interrelations between mineralization and prospecting information.
Traffic speed prediction plays an important role in intelligent transportation systems, and many approaches have been proposed over recent decades. In recent years, methods using graph convolutional networks (GCNs) have been more promising, which can extract the spatiality of traffic networks and achieve a better prediction performance than others. However, these methods only use inaccurate historical data of traffic speed to forecast, which decreases the prediction accuracy to a certain degree. Moreover, they ignore the influence of dynamic traffic on spatial relationships and merely consider the static spatial dependency. In this paper, we present a novel graph convolutional network model called FSTGCN to solve these problems, where the model adopts the full convolutional structure and avoids repeated iterations. Specifically, because traffic flow has a mapping relationship with traffic speed and its values are more exact, we fused historical traffic flow data into the forecasting model in order to reduce the prediction error. Meanwhile, we analyzed the covariance relationship of the traffic flow between road segments and designed the dynamic adjacency matrix, which can capture the dynamic spatial correlation of the traffic network. Lastly, we conducted experiments on two real-world datasets and prove that our model can outperform state-of-the-art traffic speed prediction.
Classification of electroencephalogram-based motor imagery (MI-EEG) tasks is crucial in brain computer interfaces (BCI). In view of the characteristics of non-stationarity, time-variability and individual diversity of EEG signals, a novel framework based on graph neural network is proposed for MI-EEG classification. First, an adaptive graph convolutional layer (AGCL) is constructed, by which the electrode channel information are integrated dynamically. We further propose an adaptive spatiotemporal graph convolutional network (ASTGCN), which fully exploits the characteristics of EEG signals in time domain and the channel correlations in spatial domain simultaneously. We execute the experiments using EEG signals recorded at motor imagery scenarios, where twenty-five healthy subjects performed MI movements of the right hand and feet to generate motor commands. Experimental results reveal that the proposed method outperforms state-of-the-art methods in terms of both classification quality and robustness. The advantages of ASTGCN include high accuracy, high efficiency, and robustness to cross-trial and cross-subject variations, making it an ideal candidate for long-term MI-EEG applications.
In subtropical regions, heavy rains from cumulonimbus clouds can cause disasters such as flash floods and mudslides. The accurate prediction of cumulonimbus cloud distribution is crucial for mitigating such losses. Traditional machine learning approaches have been used on radar echo data generated by constant altitude plan position indicator (CAPPI) radar systems for predicting cumulonimbus cloud distribution. However, the results are often too foggy and fuzzy. This paper proposes a novel approach that integrates graph convolutional networks (GCN) and trajectory gated recurrent units (TrajGRU) with an attention mechanism to predict cumulonimbus cloud distribution from radar echo data. Experiments were conducted using the moving modified National Institute of Standards and Technology (moving MNIST) dataset and real-world radar echo data, and the proposed model showed a 59.12% improvement in mean square error (MSE) and a 16.26% improvement in structure similarity index measure (SSIM) on average in the moving MNIST dataset, a 65.40% improvement in MSE, and an 10.29% improvement in SSIM on average in the radar echo dataset. These results demonstrate the effectiveness of the proposed approach for improving the prediction accuracy of cumulonimbus cloud distribution.
This research proposed a data analysis framework applying human action recognition (HAR) with filtering processing to recognize human workers' actions and further calculate the operating time of each action. When applying HAR to recognize the worker's operation actions on a manufacturing site, the repeated and reciprocating actions easily cause misrecognition. Without the separation of actions in advance, the evaluation of HAR in real-world manufacturing is different from the evaluation based on the open data in the literature. To resolve the practical issues of applying HAR on a manufacturing site, first, the spatial-temporal skeleton coordinates of human joints were generated as the input of the skeleton-based spatial-temporal graph convolutional neural network (ST-GCN) for training the recognition model. Once the human action is recognized in each frame, the filtering processing considering the reference correction and accumulative moving mode (AMM) was proposed to improve the recognition accuracy. The real-world case study of the forging industry was conducted, and the empirical result shows the proposed framework was able to detect human workers' repeated actions with 89% accuracy. Also, the time analysis based on HAR-Time recognition can correctly detect the associated time features that have highly correlated to the low quality of the product.
Automatic sleep staging is important for improving diagnosis and treatment, and machine learning with neuroscience explainability of sleep staging is shown to be a suitable method to solve this problem. In this paper, an explainable model for automatic sleep staging is proposed. Inspired by the Spike-Timing-Dependent Plasticity (STDP), an adaptive Graph Convolutional Network (GCN) is established to extract features from the Polysomnography (PSG) signal, named STDP-GCN. In detail, the channel of the PSG signal can be regarded as a neuron, the synapse strength between neurons can be constructed by the STDP mechanism, and the connection between different channels of the PSG signal constitutes a graph structure. After utilizing GCN to extract spatial features, temporal convolution is used to extract transition rules between sleep stages, and a fully connected neural network is used for classification. To enhance the strength of the model and minimize the effect of individual physiological signal discrepancies on classification accuracy, STDP-GCN utilizes domain adversarial training. Experiments demonstrate that the performance of STDP-GCN is comparable to the current state-of-the-art models.
This article tackles Partial Domain Adaptation (PDA) where the target label set is a subset of the source label set. A key challenging issue in PDA is to prevent negative transfer by isolating source-private classes. Since there is no label information for a target domain, PDA methods require to estimate a label commonness score between source and target domains. Existing approaches use either class-level or sample-level commonness to alleviate the negative transfer issue. However, class-level methods assign the same label commonness to all samples of the same class without considering each sample's characteristics. Also, the recently introduced sample-level approaches show better performance but they still suffer from negative transfer due to non-trivial anomaly samples. To address these limitations, we propose Adaptive Graph Adversarial Networks (AGAN) consisting of two specialized modules. The adaptive class-relational graph module is designed to utilize the intra- and inter-domain structures through adaptive feature propagation. Complementarily, the sample-level commonness predictor computes a commonness score of each sample. Extensive experimental results on public PDA benchmark datasets demonstrate that our structure-aware method outperforms state-of-the-art methods.
A spammer sends many useless advertisements to recipients via social networking sites without their permission, posing a serious threat to the information security of regular users, as well as the credit system of these sites. A social network Spammer detection technology based on graph convolution networks (GCNs) is presented with the goal of addressing the shortcomings of existing social network Spammer detection technologies, such as their shallow feature extraction and excessive computational complexity. With the help of an introduction of a network representation learning algorithm, this method extracts the local structural features of the network and then combines the GCN algorithm with renormalization technology to obtain the global structural features of the network, which can be used to detect spam. Experiments conducted on data from the social networking site demonstrate that the proposed method has good accuracy and efficiency.
Objective. Alzheimer's disease is a progressive neurodegenerative dementia that poses a significant global health threat. It is imperative and essential to detect patients in the mild cognitive impairment (MCI) stage or even earlier, enabling effective interventions to prevent further deterioration of dementia. This study focuses on the early prediction of dementia utilizing Magnetic Resonance Imaging (MRI) data, using the proposed Graph Convolutional Networks (GCNs). Approach. Specifically, we developed a functional connectivity (FC) based GCN framework for binary classifications using resting-state fMRI data. We explored different types and processing methods of FC and evaluated the performance on the OASIS-3 dataset. We developed the GCN model for two different purposes: (1) MCI diagnosis: classifying MCI from normal controls (NCs); and (2) dementia risk prediction: classifying NCs from subjects who have the potential for developing MCI but have not been clinically diagnosed as MCI. Main results. The results of the experiments revealed several important findings: First, the proposed GCN outperformed both the baseline GCN and Support Vector Machine (SVM). It achieved the best average accuracy of 80.3% (11.7% higher than the baseline GCN and 23.5% higher than SVM) and the highest accuracy of 91.2%. Secondly, the GCN framework with (absolute) individual FC performed slightly better than that with global FC generally. However, GCN using global graphs with appropriate connectivity can achieve equivalent or superior performance to individual graphs in some cases, which highlights the significance of suitable connectivity for achieving performance. Additionally, the results indicate that the self-network connectivity of specific brain network regions (such as default mode network, visual network, ventral attention network and somatomotor network) may play a more significant role in GCN classification. Significance. Overall, this study offers valuable insights into the application of GCNs in brain analysis and early diagnosis of dementia. This contributes significantly to the understanding of MCI and has substantial potential for clinical applications in early diagnosis and intervention for dementia and other neurodegenerative diseases. Our code for GCN implementation is available at: https://github.com/Shuning-Han/FC-based-GCN.
Background: The major intrinsic protein (MIP) family is a family of proteins, including aquaporins, which facilitate water and small molecule transport across plasma membranes. In plants, MIPs function in a huge variety of processes including water transport, growth, stress response, and fruit development. In this study, we characterize the structure and transcriptional regulation of the MIP family in grapevine, describing the putative genome duplication events leading to the family structure and characterizing the family's tissue and developmental specific expression patterns across numerous preexisting microarray and RNAseq datasets. Gene co-expression network (GCN) analyses were carried out across these datasets and the promoters of each family member were analyzed for cis-regulatory element structure in order to provide insight into their transcriptional regulation. Results: A total of 29 Vitis vinifera MIP family members (excluding putative pseudogenes) were identified of which all but two were mapped onto Vitis vinifera chromosomes. In this study, segmental duplication events were identified for five plasma membrane intrinsic protein (PIP) and four tonoplast intrinsic protein (TIP) genes, contributing to the expansion of PIPs and TIPs in grapevine. Grapevine MIP family members have distinct tissue and developmental expression patterns and hierarchical clustering revealed two primary groups regardless of the datasets analyzed. Composite microarray and RNA-seq gene co-expression networks (GCNs) highlighted the relationships between MIP genes and functional categories involved in cell wall modification and transport, as well as with other MIPs revealing a strong co-regulation within the family itself. Some duplicated MIP family members have undergone sub-functionalization and exhibit distinct expression patterns and GCNs. Cis-regulatory element (CRE) analyses of the MIP promoters and their associated GCN members revealed enrichment for numerous CREs including AP2/ERFs and NACs. Conclusions: Combining phylogenetic analyses, gene expression profiling, gene co-expression network analyses, and cis-regulatory element enrichment, this study provides a comprehensive overview of the structure and transcriptional regulation of the grapevine MIP family. The study highlights the duplication and sub-functionalization of the family, its strong coordinated expression with genes involved in growth and transport, and the putative classes of TFs responsible for its regulation.
Recently, an increasing number of studies have demonstrated that miRNAs are involved in human diseases, indicating that miRNAs might be a potential pathogenic factor for various diseases. Therefore, figuring out the relationship between miRNAs and diseases plays a critical role in not only the development of new drugs, but also the formulation of individualized diagnosis and treatment. As the prediction of miRNA-disease association via biological experiments is expensive and time-consuming, computational methods have a positive effect on revealing the association. In this study, a novel prediction model integrating GCN, CNN and Squeeze-and-Excitation Networks (GCSENet) was constructed for the identification of miRNA-disease association. The model first captured features by GCN based on a heterogeneous graph including diseases, genes and miRNAs. Then, considering the different effects of genes on each type of miRNA and disease, as well as the different effects of the miRNA-gene and disease-gene relationships on miRNA-disease association, a feature weight was set and a combination of miRNA-gene and disease-gene associations was added as feature input for the convolution operation in CNN. Furthermore, the squeeze and excitation blocks of SENet were applied to determine the importance of each feature channel and enhance useful features by means of the attention mechanism, thus achieving a satisfactory prediction of miRNA-disease association. The proposed method was compared against other state-of-the-art methods. It achieved an AUROC score of 95.02% and an AUPR score of 95.55% in a 10-fold cross-validation, which led to the finding that the proposed method is superior to these popular methods on most of the performance evaluation indexes. Author summary Identifying miRNA-disease associations accelerates the understanding towards pathogenicity, which is beneficial for the development of treatment tools for diseases. Different from existing methods, our GCSENet captures the deep relationship between miRNA and disease through three heterogeneous graphs (disease, gene and miRNA) to promote an accurate prediction result. We performed the 10-fold cross validation to evaluate the performance of GCSENet, which can outperform many classic methods. Furthermore, we carried out case studies on four important diseases, which were used to evaluate the performance of our model regarding to the associations with experimental evidences in literature. The result shows that most predicted miRNAs (48 for lung neoplasms, 48 for heart failure, 48 for breast cancer and 50 for glioblastoma) in the top 50 predictions were confirmed in HMDD v3.0. As a result, it shows that GCSENet can make reliable predictions and guide experiments to uncover more miRNA-disease associations.
With the growing popularity of somatosensory interaction devices, human action recognition is becoming attractive in many application scenarios. Skeleton-based action recognition is effective because the skeleton can represent the position and the structure of key points of the human body. In this paper, we leverage spatiotemporal vectors between skeleton sequences as input feature representation of the network, which is more sensitive to changes of the human skeleton compared with representations based on distance and angle features. In addition, we redesign residual blocks that have different strides in the depth of the network to improve the processing ability of the temporal convolutional networks (TCNs) for long time dependent actions. In this work, we propose the two-stream temporal convolutional networks (TS-TCNs) that take full advantage of the inter-frame vector feature and the intra-frame vector feature of skeleton sequences in the spatiotemporal representations. The framework can integrate different feature representations of skeleton sequences so that the two feature representations can make up for each other's shortcomings. The fusion loss function is used to supervise the training parameters of the two branch networks. Experiments on public datasets show that our network achieves superior performance and attains an improvement of 1.2% over the recent GCN-based (BGC-LSTM) method on the NTU RGB+D dataset.
In recent years, the pollution of organic wastewater to the environment has attracted extensive attention. The adsorption method is simple and has been used for the adsorption of organic dyes in wastewater. In this study, lithium chloride (LiCl) was intercalated on graphite like carbon nitride (g-C3N4), a series of Li intercalated g-C3N4 adsorbents (Li/GCN-x) were synthesized. And use X-ray diffraction (XRD), field emission scanning electron microscopy (SEM), N-2 adsorption-desorption and other methods to comprehensively test and characterize the phase structure, morphology, and surface area of the prepared samples. At the same time, the influence of the amount of LiCl added on the adsorption of methylene blue (MB) on the intercalation material at room temperature was investigated. The optimal Li content in the intercalation g-C3N4 was determined. The research results show that compared with pure g-C3N4, the prepared Li/GCN-5 can form fibers with uniform diameters between the layers, XRD results show that the addition of LiCl makes the lattice of g-C3N4 expand and the layer spacing expand, indicating the successful intercalation of LiCl. The pH and the binding time between the adsorbent and MB were studied. The new functional groups of the adsorbent can form hydrogen bonds with MB molecules and interact through pi-pi bonds. When only 50 mg of the adsorbent is added, the maximum adsorption capacity can reach 704 mg.g(-1) in 5 min. In addition, adsorption kinetics simulations have been carried out. The results show that the intercalation adsorbent can adsorb MB. The model conforms to the quasi-second-order kinetic equation. The Weber-Morris model was further used to explore the adsorption control process. The results showed that the adsorption of MB was caused by the combined action of surface diffusion and intrapore diffusion, in which surface diffusion was dominant, and the newly added functional groups could form hydrogen bonds with MB molecules, and the interaction enhances the adsorption capacity through pi-pi bonds. The as-prepared materials in this study are stable, uniform and have large specific surface area, which can simply and quickly realize the adsorption of MB. It provides a simple, low-cost, and efficient method for the adsorption and removal of organic pollutants, which overcomes the shortcomings of slow kinetics of commonly used adsorbents.
Graphene oxide (GO) is a compromising catalyst material with a two-dimensional layer of carbon atoms having sp2 hybridization bonded in a hexagonal lattice structure. The gCN is a member of 2D-structured metal-free carbon materials. In this study, GO, gCN, fluorine, and nitrogen treated GO and ZnO-Ag (Ag doped ZnO) loaded carbon nanocomposites were studied. Fluorine and nitrogen treated GO is an up-rising carbon member. It has high stability. Its layer structure possess unique properties due to its C-F (covalent and semi-ionic) and C-N bonds. The computer simulations of all molecules were conducted using the Hartree-Fock function with a 6-311 G* mode on Spartan'14 software. A number of properties like molecule structure, electrostatic potential, local ionization potential, density, HOMO, and LUMO level of the molecules were obtained from computer simula-tions. Electrochemical CO2 reduction to CH3OH on catalysts was investigated in different electrolysis conditions, such as different electrolytes with UV-light and 0.07 T magnetic core treatment. Results showed that the introduction of ZnO-Ag on carbon nanocomposites improved properties of carbon nanocomposites, leading to a high conversion of CO2 to CH3OH. Methanol production rate was improved by five-times after UV-light (lambda = 254 nm) and 0.07 T magnetic core treatment. Faradaic efficiencies of carbon nanocomposites for methanol pro-duction through electrochemical reduction of CO2 in bicarbonate buffer and electrolytes were found to be 67.48% and 58.93% (compared to Ag/AgCl) at -2.7 V, respectively. Charge carrier properties and morphology profile of these nanocomposites were also analyzed.
Aspect sentiment triplet extraction (ASTE) is one of the important subtasks of aspect-based sentiment analysis, it aims at detecting the aspect terms, opinion terms, and the corresponding sentiment polarity, simultaneously. Most methods directly employ GCNs to capture the syntactic dependency information in ASTE. However, these methods may lead to error propagation. Besides, the GCN-based methods are weak at capturing sequence information and long-distance information. The general neural networks such as LSTM are good at capturing this kind of information. However, these general neural networks are weak at modeling syntactic dependency information. To alleviate the above problems, we propose a novel interactive dual channel network (IDCN) for ASTE. In IDCN, an interactive word pair generating (IWPG) module is designed to model the sequence information, long-distance dependency information, and correlation relations between word pairs, simultaneously. In the IWPG module, the dual channels can learn different representations. Based on these representations, the informative word-pair representations can be learned by the interaction mechanism of dual channels. Besides, we design the syntactic dependency fusion module to model the syntax dependency information by constructing word pair dependency relation tensors and pooling mechanism, which can naturally inject the syntactic dependency knowledge into the general neural networks and reduce error propagation. Abundant experiments have been performed on multiple datasets. The experimental results show that IDCN acquires state-of-the-art results and validates the effectiveness of IDCN.
Exosomal miRNAs activates hepatic stellate cell (HSC) and promote fibrosis. miR-222 was found to be increased in hepatitis B virus (HBV)-infected hepatocytes, and ferroptosis was reported to ameliorate liver fibrosis (LF). Although miR-222 and ferroptosis have been implicated in LF, the association between miR-222 and ferroptosis and how they coordinate to regulate LF are still not explicit. This study investigates the roles of miR-222 and transferrin receptor (TFRC) in LF. Lipid reactive oxygen species (ROS) level was analyzed by flow cytometry. FerroOrange staining was used to measure intracellular iron level. Luciferase reporter assay was adopted to confirm the binding of miR-222 and TFRC. Real-time quantitative PCR and immunoblots were applied to analyze gene and protein expression. The results showed that supplementation of exosomes derived from HBV-infected LO2 cells remarkably enhanced LX-2 cell activation, evidenced by elevated hydroxyprolin (Hyp) secretion and alpha-SMA and COL1A2 expression. miR-222 was significantly increased in HBV-Exo. Overexpressing miR-222 upregulated cell viability, secretion of Hpy, and expression of alpha-SMA and COL1A2, which were all blocked by overexpression of TFRC. Further study showed that TFRC was a target of miR-222, and miR-222 promoted LX-2 cell activation through suppressing TFRC-induced ferroptosis in LX-2 cells. Exosomal miR-222 derived from HBV-infected hepatocytes promoted LF through inhibiting TFRC and TFRC-induced ferroptosis. This study emphasizes the significance of miR-222/TFRC axis in LF and suggests new insights in clinical decision making while treating LF.
Most ground-based remote sensing cloud classification methods focus on learning representation features for cloud images while ignoring the correlations among cloud images. Recently, graph convolutional network (GCN) is applied to provide the correlations for ground-based remote sensing cloud classification, in which the graph convolutional layer aggregates information from the connected nodes of graph in a weighted way. However, the weights assigned by GCN cannot reflect the importance of connected nodes precisely, which declines the discrimination of the aggregated features (AFs). To overcome the limitation, in this article, we propose the context graph attention network (CGAT) for ground-based remote sensing cloud classification. Specifically, the context graph attention layer (CGA layer) of CGAT is proposed to learn the context attention coefficients (CACs) and obtain the AFs of nodes based on the CACs. We compute the CACs not only considering the two connected nodes but also their neighborhood nodes in order to stabilize the aggregation process. In addition, we propose to utilize two different transformation matrices to transform the node and its connected nodes into new feature spaces, which could enhance the discrimination of AFs. We concatenate the AFs with the deep features (DFs) as final representations for cloud classification. Since existing ground-based cloud data sets (GCDs) have limited cloud images, we release a new data set named GCD that is the largest one for ground-based cloud classification. We conduct a series of experiments on GCD, and the experimental results verify the effectiveness of CGAT.
Novel object grasping is an important technology for robot manipulation in unstructured environments. For most of current works, a grasp sampling process is required to obtain grasp candidates, combined with a local feature extractor using deep learning. However, this pipeline is time-cost, especially when grasp points are sparse such as at the edge of a bowl. To tackle this problem, our algorithm takes the whole sparse point clouds as the input and requires no sampling or search process. Our work is combined with two steps. The first step is to predict poses, categories and scores (qualities) based on a SPH3D-GCN network. The second step is an iterative grasp pose refinement, which is to refine the best grasp generated in the first step. The whole weight sizes for these two steps are only about 0.81M and 0.52M, which takes about 73 ms for a whole prediction process including an iterative grasp pose refinement using a GeForce 840M GPU. Moreover, to generate training data of multi-object scene, a single-object dataset (79 objects from YCB object set, 23.7k grasps) and a multi-object dataset (20k point clouds with annotations and masks) combined with thin structures grasp planning are generated. Our experiment shows our work gets 76.67% success rate and 94.44% completion rate, which performs better than current state-of-the-art works.
Truth discovery methods aim to identify which piece of information is trustworthy from multi-sourced data. Most existing truth discovery methods, however, are designed for structured data and fail to meet the strong need to extract trustworthy information from raw text data. More specifically, existing methods ignore the semantic information of text answers, i.e., answers may contain multiple factors, the word usages may be diverse, and the answers may be partially correct. In addition, ubiquitous long-tail phenomenon exists in the tasks, i.e., most users provide only a few answers and only a few users provide plenty of answers, which causes the user reliability estimation for small users to be unreasonable. To tackle these challenges, we propose a Graph Convolutional Network (GCN) based truth discovery model to automatically discover trustworthy information from text data. Firstly, Smooth Inverse Frequency (SIF) is utilized to learn real-valued vector representations for answers. Then, we construct undirected graph with these vectors to capture the structural information of answers. Finally, the GCN is utilized to store and update the reliability of these answers, and sums up all the feature vectors of all neighboring answers to improve the accuracy and efficiency of truth discovery. Different from traditional methods, we use vectors to store the reliability of answers which have higher representation capability compared with real numbers, and network is utilized to capture complex relationships among answers rather than simplified functions. The experiment results on real datasets show that though text data structures are complex, our model can still find reliable answers compared with retrieval-based and state-of-the-art truth discovery methods.
Evolutionary theories of ageing predict a reduction in selection efficiency with age, a so-called "selection shadow," due to extrinsic mortality decreasing effective population size with age. Classic symptoms of ageing include a deterioration in transcriptional regulation and protein homeostasis. Understanding how ant queens defy the trade-off between fecundity and lifespan remains a major challenge for the evolutionary theory of ageing. It has often been discussed that the low extrinsic mortality of ant queens, that are generally well protected within the nest by workers and soldiers, should reduce the selection shadow acting on old queens. We tested this by comparing strength of selection acting on genes upregulated in young and old queens of the ant, Cardiocondyla obscurior. In support of a reduced selection shadow, we find old-biased genes to be under strong purifying selection. We also analyzed a gene coexpression network (GCN) with the aim to detect signs of ageing in the form of deteriorating regulation and proteostasis. We find no evidence for ageing. In fact, we detect higher connectivity in old queens indicating increased transcriptional regulation with age. Within the GCN, we discover five highly correlated modules that are upregulated with age. These old-biased modules regulate several antiageing mechanisms such as maintenance of proteostasis, transcriptional regulation, and stress response. We observe stronger purifying selection on central hub genes of these old-biased modules compared with young-biased modules. These results indicate a lack of transcriptional ageing in old C. obscurior queens, possibly facilitated by strong selection at old age and well-regulated antiageing mechanisms.
Previous video action recognition mainly focuses on extracting spatial and temporal features from videos or capturing physical dependencies among joints. The relation between joints is often ignored. Modeling the relation between joints is important for action recognition. Aiming at learning discriminative relation between joints, this paper proposes a joint spatial-temporal reasoning (JSTR) framework to recognize action from videos. For the spatial representation, a joints spatial relation graph is built to capture position relations between joints. For the temporal representation, temporal information of body joints is modeled by the intra-joint temporal relation graph. The spatial reasoning feature and the temporal reasoning feature are fused to recognize action from videos. The effectiveness of our method is demonstrated in three real-world video action recognition datasets. The experiment results display good performance across all of these datasets.
In the past, most of the entity prediction methods based on embedding lacked the training of local core relationships, resulting in a deficiency in the end-to-end training. Aiming at this problem, we propose an end-to-end knowledge graph embedding representation method. It involves local graph convolution and global cross learning in this paper, which is called the TransC graph convolutional network (TransC-GCN). Firstly, multiple local semantic spaces are divided according to the largest neighbor. Secondly, a translation model is used to map the local entities and relationships into a cross vector, which serves as the input of GCN. Thirdly, through training and learning of local semantic relations, the best entities and strongest relations are found. The optimal entity relation combination ranking is obtained by evaluating the posterior loss function based on the mutual information entropy. Experiments show that this paper can obtain local entity feature information more accurately through the convolution operation of the lightweight convolutional neural network. Also, the maximum pooling operation helps to grasp the strong signal on the local feature, thereby avoiding the globally redundant feature. Compared with the mainstream triad prediction baseline model, the proposed algorithm can effectively reduce the computational complexity while achieving strong robustness. It also increases the inference accuracy of entities and relations by 8.1% and 4.4%, respectively. In short, this new method can not only effectively extract the local nodes and relationship features of the knowledge graph but also satisfy the requirements of multilayer penetration and relationship derivation of a knowledge graph.
Graphite carbon nitride (g-C3N4) has caught far-ranging concern for its masses of advan-tages, for instance, the unique graphite-like two-dimensional lamellar structure, low cost, nontoxic, suitable bandgap of 2.7 eV and favorable stability. Whereas owing to the short-comings of low solar absorptivity and fast recombination of photo-induced charge pairs, the overall quantum efficiency of photocatalysis for g-C3N4 is suboptimal, resulting in limited practicality of g-C3N4 (GCN). In our study, modified g-C3N4 materials (HCN) with ample carbon vacancies (CVs) were obtained through calcinating of g-C3N4 in H2 atmo-sphere. Higher specific surface area and more active sites of HCN were induced by roasting of g-C3N4 in H2. CVs that occurred in the N-(C3) bond lead to the reduction of electron density around N, thus narrowing the bandgap of HCN-3h and enlarging corresponding light response capability. Under the synergistic function of abundant pore construction and CVs on HCN, the photo-excited e -/h+ pairs can be memorably separated and trans-ferred, which is favorable to photocatalytic efficiency. Among HCN, the HCN-3h sample has the highest H2 generation rate of 4297.9 mmol h-1 g-1, which achieves 2.3-fold higher than that of GCN (1291.7 mmol h-1 g-1). This paper brings forward a meaningful method of boosting the photocatalytic performance of photocatalysts by constructing abundant CVs.(c) 2022 Hydrogen Energy Publications LLC. Published by Elsevier Ltd. All rights reserved.
Real-time and reliable short-term traffic state prediction is one of the most critical technologies in intelligent transportation systems (ITS). However, the traffic state is generally perceived by single sensor in existing studies, which is difficult to satisfy the requirement of real-time prediction in complex traffic networks. In this paper, a short-term traffic prediction model based on complex neural network is proposed under the environment of vehicle-to-everything (V2X) communication systems. Firstly, a traffic perception system of multi-source sensors based on V2X communication is proposed and designed. A mobile edge computing (MEC)-assisted architecture is then introduced in a V2X network to facilitate perceptual and computational abilities of the system. Moreover, the graph convolutional network (GCN), the gated recurrent unit (GRU), and the soft-attention mechanism are combined to extract spatiotemporal features of traffic state and integrate them for future prediction. Finally, an intelligent roadside test platform is demonstrated for perception and computation of real-time traffic state. The comparison experiments show that the proposed method can significantly improve the prediction accuracy by comparing with the existing neural network models, which consider one of the spatiotemporal features. In particular, for comparison results of the traffic state prediction and the error value of root mean squared error (RMSE) is reduced by 39.53%, which is the greatest reduction in error occurrences by comparing with the GCN and GRU models in 5, 10, 15 and 30 min respectively.
Background Idiopathic inflammatory myopathies (IIM) are a group of autoimmune diseases characterised by myositis-related autoantibodies plus infiltration of leucocytes into muscles and/or the skin, leading to the destruction of blood vessels and muscle fibres, chronic weakness and fatigue. While complement-mediated destruction of capillary endothelia is implicated in paediatric and adult dermatomyositis, the complex diversity of complement C4 in IIM pathology was unknown. Methods We elucidated the gene copy number (GCN) variations of total C4, C4A and C4B, long and short genes in 1644 Caucasian patients with IIM, plus 3526 matched healthy controls using real-time PCR or Southern blot analyses. Plasma complement levels were determined by single radial immunodiffusion. Results The large study populations helped establish the distribution patterns of various C4 GCN groups. Low GCNs of C4T (C4T=2+3) and C4A deficiency (C4A=0+1) were strongly correlated with increased risk of IIM with OR equalled to 2.58 (2.28-2.91), p=5.0x10(-53) for C4T, and 2.82 (2.48-3.21), p=7.0x10(-57) for C4A deficiency. Contingency and regression analyses showed that among patients with C4A deficiency, the presence of HLA-DR3 became insignificant as a risk factor in IIM except for inclusion body myositis (IBM), by which 98.2% had HLA-DR3 with an OR of 11.02 (1.44-84.4). Intragroup analyses of patients with IIM for C4 protein levels and IIM-related autoantibodies showed that those with anti-Jo-1 or with anti-PM/Scl had significantly lower C4 plasma concentrations than those without these autoantibodies. Conclusions C4A deficiency is relevant in dermatomyositis, HLA-DRB1*03 is important in IBM and both C4A deficiency and HLA-DRB1*03 contribute interactively to risk of polymyositis.
A novel method for skeleton-based action recognition by fusing multi-level spatial features and multi-level temporal features is proposed in this article. Recently, Graph Convolutional Network (GCN) for skeleton-based action recognition has attracted the eyes of many researchers and has a great performance in the field of action recognition. But most of them focus on changing architecture of single-stream network and only use simple methods like average fusion to fuse different forms of skeleton data. In this article, we shift the focus to the problem that insufficient interactions between the different forms of features for that networks are unable to fully capture efficient information from skeleton data. To tackle this problem, we propose a multi-stream network called Symmetrical Enhanced Fusion Network (SEFN). The network is composed of a spatial stream, a temporal stream and a fusion stream. The spatial stream extracts spatial features from skeleton data by GCN. The temporal stream is able to extract temporal features from skeleton data with the help of the embedded Motion Sequence Calculation Algorithm. The fusion stream provides an early fusion method and extra fusion information for the whole network. It gathers multi-level features from two feature extractions and fuses them with the Multi-perspective Attention Fusion Module (MPAFM) we propose. The MPAFM enables different forms of data to enhance each other and can strengthen feature extractions. In the final, we generalize the skeleton data from joint data to bone data and evaluate our network in three large-scale benchmarks: NTU-RGBD, NTU-RGBD 120 and Kinetics-Skeleton. Experiment results demonstrate that our method achieves competitive performance.
Extensive efforts have been applied to develop efficient feature extraction algorithms, which aim to achieve optimal results in many fundamental tasks such as Web-based software service clustering, recommendation and composition. However, one common issue for existing methods is that mined features are problem dependent, causing poor generalization ability across different applications. Recent studies show that we can represent networked data (e.g., citation networks and social networks) as low-dimensional vectors with rich structure and content information preserved, which can then greatly facilitate many downstream tasks such as classification and clustering. In this article, we focus on the problem of Web service network embedding, which aims to learn low-dimensional vectors to represent services by encoding both Mashup-API composition structure and service functional content. We first propose a novel probabilistic topic model to predict potential links between Mashups and APIs in the service network. Then, we develop a Service Graph Convolutional Network (Service-GCN) to learn vector representations of services, where each service (e.g., Mashup or API) forms its representation through message passing between neighborhood services over the network. We evaluate the network embedding quality on two real-world datasets for downstream classification and clustering tasks. Experimental results show that the average performance of our method improves 20.7 percent (Micro-F1) in service classification and 19.0 percent (Accuracy) in Mashup clustering compared to the state-of-the-art, which verified the effectiveness of the proposed approach for learning vector representations of Web services.
Deep reinforcement learning (DRL) has been introduced to the routing and spectrum assignment (RSA) of elastic optical networks (EONs) where the RSA policies are learnt during the interaction of a DRL agent with the EON environment. Upon each new traffic arrival, the DRL agent senses the EON state, and makes the RSA decision accordingly. Therefore, the EON state feature extraction is essential for the performance. However, current approaches, mainly based on fully connected neural networks or convolutional neural networks, are unsatisfactory in EON state feature extraction due to the following two reasons. (1) The optical network topology information is not well considered. (2) The path-level features are highly related to the RSA decision, due to the spectrum continuity constraint, while path-level feature extraction has not been well exploited. To overcome the above shortcomings, in this paper, we propose to utilize the Graph Convolutional Neural Network (GCN) and the Recurrent Neural Network (RNN) for the feature extraction of the network topology, and the aggregation of link-level features to path-level features. By doing this, critical RSA-related information can be sensed by the DRL agent to make better actions. Simulation results demonstrate that our proposed method outperforms previous approaches.
With the rapid development of neural networks, much attention has been focused on network embedding for complex network data, which aims to learn low-dimensional embedding of nodes in the network and how to effectively apply learned network representations to various graph-based analytical tasks. Two typical models exist namely the shallow random walk network representation method and deep learning models such as graph convolution networks (GCNs). The former one can be used to capture the linear structure of the network using depth-first search (DFS) and width-first search (BFS), whereas Hierarchical GCN (HGCN) is an unsupervised graph embedding that can be used to describe the global nonlinear structure of the network via aggregating node information. However, the two existing kinds of models cannot simultaneously capture the nonlinear and linear structure information of nodes. Thus, the nodal characteristics of nonlinear and linear structures are explored in this paper, and an unsupervised representation method based on HGCN that joins learning of shallow and deep models is proposed. Experiments on node classification and dimension reduction visualization are carried out on citation, language, and traffic networks. The results show that, compared with the existing shallow network representation model and deep network model, the proposed model achieves better performances in terms of micro-F1, macro-F1 and accuracy scores.
Recognizing traffic command gestures with high accuracy and quick response at a low computational cost is a requisite for driver assistance or autonomous driving. However, it has been understudied for a long time. Existing research takes advantage of increasing development in human action recognition but pays little attention to onboard conditions. In this article, we propose a simple but effective recognition model based on human upper-body geometric features and a long short-term memory (LSTM) network. The handcrafted geometric features can easily be calculated with estimated 2-D human keypoints at a low computational cost but are discriminative and sufficient in classification. Offline and online inferences are implemented to comprehensively evaluate the proposed model. For the sake of robustness required in the automotive domain, dual voting is designed to filter the output in online inference. On the recently published Chinese traffic police gesture (CTPG) dataset, the presented approach is the best with a remarkable improvement of approximately 8% compared to previous LSTM-based methods with handcrafted spatial features and is competitive with advanced GCN-based deep learning methods. The tradeoff pattern is explored to demonstrate how accuracy and response time alter with different training and inference strategies so that a balanced setup can be manually chosen under various application scenarios. Field tests are also carried out with an experimental vehicle, and the results uncover the present gap between research and practical application to some extent, moving a step closer to real-life traffic command gesture recognition.
PARP (poly ADP-ribose polymerase) family is a crucial DNA repair enzyme that responds to DNA damage, regulates apoptosis, and maintains genome stability; therefore, PARP inhibitors represent a promising therapeutic strategy for the treatment of various human diseases including COVID-19. In this study, a multi-task FP-GNN (Fingerprint and Graph Neural Networks) deep learning framework was proposed to predict the inhibitory activity of molecules against four PARP isoforms (PARP-1, PARP-2, PARP-5A, and PARP-5B). Compared with baseline predictive models based on four conventional machine learning methods such as RF, SVM, XGBoost, and LR as well as six deep learning algorithms such as DNN, Attentive FP, MPNN, GAT, GCN, and D-MPNN, the evaluation results indicate that the multi-task FP-GNN method achieves the best performance with the highest average BA, F1, and AUC values of 0.753 +/- 0.033, 0.910 +/- 0.045, and 0.888 +/- 0.016 for the test set. In addition, Y-scrambling testing successfully verified that the model was not results of chance correlation. More importantly, the interpretability of the multi-task FP-GNN model enabled the identification of key structural fragments associated with the inhibition of each PARP isoform. To facilitate the use of the multi-task FP-GNN model in the field, an online webserver called PARPi-Predict and its local version software were created to predict whether compounds bear potential inhibitory activity against PARPs, thereby contributing to design and discover better selective PARP inhibitors.
View graph construction aims to effectively organise disordered image dataset through image retrieval technique before structure from motion (SfM). Existing view graph construction methods usually fail to handle scenes with duplicate structure, because these methods solely treat the construction of view graph as a process of image-pair-wise matching and lack in exploiting images' topological details in dataset. In this paper, we handle this problem from a novel perspective to construct view graph in a global paradigm by introducing an end-to-end graph convolutional network (GCN). First, a location-aware embedding module is introduced to encode images into a feature space that takes into account the feature's location by using Vision Transformer architecture, improving the distinction between features of duplicate structure. Second, graph convolutional network that consists of topological relationship preserving module and feature metric learning module is proposed. Topological relationship preserving network is proposed to help nodes maintain their connected neighbourhood features. By merging the topological connected information into images' embedding, our method can process image matching in a global mode, thus improving the disambiguation ability for images with duplicate scenes. Then a feature metric learning network is embedded into GCN to dynamically compute the linkage prediction among nodes based on their features. Finally, our method combines these three parts to jointly optimise nodes' features and linkage prediction in an end-to-end paradigm. We make qualitative and quantitative comparisons based on three public benchmark datasets and demonstrate that our proposed method performs favourably against other state-of-the-art methods.
In this study, we proposed a novel dataset and a deep learning model that can generate three-dimensional (3D) dynamic scene graphs for robotic manipulation tasks. First, we defined a new 3D scene graph to effectively represent the dynamics of a robotic manipulation task environment. Subsequently, we collected a series of input sensory data by conducting multiple manipulation tasks in a simulated environment. Based on the collected sensory data and the corresponding 3D scene graphs, we constructed a dataset, namely, D3DSG, for training and validating a scene graph generation model. In addition, we proposed a ST-GCN based context reasoning module that can utilize both rich spatial and temporal contexts, after which an effective 3D scene graph generation model, namely, SG4RMT, which consisted of a 6DoF pose estimation module and a spatio-temporal context reasoning module, was presented. The superiority and high performance of the proposed SG4RMT model were demonstrated by performing multiple experiments using the D3DSG dataset.
Recognizing surgical activities in endoscopic videos is of vital importance for developing context-aware decision support in the operating room. In this work, we model each surgical activity as an action triplet, consisting of the surgical instrument, the action, and the target organ that the instrument is interacting with. The goal is to recognize these action triplets from endoscopic videos. However, correctly recognizing fine-grained activity triplets is challenging because of the long-tail distribution of the triplet classes and the complex associations between triplets as well as within each triplet. In addition, multiple triplets may appear in a given video frame. To address these challenges, we propose a new model for surgical action triplet recognition based on a classification forest and Graph Convolutional Network (GCN), which we call Forest GCN. The classification forest is employed to calibrate fine-grained triplet classifiers by the upstream parent classifiers to suppress noisy logits of the triplet classes in the long tail. And stacked GCNs are designed to model the dependencies between triplet classes while leveraging the language embedding. Experiments on the endoscopic video dataset, CholecT50, demonstrate that our proposed method outperforms current state-of-the-art methods on surgical action triplet recognition.
BACKGROUND: John Cunningham virus (JCV) is known to cause progressive multifocal leukoencephalopathy (PML) in immuno-compromised patients due to lytic infection of oligodendrocytes and astrocytes. Rarely, it may also present as granule cell neuronopathy (GCN), leading to degeneration of cerebellar granule cell neurons. It is described in patients with underlying conditions or medication contributing to immune compromise. Case Presentation. A 73-year-old man presented with ataxia and difficulty in speech which began 3 months after initiation of treatment for idiopathic thrombocytopenic purpura with rituximab. Neurological examination was significant for torsional nystagmus, motor aphasia, right-sided dysmetria, and dysdiadochokinesia with gait ataxia. Magnetic resonance imaging (MRI) showed right cerebellar lesion and cerebrospinal fluid (CSF) polymerase chain reaction (PCR) was positive for JC virus. CONCLUSION: The diagnosis of JC virus-related cerebellar disease can be missed, due to the subacute to chronic onset and challenges in detection. Clinicians should have a high degree of suspicion for development of these symptoms, even a few months after initiation of immune-modulatory therapy because the progression and outcomes can be disastrous.
Recently, a graph neural network (GNN) was proposed to analyze various graphs/networks, which has been proven to outperform many other network analysis methods. However, it is also shown that such state-of-the-art methods suffer from adversarial attacks, i.e., carefully crafted adversarial networks with slight perturbation on clean one may invalid these methods on lots of applications, such as network embedding, node classification, link prediction, and community detection. Adversarial training has been testified as an efficient defense strategy against adversarial attacks in computer vision and graph mining. However, almost all the algorithms based on adversarial training focus on global defense through overall adversarial training. In a more practical scene, certain users would be targeted to attack, i.e., specific labeled users. It is still a challenge to defend against target node attack by existing adversarial training methods. Therefore, we propose smoothing adversarial training (SAT) to improve the robustness of GNNs. In particular, we analytically investigate the robustness of graph convolutional network (GCN), one of the classic GNNs, and propose two smooth defensive strategies: smoothing distillation and smoothing cross-entropy loss function. Both of them smooth the gradients of GCN and, consequently, reduce the amplitude of adversarial gradients, benefiting gradient masking from attackers in both global attack and target label node attack. The comprehensive experiments on five real-world networks testify that the proposed SAT method shows state-of-the-art defensibility against different adversarial attacks on node classification and community detection. Especially, the average attack success rate of different attack methods can be decreased by about 40% by SAT at the cost of tolerable embedding performance decline of the original network.
GraphSAGE is a widely-used graph neural network for classification, which generates node embeddings in two steps: sampling and aggregation. In this paper, we introduce causal inference into the GraphSAGE sampling stage, and propose Causal GraphSAGE (C-GraphSAGE) to improve the robustness of the classifier. In C-GraphSAGE, we use causal bootstrapping to obtain a weighting between the target node's neighbors and their label. Then, these weights are used to resample the node's neighbors to enforce the robustness of the sampling stage. Finally, an aggregation function is trained to integrate the features of the selected neighbors to obtain the embedding of the target node. Experimental results on the Cora, Pubmed, and Citeseer citation datasets show that the classification performance of C-GraphSAGE is equivalent to that of GraphSAGE, GCN, GAT, and RL-GraphSAGE in the case of no perturbation, and outperforms these as the perturbation ratio increases. (c) 2022 Elsevier Ltd. All rights reserved.
Multi-step prediction of long-term traffic speed is an important part of the intelligent transportation system. Traffic speed is affected by temporal features, spatial features, and various environmental features. The prediction of traffic speed considering the above features is a big challenge. This study proposed a multi-step prediction model named embedding graph convolutional long short-term memory network (EGC-LSTM) for urban road network traffic speed prediction which can deal with spatial-temporal correlation and auxiliary features at the same time. Firstly, a graph convolutional network (GCN) for capturing directed graph properties is proposed. Based on the GCN, the LSTM and sequence to sequence model are further applied to realise multi-step prediction considering the spatial-temporal correlation of the traffic network. To improve the performance of the model and obtain the importance of each step in the historical data, the attention mechanism is introduced. Then, one-hot encoding is applied to the category-type auxiliary features. Considering that the dimension becomes larger after the features are one-hot encoded, the dimensions are reduced using embedding. The experiment results prove that the proposed model's performance is better than other models, and the model is interpreted in detail.
Analyzing the runtime behaviors of Android apps is crucial for malware detection. In this paper, we attempt to learn the behavior level features of an app from function calls. The challenges of this task are twofold. First, the absence of function attributes hinders the understanding of app behaviors. Second, the graphical representation of function calls cannot be directly processed by classical machine learning algorithms. In this paper, we develop two methods to overcome these challenges. Based on function embedding, we first propose the concept of enhanced function call graphs (E-FCGs) to characterize app runtime behaviors. We then develop a Graph Convolutional Network (GCN) based algorithm to obtain vector representations of E-FCGs. Extensive experiments show that the features learned by our method can achieve surprisingly high detection performance on a variety of classifiers (e.g., LR, DT, SVM, KNN, RF, MLP and CNN), significantly outperforming the traditional static features. (C) 2020 Elsevier B.V. All rights reserved.
Relation extraction is a crucial step in the constructions of knowledge graphs (KGs). However, relation extraction is performed manually in the manufacturing field due to the sentence characteristics, which include weak correlation and high entity density. This approach has the disadvantages of low efficiency and high dependence on experts. At present, very few studies have been performed on relation extraction in the manufacturing field, so establishing a relation extraction model with high efficiency is an urgent need. Therefore, in this paper, a relation extraction model is proposed for manufacturing knowledge (MKREM), in which word embedding is obtained by the Bi-LSTM layer to improve robustness, and a Simplified Graph Convolution Network (SGC) layer is applied to quickly mine the entity information. Then, dependency and semantic features are extracted by the multi-head stacked GCN and relation attention mechanism, respectively. Finally, the dependency and semantic features are fused to generate the comprehensive features for relation extraction so that better performance on texts with weak correlation and high entity density can be obtained. The performance of MKREM is tested by experiments on the equipment maintenance dataset and the quality dataset from an automobile enterprise, and its effectiveness is verified in the automobile manufacture filed. The results show that the F1 scores obtained using MKREM are 2% higher than those of the commonly used models on both datasets, and the F1 scores when using Contextualized-MKREM are improved by 3%, so MKREM is very suitable for the automatic relation extraction during establishing manufacturing KGs. (C) 2022 Elsevier B.V. All rights reserved.
A wide range of processes have been adopted for environmental remediation; among them, photocatalysis appeared as an appealing strategy for degradation of organic pollutants. Heterogeneous photocatalysis efficiently dissociates the charge carriers and helps in reducing the rapid recombination rate of charge carriers resulting in enhanced photocatalytic degradation. A semiconductor photocatalyst graphitic carbon nitride (g-C3N4), when doped with metals or non-metals, showed increased degradation abilities. Hence, a ternary photocatalyst was synthesized by thermal condensation of urea coupled with ferric tungstate (FeWO4) and doped with a noble metal (Ag) resulting in visible light susceptive semiconductor photocatalyst Ag/FeWO4/g-C3N4. The characterization of the fabricated composite was done by Fourier transform infrared, scanning electron microscopy energy-dispersive X-ray, and X-ray diffraction. The Ag/FWO/GCN was used to degrade the rhodamine B (RhB) dye. Under sunlight, Ag/FeWO4/g-C(3)N(4)showed enhanced photocatalytic degradation of rhodamine B dye, which was ascribed to the change in bandgap and reduced charge recombination. The parameters used for the optimization of the photocatalyst were pH, catalyst dose, oxidant dose, and irradiation time. The composite (Ag/FeWO4/g-C3N4) showed similar to 98% degradation of RhB dye under optimized conditions (i.e., pH = 8, catalyst dose = 50 mg/100 ml, oxidant dose = 9 mM, irradiation time = 120 min and RhB conc. 50 ppm).
The cognitive state of the main control room (MCR) operator is the state of cognitive progress. This paper proposes a video analysis method to assist in the analysis of the operation state. A behavioral coding method is presented for the feature extraction of the MCR operator, and the time-line analysis method is used to continuously sample the operator's postures and actions. OpenPose algorithm and ST-GCN method are used for the recognition of the operator's behavior. The level of consciousness and cognition is analyzed based on the operator's body language and used to evaluate the level of mental stress in performance shaping factors (PSF). A case is presented for the feasibility analysis of the operation state evaluation method. The results of the video analysis help recognize the operator's bad or error behavior and improve the operator's operation state.
Unlike the existing Visual Question Answering(VQA) problems, the new Visual Commonsense Reasoning(VCR) problems require deep common sense reasoning for answering questions: recognizing specific relationship between two objects in the image, presenting the rationale of the answer. In this paper, we propose a novel deep neural network model, KG_VCR, for VCR problems. In addition to make use of visual relations and contextual information between objects extracted from input data (images, natural language questions, and response lists), the KG_VCR also utilizes commonsense knowledge embedding extracted from an external knowledge base called ConceptNet. Specifically the proposed model employs a Graph Convolutional Neural Network(GCN) module to obtain commonsense knowledge embedding from the retrieved ConceptNet knowledge graph. By conducting a series of experiments with the VCR benchmark dataset, we show that the proposed KG_VCR model outperforms both the state of the art(SOTA) VQA model and the R2C VCR model.
Skeleton-based action recognition methods using complete human skeletons have achieved remarkable performance, but the performance of these methods could significantly deteriorate when critical joints or frames of the skeleton sequence are occluded or disrupted. However, the acquisition of incomplete and noisy human skeletons is inevitable in realistic environments. In order to strengthen the robustness of action recognition model, we propose an Improved Spatial Temporal Graph Convolutional Network (IST-GCN) model, including three modules, namely Multi-dimension Adaptive Graph Convolutional Network (Md-AGCN), Enhanced Attention Mechanism (EAM) and Multi-Scale Temporal Convolutional Network (MS-TCN). Specifically, the Md-AGCN module can first adaptively adjust the graph structure according to different layers and the spatial dimension, temporal dimension, and channel dimension of different action samples to establish corresponding connections for long-range joints with dependencies. Then, the EAM module can focus on important information based on spatial domain, temporal domain and channel to further strengthen the dependencies between important joints. Finally, the MS-TCN module is used to enlarge the receptive field to extract more latent temporal dependencies. The comprehensive experiments on NTU-RGB+D and NTU-RGB+D 120 datasets demonstrate that our approach possesses outstanding performance in terms of both accuracy and robustness when skeleton samples are incomplete and noisy compared with the state-of-the-art (SOTA) approach. Moreover, the parameters and computational complexity of our model are far less than those of the existing approaches.
Introduction In this study we aimed to document the prevalence and age of onset of motor impairments and other key symptoms in oculopharyngeal muscular dystrophy (OPMD). Methods Retrospective chart review of patients followed at the Saguenay Neuromuscular Clinic (Quebec, Canada). Results A total of 333 participants with the (GCN)(13) mutation were included. Before the age of 75 years, 27% of them had walking limitations, 14% could not climb stairs independently, and 14% used a wheelchair for long distances or daily living. The median age of onset was 54 years for ptosis and dysphagia and 58 years for lower limb proximal weakness. Other frequent symptoms included fatigue, pharyngeal pooling of thickened secretions, and dysphonia. The median age at death was 77 years and the main cause was respiratory disease. Discussion This study provides important information to help anticipatory guidance for affected people and for the development of therapeutic trials in OPMD.
The rapid development of online social networks such as Reddit, Twitter, Facebook, and so on are widely expanded. The anomaly detection plays an important role in social networks due to different kinds of malicious activities involving misleading crowdsourcing, contact lists, and spamming results with fake accounts. In this paper, Deep Belief Neural based Interactive Autodidactic School (DBN-IAS) algorithm is proposed to detect anomalies from social networks. Particularly, the novel IAS algorithm is used for optimization of optimal hidden layers from DBN. The experimental details are obtained from both benchmark and real-time datasets. Experimentally, the DBN-IAS approach is compared with other existing methods such as GCN, RBM + SVM with SDN, and LAD. Finally, the DBN-IAS algorithm demonstrated optimal anomaly detection results from social networks and the proposed algorithm shows the detection rate of 99.32%, which is far better than the existing approaches.
This paper presents a feature reasoning-based graph convolution network (FR-GCNet) to improve the classification accuracy of airborne multispectral LiDAR (MS-LiDAR) point clouds. In the FR-GCNet, we directly assign semantic labels to all points by exploring representative features both globally and locally. Based on the graph convolution network (GCN), a global reasoning unit is embedded to obtain the global contextual feature by revealing spatial relationships of points, while a local reasoning unit is integrated to dynamically learn edge features with attention weights in each local graph. Extensive experiments on the Titan MS-LiDAR data showed that the proposed FR-GCNet achieved a promising classification performance with an overall accuracy of 93.55%, an average F1-score of 78.61%, and a mean Intersection over Union (IoU) of 66.78%. Comparative experimental results demonstrated the superiority of the FR-GCNet against other state-of-the-art approaches.
Graph neural networks (GNNs) have attracted significant attention from the chemical science community because molecules can be represented as a featured graph. In particular, graph convolutional network (GCN) and its variants have been widely used and have shown a state-of-the-art performance in analyzing molecules, such as molecular label classification, drug discovery, and molecular property prediction. However, in molecular analysis, existing GCNs have two fundamental limitations: (1) information of the molecular scale is distorted and (2) global structures in a molecule are ignored. These limitations can seriously degrade the performance in the machine learning-based molecular analysis because the scale and global structure information of a molecule occasionally have a significant effect on the molecular properties. To overcome the limitations of existing GCNs, we comprehensively analyzed the structure of GCNs and developed a costless solution for the limitations of GCNs. To demonstrate the effectiveness of our solution, extensive experiments were conducted on various benchmark datasets.
In the present work, mixed-spinel ferrite anchored onto graphitic carbon nitride (GCN) was synthesized for mineralization of antibiotic pollutant from waste water. A Z-scheme g-C3N4/Ni0.5Zn0.5Fe2O4 nano heterojunction was fabricated by three step procedure: pyrolysis, solution combustion and mechanical grinding followed by annealing. The prepared photocatlyst was tested for degradation of Doxycycline (DC) drug under the natural sun light. Results revealed that the prepared heterojunction has maximum degradation efficiency of 97.10% pollutant in 60 min experiment. The Z-scheme heterojunction between g-C3N4 and Ni-Zn ferrite improves the photoinduced charges separation and protection of redox capability and therby increases the photo degradation efficiency. The scavenging experiments suggested that O-2(-center dot) and h(+) as main active species responsible for degradation of the antibiotic. In addition, the dopant variation can drive the shists in band gap and energy band positiong too which makes then excellent candidates for synthesizing tunable heterostructures with organic semiconductors. The work focusses on designing and developing of saimpler but efficient magnetic hetero-junctions with superior redox capability for solar powered waste water treatment.
Mycolactone is the exotoxin virulence factor of Mycobacterium ulcerans that causes the neglected tropical disease Buruli ulcer. We recently showed it to be a broad spectrum inhibitor of Sec61-dependent co-translational translocation of proteins into the endoplasmic reticulum (ER). An outstanding question is the molecular pathway linking this to its known cytotoxicity. We have now used translational profiling to better understand the reprogramming that occurs in cells exposed to mycolactone. Gene ontology identified enrichment in genes involved in cellular response to stress, and apoptosis signalling among those showing enhanced translation. Validation of these results supports a mechanism by which mycolactone activates an integrated stress response meditated by phosphorylation of eIF2 alpha via multiple kinases (PERK, GCN, PKR) without activation of the ER stress sensors IRE1 or ATF6. The response therefore uncouples the integrated stress response from ER stress, and features translational and transcriptional modes of genes expression that feature the key regulatory transcription factor ATF4. Emphasising the importance of this uncoupled response in cytotoxicity, downstream activation of this pathway is abolished in cells expressing mycolactone-resistant Sec61 alpha variants. Using multiple genetic and biochemical approaches, we demonstrate that eIF2 alpha phosphorylation is responsible for mycolactone-dependent translation attenuation, which initially protects cells from cell death. However, chronic activation without stress remediation enhances autophagy and apoptosis of cells by a pathway facilitated by ATF4 and CHOP. Our findings demonstrate that priming events at the ER can result in the sensing of stress within different cellular compartments.
Previous work on clinical relation extraction from free-text sentences leveraged information about semantic types from clinical knowledge bases as a part of entity representations. In this paper, we exploit additional evidence by also making use of domain-specific semantic type dependencies. We encode the relation between a span of tokens matching a Unified Medical Language System (UMLS) concept and other tokens in the sentence. We implement our method and compare against different named entity recognition (NER) architectures (i.e., BiLSTM-CRF and BiLSTM-GCN-CRF) using different pre-trained clinical embeddings (i.e., BERT, BioBERT, UMLSBert). Our experimental results on clinical datasets show that in some cases NER effectiveness can be significantly improved by making use of domain-specific semantic type dependencies. Our work is also the first study generating a matrix encoding to make use of more than three dependencies in one pass for the NER task.
In this paper, we developed a feasible and efficient deep-learning-based framework to combine the United States (US) natality data for the last five decades, with changing variables and factors, into a consistent database. We constructed a graph based on the property and elements of databases, including variables, and conducted a graph convolutional network (GCN) to learn the embeddings of variables on the constructed graph, where the learned embeddings implied the similarity of variables. Specifically, we devised a loss function with a slack margin and a banlist mechanism (for a random walk) to learn the desired structure (two nodes sharing more information were more similar to each other.), and developed an active learning mechanism to conduct the harmonization. Toward a total of 9,321 variables from 49 databases (i.e., 783 stemmed variables, from 1970 to 2018), we applied our model iteratively together with human reviews for four rounds, then obtained 323 hyperchains of variables. During the harmonization, the first round of our model achieved recall and precision of 87.56%, 57.70%, respectively. Our harmonized graph neural network (HGNN) method provides a feasible and efficient way to connect relevant databases at a meta-level. Adapting to the database's property and characteristics, HGNN can learn patterns globally, which is powerful to discover the similarity between variables among databases. Our proposed method provides an effective way to reduce the manual effort in database harmonization and integration of fragmented data into useful databases for future research.
The continuous development of intelligent traffic control systems has a profound influence on urban traffic planning and traffic management. Indeed, as big data and artificial intelligence continue to evolve, the traffic control strategy based on deep reinforcement learning (RL) has been proven to be a promising method to improve the efficiency of intersections and save people's travel time. However, the existing algorithms ignore the temporal and spatial characteristics of intersections. In this article, we propose a multiagent RL based on the deep spatiotemporal attentive neural network (MARL-DSTAN) to determine the traffic signal timing in a large-scale road network. In this model, the state information captures the spatial dependency of the entire road network by leveraging the graph convolutional network (GCN) and integrates the information based on the importance of intersections via the attention mechanism. Meanwhile, to accumulate more valuable samples and enhance the learning efficiency, the recurrent neural network (RNN) is introduced in the exploration stage to constrain the action search space instead of fully random exploration. MARL-DSTAN decomposes the large-scale area into multiple base environments, and the agents in each base environment use the idea of ``centralized training and decentralized execution'' to learn to accelerate the algorithm convergence. The simulation results show that our algorithm significantly outperforms the fixed timing scheme and several other state-of-the-art baseline RL algorithms.
With increasingly cyber-attacks and intrusion techniques, the threat of network security has become more andmore serious. However, existing solutions are no longer sufficient in terms of accuracy as attacks continueto grow in quantity and complexity. Prior methods mainly focused on the application of deep learningtechniques to analyze data changes in traffic flow. The cunning Cyber-attacks cannot be detected becausesome advanced attack techniques can conceal attacks and make them might seem innocuous in statistics. Atthe same time, traditional models only concentrate on the statistics of traffic sent by individual hosts, so thepotential relationships of communication patterns in network traffic might be ignored. It makes these solutionsare not competent for dealing with the various uncertainty in network traffic. In this paper, we propose anefficient anomaly detection approach, called AnoGLA, which considering the complex communication patternsbetween network structure and node properties. To mine the hidden relationship between network traffic, webuilt graph structured data in network traffic and exploits graph convolution network (GCN) for modeling. Andwe also combine long short-term memory network (LSTM) with Attention mechanism to extract the changeinformation of the graph at different times. The effectiveness and robustness of proposed method are evaluatedon two real-world datasets. The experiment results indicate that our scheme can effectively detect anomalyflow and outperforms the previous ones in network anomaly detection tasks
We present a novel transient fault detection and classification approach in power transmission lines based on graph convolutional neural network. Compared with the existing techniques, the proposed approach considers explicit spatial information in sampling sequences as prior knowledge and it has stronger feature extraction ability. On this basis, a framework for transient fault detection and classification is created. Graph structure is generated to provide topology information to the task. Our approach takes the adjacency matrix of topology graph and the bus voltage signals during a sampling period after transient faults as inputs, and outputs the predicted classification results rapidly. Furthermore, the proposed approach is tested in various situations and its generalization ability is verified by experimental results. The results show that the proposed approach can detect and classify transient faults more effectively than the existing techniques, and it is practical for online transmission line protection for its rapidness, high robustness and generalization ability.
Event detection, specifically, identifying the type of events in a piece of text, is a crucial task in information extraction. Previous event detection task research proved that a syntactic graph based on a dependency tree can be integrated into a graph convolutional neural network to better capture the context of a sentence. However, most of the existing studies rely only on first-order syntactic relations and usually ignore dependence label information. In this paper, we propose a multi-order edge-aware graph convolution network (MEA-GCN) based on multi -order grammar and typed dependent label information. We use the BERT representation and the multi-head attention update mechanism to generate a variety of multi-order syntactic graph representations; consequently, our model can automatically learn dependent information and improve the representation ability of the syntactic relations. The experimental results on the widely used ACE 2005 and TAC KBP 2015 show that our model achieves significant improvement over the competitive baseline methods.
Integration of photocatalysis and membrane separation is a promising approach for foulants degradation due to its energy-saving and high efficiency. However, the widely-studied photocatalytic membranes are still hard to be industrialized because of the difficulty in set-up of light source in the membrane module under high pressure. In this work, visible-light-activated photocatalytic membrane was prepared by loading polyethyleneimine-graphitic carbon nitride (PEI-GCN) on polydopamine (PDA) coated membrane for highly efficient production of H2O2. Fenton-like reaction was triggered upon H2O2 contacting with a separation membrane with FeOOH catalytic layer, which was fabricated via a co-deposition method followed by mineralization. Oxidation of the organic compound was initiated by hydroxyl radicals generated through the Fenton-like reactions in the presence of photogenerated H2O2, thus achieving effective membrane cleaning. This sectional photocatalysis-membrane cleaning technique independent of the separation membrane module offers a possibility for sustainable membrane fouling control in large-scale application.
Multi-view clustering has become an active topic in artificial intelligence. Yet, similar investigation for graph-structured data clustering has been absent so far. To fill this gap, we present a Multi-View Graph embedding Clustering network (MVGC). Specifically, unlike traditional multi-view construction methods, which are only suitable to describe Euclidean structure data, we leverage Euler transform to augment the node attribute, as a new view descriptor, for non-Euclidean structure data. Meanwhile, we impose block diagonal representation constraint, which is measured by the l(1,2)-norm, on self-expression coefficient matrix to well explore the cluster structure. By doing so, the learned view-consensus coefficient matrix well encodes the discriminative information. Moreover, we make use of the learned clustering labels to guide the learnings of node representation and coefficient matrix, where the latter is used in turn to conduct the subsequent clustering. In this way, clustering and representation learning are seamlessly connected, with the aim to achieve better clustering performance. Extensive experimental results indicate that MVGC is superior to 11 state-of-the-art methods on four benchmark datasets. In particular, MVGC achieves an Accuracy of 96.17% (53.31%) on the ACM (IMDB) dataset, which is an up to 2.85% (1.97%) clustering performance improvement compared with the strongest baseline. (C) 2021 Elsevier Ltd. All rights reserved.
Graph Convolutional Network (GCN) has been extensively utilized to extract relations among electroencephalography (EEG) electrode channels for its strong ability to handle non-Euclidean data. However, GCN still has some issues when it comes to extracting features from EEG signals: (1) GCN with more layers may experience over-smoothing, restricting its ability to mine longer dependency relations. (2) At the moment, most GCNs used to process EEG signals construct adjacency matrices by Euclidean distance, only considering the correlations on the feature domain while ignoring changes of signals over the entire time window. To address the issues above, we introduce an Ordinary Differential Equation (ODE) based GCN, which can perfectly eliminate the over-smoothing problem of the traditional GCN. Besides, we also propose a method based on Dynamic Time Wrapping (DTW) algorithm to construct an adjacency matrix in the time domain. To handle adjacency matrices calculated by Euclidean distance and DTW distance respectively, we apply a temporal-spatial model composed of two parallel modules each containing an ODE-based GCN and Long short-term memory neural networks (LSTM) network in turn. We conducted experiments on three public datasets. The results show that our methods have achieved an improvement of 2.19%/2.77%/2.13%/2.01% on Arousal/Valence/Dominance/Liking on DEAP dataset, 1.43% on SEED dataset and 3.06%/3.27% on Arousal/Valence on DREAMER dataset compared with state-of-the-art (SOTA) baseline methods. It demonstrates that our method can effectively approve the performance to handle the relations between EEG channels. The premise of the ODE-based GCN is that signal changes of all EEG channels should be continuous rather than abrupt. We believe that it conforms to the EEG mode, as it is activated by the same emotion stimulation while being collected.
Motivation: In recent years, a large number of biological experiments have strongly shown that miRNAs play an important role in understanding disease pathogenesis. The discovery of miRNA-disease associations is beneficial for disease diagnosis and treatment. Since inferring these associations through biological experiments is time-consuming and expensive, researchers have sought to identify the associations utilizing computational approaches. Graph Convolutional Networks (GCNs), which exhibit excellent performance in link prediction problems, have been successfully used in miRNA-disease association prediction. However, GCNs only consider 1st-order neighborhood information at one layer but fail to capture information from high-order neighbors to learn miRNA and disease representations through information propagation. Therefore, how to aggregate information from high-order neighborhood effectively in an explicit way is still challenging. Results: To address such a challenge, we propose a novel method called mixed neighborhood information for miRNA-disease association (MINIMDA), which could fuse mixed high-order neighborhood information of miRNAs and diseases in multimodal networks. First, MINIMDA constructs the integrated miRNA similarity network and integrated disease similarity network respectively with their multisource information. Then, the embedding representations of miRNAs and diseases are obtained by fusing mixed high-order neighborhood information from multimodal network which are the integrated miRNA similarity network, integrated disease similarity network and the miRNA-disease association networks. Finally, we concentrate the multimodal embedding representations of miRNAs and diseases and feed them into the multilayer perceptron (MLP) to predict their underlying associations. Extensive experimental results show that MINIMDA is superior to other state-of-the-art methods overall. Moreover, the outstanding performance on case studies for esophageal cancer, colon tumor and lung cancer further demonstrates the effectiveness of MINIMDA.
Accurate residential load forecasting (RLF) is of great significance for the decision-making and operation of modern power system. In literature, deep neural network (DNN) based RLF schemes have witnessed great development due to the advantage of automatically extracting features and capturing complex non-linear pattern in the presented data. However, most existed works separately exploit the historical data of a specific residential house to forecast its load. However, the electricity consumption behaviors among residential users are not independent, and implicitly have some correlations, which can be explicitly characterized and exploited to improve the accuracy of RLF forecasting. Inspired by this idea, through exploiting the multiple correlations among households, this paper proposes a novel residential load forecasting framework based on multiple correlation-temporal graph neural networks, RLF-MGNN. Specifically, the novelty of our work includes three aspects. First, multiple graphs are explicitly constructed to represent both linear and nonlinear correlations among temporal load series of households. That is, the synchronization graph is built to describe the degree of linear correlation between two households using Pearson correlation coefficient, which characterizes the similarity of their consumption behaviors, and the causality graph is built to describe their nonlinear correlation using transfer entropy, which characterizes the amount of directional information transfer from one time series to another, and models the mutual influence between households. Second, the multiple correlation-temporal graph convolutional networks (GCNs) are designed to forecast the residential users' loads. In detail, at each timestep, latent features are first extracted by corresponding GCNs to embed multiple correlations among households, and then are sent to Long Short-Term Memory (LSTM) for further learning the latent temporal features. Finally, thorough experiments on real datasets demonstrate that our proposed RLF-MGNN outperforms the state-of-the-art independent DNN based schemes and other GNN based schemes.
Drug repositioning, an important method of drug development, is utilized to discover investigational drugs beyond the originally approved indications, expand the application scope of drugs, and reduce the cost of drug development. With the emergence of increasingly drug-diseaserelated biological networks, the challenge still remains to effectively fuse biological entity data and accurately achieve drug-disease repositioning. This paper proposes a new drug repositioning method named EMPHCN based on enhanced message passing and hypergraph convolutional networks (HGCN). It firstly constructs the homogeneous multi-view information with multiple drug similarity features and then extracts the intra-domain embedding of drugs through the combination of HGCN and channel attention mechanism. Secondly, inter-domain information of known drug-disease associations is extracted by graph convolutional networks combining node and edge embedding (NEEGCN), and a heterogeneous network composed of drugs, proteins and diseases is built as an important auxiliary to enhance the inter-domain message passing of drugs and diseases. Besides, the intra-domain embedding of diseases is also extracted through HGCN. Ultimately, intra-domain and inter-domain embeddings of drugs and diseases are integrated as the final embedding for calculating the drug-disease correlation matrix. Through 10-fold cross-validation on some benchmark datasets, we find that the AUPR of EMPHCN reaches 0.593 (T1) and 0.526 (T2), respectively, and the AUC achieves 0.887 (T1) and 0.961 (T2) respectively, which shows that EMPHCN has an advantage over other state-of-the-art prediction methods. Concerning the new disease association prediction, the AUC of EMPHCN through the five-fold cross-validation reaches 0.806 (T1) and 0.845 (T2), which are 4.3% (T1) and 4.0% (T2) higher than the second best existing methods, respectively. In the case study, EMPHCN also achieves satisfactory results in real drug repositioning for breast carcinoma and Parkinson's disease.
Lanthanum (La) has some advantages of smaller radius, cheaper price and higher affinity for oxygen in rare-earth-metallic element group, and La2O3 modification may be helpful to further extend the life of photoninduced electrons and holes due to its rich energy levels, special optical properties and 4f electronic transition properties. Inspired by these items, graphite carbon nitride (GCN)/La2O3 (denoted as CN/La) was prepared by a facile hydrothermal method. The characterizations of photocatalysts were conducted using X-ray diffraction, field emission scanning electron microscope, UV-vis diffuse reflectance spectroscopy, X-ray photoelectron spectroscopy and N-2 adsorption-desorption isotherms. The Methyl orange (MO), Methylene blue (MB) and Rhodamine B (RhB) were applied to characterize the photocatalytic performances of CN/La-x% photocatalysts under visible light irradiation (lambda > 420 nm). CN/La-6% exhibited the optimal photodegradation efficiency, and 66.6% of MO, 99.5% of RhB and 100% of MB could be removed in 120 min. The BET surface area was improved from 8.357 m(2)g(-1) to 67.818 m(2)g(-1) and the light absorption edge shifted from 468 nm to 484 nm. In addition, the photocurrent density increased from 0.96 mu A/cm(2) to 4.82 mu A/cm(2). The improved photodegradation efficiency was attributed to larger BET surface area, extended optical absorption and enhanced charge carrier separation. More interestingly, this work lays the foundation for practical application of the La2O3-modified GCN material as the photocatalytic catalysts.
Heat stress (HS) negatively affects chicken performance. Agricultural expansion will happen in regions that experience high ambient temperatures, where fast-growing commercial chickens are vulnerable. Indigenous chickens of such regions, due to generations of exposure to environmental challenges, might have higher thermal tolerance. In this study, two indigenous chicken ecotypes, from the hot and humid Mombasa (lowland) and the colder Naivasha (highland) regions, were used to investigate the effects of acute (5 h, 35 degrees C) and chronic (3days of 35 degrees C for 8 h/day) HS on the cardiac and skeletal muscle, through RNA sequencing. The rectal temperature gain and the number of differentially expressed genes (DEGs) [False Discovery Rate (FDR) < 0.05] were two times higher in the acute stage than in the chronic stage in both ecotypes, suggesting that cyclic exposure to HS can lead to adaptation. A tissue- and stage-specific difference in response to HS was observed, with peroxisome proliferator-activated-receptor (PPAR) signaling and mitogen-activate protein kinase (MAPK) signaling pathways, enriched in heart and skeletal muscle, respectively, and the p53 pathway enriched only in the acute stage in both tissues. The acute and chronic stage DEGs were integrated by a region-specific gene coexpression network (GCN), and genes with the highest number of connections (hub genes) were identified. The hub genes in the lowland network were CCNB2, Crb2, CHST9, SESN1, and NR4A3, while COMMD4, TTC32, H1F0, ACYP1, and RPS28 were the hub genes in the highland network. Pathway analysis of genes in the GCN showed that p53 and PPAR signaling pathways were enriched in both low and highland networks, while MAPK signaling and protein processing in endoplasmic reticulum were enriched only in the gene network of highland chickens. This shows that to dissipate the accumulated heat, to reduce heat induced apoptosis, and to promote DNA damage repair, the ecotypes activated or suppressed different genes, indicating the differences in thermal tolerance and HS response mechanisms between the ecotypes. This study provides information on the HS response of chickens, adapted to two different agro climatic environments, extending our understanding of the mechanisms of HS response and the effect of adaptation in counteracting HS.
Vision-based sign language translation technology (SLT) has brought the communication distance between deaf and ordinary people closer to a certain extent. The obstacle of SLT is mainly in two aspects: firstly, when capturing sign language action features, it is impossible to effectively overcome the shortcomings such as redundant information of sign language gesture features and motion ambiguity; secondly, it is difficult to define the alignment between action sequences and lexical sequences when processing sentence-level sign language videos. To overcome these problems, this paper proposes a sign language translation method based on residual spatial graph convolution network (Res-SGCN) and temporal attention model. Where, the Res-SGCN module is used to capture the spatial interaction feature information between the sign language skeleton nodes, and subsequently the temporal attention network is used to capture the temporal dimensional information fusion of the sign language spatial feature sequence and align it with the predicted vocabulary for translation. Experiments on public datasets show that the word error rate(WER) output by the proposed model reaches 4.17%, which is superior to other advanced sign language translation methods.
BACKGROUND: Depression is a common mental illness, with around 280 million people suffering from depression worldwide. At present, the main way to quantify the severity of depression is through psychometric scales, which entail subjectivity on the part of both patient and clinician. In the last few years, deep (machine) learning is emerging as a more objective approach for measuring depression severity. We now investigate how neural networks might serve for the early diagnosis of depression. SUBJECTS AND METHODS: We searched Medline (Pubmed) for articles published up to June 1, 2023. The search term included Depression AND Diagnostics AND Artificial Intelligence. We did not search for depression studies of machine learning other than neural networks, and selected only those papers attesting to diagnosis or screening for depression. RESULTS: Fifty-four papers met our criteria, among which 14 using facial expression recordings, 14 using EEG, 5 using fMRI, and 5 using audio speech recording analysis, whereas 6 used multimodality approach, two were the text analysis studies, and 8 used other methods. CONCLUSIONS: Research methodologies include both audio and video recordings of clinical interviews, task performance, including their subsequent conversion into text, and resting state studies (EEG, MRI, fMRI). Convolutional neural networks (CNN), including 3D-CNN and 2D-CNN, can obtain diagnostic data from the videos of the facial area. Deep learning in relation to EEG signals is the most commonly used CNN. fMRI approaches use graph convolutional networks and 3D-CNN with voxel connectivity, whereas the text analyses use CNNs, including LSTM (long/short-term memory). Audio recordings are analyzed by a hybrid CNN and support vector machine model. Neural networks are used to analyze biomaterials, gait, polysomnography, ECG, data from wrist wearable devices, and present illness history records. Multimodality studies analyze the fusion of audio features with visual and textual features using LSTM and CNN architectures, a temporal convolutional network, or a recurrent neural network. The accuracy of different hybrid and multimodality models is 78-99%, relative to the standard clinical diagnoses.
Synthetic aperture radar (SAR) images can capture abundant spatial and polarimetric information of land cover objects, and thus polarimetric SAR (PolSAR) image classification has been developed for various applications. Combining the advantages of spatial and polarimetric information simultaneously is of great importance for PolSAR image classification. In this article, a feature enhanced superpixel hypergraph neural network (FESHNN) is proposed for PolSAR image classification, which aims to take full advantage of spatial features and polarimetric features from PolSAR images. In the proposed model, superpixel hypergraph neural network is constructed for feature representation of superpixels, which aims to obtain spatial correlation and polarimetric correlation in a hypergraph. Then, a feature enhancement module is employed to refine the local features of pixels and the spatial features of superpixels, which aims to enhance the discrimination of feature representation. Experimental results on three PolSAR datasets demonstrate that the proposed method yields superior classification performance compared with other related approaches.
Inkjet printing (IJP) is one of the promising additive manufacturing techniques that yield many innovations in electronic and biomedical products. In IJP, the products are fabricated by depositing droplets on substrates, and the quality of the products is highly affected by the droplet pinch-off behaviors. Therefore, identifying pinch-off behaviors of droplets is critical. However, annotating the pinch-off behaviors is burdensome since a large amount of images of pinch-off behaviors can be collected. Active learning (AL) is a machine learning technique which extracts human knowledge by iteratively acquiring human annotation and updating the classification model for the pinch-off behaviors identification. Consequently, a good classification performance can be achieved with limited labels. However, during the query process, the most informative instances (i.e., images) are varying and most query strategies in AL cannot handle these dynamics since they are handcrafted. Thus, this paper proposes a multiclass reinforced active learning (MCRAL) framework in which a query strategy is trained by reinforcement learning (RL). We designed a unique intrinsic reward signal to improve the classification model performance. Moreover, how to extract the features from images for pinch-off behavior identification is not trivial. Thus, we used a graph convolutional network for droplet image feature extraction. The results show that MCRAL excels AL and can reduce human efforts in pinch-off behavior identification. We further demonstrated that, by linking the process parameters to the predicted droplet pinch-off behaviors, the droplet pinch-off behavior can be adjusted based on MCRAL.
Remote sensing image captioning, which aims to understand high-level semantic information and interactions of different ground objects, is a new emerging research topic in recent years. Though image captioning has developed rapidly with convolutional neural networks (CNNs) and recurrent neural networks (RNNs), the image captioning task for remote sensing images still suffers from two main limitations. One limitation is that the scales of objects in remote sensing images vary dramatically, which makes it difficult to obtain an effective image representation. Another limitation is that the visual relationship in remote sensing images is still underused, which should have great potential to improve the final performance. In order to deal with these two limitations, an effective framework for captioning the remote sensing image is proposed in this paper. The framework is based on multi-level attention and multi-label attribute graph convolution. Specifically, the proposed multi-level attention module can adaptively focus not only on specific spatial features, but also on features of specific scales. Moreover, the designed attribute graph convolution module can employ the attribute-graph to learn more effective attribute features for image captioning. Extensive experiments are conducted and the proposed method achieves superior performance on UCM-captions, Sydney-captions and RSICD dataset.
Polarimetric synthetic aperture radar (PolSAR) has attracted more attentions because of its excellent observation ability, and PolSAR image classification has become one of the significant tasks in remote sensing interpretation. Various types and sizes of land cover objects lead to misclassification, especially in the boundaries of different categories. To solve these issues, a multiscale superpixel-guided weighted graph convolutional network (MSGWGCN) is proposed for classifying PolSAR images. In the proposed MSGWGCN, multiscale superpixel features are imported into the weighted graph convolutional network to obtain higher level representation, which can make full use of land cover object information in PolSAR images. Moreover, to fuse pixel-level features at different scales, a multiscale feature cascade fusion module is built, which plays an important role in preserving classification details. Experiments on three PolSAR datasets indicate that the proposed MSGWGCN performs better than other advanced methods on PolSAR classification task.
Deep learning models have shown great potential in remote sensing (RS) image processing and analysis. Nevertheless, there are insufficient labeled samples to train deep networks, which seriously affects the performance of these models. To resolve this contradiction, we propose a generative self-supervised feature learning (S2FL) architecture for multimodal RS image land cover classification. Specifically, multiple complementary observed views are constructed from multimodal RS images, which are employed for following generative self-supervised learning (SSL). The proposed S2FL architecture is capable of extracting high-level meaningful feature representations from multiview data, and this process does not require any labeled information, providing a feasible solution to relieve the urgent need for annotated samples. The learned features are normalized and merged with corresponding spectral information to further improve the discriminative capability of feature representations, and we utilize these fused features for land cover classification. Compared with the existing supervised, semi-supervised, and self-supervised approaches, the proposed generative self-supervised model achieves superior performance in terms of feature learning and land cover classification, especially in the small sample classification case.
Textile defect recognition is a significant technique in the production processes of the textile industry. However, in the practical processes, it is hard to acquire large amounts of textile defect samples. Meanwhile, the textile samples with correct defect labels are rare. To address these two limitations, in this paper, we propose a novel semi-supervised graph convolutional network for few labeled textile defect recognition. First, we construct the graph convolutional network and convolution neural network to extract spectral features and spatial features. Second, the adaptive convolution structure is proposed to generate adaptive kernels according to their dynamically learned features. Finally, the spatial-spectral adaptive unified learning network (SSA-ULNet) is built for limited labeled defective samples, and graph-based semi-supervised learning is constructed. The textile defect recognition model can extract the textile image features through the image descriptors, enabling the whole network to be end-to-end trainable. To evaluate the proposed method, one public dataset and two unique self-built textile defect datasets are used to textile defect recognition. The evaluation results demonstrate that the proposed SSA-ULNet obviously outperforms existing state-of-the-art deep learning methods.
Pseudogenes are indicating more and more functional potentials recently, though historically were regarded as relics of evolution. Computational methods for predicting pseudogene functions on Gene Ontology is important for directing experimental discovery. However, no pseudogene-specific computational methods have been proposed to directly predict their Gene Ontology (GO) terms. The biggest challenge for pseudogene function prediction is the lack of enough features and functional annotations, making training a predictive model difficult. Considering the close functional similarity between pseudogenes and their parent coding genes that share great amount of DNA sequence, as well as that coding genes have rich annotations, we aim to predict pseudogene functions by borrowing information from coding genes in a graph-based way. Here we propose Pseudo2GO, a graph-based deep learning semi-supervised model for pseudogene function prediction. A sequence similarity graph is first constructed to connect pseudogenes and coding genes. Multiple features are incorporated into the model as the node attributes to enable the graph an attributed graph, including expression profiles, interactions with microRNAs, protein-protein interactions (PPIs), and genetic interactions. Graph convolutional networks are used to propagate node attributes across the graph to make classifications on pseudogenes. Comparing Pseudo2GO with other frameworks adapted from popular protein function prediction methods, we demonstrated that our method has achieved state-of-the-art performance, significantly outperforming other methods in terms of the M-AUPR metric.
Protein-protein interactions play an important role in various biological processes. Interaction among proteins has a wide range of applications. Therefore, the correct identification of protein-protein interactions sites is crucial. In this paper, we propose a novel predictor for protein-protein interactions sites, AGF-PPIS, where we utilize a multi-head self-attention mechanism (introducing a graph structure), graph convolutional network, and feed-forward neural network. We use the Euclidean distance between each protein residue to generate the corresponding protein graph as the input of AGF-PPIS. On the independent test dataset Test_60, AGF-PPIS achieves superior performance over comparative methods in terms of seven different evaluation metrics (ACC, precision, recall, F1-score, MCC, AUROC, AUPRC), which fully demonstrates the validity and superiority of the proposed AGF-PPIS model. The source codes and the steps for usage of AGF-PPIS are available at https://github. com/fxh1001/AGF-PPIS.
Understanding maritime network structure and traffic flow changes is a challenging task that must incorporate economic, energy, geopolitics, maritime transportation, and network sciences. Crude oil is the most imported energy in the world. Investigating the crude oil maritime network status and predicting the crude oil traffic flow changes has great significance for the global trade, especially for key crude oil importing/exporting regions and countries. To address this, a system-based approach using long short-term memory and graph convolution network for the crude oil traffic flow forecasting named LGCOTFF is introduced. The LGCOTFF approach constructs a maritime transportation network firstly, and then calculates and predicts the node traffic flow based on trajectory data and crude oil berth geographical position. Firstly, we construct a maritime crude oil transportation network based on supply-demand relationship, ship trajectory and route information. Then, we design an approach to calculate how many crude oil ships finished up-load/offtake tasks in a single week for each port, and gather this data to countries and regions. Finally, we design a deep learning neural network named long short-term memory and graph convolution network (L-GCN) to extract the temporal and spatial characteristics of crude oil transportation, and predict the node traffic flow. We evaluate the proposed model on China, Russia, Middle East and America respectively and observe consistent improvement of more than 10% over state-of-the-art baselines.
The pervasive impact of Alzheimer's disease on aging society represents one of the main challenges at this time. Current investigations highlight 2 specific misfolded proteins in its development: Amyloid-$\beta$ and tau. Previous studies focused on spreading for misfolded proteins exploited simulations, which required several parameters to be empirically estimated. Here, we provide an alternative view based on 2 machine learning approaches which we compare with known simulation models. The first approach applies an autoregressive model constrained by structural connectivity, while the second is based on graph convolutional networks. The aim is to predict concentrations of Amyloid-$\beta$ 2 yr after a provided baseline. We also evaluate its real-world effectiveness and suitability by providing a web service for physicians and researchers. In experiments, the autoregressive model generally outperformed state-of-the-art models resulting in lower prediction errors. While it is important to note that a comprehensive prognostic plan cannot solely rely on amyloid beta concentrations, their prediction, achieved by the discussed approaches, can be valuable for planning therapies and other cures, especially when dealing with asymptomatic patients for whom novel therapies could prove effective.
Hyperspectral images (HSIs) provide detailed spectral information of objects to be detected and play an important role in distinguishing targets with a similar appearance. However, the characteristics of high dimensionality and complexity impose significant challenges for realizing pixelwise classification. Although existing convolutional neural networks and transformer-based models have presented promising performance for HSIs classification, they mainly extract features from spectral-spatial perspective and do not fully consider the information in the frequency domain. To address this issue, in this article, we reconsider feature extraction and HSIs classification from the frequency domain. Specifically, inspired by the observation that high-frequency information contains detailed features within a local receptive field, whereas low-frequency information provides global smooth variations, a frequency domain feature extraction (FDFE) block with dual branches is developed. In the FDFE block, a multihead neighborhood attention block and a global filter block are designed to capture high- and low-frequency features, respectively. Besides, a pixel embedding module is constructed. Based on these, a novel hierarchical dual frequency transformer network is developed. Extensive experiments are performed on three open public hyperspectral datasets to evaluate the performance of our developed method. The experimental results demonstrate that our method is efficient and robust for HSIs classification, achieving overall accuracies of 94.14%, 86.92%, and 96.72% on the University of Pavia, University of Houston, and University of Trento datasets, respectively.al
As an important branch of machine learning, recommendation algorithms have attracted the attention of many experts and scholars. The current recommendation algorithms all more or less have problems such as cold start and single recommended items. In order to overcome these problems and improve the accuracy of personalized recommendation algorithms, this paper proposes a recommendation for multi-task learning based on directed graph convolutional network (referred to as MTL-DGCNR) and applies it to recommended areas for e-commerce. First, the user's micro-behavior is constructed and converted into directed graph structure data for model embedding. It can fully consider the embedding of first-order proximity nodes and second-order proximity nodes, which can effectively enhance the transformation ability of features. Secondly, this model adopts the multi-task learning method, and uses knowledge graph embedding to effectively deal with the one-to-many or many-to-many relationship between users and commodities. Finally, it is verified by experiments that MTL-DGCNR has a higher interpretability and accuracy in the field of e-commerce recommendation than other recommendation models. The ranking evaluation experiments, various training methods comparison experiments, and controlling parameter experiments are designed from multiple perspectives to verify the rationality of MTL-DGCNR.
Traffic flow forecasting, as one of the important components of intelligent transport systems (ITS), plays an indispensable role in a wide range of applications such as traffic management and city planning. However, complex spatial dependencies and dynamic changes in temporal patterns exist between different routes, and obtaining as many spatial-temporal features and dependencies as possible from node data has been a challenging task in traffic flow prediction. Current approaches typically use independent modules to treat temporal and spatial correlations separately without synchronously capturing such spatial-temporal correlations, or focus only on local spatial-temporal dependencies, thereby ignoring the implied long-term spatial-temporal periodicity. With this in mind, this paper proposes a long-term spatial-temporal graph convolutional fusion network (LSTFGCN) for traffic flow prediction modeling. First, we designed a synchronous spatial-temporal feature capture module, which can fruitfully extract the complex local spatial-temporal dependence of nodes. Second, we designed an ordinary differential equation graph convolution (ODEGCN) to capture more long-term spatial-temporal dependence using the spatial-temporal graph convolution of ordinary differential equation. At the same time, by integrating in parallel the ODEGCN, the spatial-temporal graph convolution attention module (GCAM), and the gated convolution module, we can effectively make the model learn more long short-term spatial-temporal dependencies in the processing of spatial-temporal sequences.Our experimental results on multiple public traffic datasets show that our method consistently obtained the optimal performance compared to the other baselines.
The detection of drivable areas in off-road scenes is a challenging problem due to the presence of unstructured class boundaries, irregular features, and dust noise. Three-dimensional LiDAR data can effectively describe the terrain features, and a bird's eye view (BEV) not only shows these features, but also retains the relative size of the environment compared to the forward viewing. In this paper, a method called LRTI, which is used for detecting drivable areas based on the texture information of LiDAR reflection data, is proposed. By using an instance segmentation network to learn the texture information, the drivable areas are obtained. Furthermore, a multi-frame fusion strategy is applied to improve the reliability of the output, and a shelter's mask of a dynamic object is added to the neural network to reduce the perceptual delay caused by multi-frame fusion. Through TensorRT quantization, LRTI achieves real-time processing on the unmanned ground vehicle (UGV). The experiments on our dataset show the robustness and adaptability of LRTI to sand dust and occluded scenes.
Classification of Alzheimer's Disease (AD) has been becoming a hot issue along with the rapidly increasing number of patients. This task remains tremendously challenging due to the limited data and the difficulties in detecting mild cognitive impairment (MCI). Existing methods use gait [or EEG (electroencephalogram)] data only to tackle this task. Although the gait data acquisition procedure is cheap and simple, the methods relying on gait data often fail to detect the slight difference between MCI and AD. The methods that use EEG data can detect the difference more precisely, but collecting EEG data from both HC (health controls) and patients is very time-consuming. More critically, these methods often convert EEG records into the frequency domain and thus inevitably lose the spatial and temporal information, which is essential to capture the connectivity and synchronization among different brain regions. This paper proposes a cascade neural network with two steps to achieve a faster and more accurate AD classification by exploiting gait and EEG data simultaneously. In the first step, we propose attention-based spatial temporal graph convolutional networks to extract the features from the skeleton sequences (i.e., gait) captured by Kinect (a commonly used sensor) to distinguish between HC and patients. In the second step, we propose spatial temporal convolutional networks to fully exploit the spatial and temporal information of EEG data and classify the patients into MCI or AD eventually. We collect gait and EEG data from 35 cognitively health controls, 35 MCI, and 17 AD patients to evaluate our proposed method. Experimental results show that our method significantly outperforms other AD diagnosis methods (91.07 vs. 68.18%) in the three-way AD classification task (HC, MCI, and AD). Moreover, we empirically found that the lower body and right upper limb are more important for the early diagnosis of AD than other body parts. We believe this interesting finding can be helpful for clinical researches.
Mitigating thermal errors constitutes a crucial method for enhancing the machining accuracy of four-axis machining centers. At the heart of effective thermal error control lie the thermal error control platform and a resilient thermal error prediction model. It is imperative to note that thermal errors exhibit intricate dynamic and nonlinear spatiotemporal dependencies. However, prevailing thermal error prediction models tend to primarily focus on temporal features or employ simplistic spatiotemporal characteristics, resulting in diminished accuracy and robustness. Furthermore, the present thermal error compensation system is plagued by a lack of userfriendliness, stemming from its suboptimal execution efficiency. In response to the aforementioned challenges, an innovative approach: the interactive fusion spatiotemporal graph convolutional network is proposed. This novel model is specifically designed to capture the intricate dynamic spatiotemporal dependencies inherent in thermal errors. The interactive fusion spatiotemporal graph convolutional network model consists of three essential components: a bilinear temporal convolutional network, a multi-layer spatiotemporal module, and a linear module. These components work in harmony to comprehensively extract both global and local spatiotemporal features. Subsequently, a mapping relationship between thermal errors and compensation components is established, laying the foundation for theoretical advancements in thermal error compensation within the realm of four-axis machining centers. A digital twin system framework tailored for error control is devised, which leverages cloud-edge computing to enable dynamic control and real-time monitoring of thermal errors. To assess the effectiveness of this digital twin system framework and the interactive fusion spatiotemporal graph convolutional network model, a series of rigorous experiments were conducted. The oriented to error-controlled digital twin system coupled with the interactive fusion spatiotemporal graph convolutional network model yielded exceptional machining accuracy, resulting in minimal geometric disparities of [-3.0 mu m, 3.0 mu m] for the central hole diameter D and [-3.5 mu m, 4.0 mu m] for the hole distance H.
To reduce the cargo loss rate caused by abnormal consumption behavior in smart retail cabinets, two problems need to be solved. The first is that the diversity of consumers leads to a diversity of actions contained in the same behavior, which makes the accuracy of consumer behavior identification low. Second, the difference between normal interaction behavior and abnormal interaction behavior is small, and anomalous features are difficult to define. Therefore, we propose an anomalous behavior detection algorithm with human-object interaction graph convolution and confidence-guided difference enhancement. Aiming to solve the problem of low accuracy of consumer behavior recognition, including interactive behavior, the human-object interaction graph convolutional network is used to recognize action and extract video frames of abnormal human behavior. To define anomalies, we detect anomalies by delineating anomalous areas of the anomaly video frames. We use a confidence-guided anomaly enhancement module to perform confidence detection on the encoder-extracted coded features using a confidence full connection layer. The experimental results showed that the action recognition algorithm had good generalization ability and accuracy, and the screened video frames have obvious destruction characteristics, and the area under the receiver operating characteristic (AUROC) curve reached 82.8% in the detection of abnormal areas. Our research provides a new solution for the detection of abnormal behavior that destroys commodity packaging, which has considerable application value.
The recommendation algorithm is an important means to alleviate the information explosion in the era of big data. There has been a great deal of research into the use of knowledge graphs as auxiliary information in recommender systems, which can be used to alleviate data sparsity and cold start problems. However, most knowledge graph -based recommendation methods only use rating data to capture the user's potential interest, and the rating is only a comprehensive evaluation of the item by the user, which cannot intuitively and accurately express the user's personalized preference. In addition, existing recommendation strategies that blend ratings and reviews cannot simultaneously model the aspect fine-grained sentiment preferences of users in reviews as well as the personalized characteristics of items from the user's perspective. To this end, in this paper, we propose Reviews Sentiment -Aware Knowledge Graph Convolutional Neural Network (RAKCR), a generic review and knowledge graph -based framework that provides better recommendations by fully mining the fine-grained personalization features in user reviews. In contrast to existing correlation recommendation methods, we designed a new reviews sentiment perception feature and knowledge graph alignment module to characterize user preferences for specific features of items in the knowledge graph. To better represent the personalized feature distribution of users and items, we use the proposed RAKCR to aggregate sentiment relationship weight -aware neighborhood information in the knowledge graph to capture personalized feature representations of both users and items, and to better learn user and item embeddings for more accurate personalized recommendations. Experimental results demonstrate that the proposed RAKCR model outperforms the benchmark model significantly in click -through rate prediction for recommendation scenarios. Across the three datasets, Movielens-20 m, Amazon -book, and Yelp, the AUC values show an average improvement of 6.4%, 6.0%, and 3.4%, respectively. Additionally, the F1 values exhibit an average improvement of 7.2%, 6.2%, and 4.1%, respectively, when compared to existing state-of-the-art methods.
Distinguishing similar actions has been a challenging challenge in skeleton-based action recognition. Since the joint coordinates in these actions are similar, it is difficult to accomplish the recognition task using traditional joint features. To address this issue, the use of angle features to capture subtle nuances in various body parts, along with a critical angle enhancement module that assigns weights to different angle feature representations for a given action are proposed, highlighting the critical angle feature representation. The approach is evaluated using a three-stream ensemble method on three large action recognition datasets, NTU-RGB+D, NTU-RGB+D 120, and Kinetics-400. The experimental results demonstrate that incorporating angular information can effectively complement joint and skeletal features, leading to improved recognition of similar actions and enhanced model performance and robustness. Human behaviour recognition is an important research direction in the field of computer vision, with broad application prospects in areas such as human-computer interaction, smart healthcare, video surveillance, and sports motion analysis. However, current skeleton-based behaviour recognition methods using graph convolutional networks still face some challenges, such as the difficulty of fully utilizing the dependencies among distant nodes and distinguishing similar actions. To address the limitations of existing graph convolution-based models in distinguishing similar actions, a multi-stream hierarchical perception graph convolutional network model that incorporates angle features is proposed. This model introduces four new angle feature representations to capture subtle variations in different body parts, providing discriminative features to differentiate action details. Additionally, it utilizes a key angle feature enhancement module to strengthen important angle features for specific actions. The model achieves recognition accuracies of 92.8% and 96.8% under the cross-subject and cross-view evaluation criteria of the NTU-RGB+D dataset, respectively, and attains accuracies of 89.2% and 90.8% under the cross-subject and cross-setup evaluation criteria of the NTU-RGB+D 120 dataset. The experimental results validate that angle information effectively enhances the model's accuracy and improves its ability to distinguish similar actions. image
Identification of active candidate compounds for target proteins, also called drug-protein interaction (DPI) prediction, is an essential but time-consuming and expensive step, which leads to fostering the development of drug discovery. In recent years, deep network-based learning methods were frequently proposed in DPIs due to their powerful capability of feature representation. However, the performance of existing DPI methods is still limited by insufficiently labeled pharmacological data and neglected intermolecular information. Therefore, overcoming these difficulties to perfect the performance of DPIs is an urgent challenge for researchers. In this article, we designed an innovative 'multi-modality attributes' learning-based framework for DPIs with molecular transformer and graph convolutional networks, termed, multi-modality attributes (MMA)-DPI. Specifically, intermolecular sub-structural information and chemical semantic representations were extracted through an augmented transformer module from biomedical data. A tri-layer graph convolutional neural network module was applied to associate the neighbor topology information and learn the condensed dimensional features by aggregating a heterogeneous network that contains multiple biological representations of drugs, proteins, diseases and side effects. Then, the learned representations were taken as the input of a fully connected neural network module to further integrate them in molecular and topological space. Finally, the attribute representations were fused with adaptive learning weights to calculate the interaction score for the DPIs tasks. MMA-DPI was evaluated in different experimental conditions and the results demonstrate that the proposed method achieved higher performance than existing state-of-the-art frameworks.
Learning activities interactions between small groups is a key step in understanding team sports videos. Recent research focusing on team sports videos can be strictly regarded from the perspective of the audience rather than the athlete. For team sports videos such as volleyball and basketball videos, there are plenty of intra-team and inter-team relations. In this paper, a new task named Group Scene Graph Generation is introduced to better understand intra-team relations and inter-team relations in sports videos. To tackle this problem, a novel Hierarchical Relation Network is proposed. After all players in a video are finely divided into two teams, the feature of the two teams' activities and interactions will be enhanced by Graph Convolutional Networks, which are finally recognized to generate Group Scene Graph. For evaluation, built on Volleyball dataset with additional 9660 team activity labels, a Volleyball+ dataset is proposed. A baseline is set for better comparison and our experimental results demonstrate the effectiveness of our method. Moreover, the idea of our method can be directly utilized in another video-based task, Group Activity Recognition. Experiments show the priority of our method and display the link between the two tasks. Finally, from the athlete's view, we elaborately present an interpretation that shows how to utilize Group Scene Graph to analyze teams' activities and provide professional gaming suggestions.
Artifacts are the main cause of degradation in CT image quality and diagnostic accuracy. Because of the complex texture of CT images, it is a challenging task to automatically detect artifacts from limited image samples. Recently, graph convolutional networks (GCNs) have achieved great success and shown promising results in medical imaging due to their powerful learning ability. However, GCNs do not take the attention mechanism into consideration. To overcome their limitations, we propose a novel Regional-Temporal Graph Attention Network for motion artifact detection from computed tomography images (RT-GAT). In this paper, head CT images are viewed as a heterogeneous graph by taking regional and temporal information into consideration, and the graph attention network is utilized to extract the features of the constructed graph. Then, the feature vector is input into the classifier to detect the motion artifacts. The experimental results demonstrate that our proposed RT-GAT method outperforms the state-of-the-art methods on a real-world CT dataset.
The development of technology has strongly affected regional urbanization. With development of mobile communication technology, intelligent devices have become increasingly widely used in people's lives. The application of big data in urban computing is multidimensional; it has been involved in different fields, such as urban planning, network optimization, intelligent transportation, energy consumption and so on. Data analysis becomes particularly important for wireless networks. In this paper, a method for analyzing cellular traffic data was proposed. Firstly, a method to extract trend components, periodic components and essential components from complex traffic time series was proposed. Secondly, we introduced causality data mining. Different from traditional time series causality analysis, the depth of causal mining was increased. We conducted causality verification on different components of time series and the results showed that the causal relationship between base stations is different in trend component, periodic component and essential component in urban wireless network. This is crucial for urban planning and network management. Thirdly, DIC-ST: a spatial temporal time series prediction based on decomposition and integration system with causal structure learning was proposed by combining GCN. Final results showed that the proposed method significantly improves the accuracy of cellular traffic prediction. At the same time, this method can play a crucial role for urban computing in network management, intelligent transportation, base station siting and energy consumption when combined with remote sensing map information.
The exploration of drug-target interactions (DTI) is an essential stage in the drug development pipeline. Thanks to the assistance of computational models, notably in the deep learning approach, scientists have been able to shorten the time spent on this stage. Widely practiced deep learning algorithms such as convolutional neural networks and recurrent neural networks are commonly employed in DTI prediction projects. However, they can hardly utilize the natural graph structure of molecular inputs. For that reason, a graph neural network (GNN) is an applicable choice for learning the chemical and structural characteristics of molecules when it represents molecular compounds as graphs and learns the compound features from those graphs. In an effort to construct an advanced deep learning-based model for DTI prediction, we propose Deep Neural Computation (DeepNC), which is a framework utilizing three GNN algorithms: Generalized Aggregation Networks (GENConv), Graph Convolutional Networks (GCNConv), and Hypergraph Convolution-Hypergraph Attention (HypergraphConv). In short, our framework learns the features of drugs and targets by the layers of GNN and 1-D convolution network, respectively. Then, representations of the drugs and targets are fed into fully-connected layers to predict the binding affinity values. The models of DeepNC were evaluated on two benchmarked datasets (Davis, Kiba) and one independently proposed dataset (Allergy) to confirm that they are suitable for predicting the binding affinity of drugs and targets. Moreover, compared to the results of baseline methods that worked on the same problem, DeepNC proves to improve the performance in terms of mean square error and concordance index.
Early diagnosis and intervention are clinically con-sidered the paramount part of treating cerebral palsy (CP), so it is essential to design an efficient and interpretable automatic prediction system for CP. We highlight a significant difference between CP infants' frequency of human movement and that of the healthy group, which improves prediction performance. However, the existing deep learning-based methods did not use the frequency information of infants' movement for CP prediction. This paper proposes a frequency attention informed graph convolutional network and validates it on two consumer-grade RGB video datasets, namely MINI-RGBD and RVI-38 datasets. Our proposed frequency attention module aids in improving both classification performance and system interpretability. In addition, we design a frequency-binning method that retains the critical frequency of the human joint position data while filtering the noise. Our prediction performance achieves state-of-the-art research on both datasets. Our work demonstrates the effectiveness of frequency information in supporting the prediction of CP non-intrusively and provides a way for supporting the early diagnosis of CP in the resource-limited regions where the clinical resources are not abundant.
Traffic flow prediction is of great significance for traffic control, and it has been challenging for capturing the complex spatial-temporal correlation. However, most existing prediction methods only consider the spatial adjacency of the nodes (i.e., static spatial correlation), lacking sufficient analysis of non-stationary traffic conditions (i.e., dynamic spatial correlation). The combination of static spatial correlation and dynamic spatial correlation enables the model to comprehensively analyze the feature of traffic flow at each moment and improve the mining capability. To address this problem, we use the multi-head self-attention mechanism to establish a hybrid model integrating static and dynamic spatial correlation neural network (SDSCNN) for traffic flow prediction. Specifically, we first construct static adjacency matrix and dynamic adjacency matrix according to different methods. These two matrices are simultaneously input into Graph Attention Network for analysis. The two outputs are integrated by the sum operation. Then the fused static and dynamic spatial features are fed into the multi-head self-attention layer to analyze the temporal correlation. Also, multi-layer SDSCNNs are stacked to further analyze the dynamic correlations between road sections, as well as to improve the model's multi-step prediction capability. Finally, Multi-layer Perceptron is used to output the prediction results. Extensive experiments are conducted using the datasets PEMS04, PEMS08, and METR-LA. And the results demonstrate that our model shows a good prediction performance.
Human pose transfer has typically been modeled as a 2D image-to-image translation problem. This formulation ignores the human body shape prior in 3D space and inevitably causes implausible artifacts, especially when facing occlusion. To address this issue, we propose a lifting-and-projection framework to perform pose transfer in the 3D mesh space. The core of our framework is a foreground generation module, that consists of two novel networks: a lifting-and-projection network (LPNet) and an appearance detail compensating network (ADCNet). To leverage the human body shape prior, LPNet exploits the topological information of the body mesh to learn an expressive visual representation for the target person in the 3D mesh space. To preserve texture details, ADCNet is further introduced to enhance the feature produced by LPNet with the source foreground image. Such design of the foreground generation module enables the model to better handle difficult cases such as those with occlusions. Experiments on the iPER and Fashion datasets empirically demonstrate that the proposed lifting-and-projection framework is effective and outperforms the existing image-to-image-based and mesh-based methods on human pose transfer task in both self-transfer and cross-transfer settings.
Deep subspace clustering (DSC) has achieved considerable success in the classification task of hyperspectral images (HSIs) without background (defined as noisy samples) compared with traditional subspace clustering methods. Unfortunately, directly applying DSC to classify land-cover on HSI datasets with background may suffer from the degradation of classification performance. In this article, we propose an effective deep low-rank graph convolutional subspace clustering (DLR-GCSC) framework for improving the performance of land-cover classification on HSI datasets with background. Specifically, we design a joint spatial-spectral network to extract band- and patch-level features simultaneously by combining 1-D and 2-D autoencoders. Moreover, we construct a low-rank constrained fully connected layer as a self-expression layer in the network to make the joint features more discriminative. To reduce the influence of noisy samples and obtain an informative affinity matrix, we recast the joint features into a non-Euclidean domain by introducing graph convolution. Finally, spectral clustering is applied to the informative affinity matrix to obtain the classification results. Experiments on three benchmark HSI datasets show that our proposed method achieves competitive classification performance to the state-of-the-art methods on both HSI data with background and without background.
Since the number of superpixels is lower than that of pixels, superpixels can substantially speed up subsequent processing steps and have been widely used in synthetic aperture radar (SAR) image segmentation. However, in most of the existing superpixel-wise segmentation algorithms, superpixel prediction is an isolated preprocessing step and is independent of the segmentation task. The performance of the segmentation results is determined by the accuracy of superpixels. Once superpixels are generated, their shape cannot be changed in the following segmentation stage, even if the same superpixels contain pixels of different landcovers. To address this, we propose an end-to-end trainable superpixel-wise segmentation method for single-polarization SAR images. First, we design a differentiable boundary-ware clustering method for estimating task-specific superpixels. Instead of the hard association between pixels and superpixels in the existing superpixel algorithms, this method introduces the soft association map to make the clustering differentiable. Hence, it can be implemented using a simple deep fully convolutional network. In the segmentation part, we propose a novel soft graph convolution network (Soft-GCN), which takes the association map as input and performs superpixel-wise segmentation. The advantage of our method is that superpixel generation and graph convolution parts can be trained under a unified framework, until two parts obtain the optimum parameters. In the training process, it can adaptively adjust the shape of the superpixels according to the segmentation results, ensuring the superpixels correctly adhere the boundaries. Experimental results with simulated and real SAR images demonstrate that our method outperforms other state-of-the-art segmentation algorithms, while also being faster.
The working accuracy of multi-linkage robot is seriously affected by the errors at the joints caused by the uncertainty factors such as vibration, wear, deformation, and manufacturing clearance. In order to improve the working accuracy, the joint motion prediction including these errors is researched, which can realize the follow-up errors pre-compensation. According to the spatial correlation and time dependence between the joints of the robot, the joints can be represented as a graph. This work proposes a joint trajectory prediction method based on graph convolutional neural network (GCN) and gated recurrent unit (GRU). A real experimental dataset is built to verify the effectiveness, including the uncertain errors. The method is validated by means of Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), Accuracy, and R-square. Experimental results demonstrate that the method obtains the highest performance in the joints trajectories prediction, compared with Historical Average (HA), Autoregressive Integrated Moving Average (ARIMA), and Support Vector Regression (SVR). In the case of Accuracy, the accuracy of the proposed method is 91.549%, which is 33.40%, 7.32% and 3.19% higher than that of HA, ARIMA and SVR, respectively. The method can effectively predict the joints trajectories of multi-linkage robot with uncertain error at the joint, and provide theoretical support for further error compensation, obstacle prediction, and obstacle avoidance control of robot.
Coronavirus disease (COVID-19) has caused a worldwide pandemic, putting millions of people's health and lives in jeopardy. Detecting infected patients early on chest computed tomography (CT) is critical in combating COVID-19. Harnessing uncertainty-aware consensus-assisted multiple instance learning (UC-MIL), we propose to diagnose COVID-19 using a new bilateral adaptive graph-based (BA-GCN) model that can use both 2D and 3D discriminative information in 3D CT volumes with arbitrary number of slices. Given the importance of lung segmentation for this task, we have created the largest manual annotation dataset so far with 7,768 slices from COVID-19 patients, and have used it to train a 2D segmentation model to segment the lungs from individual slices and mask the lungs as the regions of interest for the subsequent analyses. We then used the UC-MIL model to estimate the uncertainty of each prediction and the consensus between multiple predictions on each CT slice to automatically select a fixed number of CT slices with reliable predictions for the subsequent model reasoning. Finally, we adaptively constructed a BA-GCN with vertices from different granularity levels (2D and 3D) to aggregate multi-level features for the final diagnosis with the benefits of the graph convolution network's superiority to tackle cross-granularity relationships. Experimental results on three largest COVID-19 CT datasets demonstrated that our model can produce reliable and accurate COVID-19 predictions using CT volumes with any number of slices, which outperforms existing approaches in terms of learning and generalisation ability. To promote reproducible research, we have made the datasets, including the manual annotations and cleaned CT dataset, as well as the implementation code, available at https://doi.org/10.5281/zenodo.6361963.
Graph neural networks (GNNs) are the most promising deep learning models that can revolutionize non-Euclidean data analysis. However, their full potential is severely curtailed by poorly represented molecular graphs and features. Here, we propose a multiphysical graph neural network (MP-GNN) model based on the developed multiphysical molecular graph representation and featurization. All kinds of molecular interactions, between different atom types and at different scales, are systematically represented by a series of scale-specific and element-specific graphs with distance-related node features. From these graphs, graph convolution network (GCN) models are constructed with specially designed weight-sharing architectures. Base learners are constructed from GCN models from different elements at different scales, and further consolidated together using both one-scale and multi-scale ensemble learning schemes. Our MP-GNN has two distinct properties. First, our MP-GNN incorporates multiscale interactions using more than one molecular graph. Atomic interactions from various different scales are not modeled by one specific graph (as in traditional GNNs), instead they are represented by a series of graphs at different scales. Second, it is free from the complicated feature generation process as in conventional GNN methods. In our MP-GNN, various atom interactions are embedded into element-specific graph representations with only distance-related node features. A unique GNN architecture is designed to incorporate all the information into a consolidated model. Our MP-GNN has been extensively validated on the widely used benchmark test datasets from PDBbind, including PDBbind-v2007, PDBbind-v2013 and PDBbind-v2016. Our model can outperform all existing models as far as we know. Further, our MP-GNN is used in coronavirus disease 2019 drug design. Based on a dataset with 185 complexes of inhibitors for severe acute respiratory syndrome coronavirus (SARS-CoV/SARS-CoV-2), we evaluate their binding affinities using our MP-GNN. It has been found that our MP-GNN is of high accuracy. This demonstrates the great potential of our MP-GNN for the screening of potential drugs for SARS-CoV-2.
Invasion by Spartina alterniflora seriously threatens native ecosystem along Chinese coast. Determining the main influential factors and their relationships with the distribution of S. alterniflora is thus crucial for invasion control. However, the distribution is influenced by environmental variables at different scales and the relative importance of cross-scale variables is unclear. Based on the MaxEnt modelling technique, a combined regional environmental niche (CREN) model was built by integrating the global climate niche (GCN) model into the regional environment niche (REN) model to study the combined effects of global climate suitability and regional environmental variables on species distribution. The CREN model performed much better than the GCN model with AUC, TSS, specificity and sensitivity values increasing by 0.12, 0.04, 0.05 and 0.45, whereas it performed as well as the REN model, but reduced the overfitting. When considering the combined effects, the predicted suitable area decreased from 66.90% at the global scale to 18.53% at the regional scale. Global sensitivity analysis showed there were strong interactions among different variables, especially for elevation and global climate suitability, the most influential variables. Interactions reduced the importance of soil salinity, but enhanced that of soil percentage sand. The presence probability increased with increasing of global climate suitability and soil salinity, while decreased with increasing of elevation, soil organic carbon and percentage sand. The presence probability was the highest in moderately well drained and lowest in poorly drained soil. Ignoring the combined effects of cross-scale variables will prevent comprehensive elucidation of their relationship with species distribution, which should be considered to take effective measures against biological invasion.
Mycobacterium Tuberculosis (TB) is an infectious bacterial disease. In 2018, about 10 million people has been diagnosed with tuberculosis (TB) worldwide. Early diagnosis of TB is necessary for effective treatment, higher survival rate, and preventing its further transmission. The gold standard for tuberculosis diagnosis is sputum culture. Nevertheless, posterior-anterior chest radiographs (CXR) is an effective central method with low cost and a relatively low radiation dose for screening TB with immediate results. TB diagnosis from CXR is a challenging task requiring high level of expertise due to the diverse presentation of the disease. Significant intra-class variation and inter-class similarity in CXR images makes TB diagnosis from CXR a more challenging task. The main aim of this study is tuberculosis recognition from CXR images for reducing the disease burden. For this purpose, a novel multi-instance classification model is proposed in this study which is based on CNNs, complex networks and stacked ensemble (CCNSE). A main advantage of CCNSE is not requiring an accurate lung segmentation to localize the suspicious regions. Several overlapping patches are extracted from each CXR image. Features describing each patch are obtained by CNNs and then the feature vectors are clustered. Local complex networks (LCN) and global ones (GCN) of the cluster representatives are formed and feature engineering on LCN (GCN) generates other features at image-level (patch-level and image-level). Global clustering on these feature sets is performed for all patches. Each patch is assigned the purity score of its corresponding cluster. Patch-level features and purity scores are aggregated for each image. Finally, the images are classified with a proposed stacked ensemble classifier to normal and TB classes. Two datasets are used in this study including Montgomery County CXR set (MC) and Shenzhen dataset (SZ). MC/SZ includes 138/662 chest X-rays (CXR) from which 80 and 58/326 and 336 images belong to normal/TB classes, respectively. The experimental results show that the proposed method with AUC of 99.00 +/- 0.28/98.00 +/- 0.16 for MC/SZ and accuracy of 99.26 +/- 0.40/99.22 +/- 0.32 for MC/SZ with fivefold cross validation strategy is superior than the compared ones for diagnosis of TB from CXR images. The proposed method can be used as a computer-aided diagnosis system to reduce the manual time, effort and dependency to specialist's expertise level.
OBJECTIVE: To propose a coupled convolutional and graph convolutional network (CCGCN) model for diagnosis of Alzheimer's disease (AD) and its prodromal stage. METHODS: The disease-related brain regions generated by group-wise comparison were used as the input. The convolutional neural networks (CNNs) were used to extract disease-related features from different locations on brain magnetic resonance (MR) images. The generated features via the graph convolutional network (GCN) were processed, and graph pooling was performed to analyze the inherent relationship between the brain topology and the diagnosis task adaptively. Through ADNI dataset, we acquired the accuracy, sensitivity and specificity of the diagnosis tasks for AD and its prodromal stages, followed by an ablation study on the model structure. RESULTS: The CCGCN model outperformed the current state-of-the-art methods and showed a classification accuracy of 92.5% for AD with a sensitivity of 88.1% and a specificity of 96.0%. CONCLUSIONS: Based on the structural and topological features of the brain MR images, the proposed CCGCN model shows excellent performance in AD diagnosis and is expected to provide important assistance to physicians in disease diagnosis.
Research on the relationship between drugs and targets is the key to precision medicine. Ion channel is a kind of important drug targets. Aiming at the urgent needs of corona virus disease 2019 (COVID-19) treatment and drug development, this paper designed a mixed graph network model to predict the affinity between ion channel targets of COVID-19 and drugs. According to the simplified molecular input line entry specification (SMILES) code of drugs, firstly, the atomic features were extracted to construct the point sets, and edge sets were constructed according to atomic bonds. Then the undirected graph with atomic features was generated by RDKit tool and the graph attention layer was used to extract the drug feature information. Five ion channel target proteins were screened from the whole SARS-CoV-2 genome sequences of NCBI database, and the protein features were extracted by convolution neural network (CNN). Using attention mechanism and graph convolutional network (GCN), the extracted drug features and target features information were connected. After two full connection layers operation, the drug-target affinity was output, and model was obtained. Kiba dataset was used to train the model and determine the model parameters. Compared with DeepDTA,WideDTA, graph attention network (GAT),GCN and graph isomorphism network (GIN) models, it was proved that the mean square error (MSE) of the proposed model was decreased by 0.055, 0.04, 0.001, 0.046, 0.013 and the consistency index (CI) was increased by 0.028, 0.016, 0.003, 0.03 and 0.01, respectively. It can predict the drug-target affinity more accurately. According to the prediction results of drug-target affinity of SARS-CoV-2 ion channel targets, seven kinds of small molecule drugs acting on five ion channel targets were obtained, namely SCH-47112, Dehydroaltenusin, alternariol 5-o-sulfate, LPA1 antagonist 1, alternariol, butin, and AT-9283.These drugs provide a reference for drug repositioning and precise treatment of COVID-19.
Background. Multivariate time series data generally contains missing values, which can be an obstacle to subsequent analysis and may compromise downstream applications. One challenge in this endeavor is the presence of the missing values brought about by sensor failure and transmission packet loss. Imputation is the usual remedy in such circumstances. However, in some multivariate time series data, the complex correlation and temporal dependencies, coupled with the non-stationarity of the data, make imputation difficult. Methods. To address this problem, we propose a novel model for multivariate time series imputation called CGCNImp that considers both correlation and temporal dependency modeling. The correlation dependency module leverages neural Granger causality and a GCN to capture the correlation dependencies among different attributes of the time series data, while the temporal dependency module relies on an attention-driven long short term memory (LSTM) and a time lag matrix to learn its dependencies. Missing values and noise are addressed with total variation reconstruction. Results. We conduct thorough empirical analyses on two real-world datasets. Imputation results show that CGCNImp achieves state-of-the-art performance when compared to previous methods.
The blockchain whitepaper contains detailed technical and business information, so its analysis is important for blockchain text mining. Previous works focus on analyze homogeneous objects and relations. The main problem, however, is these works do not take into account the heterogeneity of information. This paper presents a new methodology for whitepapers analysis by designing heterogeneous graph neural network, named S-HGNN. In detail, this paper first builds a Heterogeneous Information Network (HIN) using heterogeneous objects and relationships extracted from the whitepaper to obtain similarity measures, then uses Graph Convolutional Network (GCN) and Graph Attention Network (GAT) to integrate both structural information and internal semantic into the whitepaper embedding. Compared with the previous models, this model improves 0.96%similar to 33.34% in terms of F1-score for classification task, and 4.94%similar to 14.14% in terms of purity for clustering task, and gets stable results on different tasks. The results show the effectiveness and robustness of this model for whitepapers analysis. (C) 2020 Elsevier Inc. All rights reserved.
Nowadays, tourists increasingly prefer to check the reviews of attractions before traveling to decide whether to visit them or not. To respond to the change in the way tourists choose attractions, it is important to classify the reviews of attractions with high precision. In addition, more and more tourists like to use emojis to express their satisfaction or dissatisfaction with the attractions. In this paper, we built a dataset for Chinese attraction evaluation incorporating emojis (CAEIE) and proposed an explicitly n-gram masking method to enhance the integration of coarse-grained information into a pre-training (ERNIE-Gram) and Text Graph Convolutional Network (textGCN) (E2G) model to classify the dataset with a high accuracy. The E2G preprocesses the text and feeds it to ERNIE-Gram and TextGCN. ERNIE-Gram was trained using its unique mask mechanism to obtain the final probabilities. TextGCN used the dataset to construct heterogeneous graphs with comment text and words, which were trained to obtain a representation of the document output category probabilities. The two probabilities were calculated to obtain the final results. To demonstrate the validity of the E2G model, this paper was compared with advanced models. After experiments, it was shown that E2G had a good classification effect on the CAEIE dataset, and the accuracy of classification was up to 97.37%. Furthermore, the accuracy of E2G was 1.37% and 1.35% ahead of ERNIE-Gram and TextGCN, respectively. In addition, two sets of comparison experiments were conducted to verify the performance of TextGCN and TextGAT on the CAEIE dataset. The final results showed that ERNIE and ERNIE-Gram combined TextGCN and TextGAT, respectively, and TextGCN performed 1.6% and 2.15% ahead. This paper compared the effects of eight activation functions on the second layer of the TextGCN and the activation-function-rectified linear unit 6 (RELU6) with the best results based on experiments.
This paper proposes a deep model-based entity alignment method for the edge-specific knowledge graphs (KGs) to resolve the semantic heterogeneity between the edge systems' data. To do so, this paper first analyzes the edge-specific knowledge graphs (KGs) to find unique characteristics. The deep model-based entity alignment method is developed based on their unique characteristics. The proposed method performs the entity alignment using a graph which is not topological but data-centric, to reflect the characteristics of the edge-specific KGs, which are mainly composed of the instance entities rather than the conceptual entities. In addition, two deep models, namely BERT (bidirectional encoder representations from transformers) for the concept entities and GAN (generative adversarial networks) for the instance entities, are applied to model learning. By utilizing the deep models, neural network models that humans cannot interpret, it is possible to secure data on the edge systems. The two learning models trained separately are integrated using a graph-based deep learning model GCN (graph convolution network). Finally, the integrated deep model is utilized to align the entities in the edge-specific KGs. To demonstrate the superiority of the proposed method, we perform the experiment and evaluation compared to the state-of-the-art entity alignment methods with the two experimental datasets from DBpedia, YAGO, and wikidata. In the evaluation metrics of Hits@k, mean rank (MR), and mean reciprocal rank (MRR), the proposed method shows the best predictive and generalization performance for the KG entity alignment.
Heart rate (HR) is a critical signal for reflecting human physical and mental conditions, and it is beneficial for diagnosing neurological and cardiovascular diseases due to its excellent accessibility. However, traditional HR measurement devices have limited usability and convenience. Recent studies have shown that the optical absorption variation of human skin due to blood volume variation in cardiac cycles can be acquired from facial videos and used to estimate HR in a noncontact manner. However, the advanced noncontact HR estimation approaches are based on a single HR information source, resulting in unsatisfactory estimation results due to noise corruption and insufficient information. To address these problems, this article proposes a multimodal information fusion framework for noncontact HR estimation. First, feature representation maps are used to effectively extract periodic signals from facial visible-light and thermal infrared videos. Then, a temporal-information-aware HR feature extraction network (THR-Net) for encoding discriminative spatiotemporal information from the representation maps is presented. Finally, based on a graph convolution network (GCN), an information fusion model is proposed for feature integration and HR estimation. Experimental and evaluation results of five different metrics on two datasets show that the proposed approach outperforms the state-of-the-art approaches. This article demonstrates the advantage of multimodal information fusion for noncontact HR estimation.
Cancer subtype classification helps us to understand the pathogenesis of cancer and develop new cancer drugs, treatment from which patients would benefit most. Most previous studies detect cancer subtypes by extracting features from individual samples, ignoring their associations with others. We believe that the interactions of cancer samples can help identify cancer subtypes. This work proposes a cancer subtype classification method based on a residual graph convolutional network and a sample similarity network. First, we constructed a sample similarity network regarding cancer gene co-expression patterns. Then, the gene expression profiles of cancer samples as initial features and the sample similarity network were passed into a two-layer graph convolutional network (GCN) model. We introduced the initial features to the GCN model to avoid over-smoothing during the training process. Finally, the classification of cancer subtypes was obtained through a softmax activation function. Our model was applied to breast invasive carcinoma (BRCA), glioblastoma multiforme (GBM) and lung cancer (LUNG) datasets. The accuracy values of our model reached 82.58%, 85.13% and 79.18% for BRCA, GBM and LUNG, respectively, which outperformed the existing methods. The survival analysis of our results proves the significant clinical features of the cancer subtypes identified by our model. Moreover, we can leverage our model to detect the essential genes enriched in gene ontology (GO) terms and the biological pathways related to a cancer subtype.
In industrial Internet of Things (IIoT), the space-time data prediction algorithm is considered as one of the key technologies for supporting real-time monitoring and intelligent control. However, the complexity of existing algorithms is too high to be deployed on edge devices with limited computational capability. To solve this problem, a novel space-time data prediction algorithm based on knowledge distillation (KD-ST) is proposed to compress teacher network to multi-student networks. Specifically, generative adversarial network (GAN) discrimination and teacher outlier elimination (TOE) are developed to minimize the discrepancy between disparate networks and avoid training errors. Furthermore, a weight transfer strategy is adopted for saving training time. Experiment results demonstrate that compared with the state-of-the-art T-GCN, the proposed Transfer-LSTM improves the real-time response speed by 17.15 times, and the proposed Transfer-1DCNN
In this study, to overcome the low charge transportation efficiency and poor visible light absorption ability, and achieve highly efficient photocatalytic applications, carbon nitride nanosheets with oxygen and carbon co-doping were successfully designed and fabricated. The resultant carbon nitride nanosheets exhibited efficient photocatalytic H-2 evolution and CO2 reduction performance, highlighting the efficacy of such a strategy. The highest H-2 evolution rate could reach 698.43 mu mol g(-1) h(-1), higher than that for graphitic carbon nitride (GCN). For CO2 reduction, the photocatalytic system shows a high CO selectivity, and MG(3.0) achieves the largest CO generation amount of 55.2 mu mol g(-1). This enhanced photocatalytic reduction performance could be attributed to oxygen and carbon co-doping, which achieves fast electron extraction and transfer, and improved visible light absorption ability. It should be noted that the excessive addition of glucose in the synthesis process could enhance conductivity and promote visible light absorption of carbon nitride, but suppress the H-2 evolution and CO2 reduction ability. Simultaneously, the photocatalytic reduction mechanism is discussed. This work confirms that a carbon nitride semiconductor with oxygen and carbon co-doping could be easily prepared by this strategy, achieving efficient photocatalytic applications.
Analyzing fish shoal behaviors is one of the concerned problems for scientists who study fish welfare and stress. However, most shoal behavior exploring methods with manual parameters are subjective and not widely available in various conditions. Therefore, this study introduced graph technology, built 29,505 shoal behavioral graphs and presented a graph neural network for analyzing four shoal behaviors (normal, resting, abnormal, and circular state) by calculating the multiple swimming indexes and swimming posture from videos. In the proposed model, motion characteristics of the shoal and swimming posture of individuals in shoal were utilized to construct a shoal graph, and then the graph convolution network (GCN) model was trained and tested. Results indicated that the model could effectively improve the identification rate of fish shoals' special behaviors, with an overall accuracy of 97.3% under the ideal condition, 92.3% for the practicable scheme that track fish by machine learning technology, compared with the artificial neural network, modified kinetic energy model and simulation feature point selection model, the accuracy of special behaviors increased by 1.6%, 57.7%, and 34.0%, respectively. Besides, the main factors that affected the accuracy of the analyzer were explored. The analyzer is sensitive to (1) the precision of tracking results, (2) edge connection in the graph and (3) features of the model's input. In addition, by interpreting the principle of the GCN model, it assigns greater weights for dispersion in normal swimming state recognition, and swimming postures are the most significant indicators to determine whether a shoal is in an abnormal state or not. In summary, the model can be used to help researchers explore the basal behavioral mechanisms in aquaculture.
Forecasting human poses given a sequence of historical pose frames has several important applications, especially in the domain of smart home safety. Recently, computer vision-based human pose forecasting has made a breakthrough using deep learning technology. However, to implement a practical system deployed on an IoT edge environment, there are still two issues to be addressed. First, existing methods on pose forecasting fail to model the coherent structural information of connected human joints and thus cannot achieve satisfactory prediction accuracy, especially for long-term predictions. Second, a general and static pre-trained prediction model may not perform well in the deployment environment due to the visual domain shift problem. In this article, we propose a hybrid cloud-edge system called GPFS to solve those issues. Specifically, we first introduce a novel graph convolutional neural network (GCN)-based sequence-to-sequence learning method, which enhances the sequence encoder by using a graph to represent both the spatial and temporal connections of the human joints in the input frames. The GCN improves the forecasting accuracy by capturing the motion pattern of each joint as well as the correlations among different human joints over time. Second, to address the domain shift issue and protect data privacy, we extend the system to perform online learning on the IoT edge to adapt the cloud trained general model with online collected on-site domain data. Extensive evaluation on Human 3.6M and Penn Action datasets demonstrates the superiority of our proposed system.
The accurate forecasting of urban taxi demands, which is a hot topic in intelligent transportation research, is challenging due to the complicated spatial-temporal dependencies, the dynamic nature, and the uncertainty of traffic. To make full use of the global and local correlations between traffic flows on road sections, this paper presents a deep learning model based on a graph convolutional network, long short-term memory (LSTM), and multitask learning. First, an undirected graph model was formed by considering the spatial pattern distribution of taxi trips on road networks. Then, LSTMs were used to extract the temporal features of traffic flows. Finally, the model was trained using a multitask learning strategy to improve the model's generalizability. In the experiments, the efficiency and accuracy were verified with real-world taxi trajectory data. The experimental results showed that the model could effectively forecast the short-term taxi demands on the traffic network level and outperform state-of-the-art traffic prediction methods.
The human finger is the essential carrier of biometric features. The finger itself contains multi-modal traits, including fingerprint and finger-vein, which provides convenience and practicality for finger bi-modal fusion recognition. The scale inconsistency and feature space mismatch of finger bi-modal images are important reasons for the fusion effect. The feature extraction method based on graph structure can well solve the problem of feature space mismatch for the finger bi-modalities, and the end-to-end fusion recognition can be realised based on graph convolutional neural networks (GCNs). However, this fusion recognition strategy based on GCNs still has two urgent problems: first, lack of stable and efficient graph fusion method; second, over-smoothing problem of GCNs will lead to the degradation of recognition performance. A novel fusion method is proposed to integrate the graph features of fingerprint (FP) and finger-vein (FV). Furthermore, we analyse the inner relationship between the information transmission process and the over-smoothing problem in GCNs from an optimisation perspective, and point out that the differentiated information between neighbouring nodes decreases as the number of layers increases, which is the direct reason for the over-smoothing problem. A modified deep graph convolution neural network is proposed, aiming to alleviate the over-smoothing problem. The intuition is that the differentiated features of the nodes should be properly preserved to ensure the uniqueness of the nodes themselves. Thus, a constraint term to the objective function of the GCN is added to emphasise the differentiation features of the nodes themselves. The experimental results show that the proposed fusion method can achieve more satisfied performance in finger bi-modal biometric recognition, and the proposed constrained GCN can well alleviate the problem of over-smoothing.
COVID-19 has caused severe threats to lives and damage to property worldwide. The immunopathology of the disease is of particular concern. Currently, researchers have used gene co-expression networks (GCNs) to deepen the study of molecular mechanisms of immune responses to COVID-19. However, most efforts have not fully explored dynamic changes of cell-type-specific molecular networks in the disease process. This study proposes a GCN construction pipeline named single-cell Disease Progression cellular module analysis (scDisProcema), which can trace dynamic changes of immune system response during disease progression using single-cell data. Here, scDisProcema considers changes in cell fate and expres-sion patterns during disease development, identifying gene modules responsible for different immune cells. The hub genes are screened for each module by the specific expression level and the intercellular connectivity of modules. Based on functional items enriched by each gene module, we elucidate the bio-logical processes of different cells involved in disease development and explain the molecular mecha-nisms underlying the process of cell depletion or proliferation caused by disease. Compared with traditional WGCNA methods, scDisProcema can make more convenient use of the heterogeneity informa-tion provided by scRNA-seq data and has great potential in exploring molecular changes during disease progression and organ development. (c) 2022 The Authors. Published by Elsevier B.V. on behalf of Research Network of Computational and Structural Biotechnology.
Predicting disease progression in the initial stage to implement early intervention and treatment can effectively prevent the further deterioration of the condition. Traditional methods for medical data analysis usually fail to perform well because of their incapability for mining the correlation pattern of pathogenies. Therefore, many calculation methods have been excavated from the field of deep learning. In this study, we propose a novel method of influence hypergraph convolutional generative adversarial network (IHGC-GAN) for disease risk prediction. First, a hypergraph is constructed with genes and brain regions as nodes. Then, an influence transmission model is built to portray the associations between nodes and the transmission rule of disease information. Third, an IHGC-GAN method is constructed based on this model. This method innovatively combines the graph convolutional network (GCN) and GAN. The GCN is used as the generator in GAN to spread and update the lesion information of nodes in the brain region-gene hypergraph. Finally, the prediction accuracy of the method is improved by the mutual competition and repeated iteration between generator and discriminator. This method can not only capture the evolutionary pattern from early mild cognitive impairment (EMCI) to late MCI (LMCI) but also extract the pathogenic factors and predict the deterioration risk from EMCI to LMCI. The results on the two datasets indicate that the IHGC-GAN method has better prediction performance than the advanced methods in a variety of indicators.
In the area of recommendation systems, one of the fundamental tasks is rating prediction. Most existing neural network methods independently extract user's and item's review features utilizing a parallel convolutional neural network(CNN) and use them as the representation of users and items to predict rating scores. There are two main drawbacks of these methods: (1) They typically only leverage user or item reviews but ignore the latent information provided by user-item interactions. (2) The historical rating scores are not integrated into the representation of users and items, they are simply used as labels to train models. Thus the rating information is not adequately utilized, leading to the prediction performance of these methods is not superior. To remedy these drawbacks mentioned above, in this paper, we build a unified graph convolutional network(GCN) to capture the interaction information between user and item, also obtain additional information provided by reviews and rating scores. As both reviews and ratings carry interactive messages among users and items, they would magnify the learning performance of user-item features. Specifically, we first construct a multi-attributed bipartite graph(MA-bipartite graph) to represent users, items, and their interactions through reviews and ratings. Then we divide the MA-bipartite graph into two sub-graphs according to the attributes of the edge types which represent the user-item interaction in review domain and item domain respectively. Next, an attributed GCN model is explicitly designed to learn latent features of users and items by incorporating review embeddings and rating score weights. Finally, the attention mechanism is carried to fuse user and item features dynamically to conduct the rating prediction. We conduct our experiments on two real-world datasets. The results demonstrate that the proposed model achieved the state-of-the-art performance, which increases the prediction accuracy by more than 3%, compared with baseline methods.
With the rise of artificial intelligence, deep learning has become the main research method of pedestrian recognition re-identification (re-id). However, most of the existing researches usually just determine the retrieval order based on the geographical location of cameras, which ignore the spatio-temporal logic characteristics of pedestrian flow. Furthermore, most of these methods rely on common object detection to detect and match pedestrians directly, which will separate the logical connection between videos from different cameras. In this research, a novel pedestrian re-identification model assisted by logical topological inference is proposed, which includes: 1) a joint optimization mechanism of pedestrian re-identification and multicamera logical topology inference, which makes the multicamera logical topology provides the retrieval order and the confidence for re-identification. And meanwhile, the results of pedestrian re-identification as a feedback modify logical topological inference; 2) a dynamic spatio-temporal information driving logical topology inference method via conditional probability graph convolution network (CPGCN) with random forest-based transition activation mechanism (RF-TAM) is proposed, which focuses on the pedestrian's walking direction at different moments; and 3) a pedestrian group cluster graph convolution network (GC-GCN) is designed to measure the correlation between embedded pedestrian features. Some experimental analyses and real scene experiments on datasets CUHK-SYSU, PRW, SLP, and UJS-reID indicate that the designed model can achieve a better logical topology inference with an accuracy of 87.3% and achieve the top-1 accuracy of 77.4% and the mAP accuracy of 74.3% for pedestrian re-identification.
Topic modeling on tweets is known to experience under-specificity and data sparsity due to its character limitation. In earlier studies, researchers attempted to address this problem by either 1) tweet aggregation, where related tweets are combined into a single document or 2) tweet expansion with related text from external sources. The first approach faces the problem of losing the topic distribution in individual tweets. While finding a relevant text from the external source for a random tweet in the second approach is challenging for various reasons like differences in writing styles, multilingual content, and informal text. In contrast to adding context from external resources or combining related tweets into a pool, this study uses the internal vocabulary (hashtags) to counter under-specificity and sparsity in tweets. Earlier studies have indicated hashtags to be an important feature for representing the underlying context present in the tweet. Sequential models like Bi-directional Long Short Term Memory (BiLSTM) and Convolution Neural Network (CNN) over distributed representation of words have shown promising results in capturing semantic relationships between words of a tweet in the past. Motivated by the above, this article proposes a unified framework of hashtag-based tweet expansion exploiting text-based and network-based representation learning methods such as BiLSTM, BERT, and Graph Convolution Network (GCN). The hashtag-based expanded tweets using the proposed framework have significantly improved topic modeling performance compared to un-expanded (raw) tweets and hashtag-pooling-based approaches over two real-world tweet datasets of different nature. Furthermore, this article also studies the significance of hashtags in topic modeling performance by experimenting with different combination of word types such as hashtags, keywords, and user mentions.
Circular RNAs (circRNAs) are covalently closed single-stranded RNA molecules, which have many biological functions. Previous experiments have shown that circRNAs are involved in numerous biological processes, especially regulatory functions. It has also been found that circRNAs are associated with complex diseases of human beings. Therefore, predicting the associations of circRNA with disease (called circRNA-disease associations) is useful for disease prevention, diagnosis and treatment. In this work, we propose a novel computational approach called GGCDA based on the Graph Attention Network (GAT) and Graph Convolutional Network (GCN) to predict circRNA-disease associations. Firstly, GGCDA combines circRNA sequence similarity, disease semantic similarity and corresponding Gaussian interaction profile kernel similarity, and then a random walk with restart algorithm (RWR) is used to obtain the preliminary features of circRNA and disease. Secondly, a heterogeneous graph is constructed from the known circRNA-disease association network and the calculated similarity of circRNAs and diseases. Thirdly, the multi-head Graph Attention Network (GAT) is adopted to obtain different weights of circRNA and disease features, and then GCN is employed to aggregate the features of adjacent nodes in the network and the features of the nodes themselves, so as to obtain multi-view circRNA and disease features. Finally, we combined a multi-layer fully connected neural network to predict the associations of circRNAs with diseases. In comparison with state-of-the-art methods, GGCDA can achieve AUC values of 0.9625 and 0.9485 under the results of fivefold cross-validation on two datasets, and AUC of 0.8227 on the independent test set. Case studies further demonstrate that our approach is promising for discovering potential circRNA-disease associations.
The weakly supervised semantic segmentation (WSSS) methods for image-level labels are among the most popular research topics. The current WSSS methods mainly generate the class activation map (CAM) regions so as to create the pseudo segmentation label seed. However, the sparsity of seed leads to less accurate local discriminative regions. Therefore, in this paper a non-bias self -attention learning segmentation network (NBSA) is proposed. First, the non-bias layer is designed to guide the network to expand the discriminative field of CAM during the training process. Second, a fine-grained learning strategy-the information enhancement module (IEM) is intro-duced to construct the graph convolutional network (GCN) for inter-semantic self-attention learning, which can further improve the generalization ability of the model. Experiments were show that on the PASCAL VOC 2012 dataset to compare the performances of our method with others, the results demonstrates that our method achieves the new state-of-the-art performance.
Increasing evidence shows that the occurrence of human complex diseases is closely related to the mutation and abnormal expression of microRNAs(miRNAs). MiRNAs have complex and fine regulatory mechanisms, which makes it a promising target for drug discovery and disease diagnosis. Therefore, predicting the potential miRNA-disease associations has practical significance. In this paper, we proposed an miRNA-disease association predicting method based on multiple kernel fusion on Graph Convolutional Network via Initial residual and Identity mapping (GCNII), called MKFGCNII. Firstly, we built a heterogeneous network of miRNAs and diseases to extract multi-layer features via GCNII. Secondly, multiple kernel fusion method was applied to weight fusion of embeddings at each layer. Finally, Dual Laplacian Regularized Least Squares was used to predict new miRNA-disease associations by the combined kernel in miRNA and disease spaces. Compared with the other methods, MKFGCNII obtained the highest AUC value of 0.9631. Code is available at .
The commonly-used large-scale knowledge bases have been facing challenges in open domain question answering tasks which are caused by the loose knowledge association and weak structural logic of triplet-based knowledge. To find a way out of this dilemma, this work proposes a novel metaknowledge enhanced approach for open domain question answering. We design an automatic approach to extract metaknowledge and build a metaknowledge network from Wiki documents. For the purpose of representing the directional weighted graph with hierarchical and semantic features, we present an original graph encoder GE4MK to model the metaknowledge network. Then, a metaknowledge enhanced graph reasoning model MEGr-Net is proposed for question answering, which aggregates both relational and neighboring interactions comparing with R-GCN and GAT. Experiments have proved the improvement of metaknowledge over main-stream triplet-based knowledge. We have found that the graph reasoning models and pre-trained language models also have influences on the metaknowledge enhanced question answering approaches.
The photoelectrochemical (PEC) performance of gCN can be enhanced by modifying its photocatalytic properties, which has been considered as a typical challenging agent for water splitting. Here, we present a study of metal-free surface charge transfer doping (SCTD) of g-CN films by means of surface alteration treatment and accordingly demonstrated its influence on the PEC performance by combining experiments and theoretical calculations. The as-prepared doped films using a boron dopant boost the photocurrent density by a factor of 3 versus RHE with no sacrificial reagents as compared to pristine g-CN films. The boron dopant can readily substitute the nitrogen atom when the film is coated five times and, consequently, reduce the band gap by raising the valence band edge. We conjecture that such improvement is due to the effective SCTD and enhanced charge carrier separation, which are beneficial for improving charge migration, charge mobility, space charge region, and recombination rate.
OBJECTIVE: Oculopharyngeal muscular dystrophy (OPMD) is a rare neuromuscular disorder characterized by late-onset development of bilateral eyelid ptosis, ophthalmoparesis and dysphagia with further progression to proximal limb muscle weakness that is an under recognized condition. The mode of inheritance is usually autosomal dominant, but a recessive form has been reported. OPMD is caused by a short expansion of the alanine repeat (GCN trinucleotide) in the poly(adenylate)-binding protein nuclear1 (PABPN1) gene. METHODS: We performed a retrospective review of undiagnosed cases that initially presented with ptosis, diplopia, dysphagia, muscle weakness, muscular dystrophy and/or myasthenia gravis from 2000 to 2015 at two institutions in Southern California. RESULTS: Twenty-five patients were identified to have OPMD with genetic confirmation. CONCLUSIONS: Even though a rare condition, the prevalence is disproportionally frequent in certain ethnic groups and in certain regions; thus, we report our experience of OPMD patients in Southern California.
In the past two years, various graph convolution neural networks (GCNs) accelerators have emerged, each with their own characteristics, but their common disadvantage is that the hardware architecture is not programmable and it is optimized for a specific network and dataset. They may not support acceleration for different GCNs and may not achieve optimal hardware resource utilization for datasets of different sizes. Therefore, given the above shortcomings, and according to the development trend of traditional neural network accelerators, this paper proposes and implements GPGCN: a general-purpose GCNs accelerator architecture based on RISC-V instruction set extension, providing the software programming freedom to support acceleration for various GCNs, and achieving the best acceleration efficiency for different GCNs with different datasets. Compared with traditional CPU, and traditional CPU with vector expansion, GPGCN achieves above 1001 x, 267 x speedup for GCN with the Cora dataset. Compared with dedicated accelerators, GPGCN has software programmability and supports the acceleration of more GCNs.
We use the first principle calculation to investigate the intrinsic magnetism of graphitic carbon nitrides (GCNs). By preserving three-fold symmetry, the GCN building blocks have been built out of different combinations between 6 components which are C atom, N atom, s-triazine, heptazine, heptazine with C atom at the center, and benzimidazole-like component. That results in 20 phases where 11 phases have been previously reported, and 9 phases are newly derived. The partial density of states and charge density have been analyzed through 20 phases to understand the origin of the presence and absence of intrinsic magnetism in GCNs. The intrinsic magnetism will be present not only because the GCNs comprising of radical components but also the pi-conjugated states are not the valence maximum to break the delocalization of unpaired electrons. The building blocks are also employed to study alloys between g-C3N4 and g-C4N3. The magnetization of the alloys has been found to be linearly dependent on a number of C atoms in the unit cell and some magnetic alloys are energetically favorable. Moreover, the intrinsic magnetism in GCNs can be promoted or demoted by passivating with a H atom depending on the passivated positions.
Pt is usually used as cocatalyst for g-C3N4 to produce H-2 by photocatalytic splitting of water. However, the photocatalytic performance is still limited by the fast recombination of photo-generated electrons and holes, as well as the poor absorption of visible light. In this work, MoO2/g-C3N4 composites were prepared, in which MoO2 synergetic with Pt photo-deposited during H-2 evolution reaction worked as unilateral dual cocatalyst to improve the photocatalytic activity. Within 4 hours of irradiation, the hydrogen production rate of MoO2-Pt dual cocatalyst modified g-C3N4 reached 3804.89 mu mol/g/h, which was 120.18 times of that of pure g-C3N4 (GCN, 31.66 mu mol/g/h), 10.98 times of that of MoO2 modified g-C3N4 (346.39 mu mol/g/h), and 9.18 times of that of Pt modified g-C3N4 (413.64 mu mol/g/h). Characterization results demonstrate that the deficient MoO2 not only promoted visible light absorption of g-C3N4, but also worked as a "electron pool" to capture and transfer electrons to Pt.
The aspect-level sentiment analysis is widely used in public opinion analysis. However, the problem of context information loss and distortion with the increase of the model depth is rarely considered in previous research. Few studies have attempted to combine the feature extracted from different embedding models. Based on the correction strategy, the ensemble correction (EC) model proposed in this study can correct context information loss and distortion. Based on the ensemble learning strategy and the weight sharing strategy, EC can extract features from different word embedding models and can reduce computational complexity. Experiments on the resturant14, laptop14, resturant16 and twitter datasets show that the accuracies of the EC model are 0.8848, 0.8213, 0.9301 and 0.7731, respectively. The accuracy of the EC model is higher than state-of-the-art models. Ablation studies and case studies are used to verify the model structure. The optimal number of graph convolutional network (GCN) layers is also verified.
The narrow band-gap and long life-time of photo-generated charges endow CdS with much higher photocatalytic hydrogen evolution (PHE) activity over other photocatalysts. Thus, CdS based materials are considered to be most promising photocatalysts for PHE activity and stability. In this work, graphitic carbon nitride (GCN) is used as sacrifice agent to synthesize is nitrogen and carbon co-doped CdS nanoparticles with of uniform small size and higher specific surface area via hydrothermal reaction. Besides, co-doping of nitrogen and especially carbon leads to electron penetration to CdS results in tuned band structure of doped CdS with down-shifted conducting band and valance band positions. Moreover, the doped heteroatoms act as charge trapping centers that enhance charge separation within CdS particles endowing their photo-generated charges with longer life-time in compared with that of bare CdS. Benefited from non-metallic heteroatoms doping, obviously increased PHE activity and stability of CdS under visible light irradiation are achieved.
Benzyl alcohol and a set ofpara-substituted derivatives (-NO2, -Cl, -CH3, -OCH3 and -OH) were converted to the corresponding aldehydes in a commercial continuous-flow microfluidic reactor. Due to the dimension and the rigidity of the commercial microfluidic reactor channels, a stable suspension with few-layer graphitic carbon nitride nanoparticles (GCN-TS) was used to avoid the blockage of the photocatalyst in the channels of the reactor. Preliminary photocatalytic batch experiments revealed that different reaction yields were obtained depending on the aromatic ring activating/deactivating nature of the substituent groups. Regarding the ex-periments under continuous-flow, the highest aldehyde production was obtained for the reactions with 4-methoxybenzyl alcohol as starting molecule, corresponding to 0.19 mM at a retention time of merely 0.75 min. The results show the possibility of employing microfluidic reactors for the selective photocatalytic conversion of aromatic alcohols for both process intensification and screening applications due to the drastic decrease of reaction time.
The performance of image captioning has been significantly improved recently through deep neural network ar-chitectures combining with attention mechanisms and reinforcement learning optimization. Exploring visual re-lationships and interactions between different objects appearing in the image, however, is far from being investigated. In this paper, we present a novel approach that combines scene graphs with Transformer, which we call SGT, to explicitly encode available visual relationships between detected objects. Specifically, we pretrain an scene graph generation model to predict graph representations for images. After that, for each graph node, a Graph Convolutional Network (GCN) is employed to acquire relationship knowledge by aggregating the informa-tion of its local neighbors. As we train the captioning model, we feed the potential relation-aware information into the Transformer to generate descriptive sentence. Experiments on the MSCOCO dataset and the Flickr30k dataset validate the superiority of our SGT model, which can realize state-of-the-art results in terms of all the standard evaluation metrics.(c) 2022 Elsevier B.V. All rights reserved.
To grasp the target object stably and orderly in the object-stacking scenes, it is important for the robot to reason the relationships between objects and obtain intelligent manipulation order for more advanced interaction between the robot and the environment. This paper proposes a novel graph-based visual manipulation relationship reasoning network (GVMRN) that directly outputs object relationships and manipulation order. The GVMRN model first extracts features and detects objects from RGB images, and then adopts graph convolutional network (GCN) to collect contextual information between objects. To improve the efficiency of relation reasoning, a relationship filtering network is built to reduce object pairs before reasoning. The experiments on the Visual Manipulation Relationship Dataset (VMRD) show that our model significantly outperforms previous methods on reasoning object relationships in object-stacking scenes. The GVMRN model is also tested on the images we collected and applied on the robot grasping platform. The results demonstrated the generalization and applicability of our method in real environment.
The task to extract relations tries to identify relationships between two named entities in a sentence. Because a sentence usually contains several named entities, capturing structural information of a sentence is important to support this task. Currently, graph neural networks are widely implemented to support relation extraction, in which dependency trees are employed to generate adjacent matrices for encoding structural information of a sentence. Because parsing a sentence is error-prone, it influences the performance of a graph neural network. On the other hand, a sentence is structuralized by several named entities, which precisely segment a sentence into several parts. Different features can be combined by prior knowledge and experience, which are effective to initialize a symmetric adjacent matrix for a graph neural network. Based on this phenomenon, we proposed a feature combination-based graph convolutional neural network model (FC-GCN). It has the advantages of encoding structural information of a sentence, considering prior knowledge, and avoiding errors caused by parsing. In the experiments, the results show significant improvement, which outperform existing state-of-the-art performances.
Breast cancer is one of the diseases with the highest incidence and mortality among women in the world, which has posed a serious threat to women's health. The appearance of clustered calcifications is one of the important signs of breast cancer, and thus how to classify clustered calcifications comes to be a key breakthrough in controlling breast cancer. In this study, the discriminant model based on image convolution is used to learn the image features related to the classification of clustered microcalcifications, and the graph convolutional network (GCN) based on topological graph is used to learn the spatial distribution characteristics of clustered microcalcifications. These two models are fused to obtain a complementary model of image information and spatial information. The results show that the performance of the fusion model proposed in this paper is obviously superior to that of the two classification models in the classification of clustered microcalcification.
Effectively detecting anomalous nodes in attributed networks is crucial for the success of many real-world applications such as fraud and intrusion detection. Existing approaches have difficulties with three major issues: sparsity and nonlinearity capturing, residual modeling, and network smoothing. We propose Residual Graph Convolutional Network (ResGCN), an attention-based deep residual modeling approach that can tackle these issues: modeling the attributed networks with GCN allows to capture the sparsity and nonlinearity, utilizing a deep neural network allows direct residual ing from the input, and a residual-based attention mechanism reduces the adverse effect from anomalous nodes and prevents over-smoothing. Extensive experiments on several real-world attributed networks demonstrate the effectiveness of ResGCN in detecting anomalies.
BackgroundAutism spectrum disorder (ASD) is a serious developmental disorder of the brain. Recently, various deep learning methods based on functional magnetic resonance imaging (fMRI) data have been developed for the classification of ASD. Among them, graph neural networks, which generalize deep neural network models to graph structured data, have shown great advantages. However, in graph neural methods, because the graphs constructed are homogeneous, the phenotype information of the subjects cannot be fully utilized. This affects the improvement of the classification performance.MethodsTo fully utilize the phenotype information, this paper proposes a heterogeneous graph convolutional attention network (HCAN) model to classify ASD. By combining an attention mechanism and a heterogeneous graph convolutional network, important aggregated features can be extracted in the HCAN. The model consists of a multilayer HCAN feature extractor and a multilayer perceptron (MLP) classifier. First, a heterogeneous population graph was constructed based on the fMRI and phenotypic data. Then, a multilayer HCAN is used to mine graph-based features from the heterogeneous graph. Finally, the extracted features are fed into an MLP for the final classification.ResultsThe proposed method is assessed on the autism brain imaging data exchange (ABIDE) repository. In total, 871 subjects in the ABIDE I dataset are used for the classification task. The best classification accuracy of 82.9% is achieved. Compared to the other methods using exactly the same subjects in the literature, the proposed method achieves superior performance to the best reported result.ConclusionsThe proposed method can effectively integrate heterogeneous graph convolutional networks with a semantic attention mechanism so that the phenotype features of the subjects can be fully utilized. Moreover, it shows great potential in the diagnosis of brain functional disorders with fMRI data.
Featured Application The proposed methodology is a computer vision application for monitoring and recognizing human-object interactions and has been evaluated over three challenging benchmark datasets. Therefore, this technique can be used to develop advanced surveillance and security systems to locate human and object targets and classify their interactions. The critical task of recognizing human-object interactions (HOI) finds its application in the domains of surveillance, security, healthcare, assisted living, rehabilitation, sports, and online learning. This has led to the development of various HOI recognition systems in the recent past. Thus, the purpose of this study is to develop a novel graph-based solution for this purpose. In particular, the proposed system takes sequential data as input and recognizes the HOI interaction being performed in it. That is, first of all, the system pre-processes the input data by adjusting the contrast and smoothing the incoming image frames. Then, it locates the human and object through image segmentation. Based on this, 12 key body parts are identified from the extracted human silhouette through a graph-based image skeletonization technique called image foresting transform (IFT). Then, three types of features are extracted: full-body feature, point-based features, and scene features. The next step involves optimizing the different features using isometric mapping (ISOMAP). Lastly, the optimized feature vector is fed to a graph convolution network (GCN) which performs the HOI classification. The performance of the proposed system was validated using three benchmark datasets, namely, Olympic Sports, MSR Daily Activity 3D, and D3D-HOI. The results showed that this model outperforms the existing state-of-the-art models by achieving a mean accuracy of 94.1% with the Olympic Sports, 93.2% with the MSR Daily Activity 3D, and 89.6% with the D3D-HOI datasets.
Graph convolution networks (GCNs) have been widely used in the field of skeleton-based human action recognition. However, it is still difficult to improve recognition performance and reduce parameter complexity. In this paper, a novel multi-scale attention spatiotemporal GCN (MSA-STGCN) is proposed for human violence action recognition by learning spatiotemporal features from four different skeleton modality variants. Firstly, the original joint data are preprocessed to obtain joint position, bone vector, joint motion and bone motion datas as inputs of recognition framework. Then, a spatial multi-scale graph convolution network based on the attention mechanism is constructed to obtain the spatial features from joint nodes, while a temporal graph convolution network in the form of hybrid dilation convolution is designed to enlarge the receptive field of the feature map and capture multi-scale context information. Finally, the specific relationship in the different skeleton data is explored by fusing the information of multi-stream related to human joints and bones. To evaluate the performance of the proposed MSA-STGCN, a skeleton violence action dataset: Filtered NTU RGB+D was constructed based on NTU RGB+D120. We conducted experiments on constructed Filtered NTU RGB+D and Kinetics Skeleton 400 datasets to verify the performance of the proposed recognition framework. The proposed method achieves an accuracy of 95.3% on the Filtered NTU RGB+D with the parameters 1.21M, and an accuracy of 36.2% (Top-1) and 58.5% (Top-5) on the Kinetics Skeleton 400, respectively. The experimental results on these two skeleton datasets show that the proposed recognition framework can effectively recognize violence actions without adding parameters.
The perturbations of protein-protein interactions (PPIs) were found to be the main cause of cancer. Previous PPI prediction methods which were trained with non-disease general PPI data were not compatible to map the PPI network in cancer. Therefore, we established a novel cancer specific PPI prediction method dubbed NECARE, which was based on relational graph convolutional network (R-GCN) with knowledge-based features. It achieved the best performance with a Matthews correlation coefficient (MCC) = 0.84 & PLUSMN;0.03 and an F1 = 91 & PLUSMN;2% compared with other methods. With NECARE, we mapped the cancer interactome atlas and revealed that the perturbations of PPIs were enriched on 1362 genes, which were named cancer hub genes. Those genes were found to over-represent with mutations occurring at protein-macromolecules binding interfaces. Furthermore, over 56% of cancer treatment-related genes belonged to hub genes and they were significantly related to the prognosis of 32 types of cancers. Finally, by coimmunoprecipitation, we confirmed that the NECARE prediction method was highly reliable with a 90% accuracy. Overall, we provided the novel network-based cancer protein-protein interaction prediction method and mapped the perturbation of cancer interactome. NECARE is available at: https://github.com/JiajunQiu/NECARE.</p> <br></p>
Positron emission tomography/computed tomography (PET/CT) is increasingly used in oncology, neurology, cardiology, and emerging medical fields. The success stems from the cohesive information that hybrid PET/CT imaging offers, surpassing the capabilities of individual modalities when used in isolation for different malig-nancies. However, manual image interpretation requires extensive disease-specific knowledge, and it is a time-consuming aspect of physicians' daily routines. Deep learning algorithms, akin to a practitioner during training, extract knowledge from images to facilitate the diagnosis process by detecting symptoms and enhancing images. This acquired knowledge aids in supporting the diagnosis process through symptom detection and image enhancement. The available review papers on PET/CT imaging have a drawback as they either included addi-tional modalities or examined various types of AI applications. However, there has been a lack of comprehensive investigation specifically focused on the highly specific use of AI, and deep learning, on PET/CT images. This review aims to fill that gap by investigating the characteristics of approaches used in papers that employed deep learning for PET/CT imaging. Within the review, we identified 99 studies published between 2017 and 2022 that applied deep learning to PET/CT images. We also identified the best pre-processing algorithms and the most effective deep learning models reported for PET/CT while highlighting the current limitations. Our review underscores the potential of deep learning (DL) in PET/CT imaging, with successful applications in lesion detection, tumor segmentation, and disease classification in both sinogram and image spaces. Common and specific pre-processing techniques are also discussed. DL algorithms excel at extracting meaningful features, and enhancing accuracy and efficiency in diagnosis. However, limitations arise from the scarcity of annotated datasets and challenges in explainability and uncertainty. Recent DL models, such as attention-based models, generative models, multi-modal models, graph convolutional networks, and transformers, are promising for improving PET/CT studies. Additionally, radiomics has garnered attention for tumor classification and predicting patient outcomes. Ongoing research is crucial to explore new applications and improve the accuracy of DL models in this rapidly evolving field.
Using unreliable information sources generating conflicting evidence may lead to a large uncertainty, which significantly hurts the decision making process. Recently, many approaches have been taken to integrate conflicting data from multiple sources and/or fusing conflicting opinions from different entities. To explicitly deal with uncertainty, a belief model called Subjective Logic (SL), as a variant of Dumpster-Shafer Theory, has been proposed to represent subjective opinions and to merge multiple opinions by offering a rich volume of fusing operators, which have been used to solve many opinion inference problems in trust networks. However, the operators of SL are known to be lack of scalability in inferring unknown opinions from large network data as a result of the sequential procedures of merging multiple opinions. In addition, SL does not consider deriving opinions in the presence of conflicting evidence. In this work, we propose a hybrid inference method that combines SL and Probabilistic Soft Logic (PSL), namely, Collective Subjective Plus, CSL+, which is resistible to highly conflicting evidence or a lack of evidence. PSL can reason a belief in a collective manner to deal with large-scale network data, allowing high scalability based on relationships between opinions. However, PSL does not consider an uncertainty dimension in a subjective opinion. To take benefits from both SL and PSL, we proposed a hybrid approach called CSL+ for achieving high scalability and high prediction accuracy for unknown opinions with uncertainty derived from a lack of evidence and/or conflicting evidence. Through the extensive experiments on four semi-synthetic and two real-world datasets, we showed that the CSL+ outperforms the state-of-the-art belief model (i.e., SL), probabilistic inference models (i.e., PSL, CSL), and deep learning model (i.e., GCN-VAE-opinion) in terms of prediction accuracy, computational complexity, and real running time.
With the rapid economic growth and the continuous increase in population, cars have become a necessity for most people to travel. The increase in the number of cars is accompanied by serious traffic congestion. In order to alleviate traffic congestion, many places have introduced policies such as vehicle restriction, and intelligent transportation systems have gradually been put into use. Due to the chaotic complexity of the traffic road network and the short-term mobility of the population, traffic flow prediction is affected by many complex factors, and an effective traffic flow forecasting system is very challenging. This paper proposes a model to predict the traffic flow of Wenyi Road in Hangzhou. Wenyi Road consists of four crossroads. The four intersections have the same changing trend in traffic flow at the same time, which indicates that the roads influence each other spatially, and the traffic flow has spatial and temporal correlation. Based on this feature of traffic flow, we propose the IMgru model to better extract the traffic flow temporal characteristics. In addition, the IMgruGcn model is proposed, which combines the graph convolutional network (GCN) module and the IMgru module, to extract the spatiotemporal features of traffic flow simultaneously. Finally, according to the morning and evening peak characteristics of Hangzhou, the Wenyi Road dataset is divided into peak period and off-peak period for prediction. Comparing the IMgruGcn model with five baseline models and a state-of-the-art method, the IMgruGcn model achieves better results. Best results were also achieved on a public dataset, demonstrating the generalization ability of the IMgruGcn model.
Knowledge-based dialog systems have attracted increasing research interest in diverse applications. However, for disease diagnosis, the widely used knowledge graph (KG) is hard to represent the symptom-symptom and symptom-disease relations since the edges of traditional KG are unweighted. Most research on disease diagnosis dialog systems highly relies on data-driven methods and statistical features, lacking profound comprehension of symptom-symptom and symptom-disease relations. To tackle this issue, this work presents a weighted heterogeneous graph-based dialog system for disease diagnosis. Specifically, we build a weighted heterogeneous graph based on symptom co-occurrence and the proposed symptom frequency-inverse disease frequency. Then, this work proposes a graph-based deep Q-network (graph-DQN) for dialog management. By combining graph convolutional network (GCN) with DQN to learn the embeddings of diseases and symptoms from both the structural and attribute information in the weighted heterogeneous graph, graph-DQN could capture the symptom-disease relations and symptom-symptom relations better. Experimental results show that the proposed dialog system rivals the state-of-the-art models. More importantly, the proposed dialog system can complete the task with fewer dialog turns and possess a better distinguishing capability on diseases with similar symptoms.
B atoms and cyano groups co-doped graphite carbon nitride with nitrogen vacancies (VN-BC-CN) was explored via one-step in-situ route. A series of comprehensive experiments confirmed that B atoms and cyano groups had been doped into the framework of graphite carbon nitride, forming VN-BC-CN catalyst sample with a large number of nitrogen-vacancy defects. As electron acceptors, B and cyano groups could be used as active sites for nitrogen conversion. The defect level caused by nitrogen vacancy led to red shift of the light absorption edge, which resulted in higher separation efficiency of photo-induced carriers and faster transfer rate of photo-induced electrons for the VN-BC-CN catalyst. This VN-BC-CN catalyst had good photocatalytic nitrogen fixation performance in the ultrapure water without any hole scavengers. The nitrogen photofixation rate of VN-BC-CN (115.53 mu mol g(-1) h(-1)) was 25.5 times that of pure carbon nitride (GCN, 4.53 mu mol g(-1) h(-1)). Moreover, NH4+ generation rate hardly decreased after 10 h reaction, and the NH4+ generation rate could reach 79.56 mu mol g(-1) h(-1) in the fifth cycle, showing the good photocatalytic stability of the VN-BC-CN catalyst. (C) 2021 Published by Elsevier Inc.
Root nodulation results from a symbiotic relationship between a plant host and Rhizobium bacteria. Synchronized gene expression patterns over the course of rhizobial infection result in activation of pathways that are unique but overlapping with the highly conserved pathways that enable mycorrhizal symbiosis. We performed RNA sequencing of 30 Medicago truncatula root maturation zone samples at five distinct time points. These samples included plants inoculated with Sinorhizobium medicae and control plants that did not receive any Rhizobium. Following gene expression quantification, we identified 1,758 differentially expressed genes at various time points. We constructed a gene co-expression network (GCN) from the same data and identified link community modules (LCMs) that were comprised entirely of differentially expressed genes at specific time points post-inoculation. One LCM included genes that were up-regulated at 24 h following inoculation, suggesting an activation of allergen family genes and carbohydrate-binding gene products in response to Rhizobium. We also identified two LCMs that were comprised entirely of genes that were down regulated at 24 and 48 h post-inoculation. The identity of the genes in these modules suggest that down-regulating specific genes at 24 h may result in decreased jasmonic acid production with an increase in cytokinin production. At 48 h, coordinated down-regulation of a specific set of genes involved in lipid biosynthesis may play a role in nodulation. We show that GCN-LCM analysis is an effective method to preliminarily identify polygenic candidate biomarkers of root nodulation and develop hypotheses for future discovery.
Identifying synergistic drug combinations (SDCs) is a great challenge due to the combinatorial complexity and the fact that SDC is cell line specific. The existing computational methods either did not consider the cell line specificity of SDC, or did not perform well by building model for each cell line independently. In this paper, we present a novel encoder-decoder network named SDCNet for predicting cell line-specific SDCs. SDCNet learns common patterns across different cell lines as well as cell line-specific features in one model for drug combinations. This is realized by considering the SDC graphs of different cell lines as a relational graph, and constructing a relational graph convolutional network (R-GCN) as the encoder to learn and fuse the deep representations of drugs for different cell lines. An attention mechanism is devised to integrate the drug features from different layers of the R-GCN according to their relative importance so that representation learning is further enhanced. The common patterns are exploited through partial parameter sharing in cell line-specific decoders, which not only reconstruct the known SDCs but also predict new ones for each cell line. Experiments on various datasets demonstrate that SDCNet is superior to state-of-the-art methods and is also robust when generalized to new cell lines that are different from the training ones. Finally, the case study again confirms the effectiveness of our method in predicting novel reliable cell line-specific SDCs.
Protein kinase-inhibitor interactions are key to the phosphorylation of proteins involved in cell proliferation, differentiation, and apoptosis, which shows the importance of binding mechanism research and kinase inhibitor design. In this study, a novel machine learning module (i.e., the WL Box) was designed and assembled to the Prediction of Interaction Sites of Protein Kinase Inhibitors (PISPKI) model, which is a graph convolutional neural network (GCN) to predict the interaction sites of protein kinase inhibitors. The WL Box is a novel module based on the well-known Weisfeiler-Lehman algorithm, which assembles multiple switch weights to effectively compute graph features. The PISPKI model was evaluated by testing with shuffled datasets and ablation analysis using 11 kinase classes. The accuracy of the PISPKI model with the shuffled datasets varied from 83 to 86%, demonstrating superior performance compared to two baseline models. The effectiveness of the model was confirmed by testing with shuffled datasets. Furthermore, the performance of each component of the model was analyzed via the ablation study, which demonstrated that the WL Box module was critical. The code is available at https://github.com/feiqiwang/PISPKI.
Runoff modelling is a crucial element in hydrologic sciences. However, a global runoff database is not currently available at a resolution higher than 0.1 degrees. We use the recently developed Global Curve Number dataset (GCN250) to develop a dynamic runoff application (2015 - present) and that can be accessed via a Google Earth Engine application. We also provide a global mean monthly runoff dataset for April 2015-2021 in GeoTIFF format at a 250-meter resolution. We utilize soil moisture and GPM rainfall to dynamically retrieve the appropriate curve number and generate the corresponding runoff anywhere on Earth. Mean annual global runoff ratio results for 2021 were comparable to the runoff ratio from the Global Land Data Assimilation System (0.079 vs. 0.077, respectively). Mean annual global runoff from GCN and GLDAS were within 11% each other for 2020-2021 (0.18 vs. 0.16 mm/day, respectively). The GCN250 runoff application and the dataset are useful for many water applications such hydrologic design, land management, water resources management, and flood risk assessment.
Background: Gene co-expression networks (GCNs) are not easily comparable due to their complex structure. In this paper, we propose a tool, Juxtapose, together with similarity measures that can be utilized for comparative transcriptomics between a set of organisms. While we focus on its application to comparing co-expression networks across species in evolutionary studies, Juxtapose is also generalizable to co-expression network comparisons across tissues or conditions within the same species. Methods: A word embedding strategy commonly used in natural language processing was utilized in order to generate gene embeddings based on walks made throughout the GCNs. Juxtapose was evaluated based on its ability to embed the nodes of synthetic structures in the networks consistently while also generating biologically informative results. Evaluation of the techniques proposed in this research utilized RNA-seq datasets from GTEx, a multi-species experiment of prefrontal cortex samples from the Gene Expression Omnibus, as well as synthesized datasets. Biological evaluation was performed using gene set enrichment analysis and known gene relationships in literature. Results: We show that Juxtapose is capable of globally aligning synthesized networks as well as identifying areas that are conserved in real gene co-expression networks without reliance on external biological information. Furthermore, output from a matching algorithm that uses cosine distance between GCN embeddings is shown to be an informative measure of similarity that reflects the amount of topological similarity between networks. Conclusions: Juxtapose can be used to align GCNs without relying on known biological similarities and enables post-hoc analyses using biological parameters, such as orthology of genes, or conserved or variable pathways.
Automated multi-label chest X-ray (CXR) image classification has recently made significant progress in clinical diagnosis based on the advanced deep learning techniques. However, most existing methods mainly focus on analyzing locality visual cues from a single image but fail to leverage the underlying explicit correlations among different images for precise disease diagnosis. By contrast, an experienced radiologist expertizes in transferring knowledge from previous tasks to diagnose the present radiograph. To enable the machine like a radiologist, this paper proposes a novel Semantic Similarity Graph Embedding (SSGE) framework, which explicitly explores the semantic similarities among images to optimize the visual feature embedding for improving the performance of multi-label CXR images classification. Specifically, the proposed SSGE framework contains three main components: the image feature embedding (IFE) module, similarity graph construction (SGC) module, and semantic similarity learning (SSL) module. To realize interactive teaching and learning between visual and semantic information, the proposed SSGE framework is built on the "Teacher-Student" (semantic-visual) learning mechanism. With the guidance and supervision of the cross-image similarity graph generated by the SGC module, the SSL module leverages Graph Convolutional Network (GCN) to adaptively recalibrate the multi-image feature representations extracted from the IFE module, which guarantees their semantic consistency. Furthermore, we propose a novel re-weighting strategy to learn a more optimal semantic-similarity graph for the information propagation of the GCN layers. Extensive experiments on two benchmark datasets demonstrate the effectiveness of the proposed method in comparison with some state-of-the-art baselines.
Graphite carbon nitride (gCN) has attracted extensive attention due to excellent 2D structure and photocatalytic performance since it was discovered. In this work, the novel membrane was fabricated with acidified graphite carbon nitrogen (aCN) as a selective layer and dopamine (DA) as a cushion layer on a polysulfone (PS) membrane. The removal effect of aCN membrane on methyl blue and ciprofloxacin has improved with the excellent photocatalytic property of aCN. Meanwhile, SEM, XRD, FTIR spectra and DLS was performed to investigate the morphology, structure and property of the obtained membranes. The results showed that dopamine not only provided adhesion for aCN, but also enhanced photoelectron transfer. The membrane with optimized conditions aided by the structure and photocatalytic performance of aCN exhibited great removal rates for both methyl blue (97.2%) and ciprofloxacin (99.4%). The above experiments proved the advantages of aCN in the removal of dyes and antibiotics in coupling filtration and photocatalysis.
The signalling pathway governing general control nonderepressible (Gcn)2 kinase allows cells to cope with amino acid shortage. Under starvation, Gcn2 phosphorylates the translation initiation factor eukaryotic translation initiation factor (eIF)2 alpha, triggering downstream events that ultimately allow cells to cope with starvation. Under nutrient-replete conditions, the translation elongation factor eEF1A binds Gcn2 to contribute to keeping Gcn2 inactive. Here, we aimed to map the regions in eEF1A involved in binding and/or regulating Gcn2. We find that eEF1A amino acids 1-221 and 222-315, containing most of domains I and II, respectively, bind Gcn2 in vitro. Overexpression of eEF1A lacking or containing domain III impairs eIF2 alpha phosphorylation. While the latter reduces growth under starvation similarly to eEF1A lacking domain I, the former enhances growth in a Gcn2-dependent manner. Our studies suggest that domain II is required for Gcn2 inhibition and that eEF1A lacking domain III mainly affects the Gcn2 response pathway downstream of Gcn2.
Diagnosis assistant is an effective way to reduce the workloads of professional doctors. The rich professional knowledge plays a crucial role in diagnosis. Therefore, it is important to introduce the relevant medical knowledge into diagnosis assistant. In this paper, diagnosis assistant is treated as a classification task, and a Graph-based Structural Knowledge-aware Network (GSKN) model is proposed to fuse Electronic Medical Records (EMRs) and medical knowledge graph. Considering that different information in EMRs affects the diagnosis results differently, the information in EMRs is categorized into general information, key information and numerical information, and is introduced to GSKN by adding an enhancement layer to the Bidirectional Encoder Representation from Transformers (BERT) model. The entities in EMRs are recognized, and Graph Convolutional Neural Networks (GCN) is employed to learn deep-level graph structure information and dynamic representation of these entities in the subgraphs. An interactive attention mechanism is utilized to fuse the enhanced textual representation and the deep representation of these subgraphs. Experimental results on Chinese Obstetric Electronic Medical Records (COEMRs) and open dataset C-EMRs demonstrate the e ffectiveness of our model.
Motivation: The analysis of gene co-expression network (GCN) is critical in examining the gene-gene interactions and learning the underlying complex yet highly organized gene regulatory mechanisms. Numerous clustering methods have been developed to detect communities of co-expressed genes in the large network. The assumed independent community structure, however, can be oversimplified and may not adequately characterize the complex biological processes. Results: We develop a new computational package to extract interconnected communities from gene co-expression network. We consider a pair of communities be interconnected if a subset of genes from one community is correlated with a subset of genes from another community. The interconnected community structure is more flexible and provides a better fit to the empirical co-expression matrix. To overcome the computational challenges, we develop efficient algorithms by leveraging advanced graph norm shrinkage approach. We validate and show the advantage of our method by extensive simulation studies. We then apply our interconnected community detection method to an RNA-seq data from The Cancer Genome Atlas (TCGA) Acute Myeloid Leukemia (AML) study and identify essential interacting biological pathways related to the immune evasion mechanism of tumor cells.
In a complex network, some nodes are relatively concentrated in topological structure, thus forming a relatively independent node group, which we call a community. Usually, there are multiple communities on a network, and these communities are interconnected and exchange information with each other. A node that plays an important role in the process of information exchange between communities is called an inter-community bridge node. Traditional methods of defining and detecting bridge nodes mostly quantify the bridging effect of nodes by collecting local structural information of nodes and defining index operations. However, on the one hand, it is often difficult to capture the deep topological information in complex networks based on a single indicator, resulting in inaccurate evaluation results; on the other hand, for networks without community structure, such methods may rely on community partitioning algorithms, which require significant computing power. In this paper, considering the multi-dimensional attributes and structural characteristics of nodes, a deep learning-based framework named BND is designed to quickly and accurately detect bridge nodes. Considering that the bridging function of nodes between communities is abstract and complex, and may be related to the multi-dimensional information of nodes, we construct an attribute graph on the basis of the original graph according to the features of the five dimensions of the node to meet our needs for extracting bridging-related attributes. In the deep learning model, we overlay graph neural network layers to process the input attribute graph and add fully connected layers to improve the final classification effect of the model. Graph neural network algorithms including GCN, GAT, and GraphSAGE are compatible with our proposed framework. To the best of our knowledge, our work is the first application of graph neural network techniques in the field of bridge node detection. Experiments show that our designed framework can effectively capture network topology information and accurately detect bridge nodes in the network. In the overall model effect evaluation results based on indicators such as Accuracy and F1 score, our proposed graph neural network model is generally better than baseline methods. In the best case, our model has an Accuracy of 0.9050 and an F1 score of 0.8728.
Recent works have shown that multi-label image recognition is still a challenging task in computer vision due to the complicatedness and diversity of multi-label images. However, the existing works ignore the co-occurrence correlation and global contextual information between image space and objects. We present a model to solve these problems. On the one hand, we devise the graph attention mechanism to compute the hidden representations of different categories in multi-label images. It can specify different weights to different neighbor objects and well model the label dependency. On the other hand, we iterate the global contextual information by the second-order covariance pooling to enhance nonlinear modeling capability and use basic residual network to extract features. The proposed model is thoroughly evaluated on PASCAL VOC 2007 and MS-COCO datasets. Compared with classical ML-GCN, the model can better combine the image features and label embedding. Meanwhile, experiments show that it outperforms the state-of-the-art methods such as residual multi-layer perception, EfficientNet, and vision transformer. (C) 2021 SPIE and IS&T
Computer-vision techniques provide a way to conduct low-cost, portable, and real-time evaluations of exercises performed as a part of physical rehabilitation. Recent data-driven methods have explored using deep learning on 3D body-landmark sequences for automatic assessment of physical rehabilitation exercises. However, existing deep learning methods using convolutional neural networks (CNN) fail to utilize the spatial connection information of the human body, which limits the accuracy of these assessments. To overcome these limitations and provide a more accurate method to assess physical rehabilitation exercises, we propose a deep learning framework using a graph convolutional network (GCN) with self-supervised regularization. The experimental results on an existing benchmark dataset validate that the proposed method achieves state-of-the-art performance with lower error than other CNN methods, and the self-supervised learning improves the prediction accuracy.Clinical relevance-This work established a supervised learning method to automatically assess physical rehabilitation exercises in the home environment using computer vision. This low-cost, portable, and real-time evaluation may provide clinicians with a way to provide feedback to patients about their exercise performance without having to provide in-person supervision.
A key component of the conserved GCN (General Control Non-repressive) signalling pathway in plants is the ILITHYIA(ILA) protein, homologous to the yeast GCN1 protein. Similar to yeast and animals, ILA seems to be involved in the activation of the eIF2 alpha kinase GCN2, allowing protein arrest under stress conditions. Recently, it has been reported that, in plants, ILA could be also playing a role in development independent of GCN2. To gain insight into this new function of the ILA protein, we have performed proteomic analysis to identify differentially-expressed proteins in the strong loss-of-function allele of ILA (ila2). ila2 plants present a reduced expression of photosynthetic proteins, and an increased expression of the translational initiation factor eiF5A, ribosomal proteins and heat-shock proteins. These results open new hypothesis to understand the roles of this important translational regulator in plant tissues.
This paper investigates vehicle trajectory prediction problems in real traffic scenarios by fully harnessing the spatio-temporal dependencies between multiple vehicles. The existing GCN-based trajectory predictions are often considered in a single traffic scene without time attributes, complete interaction information, dynamic graph-based model, etc. Time and interaction aware models are more challenging than the existing ones. Despite very well does the graph-based model describe the relationship between driving vehicles, the critical problem in the traffic scene is how to deeply explore the spatiotemporal characteristics of dynamic graphs. Therefore, a novel dynamic graph and interaction-aware neural network model called as DGInet is proposed by combining a semi-global graph mechanism and an M-product based graph convolutional network, which are built into novel dual-network architecture in the entire model. The DGInet is built by exploiting the dynamic interaction in depth between driving vehicles in urban traffic scenarios, and then realized by utilizing semi-global graph convolution operations on the input data cell to capture the basic spatial interaction features of the driving scene. Meanwhile, the dynamic graph is further extracted by a novel M-product approach, in which the embedding of the model is then established along with the embedding of the semi-global network to perform the final embedding. Extensive experiments have been conducted on the two public datasets, named NGSIM and Apollo respectively, to show that our approach outperforms the existing ones with better performance and less computing time. Besides the real-world Shenzhen traffic dataset, China, is also developed to verify the effectiveness of our approach. (C) 2022 Elsevier Ltd. All rights reserved.
With the rapid development of information technology, the amount of textual data generated in biomedical field becomes larger and larger. Biomedical event extraction, which is a fundamental information extraction task, has gained a growing interest in biomedical community. Although researchers have proposed various approaches to this task, the performance is still undesirable since previous approaches fail to model biomedical documents effectively. In this paper, we propose an end-to-end framework for document-level joint biomedical event extraction. To better capture the complex relationships among contexts in biomedical documents, a two-level modeling approach is introduced for biomedical documents. More specifically, the dependency-based GCN and hypergraph are used to model local context and global context in each biomedical document, respectively. In addition, a fine-grained interaction mechanism is proposed to model effectively the interaction between local and global contexts to learn better contextualized representations for biomedical event extraction. Comprehensive experiments on two widely used datasets are conducted and the results demonstrate the effectiveness of the proposed framework over state-of-the-art methods. (C) 2020 Elsevier Inc. All rights reserved.
With the remarkable success of representation learning for prediction problems, we have witnessed a rapid expansion of the use of machine learning and deep learning for the analysis of digital pathology and biopsy image patches. However, learning over patch-wise features using convolutional neural networks limits the ability of the model to capture global contextual information and comprehensively model tissue composition. The phenotypical and topological distribution of constituent histological entities play a critical role in tissue diagnosis. As such, graph data representations and deep learning have attracted significant attention for encoding tissue representations, and capturing intra-and inter-entity level interactions. In this review, we provide a conceptual grounding for graph analytics in digital pathology, including entity-graph construction and graph architectures, and present their current success for tumor localization and classification, tumor invasion and staging, image retrieval, and survival prediction. We provide an overview of these methods in a systematic manner organized by the graph representation of the input image, scale, and organ on which they operate. We also outline the limitations of existing techniques, and suggest potential future research directions in this domain.
Electroanatomic mapping is the gold standard for the assessment of ventricular tachycardia. Acquiring high resolution electroanatomic maps is technically challenging and may require interpolation methods to obtain dense measurements. These methods, however, cannot recover activation times in the entire biventricular domain. This work investigates the use of graph convolutional neural networks to estimate biventricular activation times from sparse measurements. Our method is trained on more than 15,000 synthetic examples of realistic ventricular depolarization patterns generated by a computational electrophysiology model. Using geometries sampled from a statistical shape model of biventricular anatomy, diverse wave dynamics are induced by randomly sampling scar and border zone distributions, locations of initial activation, and tissue conduction velocities. Once trained, the method accurately reconstructs biventricular activation times in left-out synthetic simulations with a mean absolute error of 3.9 ms +/- 4.2 ms at a sampling density of one measurement sample per cm(2). The total activation time is matched with a mean error of 1.4 ms +/- 1.4 ms. A significant decrease in errors is observed in all heart zones with an increased number of samples. Without re-training, the network is further evaluated on two datasets: (1) an in-house dataset comprising four ischemic porcine hearts with dense endocardial activation maps; (2) the CRT-EPIGGY19 challenge data comprising endo- and epicardial measurements of 5 infarcted and 6 non-infarcted swines. In both setups the neural network recovers biventricular activation times with a mean absolute error of less than 10 ms even when providing only a subset of endocardial measurements as input. Furthermore, we present a simple approach to suggest new measurement locations in real-time based on the estimated uncertainty of the graph network predictions. The model-guided selection of measurement locations allows to reduce by 40% the number of measurements required in a random sampling strategy, while achieving the same prediction error. In all the tested scenarios, the proposed approach estimates biventricular activation times with comparable or better performance than a personalized computational model and significant runtime advantages.
Purpose A community demonstrates the unique qualities and relationships between its members that distinguish it from other communities within a network. Network analysis relies heavily on community detection. Despite the traditional spectral clustering and statistical inference methods, deep learning techniques for community detection have grown in popularity due to their ease of processing high-dimensional network data. Graph convolutional neural networks (GCNNs) have received much attention recently and have developed into a potential and ubiquitous method for directly detecting communities on graphs. Inspired by the promising results of graph convolutional networks (GCNs) in analyzing graph structure data, a novel community graph convolutional network (CommunityGCN) as a semi-supervised node classification model has been proposed and compared with recent baseline methods graph attention network (GAT), GCN-based technique for unsupervised community detection and Markov random fields combined with graph convolutional network (MRFasGCN). Design/methodology/approach This work presents the method for identifying communities that combines the notion of node classification via message passing with the architecture of a semi-supervised graph neural network. Six benchmark datasets, namely, Cora, CiteSeer, ACM, Karate, IMDB and Facebook, have been used in the experimentation. Findings In the first set of experiments, the scaled normalized average matrix of all neighbor's features including the node itself was obtained, followed by obtaining the weighted average matrix of low-dimensional nodes. In the second set of experiments, the average weighted matrix was forwarded to the GCN with two layers and the activation function for predicting the node class was applied. The results demonstrate that node classification with GCN can improve the performance of identifying communities on graph datasets. Originality/value The experiment reveals that the CommunityGCN approach has given better results with accuracy, normalized mutual information, F1 and modularity scores of 91.26, 79.9, 92.58 and 70.5 per cent, respectively, for detecting communities in the graph network, which is much greater than the range of 55.7-87.07 per cent reported in previous literature. Thus, it has been concluded that the GCN with node classification models has improved the accuracy.
The Transformer has been applied into computer vision to explore long-range dependencies with multi -head self-attention strategy, therefore numerous Transformer-based methods for person re-identification (ReID) are designed for extracting effective as well as robust representation. However, the memory and computational complexity of scaled dot-product attention in Transformer cost vast overheads. To over-come these limitations, this paper presents ResT-ReID method, which designs a hybrid backbone Res-Transformer based on ResNet-50 and Transformer block for effective identify information. Specifically, we use global self-attention in place of depth-wise convolution in the fourth layer's residual bottleneck of ResNet-50. For fully exploiting the entire knowledge of the person, we devise attention-guided Graph Convolution Networks (GCNs) with side information embedding (SIE-AGCN), which has an attention layer located into two GCN layers. The quantified experiments on two large-scale ReID benchmarks demon-strate that the proposed ResT-ReID achieves competitive results compared with several state-of-the-art approaches. (c) 2022 Published by Elsevier B.V.
While the technologies of ribonucleic acid-sequence (RNA-seq) and transcript assembly analysis have continued to improve, a novel topology of RNA transcript was uncovered in the last decade and is called circular RNA (circRNA). Recently, researchers have revealed that they compete with messenger RNA (mRNA) and long noncoding for combining with microRNA in gene regulation. Therefore, circRNA was assumed to be associated with complex disease and discovering the relationship between them would contribute to medical research. However, the work of identifying the association between circRNA and disease in vitro takes a long time and usually without direction. During these years, more and more associations were verified by experiments. Hence, we proposed a computational method named identifying circRNA-disease association based on graph representation learning (iGRLCDA) for the prediction of the potential association of circRNA and disease, which utilized a deep learning model of graph convolution network (GCN) and graph factorization (GF). In detail, iGRLCDA first derived the hidden feature of known associations between circRNA and disease using the Gaussian interaction profile (GIP) kernel combined with disease semantic information to form a numeric descriptor. After that, it further used the deep learning model of GCN and GF to extract hidden features from the descriptor. Finally, the random forest classifier is introduced to identify the potential circRNA-disease association. The five-fold cross-validation of iGRLCDA shows strong competitiveness in comparison with other excellent prediction models at the gold standard data and achieved an average area under the receiver operating characteristic curve of 0.9289 and an area under the precision-recall curve of 0.9377. On reviewing the prediction results from the relevant literature, 22 of the top 30 predicted circRNA-disease associations were noted in recent published papers. These exceptional results make us believe that iGRLCDA can provide reliable circRNA-disease associations for medical research and reduce the blindness of wet-lab experiments.
The rapidly increasing wind power penetration presents new challenges to the operation of power systems. Improving the accuracy of wind power forecasting is a possible solution under this circumstance. In the power forecasting of multiple wind farms, determining the spatio-temporal correlation of multiple wind farms is critical for improving the forecasting accuracy. This paper proposes a spatio-temporal convolutional network (STCN) that utilizes a directed graph convolutional structure. A temporal convolutional network is also adopted to characterize the temporal features of wind power. Historical data from 15 wind farms in Australia are used in the case study. The forecasting results show that the proposed model has higher accuracy than the existing methods. Based on the structure of the STCN, asymmetric spatial correlation at different temporal scales can be observed, which shows the effectiveness of the proposed model.
It is the prerequisite to ensure the safety of road users in traffic scenes for the application of autonomous vehicles. Pedestrians are the main participants in traffic scenes, and reasonable inference and prediction of their future trajectories are crucial for autonomous driving technology and road safety. Pedestrian trajectories are highly dynamic, apparently random, and complex to interact with traffic environment agents; therefore, selective modeling of spatial interaction and temporal dependence of pedestrians is necessary. To address this challenge, this paper proposes a novel pedestrian trajectory prediction model based on a spatio-temporal graph convolutional network (PTP-STGCN). Specifically, a new crowd interaction attention (CIA) function is defined to quantify the interaction information between adjacent pedestrians better. This function captures the spatial interaction features of pedestrians at each time step by a spatial graph convolution network (S-GCN). Meanwhile, the time-series motion features of each pedestrian are extracted by a temporal transformer network (T-transformer), and a spatio-temporal interaction graph of pedestrian features is constructed by the STGCN composed of the S-GCN and T-transformer. Finally, a time-extrapolator convolutional neural network (TXP-CNN) is used to predict pedestrian trajectories in the time dimension of the STGCN. The experimental results on the ETH and UCY datasets show that the proposed model achieves better performance than the state-of-the-art baselines regarding the average displacement error (ADE) and final displacement error (FDE). Due to the excellent performance in pedestrian trajectory prediction, the proposed network achieves more predictive final planned trajectory of an autonomous vehicle, while avoiding unnecessary trajectory changes and collision risk, thus providing a promising solution for practical pedestrian trajectory prediction applications.
Recent advances in deep convolution neural networks (CNNs) boost the development of video salient object detection (SOD), and many remarkable deep-CNNs video SOD models have been proposed. However, many existing deep-CNNs video SOD models still suffer from coarse boundaries of the salient object, which may be attributed to the loss of high-frequency information. The traditional graph-based video SOD models can preserve object boundaries well by conducting superpixels/supervoxels segmentation in advance, but they perform weaker in highlighting the whole object than the latest deep-CNNs models, limited by heuristic graph clustering algorithms. To tackle this problem, we find a new way to address this issue under the framework of graph convolution networks (GCNs), taking advantage of graph model and deep neural network. Specifically, a superpixel-level spatiotemporal graph is first constructed among multiple frame-pairs by exploiting the motion cues implied in the frame-pairs. Then the graph data is imported into the devised multi-stream attention-aware GCN, where a novel Edge-Gated graph convolution (GC) operation is proposed to boost the saliency information aggregation on the graph data. A novel attention module is designed to encode the spatiotemporal sematic information via adaptive selection of graph nodes and fusion of the static-specific and the motion-specific graph embedding. Finally, a smoothness-aware regularization term is proposed to enhance the uniformity of salient object. Graph nodes (superpixels) inherently belonging to the same class will be ideally clustered together in the learned embedding space. Extensive experiments have been conducted on three widely used datasets. Compared with fourteen state-of-the-art video SOD models, our proposed method can well retain the salient object boundaries and possess a strong learning ability, which shows that this work is a good practice for designing GCNs for video SOD.
Many studies on Graph Data Augmentation (GDA) approaches have emerged. The techniques have rapidly improved performance for various graph neural network (GNN) models, increasing the current state-of-the-art accuracy by absolute values of 4.20%, 5.50%, and 4.40% on Cora, Citeseer, and PubMed, respectively. The success is attributed to two integral properties of relational approaches: topology -level and feature-level augmentation. This work provides an overview of some GDA algorithms which are reasonably categorized based on these integral properties. Next, we engage the three most widely used GNN backbones (GCN, GAT, and GraphSAGE) as plug-and-play methods for conducting experiments. We conclude by evaluating the algorithm's effectiveness to demonstrate significant differences among various GDA techniques based on accuracy and time complexity with additional datasets different from those used in the original works. While discussing practical and theoretical motivations, considerations, and strategies for GDA, this work comprehensively investigates the challenges and future direction by pinpointing several open conceivable issues that may require further study based on far-reaching literature interpretation and empirical outcomes.
Traffic prediction is the key for Intelligent Transport Systems (ITS) to achieve traffic control and traffic guidance, and the key challenge is that traffic flow has complex spatial-temporal dependence and nonlinear dynamics. Aiming at the lack of the ability to model complex and dynamic spatial-temporal dependencies in current research, this paper proposes a traffic flow prediction model Attention based Graph Convolution Network (GCN) and Transformer (AGCN-T) to model spatial-temporal network dynamics of traffic flow, which can extract dynamic spatial dependence and long-distance temporal dependence to improve the accuracy of multistep traffic prediction. AGCN-T consists of three modules. In the spatial dependency extraction module, according to the similarity of historical traffic flow sequences of different loop detectors, an adjacency matrix for the road network is constructed based on a sequence similarity calculation method, Predictive Power Score (PPS), to express latent spatial dependency; and then GCN is used on the adjacency matrix to capture the global spatial correlation and Transformer is used to capture dynamic spatial dependency from the most recently flow sequences. And then, the dynamic spatial dependency is merged with the global spatial correlation to obtain the overall spatial dependency pattern. In the temporal dependency extraction module, the temporal dependency pattern of each traffic flow sequence is learned by the temporal Transformer. The prediction module integrates both patterns to form spatial-temporal dependency patterns and performs multistep traffic flow prediction. Four sets of experiments are performed on three actual traffic datasets to show that AGCN-T can effectively capture the dynamic spatial-temporal dependency of the traffic network, and its prediction performance and efficiency are better than existing baselines. AGCN-T can effectively capture the dynamics in traffic flow. In addition to traffic flow prediction, it can also be applied to other spatial-temporal prediction tasks, such as passenger demand prediction and crowd flow prediction.
Target-oriented Opinion Words Extraction (TOWE) aims to identify opinion words toward a specific target given the sentence. Syntax structure, which contains dependency relationships among words, is a vital clue for this task. With the help of syntax structure as a constraint, the model could remove irrelevant words and focus on tokens that are relevant to the given target. Directly adapting existing syntactic based methods faces the problem that these models do not explicitly learn target-centric representations. Another challenge is that prior works only learn fixed order dependency relations, while context words require syntactic information in different scales. To handle these issues, we propose Target-Specific Graph Convolutional Network (TS-GCN) to explicitly integrate dependency structure. The proposed method could build high-quality syntax-aware representations by propagating target information to syntactically related words via graph convolution. Furthermore, we design a memory-based module to dynamically learn multi-granularity syntactic knowledge and infuse local features. Experimental results demonstrate the effectiveness of our method, and we achieve state-of-the-art performances on four SemEval datasets. (c) 2021 Published by Elsevier B.V.
Detecting pedestrians, especially under heavy occlusion, is a challenging computer vision problem with numerous real-world applications. This paper introduces a novel approach, termed as PSC-Net, for occluded pedestrian detection. The proposed PSC-Net contains a dedicated module that is designed to explicitly capture both inter and intra-part co-occurrence information of different pedestrian body parts through a graph convolutional network (GCN). Both inter and intra-part co-occurrence information contribute towards improving the feature representation for handling varying level of occlusions, ranging from partial to severe occlusions. Our PSC-Net exploits the topological structure of pedestrian and does not require part-based annotations or additional visible bounding-box (VBB) information to learn part spatial co-occurrence. Comprehensive experiments are performed on three challenging datasets: CityPersons, Caltech, and CrowdHuman datasets. Particularly, in terms of log-average miss rates and with the same backbone and input scale as those of the state-of-the-art MGAN, the proposed PSC-Net achieves absolute gains of 4.0% and 3.4% over MGAN on the heavy occlusion subsets of CityPersons and Caltech test sets, respectively.
ALSC (Aspect-level Sentiment Classification) is a fine-grained task in the field of NLP (Natural Language Processing) which aims to identify the sentiment toward a given aspect. In addition to exploiting the sentence semantics and syntax, current ALSC methods focus on introducing external knowledge as a supplementary to the sentence information. However, the integration of the three categories of information is still challenging. In this paper, a novel method is devised to effectively combine sufficient semantic and syntactic information as well as use of external knowledge. The proposed model contains a sentence encoder, a semantic learning module, a syntax learning module, a knowledge enhancement module, an information fusion module and a sentiment classifier. The semantic information and syntactic information are respectively extracted via a self-attention network and a graphical convolutional network. Specifically, the KGE (Knowledge Graph Embedding) is employed to enhance the feature representation of the aspect. Then, the attention-based gate mechanism is taken to fuse three types of information. We evaluated the proposed model on three benchmark datasets and the experimental results establish strong evidence of high accuracy.
As a typical spatiotemporal problem, there are three main challenges in traffic forecasting. First, the road network is a nonregular topology, and it is difficult to extract complex spatial dependence accurately. Second, there are short- and long-term dependencies between traffic dates. Third, there are many other factors besides the influence of spatiotemporal dependence, such as semantic characteristics. To address these issues, we propose a spatiotemporal DeepWalk gated recurrent unit model (ST-DWGRU), a deep learning framework that fuses spatial, temporal, and semantic features for traffic speed forecasting. In the framework, the spatial dependency between nodes of an entire road network is extracted by graph convolutional network (GCN), whereas the temporal dependency between speeds is captured by a gated recurrent unit network (GRU). DeepWalk is used to extract semantic information from road networks. Three publicly available datasets with different time granularities of 15, 30, and 60 min are used to validate the short- and long-time prediction effect of this model. The results show that the ST-DWGRU model significantly outperforms the state-of-the-art baselines.
One trend in the latest bottom-up approaches for arbitrary-shape scene text detection is to determine the links between text segments using Graph Convolutional Networks (GCNs). However, the performance of these bottom-up methods is still inferior to that of state-of-the-art top-down methods even with the help of GCNs. We argue that a cause of this is that bottom-up methods fail to make proper use of visual-relational features, which results in accumulated false detection, as well as the error-prone route-finding used for grouping text segments. In this paper, we improve classic bottom-up text detection frameworks by fusing the visual-relational features of text with two effective false positive/negative suppression (FPNS) mechanisms and developing a new shape-approximation strategy. First, dense overlapping text segments depicting the "characterness" and "streamline" properties of text are constructed and used in weakly supervised node classification to filter the falsely detected text segments. Then, relational features and visual features of text segments are fused with a novel Location-Aware Transfer (LAT) module and Fuse Decoding (FD) module to jointly rectify the detected text segments. Finally, a novel multiple-text-map-aware contour-approximation strategy is developed based on the rectified text segments, instead of the error-prone route-finding process, to generate the final contour of the detected text. Experiments conducted on five benchmark datasets demonstrate that our method outperforms the state-of-the-art performance when embedded in a classic text detection framework, which revitalizes the strengths of bottom-up methods.
Slot filling and intent detection are the basic and crucial fields of natural language processing (NLP) for understanding and analyzing human language, owing to their wide applications in real-world scenarios. Most existing methods of slot filling and intent detection tasks utilize linear chain conditional random field (CRF) for only optimizing slot filling, no matter the method is a pipeline or a joint model. In order to describe and exploit the implicit connections which indicate the appearance compatibility of different tag pairs, we introduce a graph-based CRF for a joint optimization of tag distribution of the slots and the intents. Instead of applying the complex inference algorithm of traditional graph-based CRF, we use an end-to-end method to implement the inference, which is formulated as a specialized multi-layer graph convolutional network (GCN). Furthermore, mask mechanism is introduced to our model for addressing multi-task problems with different tag-sets. Experimental results show the superiority of our model com- pared with other alternative methods. Our code is available at https://github.com/tomsonsgs/e2e-mask-graph-crf. (C) 2020 Elsevier B.V. All rights reserved.
Convolutional neural networks (CNNs) have attracted significant attention as a commonly used method for hyperspectral image (HSI) classification in recent years; however, CNNs can only be applied to Euclidean data and have difficulties in dealing with relationships due to their limitations of local feature extraction. Each pixel of a hyperspectral image contains a set of spectral bands that are correlated and interact with each other, and the methods used to process Euclidean data cannot effectively obtain these correlations. In contrast, the graph convolutional network (GCN) can be used in non-Euclidean data but usually leads to over-smoothing and ignores local detail features due to the need for superpixel segmentation processing to reduce computational effort. To overcome the above problems, we constructed a fusion network based on the GCN and CNN which contains two branches: a graph convolutional network based on superpixel segmentation and a convolutional network with an added attention mechanism. The graph convolutional branch can extract the structural features and capture the relationships between the nodes, and the convolutional branch can extract detailed features in the local fine region. Owing to the fact that the features extracted from the two branches are different, the classification performance can be improved by fusing the complementary features extracted from the two branches. To validate the proposed algorithm, experiments were conducted on three widely used datasets, namely Indian Pines, Pavia University, and Salinas. An overall accuracy of 98.78% was obtained in the Indian Pines dataset, and overall accuracies of 98.99% and 98.69% were obtained in the other two datasets. The results show that the proposed fusion network can obtain richer features and achieve a high classification accuracy.
In an urban environment, the accurate prediction of congestion levels is a prerequisite for formulating traffic demand management strategies reasonably. Current traffic forecasting studies mostly focus on the road topological network and assume that the spatial linkages of road segments is fixed, thus ignoring associated congestion level changes between road segments. This study introduces a fusion-based graph convolutional network called the F-GCN. The model aims to capture the dynamic correlations of the congestion levels among road segments while constructing the static topology of the road network. In particular, the entropy-based grey relation analysis method is first implemented in the dynamic graph convolutional network (GCN) module to measure the potential correlations among the observed congestion levels. Then, spatio-temporal blocks that integrate GCN layers, spatial attention mechanisms, and long short-term memory layers are built for both the static and dynamic GCN modules. Finally, the F-GCN model is developed by fusing the static GCN and dynamic GCN module. The numerical experiments on Beijing taxies demonstrated that the proposed F-GCN model achieved a significant 5.47%, 5.64%, and 8.14% improvements for the 15-, 30-, and 45-min prediction tasks in the weighted mean absolute percentage error compared to the state-of-the-art baseline models. This improvement highlights the effectiveness of the model in predicting congestion levels, demonstrating its superiority and potential in capturing the dynamic potential correlations among the congestion levels of road segments.
The discovery of hydrocarbon reserves has declined significantly in recent years owing to the structural and lithological heterogeneities present in reservoirs. To overcome this decline, it is crucial to incorporate advanced computational methods, such as machine learning (ML) and deep learning (DL). These technologies can facilitate more precise discovery of hydrocarbon reserves, thereby replenishing and increasing the supply of proven reserves. By utilizing ML and DL, likelihood of errors arising from human error or bias during exploration activities can be diminished substantially. This is due to the extensive incorporation of sophisticated statistical techniques within the applications of ML and DL. Well logs provide valuable information about the physical characteristics of subterranean fluids and rocks. In the McKee field in New Zealand, the lithology of three wells was determined using petrophysical parameters, such as porosity, permeability, water saturation, volume shale, and oil saturation that were extracted from the well logs. The unsupervised method K-means clustering (KMC) was used to perform facies classification tasks, utilizing clusters that matched the well's facies and ranged from 5 to 10 and each well yielded six pairs of outputs. Graph convolutional networks (GCN) are reliable technique for working with graph representations. The best performance is achieved by directly integrating graph convolutions with feature information and related parameters. The petrophysical parameters were combined with the unlabeled KMC outputs to form the GCN dataset. The initial potential zones were classified into five classes based on petrophysical criteria: very high, high, moderate, low, and very low. This GCN approach was used to identify each graph quality in the dataset. The hydrocarbon potential of the three wells was evaluated using the graph dataset and the GCN approach, which produced results with higher accuracy when real labels were used. The findings of this study indicate that the identification of a hydrocarbon-rich region through the utilization of a graph that integrates lithological and petrophysical data requires a comprehensive understanding of the subsurface that goes beyond lithology alone. To achieve this, a novel method for predicting hydrocarbon potential based on GCN is proposed, which combines graph datasets derived from well logs consisting of petrophysical entities and depth values.
Traffic flow forecasting is a basic function of intelligent transportation systems, and the accuracy of prediction is of great significance for traffic management and urban planning. The main difficulty of traffic flow predictions is that there is complex underlying spatiotemporal dependence in traffic flow; thus, the existing spatiotemporal graph neural network (STGNN) models need to model both temporal dependence and spatial dependence. Graph neural networks (GNNs) are adopted to capture the spatial dependence in traffic flow, which can model the symmetric or asymmetric spatial relations between nodes in the traffic network. The transmission process of traffic features in GNNs is guided by the node-to-node relationship (e.g., adjacency or spatial distance) between nodes, ignoring the spatial dependence caused by local topological constraints in the road network. To further consider the influence of local topology on the spatial dependence of road networks, in this paper, we introduce Ollivier-Ricci curvature information between connected edges in the road network, which is based on optimal transport theory and makes comprehensive use of the neighborhood-to-neighborhood relationship to guide the transmission process of traffic features between nodes in STGNNs. Experiments on real-world traffic datasets show that the models with Ollivier-Ricci curvature information outperforms those based on only node-to-node relationships between nodes by ten percent on average in the RMSE metric. This study indicates that by utilizing complex topological features in road networks, spatial dependence can be captured more sufficiently, further improving the predictive ability of traffic forecasting models.
The biggest challenge to recommendation systems based on user preferences is how to improve the ability of the recommendation system to mine and analyse user preferences and behaviours. In this process, we must not only consider the continuation of the user's long-term preference but also improve the system's ability to accommodate short-term preferences and discrete preferences. To this end, we focus on the performance of time factors of user preferences. However, the issue we are concerned about has not received much attention in the existing research. We propose a new recommendation model based on the perspective of user sessions, namely GACOforRec. This model can handle long-term and stable preferences at the same time and preserve the hierarchy of potential preferences. We conducted a large number of comparative experiments on two real datasets, and the results show that GACOforRec is significantly better than other state-of-the-art methods in the study of user sessions.
In the few-shot common-localization task, given few support images without bounding box annotations at each episode, the goal is to localize the common object in the query image of unseen categories. The few-shot common-localization task involves common object reasoning from the given images, predicting the spatial locations of the object with different shapes, sizes, and orientations. In this work, we propose a common-centric localization (CCL) network for few-shot common-localization. The motivation of our common-centric localization network is to learn the common object features by dynamic feature relation reasoning via a graph convolutional network with conditional feature aggregation. First, we propose a local common object region generation pipeline to reduce background noises due to feature misalignment. Each support image predicts more accurate object spatial locations by replacing the query with the images in the support set. Second, we introduce a graph convolutional network with dynamic feature transformation to enforce the common object reasoning. To enhance the discriminability during feature matching and enable a better generalization in unseen scenarios, we leverage a conditional feature encoding function to alter visual features according to the input query adaptively. Third, we introduce a common-centric relation structure to model the correlation between the common features and the query image feature. The generated common features guide the query image feature towards a more common object-related representation. We evaluate our common-centric localization network on four datasets, i.e., CL-VOC-07, CL-VOC-12, CL-COCO, CL-VID. We obtain significant improvements compared to state-of-the-art. Our quantitative results confirm the effectiveness of our network.
We propose to use segment graph convolutional and recurrent neural networks (Seg-GCRNs), which use only word embedding and sentence syntactic dependencies, to classify relations from clinical notes without manual feature engineering. In this study, the relations between 2 medical concepts are classified by simultaneously learning representations of text segments in the context of sentence syntactic dependency: preceding, concept(1), middle, concept(2), and succeeding segments. Seg-GCRN was systematically evaluated on the i2b2/VA relation classification challenge datasets. Experiments show that Seg-GCRN attains state-of-the-art micro-averaged F-measure for all 3 relation categories: 0.692 for classifying medical treatment-problem relations, 0.827 for medical test-problem relations, and 0.741 for medical problem-medical problem relations. Comparison with the previous state-of-the-art segment convolutional neural network (Seg-CNN) suggests that adding syntactic dependency information helps refine medical word embedding and improves concept relation classification without manual feature engineering. Seg-GCRN can be trained efficiently for the i2b2/VA dataset on a GPU platform.
This study aimed to evaluate the feasibility of applying a clinical multimodal radiomics nomogram based on ultrasonography (US) and multiparametric magnetic resonance imaging (MRI) for the prediction of cervical lymph node metastasis (LNM) in papillary thyroid carcinoma (PTC) preoperatively. We performed retrospective evaluations of 133 patients with pathologically confirmed PTC, who were assigned to the training cohort and validation cohort (7:3), and extracted radiomics features from the preoperative US, T2-weighted (T2WI),diffusion-weighted (DWI), and contrast-enhanced T1-weighted (CE-T1WI) images. Optimal subsets were selected using minimum redundancy, maximum relevance, and recursive feature elimination in the support vector machine (SVM). For LNM prediction, the radiomics model was constructed by SVM, and Multi-Omics Graph cOnvolutional NETworks (MOGONET) was used for the effective classification of multiradiomics data. Multivariable logistic regression incorporating multiradiomics signatures and clinical risk factors was used to generate a nomogram, whose performance and clinical utility were assessed. Results showed that the nine most predictive features were separately selected from US, T2WI, DWI, and CE-T1WI images, and 18 features were selected in the combined model. The combined radiomics model showed better performance than models based on US, T2WI, DWI, and CE-T1WI. In a comparison of the combined radiomics and MOGONET model, receiver operating curve analysis showed that the area under the curve (AUC) value (95% CI) was 0.84 (0.76-0.93) and 0.84 (0.71-0.96) for the MOGONET model in the training and validation cohorts, respectively. The corresponding values (95% CI) for the combined radiomics model were 0.82 (0.74-0.90) and 0.77 (0.61-0.94), respectively. The MOGONET model had better performance and better prediction specificity compared with the combined radiomics model. The nomogram including the MOGONET signature showed a better predictive value (AUC: 0.81 vs. 0.88) in the training and validation (AUC: 0.74vs. 0.87) cohorts, as compared with the clinical model. Calibration curves showed good agreement in both cohorts. The applicability of the clinical multimodal radiomics (CMR) nomogram in clinical settings was validated by decision curve analysis. In patients with PTC, the CMR nomogram could improve the prediction of cervical LNM preoperatively and may be helpful in clinical decision-making.
Hyperspectral image (HSI) classification is commonly influenced by convolution neural networks (CNNs). However, the large number of parameters and computational complexity associated with CNNs can limit their practical application, particularly when computing and storage resources are limited. To address this challenge, we propose a channel-layer-oriented lightweight network for HSI classification. Motivated by existing structures that typically set large channels and stack multiple layers, we give more optimal solutions strategically to further compress the model. For intralayer feature extraction, we develop a channel-oriented spectral-spatial module (COS2M), which introduces a dual-single-channel (DSC) 3-D convolution that works in conjunction with depthwise convolution to fully extract spectral-spatial information. For interlayer information transmission, we propose a novel neighbor-pixel-aware activation function (NPAF), where the activation of a single pixel is determined by the learnable interaction with its neighbor range that enhances information transmission and improves the network's fitting ability through the single activation layer. By implementing these strategies, we aim to overcome the limitations of traditional CNNs and enable efficient HSI classification within resource-constrained environments. The whole network is designed to be a compact end-to-end structure. It achieves better classification performance than other deep learning methods and lightweight models, even with limited training samples. The network parameters, model complexity, and inference time also demonstrate significant superiority, as confirmed by experiments on three benchmark datasets. The source codes are available publicly at: https://github.com/AchunLee/CLOLN_TGRS
Scene flow estimation is a fundamental task of autonomous driving. Compared with optical flow, scene flow can provide sufficient 3D motion information of the dynamic scene. With the increasing popularity of 3D LiDAR sensors and deep learning technology, 3D LiDAR-based scene flow estimation methods have achieved outstanding results on public benchmarks. Current methods usually adopt Multiple Layer Perceptron (MLP) or traditional convolution-like operation for feature extraction. However, the characteristics of point clouds are not exploited adequately in these methods, and thus some key semantic and geometric structures are not well captured. To address this issue, we propose to introduce graph convolution to exploit the structural features adaptively. In particular, multiple graph-based feature generators and a graph-based flow refinement module are deployed to encode geometric relations among points. Furthermore, residual connections are used in the graph-based feature generator to enhance feature representation and deep supervision of the graph-based network. In addition, to focus on short-term dependencies, we introduce a single gate-based recurrent unit to refine scene flow predictions iteratively. The proposed network is trained on the FlyingThings3D dataset and evaluated on the FlyingThings3D, KITTI, and Argoverse datasets. Comprehensive experiments show that all proposed components contribute to the performance of scene flow estimation, and our method can achieve potential performance compared to the recent approaches.
Phishing, a well-known cyber-attack practice has gained significant research attention in the cyber-security domain for the last two decades due to its dynamic attacking strategies. Although different solutions have been exercised against phishing, phishing attacks have dramatically increased in the past few years. Recent studies have shown that machine learning has become prominent in the present anti-phishing context, and the techniques like deep learning have extensively improved anti-phishing tools' detection ability. This paper proposes PhishDet, a new way of detecting phishing websites through Long-term Recurrent Convolutional Network and Graph Convolutional Network using URL and HTML features. PhishDet is the first of its kind, which uses the powerful analysis and processing capabilities of Graph Neural Network in the anti-phishing domain and recorded 96.42% detection accuracy, with a 0.036 false-negative rate. It is effective against zero-day attacks, and the average detection time which is 1.8 seconds could also be considered realistic. The feature selection of PhishDet is automatic and occurs inside the system, as PhishDet gradually learns URLs and HTML content features to handle constantly changing phishing attacks. This has outperformed similar solutions by achieving a 99.53% f1-score with a public benchmark dataset. However, PhishDet requires periodic retraining to maintain its performance over time. If such retraining could be facilitated, PhishDet could fight against phishers for a more extended period to safeguard Internet users from this Internet threat.
Deep learning has achieved impressive results on hyperspectral image (HSI) classification. Among them, both convolutional neural networks (CNNs) and graph neural networks (GNNs) have great potential for HSI classification. Supervised CNNs can efficiently extract hierarchical spatial-spectral features of HSIs, but these methods face the problem of high time complexity as the number of network layers increases. Semisupervised GNNs can rapidly capture the structural information of HSIs, while they cannot be well extended to HSI applications because of the process of adjacency matrix consuming large amount of memory resources. In this article, we propose a fast dynamic graph convolutional network and CNN (FDGC) parallel network for HSI classification. We first obtain two classification features by flattening and pooling operations on the results of the convolution layers, which fully exploits the spatial-spectral information contained in the hyperspectral data cube. Then, a dynamic graph convolution module is applied to extract the intrinsic structural information of each patch. Finally, we can obtain the HSI classification results based on these spatial, spectral, and structural features. By using three branches, FDGC can parallelly process multiple features of HSI in a supervised learning manner. In addition, regularization techniques, such as DropBlock and label smoothing, are applied to further improve the generalization capability of the model. Experimental results on three datasets show that our proposed algorithm is comparable with the state-of-the-art supervised learning models in terms of accuracy while also significantly outperforming in terms of training and inference time.
Fundus photography has been widely used for inspecting eye disorders by ophthalmologists or computer algorithms. Biomarkers related to retinal vessels plays an essential role to detect early diabetes. To quantify vascular biomarkers or the corresponding changes, an accurate artery and vein classification is necessary. In this work, we propose a new framework to boost local vessel classification with a global vascular network model using graph convolution. We compare our proposed method with two traditional state-of-the-art methods on a testing dataset of 750 images from the Maastricht Study. After incorporating global information, our model achieves the best accuracy of 86.45% compared to 85.5% from convolutional neural networks (CNN) and 82.9% from handcrafted pixel feature classification (HPFC). Our model also obtains the best area under receiver operating characteristic curve (AUC) of 0.95, compared to 0.93 from CNN and 0.90 from HPFC. The new classification framework has the advantage of easy deployment on top of local classification features. It corrects the local classification error by minimizing global classification error and it brings free additional classification performance.
Vehicle re-identification (Re-ID) is a critical task in intelligent transportation, aiming to match vehicle images of the same identity captured by non-overlapping cameras. However, it is difficult to achieve satisfactory results based on RGB images alone in darkness. Therefore, it is of great importance to consider multi-modality vehicle re-identification. Currently, the proposed works deal with different modality features through direct summation and fusion based on heat map, which however ignores the relationship between them. Meanwhile, there is a huge gap between the different modalities, which needs to be reduced. In this paper, to solve the above two problems, we propose a Graph-based Progressive Fusion Network (GPFNet) using a graph convolutional network to adaptively fuse multi-modality features in an end-to-end learning framework. GPFNet consists of a CNN feature extraction module (FEM), a GCN feature fusion module (FFM), and a loss function module (LFM). Firstly, in FEM, we employ a multi-stream network architecture to extract single-modality features and common-modality features and employ a random modality substitution module to extract mixed-modality features. Secondly, in FFM, we design an efficient graph structure to associate the features of different modalities and adopt a progressive two-stage strategy to fuse them. Finally, in LFM, we use GCN-aware multi-modality loss to constrain the features. For reducing modality differences and contributing better initial mixed-modality features to FFM, we propose random modality substitution as a data enhancement method for multi-modality datasets. Extensive experiments on multi-modality vehicle Re-ID datasets RGBN300 and RGBNT100 show that our model achieves state-of-the-art performance.
As one of the critical branches of medical image processing, the task of segmentation of breast cancer tumors is of great importance for planning surgical interventions, radiotherapy and chemotherapy. Breast cancer tumor segmentation faces several challenges, including the inherent complexity and heterogeneity of breast tissue, the presence of various imaging artifacts and noise in medical images, low contrast between the tumor region and healthy tissue, and inconsistent size of the tumor region. Furthermore, the existing segmentation methods may not fully capture the rich spatial and contextual information in small-sized regions in breast images, leading to suboptimal performance. In this paper, we propose a novel breast tumor segmentation method, called the transformer and graph convolutional neural (TS-GCN) network, for medical imaging analysis. Specifically, we designed a feature aggregation network to fuse the features extracted from the transformer, GCN and convolutional neural network (CNN) networks. The CNN extract network is designed for the image's local deep feature, and the transformer and GCN networks can better capture the spatial and context dependencies among pixels in images. By leveraging the strengths of three feature extraction networks, our method achieved superior segmentation performance on the BUSI dataset and dataset B. The TS-GCN showed the best performance on several indexes, with Acc of 0.9373, Dice of 0.9058, IoU of 0.7634, F1 score of 0.9338, and AUC of 0.9692, which outperforms other state-of-the-art methods. The research of this segmentation method provides a promising future for medical image analysis and diagnosis of other diseases.
Long-range regulatory interactions among genomic regions are critical for controlling gene expression, and their disruption has been associated with a host of diseases. However, when modeling the effects of regulatory factors, most deep learning models either neglect long-range interactions or fail to capture the inherent 3D structure of the underlying genomic organization. To address these limitations, we present a Graph Convolutional Model for Epigenetic Regulation of Gene Expression (GC-MERGE). Using a graph-based framework, the model incorporates important information about long-range interactions via a natural encoding of genomic spatial interactions into the graph representation. It integrates measurements of both the global genomic organization and the local regulatory factors, specifically histone modifications, to not only predict the expression of a given gene of interest but also quantify the importance of its regulatory factors. We apply GC-MERGE to data sets for three cell lines-GM12878 (lymphoblastoid), K562 (myelogenous leukemia), and HUVEC (human umbilical vein endothelial)-and demonstrate its state-of-the-art predictive performance. Crucially, we show that our model is interpretable in terms of the observed biological regulatory factors, highlighting both the histone modifications and the interacting genomic regions contributing to a gene's predicted expression. We provide model explanations for multiple exemplar genes and validate them with evidence from the literature. Our model presents a novel setup for predicting gene expression by integrating multimodal data sets in a graph convolutional framework. More importantly, it enables interpretation of the biological mechanisms driving the model's predictions.
Although deep learning-based approaches have made significant progress in remote sensing (RS) image classification, the supervised learning paradigm has shortcomings under a limited number of labeled samples, which restricts the classification performance to a great extent. In this article, we investigate an effective self-supervised feature representation (SSFR) architecture for multimodal RS images' few-shot land cover classification. Specifically, we exploit a multiview learning strategy to construct multiple views from multimodal RS images. This method builds several complementary views of the same observed scenes from hyperspectral images or different modalities of RS data. Then, we build the deep feature extractor to learn high-level feature representations from each view via contrastive learning. Contrastive learning aggregates the samples of the same scene while separating samples of different scenes in the latent space, and this process does not require any labeled information. What is more, to learn more robust features from different views, we utilize multitask learning strategy to train the feature extraction network. Finally, a lightweight machine learning method is employed to classify the learned features using a few annotated samples. To further demonstrate the self-supervised feature learning capability of the proposed model, we train the feature representation network in multiple source datasets. Comprehensive feature learning and classification experiments have certified the effectiveness and superiority of the proposed method.
The composition and arrangement of spatial entities, i.e., land cover objects, play a key role in distinguishing land use types from very high resolution (VHR) remote sensing images, in particular in urban environments. This paper presents a new method to characterize the spatial arrangement for urban land use extraction using VHR images. We derive an adjacency unit matrix to represent the spatial arrangement of land cover objects obtained from a VHR image, and use a graph convolutional network to quantify the spatial arrangement by extracting hidden features from adjacency unit matrices. The distribution of the spatial arrangement variables, i.e., hidden features, and the spatial composition variables, i.e., widely used land use indicators, are then estimated. We use a Bayesian method to integrate the variables of spatial arrangement and composition for urban land use extraction. Experiments were conducted using three VHR images acquired in two urban areas: a Pleiades image in Wuhan in 2013, a Superview image in Wuhan in 2019, and a GeoEye image in Oklahoma City in 2012. Our results show that the proposed method provides an effective means to characterize the spatial arrangement of land cover objects, and produces urban land use extractions with overall accuracies (i.e., 86% and 93%) higher than existing methods (i.e., 83% and 88%) that use spatial arrangement information based on building types on the Pleiades and GeoEye datasets. Moreover, it is unnecessary to further categorize the dominant land cover type into finer types for the characterization of spatial arrangement. We conclude that the proposed method has a high potential for the characterization of urban structure using different VHR images, and for the extraction of urban land use in different urban areas.
Vessel segmentation is widely used to help with vascular disease diagnosis. Vessels reconstructed using existing methods are often not sufficiently accurate to meet clinical use standards. This is because 3D vessel structures are highly complicated and exhibit unique characteristics, including sparsity and anisotropy. In this paper, we propose a novel hybrid deep neural network for vessel segmentation. Our network consists of two cascaded subnetworks performing initial and refined segmentation respectively. The second subnetwork further has two tightly coupled components, a traditional CNN-based U-Net and a graph U-Net. Cross-network multi-scale feature fusion is performed between these two U-shaped networks to effectively support high-quality vessel segmentation. The entire cascaded network can be trained from end to end. The graph in the second subnetwork is constructed according to a vessel probability map as well as appearance and semantic similarities in the original CT volume. To tackle the challenges caused by the sparsity and anisotropy of vessels, a higher percentage of graph nodes are distributed in areas that potentially contain vessels while a higher percentage of edges follow the orientation of potential nearby vessels. Extensive experiments demonstrate our deep network achieves state-of-the-art 3D vessel segmentation performance on multiple public and in-house datasets.
Semantic segmentation in aerial imagery is still an important, yet challenging task due to the complex characteristics of remote-sensing data. The critical issues consist of: 1) extreme foreground-background imbalance; 2) large intra-class variance; and 3) arbitrary-oriented, dense, and small objects. The above challenges make it unlikely to model the effective global interdependencies of semantic heterogeneous regions. Besides, general semantic segmentation methods suffer from feature ambiguity due to the joint feature learning paradigm, leading to inferior detail information. In this article, we propose an improved semantic segmentation framework to tackle these problems via graph reasoning (GR) and disentangled learning. On the one hand, a simple, yet effective GR unit is introduced to implement coordinate-interaction space mapping and perform relation reasoning over the graph. It can be deployed on the feature pyramid network (FPN) to exploit cross-stage multi-scale information. On the other hand, we propose a so- called disentangled learning paradigm to explicitly model the foreground and boundary objects, instantiated as foreground prior estimation (FPE) and boundary alignment (BA). The indication of the intermediate feature can be effectively emphasized to enhance the discriminative abilities of the network. Extensive experiments over iSAID, ISPRS Vaihingen, and the general Cityscapes datasets demonstrate the effectiveness and efficiency of the proposed framework over other state-of-the-art semantic segmentation methods.
The transformer has become a prominent technique for hyperspectral image (HSI) classification, attributed to its capability to model global dependencies between features. Nevertheless, the predominant transformer-based methods rely on a direct information flow with a fixed number of tokens, causing the sequential transformer encoders to lack crucial interaction. This deficiency results in an inappropriate granularity of discriminative features and the loss of subtle patterns. In response to this limitation, we introduce a novel approach named multilevel class token transformer (MCTT) with cross tokenmixer for HSI classification. Specifically, we explore a convolutional neural network (CNN) stem network that incorporates 3-D, 2-D, and pointwise convolutions to encode local spatial-spectral information. The spectral-spatial features undergo transformation into semantic tokens using a semantic tokenizer. These tokens are then input into the transformer encoder to capture global interactions between different pixels. To create a hierarchical semantic representation, we propose a cross tokenmixer that integrates different levels of class tokens and patch tokens, enabling a multigrained representation. The cross tokenmixers, with their varied number of tokens, facilitate the learning of distinct discriminative spectral-spatial representations and enable a comprehensive understanding of the HSI through a voting mechanism. Extensive experiments and ablation studies are conducted on three public HSI datasets to evaluate the performance of our proposed method. The results demonstrate the effectiveness and superior performance of our approach in HSI classification.
Supervised cross-modal retrieval has significant advantages in retrieval efficiency and storage cost. In the field of hashing retrieval, existing supervised methods are divided into single-label and multi-label methods. For the single-label method, simply using a single label to measure the semantic relevance between instances will cause an error in supervision information. However, the existing multi-label hashing methods also have some problems. For example, only considering the co-occurrence of multiple labels among instances may not accurately reflect their similarity. At the same time, in the previous methods, the text modality processing did not reach the fine level of image modality, resulting in insufficient use of text information. To address these issues, we proposed Non-co-occurrence enhanced Multi-label cross-modal hashing retrieval based on Graph Convolutional Network (MHGCN). Firstly, we introduced a multi-label non-co-occurrence similarity measurement method, which adds multi-label non-co-occurrence information among instances in the multi-label similarity measurement to measure the differences between instances; Secondly, we used Graph Convolutional Networks (GCNS) to process the information on text modality; Thirdly, we introduced the memory mechanism to restrict the difference of hash code learning. Many experiments show that the proposed method has excellent performance. In three widely used datasets (NUS-WIDE, MIRFlickr-25k, IAPR TC-12), MAP performance in image-text and text-image tasks was significanlty improved by about 8%, 9%, and 7%, respectlively.
Cross-lingual spoken language understanding (cross-lingual SLU), as a key component of task-oriented dialogue systems, is widely used in various industrial and real-world scenarios, such as multilingual customer support systems, cross-border communication platforms, and international language learning tools. However, obtaining large-scale and high-quality datasets for SLU is challenging due to the high cost of dialogue collection and manual annotation, particularly for minority languages. As a result, there is increasing interest in leveraging high-resource language data for cross-lingual transfer learning. Existing approaches for zero-shot cross-lingual SLU primarily focus on the relationship between the source language sentence and the single generated cross-lingual sentence, disregarding the shared information among multiple languages. This limitation weakens the robustness of multilingual word embedding representations and hampers the scalability of the model. In this paper, we propose the multilingual mixture attention interaction framework with adversarial training to alleviate the above problems. Specifically, we leverage the source language sentence to generate multiple multilingual hybrid sentences, in which words can adaptively capture unambiguous representations from the aligned multilingual words during the encoding phase, and adversarial training is introduced to enhance the scalability of the model. Then, we incorporate the symmetric kernel self-attention module with positional embedding to learn contextual information within a sentence, and employ the multi-relation graph convolutional networks to learn different granularity information between two highly correlated intent detection and slot filling tasks. Experimental results on the public dataset MultiATIS++ demonstrate that our proposed model achieves state-of-the-art performance, and comprehensive analysis validates the effectiveness of each component.
Dynamic visual vending machines are rapidly growing in popularity, offering convenience and speed to customers. However, there is a prevalent issue with consumers damaging goods and then returning them to the machine, severely affecting business interests. This paper addresses the issue from the standpoint of defect detection. Although existing industrial defect detection algorithms, such as PatchCore, perform well, they face challenges, including handling goods in various orientations, detection speeds that do not meet real-time monitoring requirements, and complex backgrounds that hinder detection accuracy. These challenges hinder their application in dynamic vending environments. It is crucial to note that efficient visual features play a vital role in memory banks, yet current memory repositories for industrial inspection algorithms do not adequately address the problem of location-specific feature redundancy. To tackle these issues, this paper introduces a novel defect detection algorithm for goods using adaptive subsampling and partitioned memory banks. Firstly, Grad-CAM is utilized to extract deep features, which, in combination with shallow features, mitigate the impact of complex backgrounds on detection accuracy. Next, graph convolutional networks extract rotationally invariant features. The adaptive subsampling partitioned memory bank is then employed to store features of non-defective goods, which reduces memory consumption and enhances training speed. Experimental results on the MVTec AD dataset demonstrate that the proposed algorithm achieves a marked improvement in detection speed while maintaining accuracy that is comparable to state-of-the-art models.
Traditional Euclidean spatial data processing is difficult to capture the inherent relationships of unstructured data such as bearing vibration signals. Representing vibration signals in graphical form helps to preserve their topological structure and temporal information. Secondly, most existing graph convolutional network methods are based on large graph structured data, which incurs certain memory overhead when aggregating high-order neighborhood node information and ignores important information between samples in the global graph structure. To address these issues, this paper proposes a high-order multi-head graph attention network based on an adaptive small graph structure (ASG-HOMGAT) for fault diagnosis of rolling bearings. Firstly, the adaptive preprocessing layer is used to adaptively denoise and compress the one-dimensional time-domain vibration signal, generating small rule graph data with topological structure. Then, these small graph structured data samples are input into a higher-order graph neural network, which aggregates features from multiple higher-order neighborhoods to achieve richer feature representations and fully explore the intrinsic correlation between samples. Finally, these features are aggregated into a reinforced representation of graph nodes through a multi head attention mechanism, and a SoftMax classifier is used for fault classification. The experimental results show that the ASG-HOMGAT method has better performance compared to mainstream graph neural network diagnostic models. The code and model will be released at: https://github.com/ding-ss/ASG-HOMGAT.
Water ecosystems are highly sensitive to environmental conditions, including meteorological factors, which influence dissolved oxygen (DO) concentrations, a critical indicator of water quality. However, the complex relationships between multiple meteorological factors from various sites and DO concentrations pose a significant challenge for accurate prediction. This study introduces an innovative framework for enhancing DO concentration predictions in water bodies by integrating multi-station meteorological data. We first construct a dynamic meteorological graph with station-specific factors as node features and geographic distances as edge weights. This graph is processed using a Geo-Contextual Graph Embedding Module, leveraging a Graph Convolutional Network (GCN) to distill geographical and meteorological features from multi-station data. Extracted features are encoded and then temporally merged with historical DO values to form time-series data. Finally, a Temporal Transformer module is used for future DO concentration predictions. The proposed model shows superior performance compared to traditional methods, successfully capturing the complex relationships between meteorological factors and DO levels. It provides an effective tool for environmental scientists and policymakers in water quality monitoring and management. This study suggests that the integration of graph-based learning and a Temporal Transformer in environmental modeling is a promising direction for future research.
With the prevalence of accessible depth sensors, dynamic skeletons have attracted much attention as a robust modality for action recognition. Convolutional neural networks (CNNs) excel at modeling local relations within local receptive fields and are typically inefficient at capturing global relations. In this article, we first view the dynamic skeletons as a spatio-temporal graph (STG) and then learn the localized correlated features that generate the embedded nodes of the STG by message passing. To better extract global relational information, a novel model called spatial-temporal graph interaction networks (STG-INs) is proposed, which perform long-range temporal modeling of human body parts. In this model, human body parts are mapped to an interaction space where graph-based reasoning can be efficiently implemented via a graph convolutional network (GCN). After reasoning, global relation-aware features are distributed back to the embedded nodes of the STG. To evaluate our model, we conduct extensive experiments on three large-scale datasets. The experimental results demonstrate the effectiveness of our proposed model, which achieves the state-of-the-art performance.
Graphitic carbon nitride (g-C3N4) has emerged as a promising photocatalyst, but poor charge separation and low surface area limit its activity. Here, we report a hydrothermal method to generate hydrogen bonded supramolecular complex via water-based homogeneous supramolecular assembly, which is a promising precursor to fabricate porous and oxygen-doped g-C3N4. The hydrothermal treatment provides a homogeneous environment for hydrolysis of melamine to produce cyanuric acid and reaction of cyanuric acid with remained melamine to create the in-plane ordering and hydrogen bonded supramolecular complex. The complex can template uniform nanoporous structure and also provide an opportunity for O-doping in the g-C3N4 network upon calcination in air. The resulted g-C3N4(GCN-4) possesses high surface area, well-defined 3D morphology and oxygen-dopant in the lattice. Subsequently, the visible light absorption, charge separation, and wettability are considerably enhanced. This catalyst exhibits higher hydrogen evolution rate by 11.3 times than the bulk g-C3N4 under visible light irradiation, with apparent quantum efficiency of 10.3% at 420 mn.
Accurate traffic flow prediction is essential to building a smart transportation city. Existing research mainly uses a given single-graph structure as a model, only considers local and static spatial dependencies, and ignores the impact of dynamic spatio-temporal data diversity. To fully capture the characteristics of spatio-temporal data diversity, this paper proposes a cross-Attention Fusion Based Spatial-Temporal Multi-Graph Convolutional Network (CAFMGCN) model for traffic flow prediction. First, introduce GCN to model the historical traffic data's three-time attributes (current, daily, and weekly) to extract time features. Second, consider the relationship between distance and traffic flow, constructing adjacency, connectivity, and regional similarity graphs to capture dynamic spatial topology information. To make full use of global information, a cross-attention mechanism is introduced to fuse temporal and spatial features separately to reduce prediction errors. Finally, the CAFMGCN model is evaluated, and the experimental results show that the prediction of this model is more accurate and effective than the baseline of other models.
This paper presents new designs of graph convolutional neural networks (GCNs) on 3D meshes for 3D object segmentation and classification. We use the faces of the mesh as basic processing units and represent a 3D mesh as a graph where each node corresponds to a face. To enhance the descriptive power of the graph, we introduce a 1 ring face neighborhood structure to derive novel multi-dimensional spatial and structure features to represent the graph nodes. Based on this new graph representation, we then design a densely connected graph convolutional block which aggregates local and regional features as the key construction component to build effective and efficient practical GCN models for 3D object classification and segmentation. We present experimental results to show that our new technique performs comparably to state of the art across a number of benchmark datasets where our models are also shown to have smaller number of parameters. We also present ablation studies to demonstrate the soundness of our design principles and the effectiveness of our practical models. (c) 2021 Published by Elsevier B.V.
Tailoring the interfacial interaction between metal species and supports in supported electrocatalysts is of great importance for enhanced electrocatalytic performance. Herein, a highly active interface was engineered in S-doped graphitic carbon nitride (SGCN)-supported Pt heterostructured electrocatalysts toward fast oxygen reduction reaction (ORR). The coordination and electronic structure of Pt species is modulated with enhanced Pt-N bonding by S doping, which induces electron deficiency aacent C and N atoms a hence reinforces the metal-support interaction. The optimal 20Pt/SGCN-550 electrocatalyst exhibits excellent ORR performance with a half-wave potential of 0.91 V and a mass activity of 0.68 A mg(Pt)(-1), substantially surpassing that of 20Pt/GCN and commercial Pt/C. Besides, the 20Pt/SGCN-550 electrocatalyst achieves decent durability due to the superb stability of SGCN and the strong confinement effect at the interface. This work not only advances the development of robust ORR electrocatalysts but also offers a strategy to engineer heterostructured electrocatalysts with tunable interface chemistry toward various catalytic applications.
The graph neural network (GNN) has become a popular research area for its state-of-the-art performance in many graph analysis tasks. Recently, various graph neural network libraries have emerged. They make developing GNNs convenient, but the performance bottlenecks of GNNs on large datasets are not well studied. In this work, we analyze the performance bottlenecks in GNN training and inference with GPUs empirically. A GNN layer can be decomposed into two parts: the vertex and the edge calculation parts. We select four representative GNNs (GCN, GGNN, GAT, GaAN) for evaluation according to their computational complexity. We decompose their running time and memory usage, evaluate the effects of hyper-parameters and assess the efficiency of the sampling techniques. The experimental evaluation with PyTorch Geometric indicates that the edge-related calculation is the performance bottleneck for most GNNs, dominating the training/inference time and memory usage. The sampling techniques are essential for GNN training and inference on big graphs with GPUs, but their current implementation still has non-trivial overheads in sampling and data transferring. (c) 2021 Elsevier B.V. All rights reserved.
Knowledge graph embedding, which aims to address the limitation of symbolic representation of knowledge, has become an effective method for many AI downstream tasks, such as relation extraction, question answering. Existing knowledge graph embedding models mainly consider triples individually, and ignore the structural information connected with other entities. However, the connectivity between entities not only provides explicit structural information represented in triples, but also embodies a lot of implicit structure information. In this paper, a new knowledge graph embedding model is proposed, which can capture both the information of relational structure-context and edge structure-context by two-interaction. In addition, in order to model complex relations, we define different score function for different relation types. Moreover, the four relation connectivity types in knowledge graph (i.e. symmetry/antisymmetry, inversion, and composition) also can be modeled and inferred by StructurE. We evaluate our StructurE for knowledge graph link prediction task. Benefiting from the structural context and the relation-type-specific score function, compared with conventional geometric transformation based knowledge graph embedding models StructurE achieves state-of-the-art results for link prediction. Moreover, compared with GCN-based models StructurE also achieves state-of-the-art results on more challenging dataset WN18RR which contains more symmetric relations. (c) 2021 Elsevier B.V. All rights reserved.
Anomaly detection is a critical technique that ensures the reliability of WSNs. However, most existing anomaly detectionmethods only consider the case of single modal data flow anomaly detection for each node or multiple modal time series data flowanomaly detection for a single node and do not consider the case of multiple nodes and multiple time series data flow simultaneously,and it limited the ability of anomaly detection. In this paper, a novel anomaly detection model is proposed for multimodal WSN data flows. First, the temporal features and modal correlation features extracted from each sensor node are fused into one vectorrepresentation, then it is further aggregated with the spatial features represented the spatial position relationship of the nodes; finally,the current time-series data of WSN nodes are predicted, and abnormal states are identified according to the fusion features. Thesimulation results obtained on a public dataset show that the proposed approach can significantly improve upon existing methods interms of robustness, and its F1 score reaches 0.90, which is 14.2% higher than that of the graph convolution network (GCN) with longshort-term memory (LSTM).
Graph neural networks (GNNs) have shown great power in learning on graphs. However, it is still a challenge for GNNs to model information faraway from the source node. The ability to preserve global information can enhance graph representation and hence improve classification precision. In the paper, we propose a new learning framework named G-GNN (Global information for GNN) to address the challenge. First, the global structure and global attribute features of each node are obtained via unsupervised pre-training, and those global features preserve the global information associated with the node. Then, using the pre-trained global features and the raw attributes of the graph, a set of parallel kernel GNNs is used to learn different aspects from these heterogeneous features. Any general GNN can be used as a kernal and easily obtain the ability of preserving global information, without having to alter their own algorithms. Extensive experiments have shown that state-of-the-art models, e.g., GCN, GAT, Graphsage and APPNP, can achieve improvement with G-GNN on three standard evaluation datasets. Specially, we establish new benchmark precision records on Cora (84.31%) and Pubmed (80.95%) when learning on attributed graphs.
Background: Capmatinib, a potent and selective MET inhibitor, is an effective treatment option for nonsmall cell lung cancer (NSCLC) patients with MET exon 14 skipping mutations or gene amplification. However, the mechanisms that confer resistance to capmatinib remain elusive. Here, we present a case of primary resistance to capmatinib in a MET-amplified NSCLC patient which was conferred by concurrent Case Description: Capmatinib was administered as first-line treatment in an 82-year-old METamplified (Gene Copy Number (GCN) 13.5) and MET overexpressed (immunohistochemical staining 3+/3, >50%) NSCLC patient. However, the tumor rapidly progressed and showed primary resistance to capmatinib. Next-generation target sequencing using rebiopsy tumor samples revealed MYC amplification. We also performed functional drug susceptibility testing using patient-derived cells (PDCs), which showed overexpression of MYC mRNA and resistance to capmatinib. Meanwhile, ICX-101, an investigational MYC inhibitor, successfully inhibited the growth of PDCs at a relatively low IC50 value. Also, a synergistic effect was shown when capmatinib treatment was followed by ICX-101. Conclusions: Concurrent MYC amplification could potentially confer primary resistance to capmatinib in highly MET amplified NSCLC patients. Further clinical studies are warranted to corroborate these findings, and treatment with MYC inhibitors could be suggested as an alternative therapeutic strategy for this subset of patients.
Deep clustering is a promising technique for speech separation that is crucial to speech communication, acoustic target detection, acoustic enhancement and speech recognition. In the study of monophonic speech separation, the problem is that the decrease in separation and generalization performance of the model in the case of reducing the variety of the training data set. In this paper, we propose a comprehensive deep clustering framework that construction the structural speech data based on GCN, named graph deep clustering (GDC) to further improve the separation performance of the separation model. In particular, embedding features are transformed into graph-structured data, and the speech separation mask is achieved by clustering these graph-structured data. Graph structural information aggregates nodes within a class, which makes feature representations conducive to clustering. Experimental results demonstrate that the proposed scheme can improve the clustering performance. The SDR of the separated speech is improved by about 1.2 dB, and the clustering accuracy is improved by 15 & x0025;. We also use the perceptually motivated objective measures for the evaluation of audio source separation to score the speech quality. The target speech quality and the overall perceptual score are improved by 10.7 & x0025; compared with other speech separation algorithms.
Phasor measurement units (PMUs) are time-synchronized measurement devices that have been proliferated in transmission networks during the last two decades. Recently, there have been efforts to bring this technology to distribution grids for different applications such as three-phase state estimation, fault and event analyses, and phase identification. Streamed time-synchronized voltage and current phasor data can be used for events classification and region identification along distribution feeders to determine the type and location of events, which are important features of any fault and event detection, location, and isolation software. In this paper, the spectral theory-based graph convolution is used for event classification and region identification. The proposed model uses modified graph convolution filters to aggregate the regional multi-rate samples of PMU data, i.e., voltage magnitude and angles from several nodes. Besides these temporal data of the measured nodes, the physical configuration of the network containing edge features are given to the graph convolution network (GCN) to not only classify the event type, but also identify the affected region and location. The proposed graph-based method is tested on a standard test system with capacitor and distributed energy resources-related events, malfunction of voltage regulator, sudden load changes, and different types of faults. The results are compared with baseline methods, Chebyshev graph neural network (GNN), decision tree, logistic regression and K-nearest neighbor using the accuracy, recall, precision and F-1 score metrics. Furthermore, performance sensitivity analysis is carried out with respect to the number of installed PMUs, measurement noise level, size of available historical data, availability of network edge features, and different designs of GNN.
Leucine rich repeat LGI family member 3 (LGI3) is a member of the LGI protein family. Our previous studies reported that LGI3 was expressed in adipose tissues, brain and skin, where it served roles as a multifunctional cytokine and pro-inflammatory adipokine. It was hypothesized that LGI3 may be involved in cytokine networks in cancer. The present study aimed to analyze differentially expressed genes in non-small cell lung cancer (NSCLC) tissues and NSCLC cohort data, to evaluate the prognostic role of LGI3. Expression microarray and NSCLC cohort data were statistically analyzed by bioinformatic methods, and protein-protein interactions, functional enrichment and pathway, gene coexpression network (GCN) and prognostic association analyses were performed. The results demonstrated that the expression levels of LGI3 and its receptor a disintegrin and metalloproteinase domain-containing protein 22 were significantly decreased in NSCLC tissues. A total of two upregulated genes and 11 downregulated genes in NSCLC tissues were identified as LGI3-regulated genes. Protein-protein interaction network analysis demonstrated that all LGI3-regulated genes that were altered in NSCLC were involved in a protein-protein interaction network cluster. Functional enrichment, Kyoto Encyclopedia of Genes and Genomes pathway and GCN analyses demonstrated the association of these genes with the immune and inflammatory responses, angiogenesis, the tumor necrosis factor pathway, and chemokine and peroxisome proliferator-activated receptor signaling pathways. Analysis of NSCLC cohorts revealed that low expression levels of LGI3 was significantly associated with poor prognosis of NSCLC. Analysis of the somatic mutations of the LGI3 gene in NSCLC revealed that the amino acid residues altered in NSCLC included two single nucleotide polymorphism sites and three phylogenetically coevolved amino acid residues. Taken together, these results suggest that LGI3 may be a potential prognostic marker of NSCLC.
Multimedia-based recommendation (MMRec) is a challenging task, which goes beyond the collaborative filtering (CF) schema that only captures collaborative signals from interactions and explores multimodal user preference cues hidden in complex multimedia content. Despite the significant progress of current solutions for MMRec, we argue that they are limited by multimodal noise contamination. Specifically, a considerable amount of preference-irrelevant multimodal noise (e.g., the background, layout, and brightness in the image of the product) is incorporated into the representation learning of items, which contaminates the modeling of multimodal user preferences. Moreover, most of the latest researches are based on graph convolution networks (GCNs), which means that multimodal noise contamination is further amplified because noisy information is continuously propagated over the user-item interaction graph as recursive neighbor aggregations are performed. To address this problem, instead of the common MMRec paradigm which learns user preferences in an integrated manner, we propose a hierarchical framework to separately learn collaborative signals and multimodal preferences cues, thus preventing multimodal noise from flowing into collaborative signals. Then, to alleviate the noise contamination for multimodal user preference modeling, we propose to extract semantic entities from multimodal content that are more relevant to user interests, which can model semantic-level multimodal preferences and thus remove a large fraction of noise. Furthermore, we use the full multimodal features to model content-level multimodal preferences like the existing MMRec solutions, which ensures the sufficient utilization of multimodal information. Overall, we develop a novel model, multimodal hierarchical graph CF (MHGCF), which consists of three types of GCN modules tailored to capture collaborative signals, semantic-level preferences, and content-level preferences, respectively. We conduct extensive experiments to demonstrate the effectiveness of MHGCF and its components. The complete data and codes of MHGCF are available at.
Inferring missing links in Knowledge Graphs (KGs) is a key evaluation task for KG reasoning, which aims to find relations for a given entity pair. Existing research often employs the IDA* (Iterative Deepening A*) algorithm for the path discovery task owing to its efficiency and accuracy. However, it relies on heuristics to set cost functions and is also difficult to utilize useful context information in the search process. In this paper, we propose the Deep-IDA* framework which applies neural networks and reinforcement learning (RL) to empower the IDA* algorithm to tackle the path discovery problem in KG reasoning. We model KG reasoning as a Markov Decision Process (MDP) and divide our Deep-IDA* framework and the resulting path into two parts: path-finding and path-reasoning. For path-finding, we propose a policy network to model the cost from the source to a candidate location. In this process, we employ the GCN (Graph Convolutional Network) to embed the observable sub-track, then employ the LSTM (Long Short-Term Memory) to record the historical trajectory, and introduce the attention to utilize the context information, and finally form policy. For path-reasoning with the searched candidate paths passed from the former process, we employ a value network to estimate the cost from the candidate to the destination entity, using the GNN (Graph Neural Networks) to learn a message-passing algorithm that solves the path inference problem, and using the GRU (Gated Recurrent Unit) to update the historical information. Finally, the actor-learner algorithm is utilized to minimize the sum of the losses of the two parts. Experiment results on three datasets demonstrate the effectiveness and efficiency of our framework. (C) 2020 Elsevier B.V. All rights reserved.
Novel per-and polyfluoroalkyl substances (PFASs) in the environment and populations have received extensive attention; however, their distribution and potential toxic effects in the general population remain unclear. Here, a comprehensive study on PFAS screening was carried out in serum samples of 202 individuals from the general population in four cities in China. A total of 165 suspected PFASs were identified using target and nontarget analysis, including seven identified PFAS homolog series, of which 16 PFASs were validated against standards, and seven PFASs [4:2 chlorinated polyfluorinated ether sulfonate (4:2 ClPFESA), 7:2 chlorinated polyfluorinated ether sulfonate (7:2 Cl-PFESA), hydrosubstituted perfluoroheptanoate (H-PFHpA), chlorine-substituted perfluorooctanoate (Cl-PFOA), chlorine-substituted perfluorononanate (Cl-PFNA), chlorine-substituted perfluorodecanoate (Cl-PFDA), and perfluorodecanedioic acid (PFLDCA n = 8)] were reported for the first time in human serum. The Tox21-GCN model (a graph convolutional neural network model based on the Tox21 database) was established to predict the toxicity of the discovered PFASs, revealing that PFASs containing sulfonic acid groups exhibited multiple potential toxic effects, such as estrogenic effects and stress responses. Our study indicated that the general population was exposed to various PFASs, and the toxicity prediction results of individual PFASs suggested potential health risks that could not be ignored.
Transformers have demonstrated remarkable accomplishments in several natural language processing (NLP) tasks as well as image processing tasks. Herein, we present a deep-learning (DL) model that is capable of improving the semantic segmentation network in two ways. First, utilizing the pre-training Swin Transformer (SwinTF) under Vision Transformer (ViT) as a backbone, the model weights downstream tasks by joining task layers upon the pretrained encoder. Secondly, decoder designs are applied to our DL network with three decoder designs, U-Net, pyramid scene parsing (PSP) network, and feature pyramid network (FPN), to perform pixel-level segmentation. The results are compared with other image labeling state of the art (SOTA) methods, such as global convolutional network (GCN) and ViT. Extensive experiments show that our Swin Transformer (SwinTF) with decoder designs reached a new state of the art on the Thailand Isan Landsat-8 corpus (89.8% F1 score), Thailand North Landsat-8 corpus (63.12% F1 score), and competitive results on ISPRS Vaihingen. Moreover, both our best-proposed methods (SwinTF-PSP and SwinTF-FPN) even outperformed SwinTF with supervised pre-training ViT on the ImageNet-1K in the Thailand, Landsat-8, and ISPRS Vaihingen corpora.
Conventional image retrieval techniques for Structure-from-Motion (SfM) are limited in their ability to effectively distinguish symmetric or repetitive textured patterns and cannot guarantee an accurate generation of pairwise matches without costly redundancy. In this paper, we formulate the image retrieval task as a node binary classification problem with graph data: if a candidate node is marked as positive, it is believed to share the same scene with the query image. The key idea of our approach is that the local context in the feature space around a query image contains abundant information about the matchable relation between the image and its neighbours. By constructing a subgraph surrounding the query image as input data, we adopt a learnable Graph Convolutional Network (GCN) to deter-mine whether nodes in the subgraph have overlapping regions with the query photograph. Experiments demonstrate that our method performs remarkably well on a challenging dataset of highly ambiguous and duplicated scenes. Furthermore, compared with state -of-the-art matchable retrieval methods, the proposed approach significantly reduces unnecessary attempted matches without sacrificing the accuracy and completeness of reconstruction. (c) 2021 Elsevier Inc. All rights reserved.
Exploring multimorbidity relationships among diseases is of great importance for understanding their shared mechanisms, precise diagnosis and treatment. However, the landscape of multimorbidities is still far from complete due to the complex nature of multimorbidity. Although various types of biological data, such as biomolecules and clinical symptoms, have been used to identify multimorbidities, the population phenotype information (e.g. physical activity and diet) remains less explored for multimorbidity. Here, we present a graph convolutional network (GCN) model, named MorbidGCN, for multimorbidity prediction by integrating population phenotypes and disease network. Specifically, MorbidGCN treats the multimorbidity prediction as a missing link prediction problem in the disease network, where a novel feature selection method is embedded to select important phenotypes. Benchmarking results on two large-scale multimorbidity data sets, i.e. the UK Biobank (UKB) and Human Disease Network (HuDiNe) data sets, demonstrate that MorbidGCN outperforms other competitive methods. With MorbidGCN, 9742 and 14 010 novel multimorbidities are identified in the UKB and HuDiNe data sets, respectively. Moreover, we notice that the selected phenotypes that are generally differentially distributed between multimorbidity patients and single-disease patients can help interpret multimorbidities and show potential for prognosis of multimorbidities.
3D hand shape and pose estimation from a single depth map is a new and challenging computer vision problem with many applications. Existing methods addressing it directly regress hand meshes via 2D convolutional neural networks, which leads to artifacts due to perspective distortions in the images. To address the limitations of the existing methods, we develop HandVoxNet++, i.e., a voxel-based deep network with 3D and graph convolutions trained in a fully supervised manner. The input to our network is a 3D voxelized-depth-map-based on the truncated signed distance function (TSDF). HandVoxNet++ relies on two hand shape representations. The first one is the 3D voxelized grid of hand shape, which does not preserve the mesh topology and which is the most accurate representation. The second representation is the hand surface that preserves the mesh topology. We combine the advantages of both representations by aligning the hand surface to the voxelized hand shape either with a new neural Graph-Convolutions-based Mesh Registration (GCN-MeshReg) or classical segment-wise Non-Rigid Gravitational Approach (NRGA++) which does not rely on training data. In extensive evaluations on three public benchmarks, i.e., SynHand5M, depth-based HANDS19 challenge and HO-3D, the proposed HandVoxNet++ achieves the state-of-the-art performance. In this journal extension of our previous approach presented at CVPR 2020, we gain 41.09% and 13.7% higher shape alignment accuracy on SynHand5M and HANDS19 datasets, respectively. Our method is ranked first on the HANDS19 challenge dataset (Task 1: Depth-Based 3D Hand Pose Estimation) at the moment of the submission of our results to the portal in August 2020.
To explain how cartilage appeared in different parts of the vertebrate body at discrete times during evolution, we hypothesize that different embryonic populations co-opted expression of a core gene regulatory network (GRN) driving chondrocyte differentiation. To test this hypothesis, laser-capture microdissection coupled with RNA-seq was used to reveal chondrocyte transcriptomes in the developing chick humerus and ceratobranchial, which are mesoderm- and neural crest-derived, respectively. During endochondral ossification, two general types of chondrocytes differentiate. Immature chondrocytes (IMM) represent the early stages of cartilage differentiation, while mature chondrocytes (MAT) undergo additional stages of differentiation, including hypertrophy and stimulating matrix mineralization and degradation. Venn diagram analyses generally revealed a high degree of conservation between chondrocyte transcriptomes of the limb and head, including SOX9, COL2A1, and ACAN expression. Typical maturation genes, such as COL10A1, IBSP, and SPP1, were upregulated in MAT compared to IMM in both limb and head chondrocytes. Gene co-expression network (GCN) analyses of limb and head chondrocyte transcriptomes estimated the core GRN governing cartilage differentiation. Two discrete portions of the GCN contained genes that were differentially expressed in limb or head chondrocytes, but these genes were enriched for biological processes related to limb/forelimb morphogenesis or neural crest-dependent processes, respectively, perhaps simply reflecting the embryonic origin of the cells. A core GRN driving cartilage differentiation in limb and head was revealed that included typical chondrocyte differentiation and maturation markers, as well as putative novel "chondrocyte" genes. Conservation of a core transcriptional program during chondrocyte differentiation in both the limb and head suggest that the same core GRN was co-opted when cartilage appeared in different regions of the skeleton during vertebrate evolution.
To further improve the effect of gene modules identification, combining the Newman algorithm in community detection and K-means algorithm framework, a new method of gene module identification, GCNA-Kpca algorithm, was proposed. The core idea of the algorithm was to build a gene co-expression network (GCN) based on gene expression data firstly; Then the Newman algorithm was used to initially identify gene modules based on the topology of GCN, and the number of clusters and clustering centers were determined; Finally the number of clusters and clustering centers were input into the K-means algorithm framework, and the secondary clustering was performed based on the gene expression profile to obtain the final gene modules. The algorithm took into account the role of modularity in the clustering process, and could find the optimal membership module for each gene through multiple iterations. Experimental results showed that the algorithm proposed in this paper had the best performance in error rate, biological significance and CNN classification indicators (Precision, Recall and F-score). The gene module obtained by GCNA-Kpca was used for the task of key gene identification, and these key genes had the highest prognostic significance. Moreover, GCNA-Kpca algorithm was used to identify 10 key genes in hepatocellular carcinoma (HCC): CDC20, CCNB1, EIF4A3, H2AFX, NOP56, RFC4, NOP58, AURKA, PCNA, and FEN1. According to the validation, it was reasonable to speculate that these 10 key genes could be biomarkers for HCC. And NOP56 and NOP58 are key genes for HCC that we discovered for the first time.
Traditional collaborative filtering based recommender systems generally suffer from the interaction data sparsity problem. Therefore, social recommendation is proposed to mitigate the issue and improve recommendation performance by introducing social information. Existing social recommendation studies primarily focus on the direct connections between users, such as friendship or users' correlation. Unfortunately, there often is a severe data sparsity issue in above social data as well, which limits the performance of these models. In contrast, user-group relationships, another valuable social information that is formed by users joining the groups they are interested in, have received insufficient attention. In this paper, we focus on this relationship, demonstrate its excellent effectiveness in alleviating the problem of data sparsity, and integrate it into our recommendation model IGRec (Integrating user Group relationships for social Recommendation) in a reasonable way. Specifically, to address the problem that existing group-information-enhanced methods have not modeled users' collaborative interests and social influence in depth, we reformulate the available data into two bipartite graphs: user-item graph and user-group graph. And then employ more robust high-order GCN-based model combining a multi-layer attention mechanism to learn user and item representation from two graphs. Furthermore, we notice that due to the high complexity of user-group networks, the interests of some users in the same group may be far different, especially in those large-scale groups. The indiscriminate use of high-order neighbors' information in user-group graph may result in the introduction of negative information during the embedding propagation. Thus, to obtain a more precise representation for user and item, we propose to constrain the graph convolution operations at the social side inside subgraphs composed of users with similar interests and the groups they have joined in our model. Finally, experimental results on three real-world datasets clearly show the effectiveness of our proposed model. (C) 2022 Elsevier B.V. All rights reserved.
The recent methods for cross-network node classification mainly exploit graph neural networks (GNNs) as feature extractor to learn expressive graph representations across the source and target graphs. However, GNNs are vulnerable to noisy factors, such as adversarial attacks or perturbations on the node features or graph structure, which can cause a significant negative impact on their learning performance. To this end, we propose a robust graph domain adaptive learning framework RGDAL which exploits an information-theoretic principle to filter the noisy factors for cross-network node classification. Specifically, RGDAL utilizes graph convolutional network (GCN) with constrained graph mutual information and an adversarial learning component to learn noise-resistant and domain -invariant graph representations. To overcome the difficulties of estimating the mutual information for the non independent and identically distributed (non-i.i.d.) graph structured data, we design a dynamic neighborhood sampling strategy that can discretize the graph and incorporate the graph structural information for mutual information estimation. Experimental results on two real-world graph datasets demonstrate that RGDAL shows better robustness for cross-network node classification compared with the SOTA graph adaptive learning methods.(c) 2022 Elsevier B.V. All rights reserved.
Simple Summary With the development of circRNA-miRNA-mediated models, circRNAs have been shown to play a prominent role in the development and treatment of diseases such as cancer, and unearthing potential miRNA-associated circRNAs may provide new insights and ideas for the diagnosis and treatment of complex diseases such as cancer. Large-scale prediction using computer technology can provide an a priori guide to biological experiments and save costs. This paper presents the third computational method in this field with the highest accuracy to date, and we also collected and integrated high-quality datasets from the current database, which we believe will allow future computational innovations to develop. Computational prediction of miRNAs, diseases, and genes associated with circRNAs has important implications for circRNA research, as well as provides a reference for wet experiments to save costs and time. In this study, SGCNCMI, a computational model combining multimodal information and graph convolutional neural networks, combines node similarity to form node information and then predicts associated nodes using GCN with a distributive contribution mechanism. The model can be used not only to predict the molecular level of circRNA-miRNA interactions but also to predict circRNA-cancer and circRNA-gene associations. The AUCs of circRNA-miRNA, circRNA-disease, and circRNA-gene associations in the five-fold cross-validation experiment of SGCNCMI is 89.42%, 84.18%, and 82.44%, respectively. SGCNCMI is one of the few models in this field and achieved the best results. In addition, in our case study, six of the top ten relationship pairs with the highest prediction scores were verified in PubMed.
Spatio-temporal prediction has drawn much attention given its wide application, of which traffic flow prediction is a typical task. Within the vision of smart cities, traffic flow predic-tion plays a vital role in traffic control and optimization. The current approaches commonly use a graph convolutional network (GCN) to capture any spatial correlations and a recur-rent neural network (RNN) to mine any temporal correlations. However, GCNs cannot detect spatial heterogeneity and time-varying spatial correlations, and RNNs cannot model the periodicity of traffic series data. Further, iterative training of RNNs may come at a high computational cost and result in problems with error propagation. To this end, we propose STSSN, a spatio-temporal sequence-to-sequence network, that not only explores heteroge-neous and time-varying spatial correlations, but also efficiently exploits sequential and periodic temporal correlations. STSSN is based on an encoder-decoder framework. In the network, the model's input is processed to extract the periodic daily and weekly patterns in traffic flows. Both the encoder and decoder mainly consist of an enhanced diffusion con-volutional network (EDCN) and a temporal convolutional network (TCN). In the EDCN mod-ule, the diffusion convolution incorporates time-varying node representations so as to capture both node-specific patterns and time-varying spatial correlations. In the TCN mod-ule, we take full advantage of the parallel computing in the dilated causal convolution to mine local (short-term) temporal correlations. More importantly, global (long-term) tem-poral correlations are discovered through an encoder-decoder attention (EDA) module. This EDA mechanism directly models the relationship between the encoder and decoder to mitigate problems with error propagation. Experiments on two real-world datasets ver-ify the superiority of STSSN, with STSSN's MAE at between 3.85% -6.17% lower than the state-of-the-art baselines on the PEMS-BAY dataset.(c) 2022 Elsevier Inc. All rights reserved.
With the significant importance of riboflavin (RF) in food, biological, and pharmaceutical areas, precisely determining its level is critical for regulating health and nutrition, diagnosis/treatment of related diseases, pharmacological research, and food/drug quality monitoring. Thus, the sensitive and accurate determination of RF is necessary. Herein, we construct facile and low-cost ruthenium (Ru) doped cobalt phosphide (R-CoP) embedded graphitic carbon nitride as an electrode modifier via a two-step synthesis method. By the virtue of its unique physiochemical properties such as high active surface area (69.43 m(2)/g) compares to similar electrocatalyst and high electron transfer kinetics with low charge transfer resistance (R-ct = 367.89 omega), it has been successfully employed in the electrochemical evaluation of RF. In this regard, it has been effectively employed in the electrochemical evaluation of RF through cyclic voltammetry (CV) and amperometric (i t) techniques. The proposed R-CoP/GCN/GCE sensor shows exquisite electrochemical characteristics including a wide linear range (0.062 - 3468.75 mu M), Nanomolar detection limit (1.09 nM), and encouraging sensitivity (1.277 mu A mu M-1 cm(-2)). Moreover, it also exemplifies exquisite selectivity, repeatability, reproducibility, and storage stability therefore it has been employed in the practical feasibility analysis in various real samples which shows excellent recovery results. On comparing, it exemplifies excellent electrochemical performance than the similar electrocatalyst in the electrochemical sensing of biological compounds in various real samples.
Background Gene co-expression networks (GCNs) are powerful tools that enable biologists to examine associations between genes during different biological processes. With the advancement of new technologies, such as single-cell RNA sequencing (scRNA-seq), there is a need for developing novel network methods appropriate for new types of data. Results We present a novel sparse Bayesian factor model to explore the network structure associated with genes in scRNA-seq data. Latent factors impact the gene expression values for each cell and provide flexibility to account for common features of scRNA-seq: high proportions of zero values, increased cell-to-cell variability, and overdispersion due to abnormally large expression counts. From our model, we construct a GCN by analyzing the positive and negative associations of the factors that are shared between each pair of genes. Conclusions Simulation studies demonstrate that our methodology has high power in identifying gene-gene associations while maintaining a nominal false discovery rate. In real data analyses, our model identifies more known and predicted protein-protein interactions than other competing network models.
The disease image recognition models based on deep learning have achieved relative success under limited and restricted conditions, but such models are generally subjected to the shortcoming of weak robustness. The model accuracy would decrease obviously when recognizing disease images with complex backgrounds under field conditions. Moreover, most of the models based on deep learning only involve characterization learning on visual information in the image form, while the expression of other modal information rather than the image form is often ignored. The present study targeted the main invasive diseases in tomato and cucumber as the research object. Firstly, in response to the problem of weak robustness, a feature decomposition and recombination method was proposed to allow the model to learn image features at different granularities so as to accurately recognize different test images. Secondly, by extracting the disease feature words from the disease text description information composed of continuous vectors and recombining them into the disease graph structure text, the graph convolutional neural network (GCN) was then applied for feature learning. Finally, a vegetable disease recognition model based on the fusion of images and graph structure text was constructed. The results show that the recognition accuracy, precision, sensitivity, and specificity of the proposed model were 97.62, 92.81, 98.54, and 93.57%, respectively. This study improved the model robustness to a certain extent, and provides ideas and references for the research on the fusion method of image information and graph structure information in disease recognition.
Human action recognition has been applied in many fields, such as video surveillance and human computer interaction, where it helps to improve performance. Numerous reviews of the literature have been done, but rarely have these reviews concentrated on skeleton-graph-based approaches. Connecting the skeleton joints as in the physical appearance can naturally generate a graph. This paper provides an up-to-date review for readers on skeleton graph-neural-network-based human action recognition. After analyzing previous related studies, a new taxonomy for skeleton-GNN-based methods is proposed according to their designs, and their merits and demerits are analyzed. In addition, the datasets and codes are discussed. Finally, future research directions are suggested.
Salinity stress tolerance is a complex polygenic trait involving multi-molecular pathways. This study aims to demonstrate an effective transcriptomic approach for identifying genes regulating salt tolerance in rice. The chromosome segment substitution lines (CSSLs) of "Khao Dawk Mali 105 (KDML105)" rice containing various regions of DH212 between markers RM1003 and RM3362 displayed differential salt tolerance at the booting stage. CSSL16 and its nearly isogenic parent, KDML105, were used for transcriptome analysis. Differentially expressed genes in the leaves of seedlings, flag leaves, and second leaves of CSSL16 and KDML105 under normal and salt stress conditions were subjected to analyses based on gene co-expression network (GCN), on two-state co-expression with clustering coefficient (CC), and on weighted gene co-expression network (WGCN). GCN identified 57 genes, while 30 and 59 genes were identified using CC and WGCN, respectively. With the three methods, some of the identified genes overlapped, bringing the maximum number of predicted salt tolerance genes to 92. Among the 92 genes, nine genes, OsNodulin, OsBTBZ1, OsPSB28, OsERD, OsSub34, peroxidase precursor genes, and three expressed protein genes, displayed SNPs between CSSL16 and KDML105. The nine genes were differentially expressed in CSSL16 and KDML105 under normal and salt stress conditions. OsBTBZ1 and OsERD were identified by the three methods. These results suggest that the transcriptomic approach described here effectively identified the genes regulating salt tolerance in rice and support the identification of appropriate QTL for salt tolerance improvement.
Carbon nitride is widely used in photocatalytic hydrogen production, but it is still difficult to split water without any sacrificial reagent. Herein, nanosized Fe2O3 is combined with 3D nitrogen-rich carbon nitride tubes (ACN), to form an Fe2O3@ACN Z-scheme heterojunction, which accelerates the electrons' transfer from Fe2O3 to ACN and improves the charge separation efficiency. Meanwhile, the bandgap of Fe2O3@ACN is about 2.01 eV, beneficial to the enhancement of visible light absorption capacity. As a result, without any sacrificial agent, the hydrogen evolution rate reaches 3.7 mu mol h(-1) (10 mg catalyst, AM1.5) through water splitting, which is three times that of ACN and 45 times that of bulk C3N4 (GCN). This work provides a new strategy to prompt pure water splitting based on carbon nitride catalysts.
Large-scale multi-label image classification requires determining the presence or absence of a target object in a large number of sample images. For highly specialized and complex multi-label image sets, it is especially important to ensure the accuracy of image classification. Traditional deep learning models usually don't take into account image-label correlation constraints when classifying multi-label images, and the strategy of classifying images based only on their own features greatly limits the model performance. In this context, this paper focuses a deep learning-based cluster analysis method for large-scale multi-label images. We constructed a model for large-scale multi-label image category recognition, which consists of a global image feature extraction module, a feature activation vector generation module and an image category inter-label connection module. Using a graph convolutional network (GCN), we aggregated the information of image category label nodes in the constructed multi-label graph structure, while exploring the correlation between image category labels. A detailed description is presented on how to introduce the attention mechanism into the constructed model mentioned above for image category recognition. Experimental results have validated the effectiveness of the constructed model.
Crowd flow prediction is an essential task benefiting a wide range of applications for the transportation system and public safety. However, it is a challenging problem due to the complex spatio-temporal dependence and the complicated impact of urban structure on the crowd flow patterns. In this article, we propose a novel framework, 3-Dimensional Graph Convolution Network (3DGCN), to predict citywide crowd flow. We first model it as a dynamic spatio-temporal graph prediction problem, where each node represents a region with time-varying flows, and each edge represents the origin-destination (OD) flow between its corresponding regions. As such, OD flows among regions are treated as a proxy for the spatial interactions among regions. To tackle the complex spatio-temporal dependence, our proposed 3DGCN can model the correlation among graph spatial and temporal neighbors simultaneously. To learn and incorporate urban structures in crowd flow prediction, we design the GCN aggregator to be learned from both crowd flow prediction and region function inference at the same time. Extensive experiments with real-world datasets in two cities demonstrate that our model outperforms state-of-the-art baselines by 9.6%similar to 19.5% for the next-time-interval prediction.
Person re-identification (re-id) aims to identity the same person over multiple cameras; it has been successfully applied to various computer vision applications as a fundamental method. Owing to the development of deep learning, person re-id methods, which typically use triplet networks based on triplet loss, have demonstrated great success. However, the appearances of people are similar and hence difficult to distinguish in many cases. Therefore, we present a novel graph convolution network and enhances traditional triplet loss functions. Our method defines reference, positive, and negative features for triplet loss as three vertices of a graph, respectively, and adjusts their mutual distance through learning. The method adopts graph convolutions efficiently, thereby affording low computational costs. Experimental results demonstrate that our method is superior to the baseline on the Market-1501 dataset. The proposed GCN-based triplet loss considerably contributes to improve re-identification methods quantitatively and qualitatively.
Different synthesis temperatures (450-550 degrees C) were applied to synthesize g-C3N4 with the highest visible-light triggered photocatalytic activity. The best performing g-C3N4 photocatalyst was synthesized at 550 degrees C due to the created favourable structure that expressed the lowest band gap and charge carrier recombination rate. To further improve the photocatalytic activity of g-C3N4, different g-C3N4/TiO2 (gCN/TNP) composites with varying weight concentrations of g-C3N4 and TiO2 were prepared. Charge carrier separation was enabled due to the injection of photogenerated electrons from the g-C3N4 conduction band (CB) to the TiO2 CB, where they reacted with water-dissolved oxygen to form reactive oxygen species. The best performing composite was 0.50gCN/TNP 2 h with 50 wt% of g-C3N4 and 2 h calcination at 350 degrees C. The improved photocatalytic activity is due to an appropriate ratio between the shielding effect of TiO2, higher contact area and the consecutive improvement of the charge carrier separation, which is the key determining factor.
Distantly supervised relation extraction is a prevalent technique for identifying semantic relations between two entities. Most prior models cannot distinguish the local and global information in the long-range dependency among words effectively. The latent semantic information presented in existing knowledge graphs is completely neglected, as the knowledge graph information is simply used as a label to specify the class of relations instead of being treated as a graph. Moreover, previous studies only utilized a selective attention mechanism over sentences to alleviate the impact of noise; they did not consider the implicit interaction between sentences in a sentence bag. In this paper, (1) we propose a knowledge-aware framework to enhance word representations, which can highlight the importance of key words and relation clues; (2) we adopt a piecewise self-attention mechanism to model long-range dependency among words; (3) we design a heterogeneous graph structure for each sentence bag and introduce a heterogeneous graph convolutional network with knowledge attention to aggregate the implicit interaction among sentences from a local-to-global perspective. Experimental results on two popular relation extraction datasets demonstrate that our model obtains more discriminative relation representations and outperforms most of the state-of-the-art models. (C) 2021 Elsevier B.V. All rights reserved.
Deep learning has recently demonstrated its promising performance for vision-based parking-slot detection. However, very few existing methods explicitly take into account learning the link information of the marking-points, resulting in complex post-processing and erroneous detection. In this letter, we propose an attentional graph neural network based parking-slot detection method, which refers the marking-points in an around-view image as graph-structured data and utilize graph neural network to aggregate the neighboring information between marking-points. Without any manually designed post-processing, the proposed method is end-to-end trainable. Extensive experiments have been conducted on public benchmark dataset, where the proposed method achieves state-of-the-art accuracy. Code is publicly available at https://github.com/Jiaolong/gcn-parking-slot.
Triplet repeat diseases (TRDs) refer to a group of diseases caused by three nucleotide repeats elongated beyond a pathologic threshold. TRDs are divided into the following four groups depending on the pathomechanisms, although the pathomechanisms of several diseases remain unelucidated: polyglutamine disorders, caused by a pathologic repeat expansion of CAG (coding the amino acid glutamine) located within the exon; loss-of-function repeat disorders, characterized by the common feature of a loss of function of the gene within which they occur; RNA gain-of-function disorders, involving the production of a toxic RNA species; and polyalanine disorders, caused by a pathologic repeat expansion of GCN (coding the amino acid alanine) located within the exon. Many of these TRDs manifest through neurologic symptoms; moreover, neuroimaging, especially brain magnetic resonance imaging, plays a pivotal role in the detection of abnormalities, differentiation, and management of TRDs. In this article, we reviewed the clinical and neuroimaging features of TRDs. An early diagnosis of TRDs through clinical and imaging approaches is important and may contribute to appropriate medical intervention for patients and their families.
There has been a surge of recent interest in graph representation learning (GRL). GRL methods have generally fallen into three main categories, based on the availability of la-beled data. The first, network embedding, focuses on learning unsupervised representations of relational structure. The second, graph regularized neural networks, leverages graphs to augment neural network losses with a regularization objective for semi-supervised learning. The third, graph neural networks, aims to learn differentiable functions over discrete topolo-gies with arbitrary structure. However, despite the popularity of these areas there has been surprisingly little work on unifying the three paradigms. Here, we aim to bridge the gap between network embedding, graph regularization and graph neural networks. We pro-pose a comprehensive taxonomy of GRL methods, aiming to unify several disparate bodies of work. Specifically, we propose the GRAPHEDM framework, which generalizes popular algorithms for semi-supervised learning (e.g. GraphSage, GCN, GAT), and unsupervised learning (e.g. DeepWalk, node2vec) of graph representations into a single consistent ap-proach. To illustrate the generality of GRAPHEDM, we fit over thirty existing methods into this framework. We believe that this unifying view both provides a solid foundation for understanding the intuition behind these methods, and enables future research in the area.
Aim We propose a novel graph rank-based average pooling neural network (GRAPNN) to detect secondary pulmonary tuberculosis patients via chest CT imaging. Methods First, we propose a novel rank-based pooling neural network (RAPNN) to learn the individual image-level features from chest CT images. Second, we integrate the graph convolutional network (GCN), which learns relation-aware representation among the batch of chest CT images, to RAPNN. Third, we build a novel Graph RAPNN (GRAPNN) model based on the previous integration via k-means clustering and k-nearest neighbors' algorithm. Besides, an improved data augmentation is utilized to handle overfitting problem. Grad-ACM is used to make this GRAPNN model explainable. Results This proposed GRAPNN method is compared with seven state-of-the-art algorithms. The results showed GRAPNN model yields the best performances with a sensitivity of 94.65%, a specificity of 95.12%, a precision of 95.17%, an accuracy of 94.88%, and an F1 score of 94.87%. Conclusions Our GRAPNN is superior to other seven state-of-the-art approaches. The explainable mechanism in our method can identify the lesions of important lung parts (tuberculosis cavities and surrounding small lesions) for transparent decision.
Defect engineering is an effective path to prune the performance of photocatalysts but are rarely reported in graphene-semiconductor composites. Here, the few-layered graphene materials with different defect contents are obtained through facile alkali-assisted "cutting-thin" technique. Meanwhile, the monolayer graphene with low defect content is also synthesized on a variety of biomasses via the same uncomplicated process. Importantly, the defects in few-layered graphene have been established as an important platform to research the relationship between catalytic activity and defect. Therefore, a series of graphene-GCN photocatalysts with different defect contents were prepared by the wet-chemistry synthesis process. Compared to more defects and less content of defects, the optimal defect content displays greatly improved H-2 production rate. Therefore, a suitable defect content in graphene can not only increase the photogenerated electron transport, but also hinder the photoinduced electron recombination. This successful application of defect engineering is awaited to furnish guidance for intelligent contexture of graphene-based photocatalyst for extensive uptake in other directions, including photoelectrochemical sensors, dye-sensitized solar cells, and photocatalytic CO2 reduction. (C) 2021 Elsevier B.V. All rights reserved.
Proteins are the fundamental biological macromolecules which underline practically all biological activities. Protein-protein interactions (PPIs), as they are known, are how proteins interact with other proteins in their environment to perform biological functions. Understanding PPIs reveals how cells behave and operate, such as the antigen recognition and signal transduction in the immune system. In the past decades, many computational methods have been developed to predict PPIs automatically, requiring less time and resources than experimental techniques. In this paper, we present a comparative study of various graph neural networks for protein-protein interaction prediction. Five network models are analyzed and compared, including neural networks (NN), graph convolutional neural networks (GCN), graph attention networks (GAT), hyperbolic neural networks (HNN), and hyperbolic graph convolutions (HGCN). By utilizing the protein sequence information, all of these models can predict the interaction between proteins. Fourteen PPI datasets are extracted and utilized to compare the prediction performance of all these methods. The experimental results show that hyperbolic graph neural networks tend to have a better performance than the other methods on the protein-related datasets.
The adversarial attack methods based on gradient information can adequately find the perturbations, that is, the combinations of rewired links, thereby reducing the effectiveness of the deep learning model-based graph embedding algorithms, but it is also easy to fall into a local optimum. Therefore, this article proposes a momentum gradient attack (MGA) against the graph convolutional network (GCN) model, which can achieve more aggressive attacks with fewer rewiring links. Compared with directly updating the original network using gradient information, integrating the momentum term into the iterative process can stabilize the updating direction, which makes the model jump out of poor local optimum and enhances the method with stronger transferability. Experiments on node classification and community detection methods based on three well-known network embedding algorithms show that MGA has a better attack effect and transferability.
Learning to infer missing links is one of the fundamental tasks in the knowledge graph. Instead of reasoning based on separate paths in the existing methods, in this paper, we propose a new model, Sequential Relational Graph Convolutional Network (SRGCN), which treats the multiple paths between an entity pair as a sequence of subgraphs. Specifically, to reason the relationship between two entities, we first construct a graph for the entities based on the knowledge graph and serialize the graph to a sequence. For each hop in the sequence, Relational Graph Convolutional Network (R-GCN) is then applied to update the embeddings of the entities. The updated embedding of the tail entity contains information of the entire graph, hence the relationship between two entities can be inferred from it. Compared to the existing approaches that deal with paths separately, SRGCN treats the graph as a whole, which can encode structural information and interactions between paths better. Experiments show that SRGCN outperforms path-based baselines on both link and fact prediction tasks. We also show that SRGCN is highly efficient in the sense that only one epoch of training is enough to achieve high accuracy, and even partial datasets can lead to competitive performance. (c) 2021 Elsevier B.V. All rights reserved.
Oculopharyngeal muscular dystrophy (OPMD) is a late-onset intractable myopathy, characterized by slowly progressive ptosis, dysphagia, and proximal limb weakness. It is caused by the abnormal expansion of the alanine-encoding (GCN)n trinucleotide repeat in the exon 1 of the polyadenosine (poly[A]) binding protein nuclear 1 gene (11-18 repeats in OPMD instead of the normal 10 repeats). As the disease progresses, the patients gradually develop a feeling of suffocation, regurgitation of food, and aspiration pneumonia, although the initial symptoms and the progression patterns vary among the patients. Autologous myoblast transplantation may provide therapeutic benefits by reducing swallowing problems in these patients. Therefore, it is important to assemble information on such patients for the introduction of effective treatments in nonendemic areas. Herein, we present a concise review of recent progress in clinical and pathological studies of OPMD and introduce an idea for setting up a nation-wide OPMD disease registry in Japan. Since it is important to understand patients' unmet medical needs, realize therapeutically targetable symptoms, and identify indices of therapeutic efficacy, our attempt to establish a unique patient registry of OPMD will be a helpful tool to address these urgent issues.
Tracking the behaviour of animals in group-housed situations is a critical area of study for precision livestock farming, but it poses challenges in diverse and crowded environments. Existing methods often struggle with false positives and false negatives due to the complexities of these scenarios. In this study, we propose a robust computer vision algorithm for long-term (>10mins) animal tracking, with a primary focus on group-housed pigs. Our method addresses the limitations of current approaches by effectively handling errors from the detector in challenging environments. Our approach integrates Graph Convolutional Networks.(GCNs) with deep learning-based object detection techniques. We represent the data as a graph structure, with nodes corresponding to multiple animal detections over several frames. Edges connect the detections that do not appear in the same frame. The model's objective is to perform edge classification, where each edge is associated with a scalar representing the probability of being the same object. To enhance the robustness of edge classification, we combine the classifier with an ensemble predictor, enabling accurate tracking of animal identities for extended periods. Notably, our graph convolutional model achieves accurate re identification of non-consecutive animal detections in real-time without the need for trajectory prediction or ID association. We evaluate our method by comparing its performance against other tracking methods, including DeepSORT-a state-of-the-art animal tracking method that relies on a Kalman filter, a deep appearance descriptor, and the Hungarian algorithm for trajectory prediction and ID association. Our comparison demonstrates the advantages of our method, as it (1) improves the IDF1 score, indicating enhanced ID association accuracy, by 1.72%; (2) mitigates 93% of errors resulting from ID-switch and deviation; (3) extends the tracking duration of each animal by approximately 66% in challenging conditions; and (4) achieves a processing speed that is 1000 times faster than DeepSORT when operating at 22fps with the detector. The potential applications of our method extend to various aspects of livestock management. By accurately tracking individual animals, we can monitor behaviours such as feeding, drinking, and aggressive interactions. This information can lead to improvements in animal welfare, resource allocation, and breeding strategies. Follow-ups of this research are available at: https://gitlab.kuleuven.be/m3-biores/public/m3pig.
Facial reenactment is aimed at animating a source face image into a new place using a driving facial picture. In a few shot scenarios, the present strategies are designed with one or more identities or identity-sustained suffering protection challenges. These current solutions are either developed with one or more identities in mind, or face identity protection issues in one or more shot situations. Multiple pictures from the same entity have been used in previous research to model facial reenactment. In contrast, this paper presents a novel model of one-shot many-to-many facial reenactments that uses only one facial image of a face. The proposed model produces a face that represents the objective representation of the same source identity. The proposed technique can simulate motion from a single image by decomposing an object into two layers. Using bi-layer with Convolutional Neural Network (CNN), we named our model Bi-Layer Graph Convolutional Layers (BGCLN) which utilized to create the latent vector's optical flow representation. This yields the precise structure and shape of the optical stream. Comprehensive studies suggest that our technique can produce high-quality results and outperform most recent techniques in both qualitative and quantitative data comparisons. Our proposed system can perform facial reenactment at 15 fps, which is approximately real time. Our code is publicly available at https://github.com/usaeed786/BGCLN. (c) 2022 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
Due to the inherent vulnerability of deep neural networks (DNNs), the adversarial example (AE) attack has become a serious threat to intelligent systems, e.g., the failure cause of an image classification system. Different to existing works, in this article we are interested in the generation of AEs for DNNs with defensive mechanisms. To make the attack more practical, we exploit a query-based method to generate image AEs in a black-box attack setting. Considering that the generation of AEs is inherently a constrained optimization problem, this article first formulates three objectives regarding defensive DNNs, i.e., attack effectiveness, attack evasiveness and attack coverage. Then, this article proposes a query-efficient AE attack based on the genetic algorithm (GA) and particle swarm optimization (PSO) to address the perturbation optimization problem. To improve the efficiency of search and query, AE-specific operators including block-level and pixel-level crossovers, discrete perturbation mutation and direction-driven reproduction are designed within the GA-based search framework. In addition, predication-based adaptation of reproduction-related parameters is implemented to speed up the search convergence. PSO-based jumping process is further devised to avoid stuck in local optimum. Benchmark-based experiments evaluated the efficiency of our method, which can achieve an attack success rate of 100% with averagely 52.95% reduced queries in contrast to existing black-box attacks on nondefensive models. For defensive DNN models, our method can obtain top attack performance with the query reduction up to 70.92% comparing with the candidates.
BACKGROUND: To establish a predictive model based on multisequence magnetic resonance imaging (MRI) using deep learning to identify wild-type (WT) epidermal growth factor receptor (EGFR), EGFR exon 19 deletion (19Del), and EGFR exon 21-point mutation (21L858R) simultaneously. METHODS: A total of 399 patients with proven brain metastases of non-small cell lung cancer (NSCLC) were retrospectively enrolled and divided into training (n = 306) and testing (n = 93) cohorts separately based on two timepoints. All patients underwent 3.0-T brain MRI including T2-weighted, T2-weighted fluid-attenuated inversion recovery, diffusion-weighted imaging, and contrast-enhanced T1-weighted sequences. Radiomics features were extracted from each lesion based on four sequences. An algorithm combining radiomics approach with graph convolutional networks architecture (Radio-GCN) was designed for the prediction of EGFR mutation status and subtype. The area under the curve (AUC) at receiver operating characteristic analysis was used to evaluate the predication capabilities of each model. RESULTS: We extracted 1,290 radiomics features from each MRI sequence. The AUCs of the Radio-GCN model for identifying EGFR 19Del, 21L858R, and WT for the lesion-wise analysis were 0.996 ± 0.004, 0.971 ± 0.013, and 1.000 ± 0.000 on the independent testing cohort separately. It also yielded AUCs of 1.000 ± 0.000, 0.991 ± 0.009, and 1.000 ± 0.000for predicting EGFR mutations respectively for the patient-wise analysis. The kappa coefficients were 0.735 and 0.812, respectively. CONCLUSIONS: The constructed Radio-GCN model is a new potential tool to predict the EGFR mutation status and subtype in NSCLC patients with brain metastases. RELEVANCE STATEMENT: The study demonstrated that a deep learning approach based on multisequence MRI can help to predict the EGFR mutation status in NSCLC patients with brain metastases, which is beneficial to guide a personalized treatment. KEY POINTS:  This is the first study to predict the EGFR mutation subtype simultaneously.  The Radio-GCN model holds the potential to be used as a diagnostic tool.  This study provides an imaging surrogate for identifying the EGFR mutation subtype.
Non-stationarity of EEG signals leads to high variability between subjects, making it challenging to directly use data from other subjects (source domain) for the classifier in the current subject (target domain). In this study, we propose MI-DAGSC to address domain adaptation challenges in EEG-based motor imagery (MI) decoding. By combining domain-level information, class-level information, and inter-sample structure information, our model effectively aligns the feature distributions of source and target domains. This work is an extension of our previous domain adaptation work MI-DABAN (Li et al., 2023). Based on MI-DABAN, MI-DAGSC designs Sample-Feature Blocks (SFBs) and Graph Convolution Blocks (GCBs) to focus on intra-sample and inter-sample information. The synergistic integration of SFBs and GCBs enable the model to capture comprehensive information and understand the relationship between samples, thus improving representation learning. Furthermore, we introduce a triplet loss to enhance the alignment and compactness of feature representations. Extensive experiments on real EEG datasets demonstrate the effectiveness of MI-DAGSC, confirming that our method makes a valuable contribution to the MI-EEG decoding. Moreover, it holds great potential for various applications in brain-computer interface systems and neuroscience research. And the code of the proposed architecture in this study is available under https://github.com/zhangdx21/MI-DAGSC.& COPY; 2023 Elsevier Ltd. All rights reserved.
Background: Gene co-expression networks (GCNs) can be used to determine gene regulation and attribute gene function to biological processes. Different high throughput technologies, including one and two-channel microarrays and RNA-sequencing, allow evaluating thousands of gene expression data simultaneously, but these methodologies provide results that cannot be directly compared. Thus, it is complex to analyze co-expression relations between genes, especially when there are missing values arising for experimental reasons. Networks are a helpful tool for studying gene co-expression, where nodes represent genes and edges represent co-expression of pairs of genes. Results: In this paper, we establish a method for constructing a gene co-expression network for the Anopheles gambiae transcriptome from 257 unique studies obtained with different methodologies and experimental designs. We introduce the sliding threshold approach to select node pairs with high Pearson correlation coefficients. The resulting network, which we name AgGCN1.0, is robust to random removal of conditions and has similar characteristics to small-world and scale-free networks. Analysis of network sub-graphs revealed that the core is largely comprised of genes that encode components of the mitochondrial respiratory chain and the ribosome, while different communities are enriched for genes involved in distinct biological processes. Conclusion: Analysis of the network reveals that both the architecture of the core sub-network and the network communities are based on gene function, supporting the power of the proposed method for GCN construction. Application of network science methodology reveals that the overall network structure is driven to maximize the integration of essential cellular functions, possibly allowing the flexibility to add novel functions.
The construction industry is accident-prone, and unsafe behaviors of construction workers have been identified as a leading cause of accidents. One important countermeasure to prevent accidents is monitoring and managing those unsafe behaviors. The most popular way of detecting and identifying workers' unsafe behaviors is the computer vision-based intelligent monitoring system. However, most of the existing research or products focused only on the workers' behaviors (i.e., motions) recognition, limited studies considered the interaction between man-machine, man-material or man-environments. Those interactions are very important for judging whether the workers' behaviors are safe or not, from the standpoint of safety management. This study aims to develop a new method of identifying construction workers' unsafe behaviors, i.e., unsafe interaction between man-machine/material, based on ST-GCN (Spatial Temporal Graph Convolutional Networks) and YOLO (You Only Look Once), which could provide more direct and valuable information for safety management. In this study, two trained YOLO-based models were, respectively, used to detect safety signs in the workplace, and objects that interacted with workers. Then, an ST-GCN model was trained to detect and identify workers' behaviors. Lastly, a decision algorithm was developed considering interactions between man-machine/material, based on YOLO and ST-GCN results. Results show good performance of the developed method, compared to only using ST-GCN, the accuracy was significantly improved from 51.79% to 85.71%, 61.61% to 99.11%, and 58.04% to 100.00%, respectively, in the identification of the following three kinds of behaviors, throwing (throwing hammer, throwing bottle), operating (turning on switch, putting bottle), and crossing (crossing railing and crossing obstacle). The findings of the study have some practical implications for safety management, especially workers' behavior monitoring and management.
To increase the success in Covid 19 treatment, many drug suggestions are presented, and some clinical studies are shared in the literature. There have been some attempts to use some of these drugs in combination. However, using more than one drug together may cause serious side effects on patients. Therefore, detecting drug-drug interactions of the drugs used will be of great importance in the treatment of Covid 19. In this study, the interactions of 8 drugs used for Covid 19 treatment with 645 different drugs and possible side effects estimates have been produced using Graph Convolutional Networks. As a result of the experiments, it has been found that the hematopoietic system and the cardiovascular system are exposed to more side effects than other organs. Among the focused drugs, Heparin and Atazanavir appear to cause more adverse reactions than other drugs. In addition, as it is known that some of these 8 drugs are used together in Covid-19 treatment, the side effects caused by using these drugs together are shared. With the experimental results obtained, it is aimed to facilitate the selection of the drugs and increase the success of Covid 19 treatment according to the targeted patient.
Knowledge tracing models have gained prominence in educational data mining, with applications like the Self-Attention Knowledge Tracing model, which captures the exercise-knowledge relationship. However, conventional knowledge tracing models focus solely on static question-knowledge and knowledge-knowledge relationships, treating them with equal significance. This simplistic approach often succumbs to subjective labeling bias and lacks the depth to capture nuanced exercise-knowledge connections. In this study, we propose a novel knowledge tracing model called Knowledge Relation Rank Enhanced Heterogeneous Learning Interaction Modeling for Neural Graph Forgetting Knowledge Tracing. Our model mitigates the impact of subjective labeling by fine-tuning the skill relation matrix and Q-matrix. Additionally, we employ Graph Convolutional Networks (GCNs) to capture intricate interactions between students, exercises, and skills. Specifically, the Knowledge Relation Importance Rank Calibration method is employed to generate the skill relation matrix and Q-matrix. These calibrated matrices, alongside heterogeneous interactions, serve as input for the GCN to compute exercise and skill embeddings. Subsequently, exercise embeddings, skill embeddings, item difficulty, and contingency tables collectively contribute to an exercise relation matrix, which is then fed into an attention mechanism for predictions. Experimental evaluations on two publicly available educational datasets demonstrate the superiority of our proposed model over baseline models, evidenced by enhanced performance across three evaluation metrics.
Rumor source detection has long been an important but difficult problem. Due to the complexity of the underlying propagation model, most existing methods only rely on the limit observation of a single batch of single snapshot during the propagation process in the spatial graph networks, which neglects temporal dependency and temporal features of the rumor propagation process. Taking multiple batches of multiple snapshots as input can reveal the temporal dependency. Inspired by the traditional spatial-temporal graph convolution network (STGCN), which is a model that can combine spatial and temporal features. In this paper, we propose a STGCN based model called Spatio-Temporal Approximate Personalized Propagation of Neural Predictions (STAPPNP), which firstly learns both the spatial and temporal features automatically from multiple batches of multiple snapshots to locate the rumor source. As there are no input algorithms that are suitable for multiple batches of multiple snapshots to capture the feature of nodes' connectivity in STAPPNP, we develop an input algorithm to generate a 4-dimensional input matrix from the multiple batches of multiple snapshots to feed the proposed model. Nonetheless, for deep learning models, such input of multiple batches of multiple snapshots requires multiple convolutional layers to extract spatial features. Too many convolutional layers can lead to over-smoothing and long training time. To address these issues, we improve the Spatio-Temporal-Convolutional(ST-Conv) block, in which we adopt the approximate personalized propagation of neural predictions in the spatial convolutional layer of STAPPNP. Our experimental results show that the accuracy of the rumor source detection is improved by using STAPPNP, and the speed of the training process of STAPPNP outperforms state-of-the-art deep learning approaches under the popular epidemic susceptible-infected (SI) and susceptible-infected-recovery (SIR) models in social networks.
In the field of environmental science, traditional methods for predicting PM2.5 concentrations primarily focus on singular temporal or spatial dimensions. This approach presents certain limitations when it comes to deeply mining the joint influence of multiple monitoring sites and their inherent connections with meteorological factors. To address this issue, we introduce an innovative deep-learning-based multi-graph model using Beijing as the study case. This model consists of two key modules: firstly, the 'Meteorological Factor Spatio-Temporal Feature Extraction Module'. This module deeply integrates spatio-temporal features of hourly meteorological data by employing Graph Convolutional Networks (GCN) and Long Short-Term Memory (LSTM) for spatial and temporal encoding respectively. Subsequently, through an attention mechanism, it retrieves a feature tensor associated with air pollutants. Secondly, these features are amalgamated with PM2.5 concentration values, allowing the 'PM2.5 Concentration Prediction Module' to predict with enhanced accuracy the joint influence across multiple monitoring sites. Our model exhibits significant advantages over traditional methods in processing the joint impact of multiple sites and their associated meteorological factors. By providing new perspectives and tools for the in-depth understanding of urban air pollutant distribution and optimization of air quality management, this model propels us towards a more comprehensive approach in tackling air pollution issues.
This paper proposes a new method for blind mesh visual quality assessment (MVQA) based on a graph convolutional network. For that, we address the node classification problem to predict the perceived visual quality. First, two matrices representing the 3D mesh are considered: a graph adjacency matrix and a feature matrix. Both matrices are used as input to a shallow graph convolutional network. The network consists of two convolutional layers followed by a max-pooling layer to provide the final feature representation. With this structure, the Softmax classifier predicts the quality score category without the reference mesh's availability. Experiments are conducted on four publicly available databases constructed explicitly for the mesh quality assessment task. We investigate several perceptual and visual features to select the most effective combination. Comparisons with the state-of-the-art alternative methods show the effectiveness of the proposed framework.
Water distribution system monitoring is currently carried out using advanced real-time control technologies to achieve a higher operational efficiency. Data analysis techniques can be implemented for condition estimation, which are crucial tools for managing, developing, and operating water networks using the monitored flow rate and pressure data at some network pipes and nodes. This work proposes a state estimation methodology that enables one to infer the hydraulic state of the operating speed of pumping systems from these pressure and flow measurements. The presented approach suggests using graph convolutional neural network theory linked to hydraulic models for generating a digital twin of the water system. It is validated on two benchmark hydraulic networks: the Patios-Villa del Rosario, Colombia, and the C-Town networks. The results show that the proposed model effectively predicts the state estimation in the two hydraulic networks used. The results of the evaluation metrics indicate low values of mean squared error and mean absolute error and high values of the coefficient of determination, reflecting high predictive ability and that the prediction results adequately represent the real data.
With the increasing popularity of cab services such as Didi and Uber, cities are faced with the challenge of high carbon emissions and traffic congestion. Ride-sharing services, as a novel green mode of transportation, have emerged as a key technology in smart transportation for addressing these problems. The implementation of ride-sharing is predicated on an accurate ridership demand forecasting model, which can effectively prevent vehicle resource waste, alleviate traffic congestion, and reduce carbon emissions. In this paper, a periodic attentional graph convolutional spatio-temporal network model (PAG-TSN) is proposed to predict regional ridership demand. Specifically, the model is trained using a large amount of GPS data and user demand data collected by the travel service provider. PAG-TSN consists of two parts: the bicomponent attention graph convolution model (BAT-GCN) and the periodic attentional gated recurrent unit model (PA-GRU). The former uses GCN to extract spatial features from pointwise and edgewise graphs; the latter uses the spatial feature vectors extracted from the former with external information as input, and uses GRU to extract temporal features from feature data of different periods, and finally uses attention mechanism and POI requirement correlation to integrate the extracted spatio-temporal information to derive prediction results. Extensive experiments and evaluations on the CD2Date and XA2Date datasets show that PAG-TSN outperforms other baseline models in accurately predicting regional ridership demand, with MAPE and RMSE values of 0.1147 and 5.56, respectively.
It has been an important task for recommender systems to suggest satisfying activities to a group of users in people's daily social life. The major challenge in this task is how to aggregate personal preferences of group members to infer the decision of a group. Conventional group recommendation methods applied a predefined strategy for preference aggregation. However, these static strategies are too simple to model the real and complex process of group decision-making, especially for occasional groups which are formed ad-hoc. Moreover, group members should have non-uniform influences or weights in a group, and the weight of a user can be varied in different groups. Therefore, an ideal group recommender system should be able to accurately learn not only users' personal preferences but also the preference aggregation strategy from data. In this paper, we propose a novel end-to-end group recommender system named CAGR (short for "Centrality-Aware Group Recommender"), which takes Bipartite Graph Embedding Model (BGEM), the self-attention mechanism and Graph Convolutional Networks (GCNs) as basic building blocks to learn group and user representations in a unified way. Specifically, we first extend BGEM to model group-item interactions, and then in order to overcome the limitation and sparsity of the interaction data generated by occasional groups, we propose a self-attentive mechanism to represent groups based on the group members. In addition, to overcome the sparsity issue of user-item interaction data, we leverage the user social networks to enhance user representation learning, obtaining centrality-aware user representations. To further alleviate the group data sparsity problem, we propose two model optimization approaches to seamlessly integrate the user representations learning process. We create three large-scale benchmark datasets and conduct extensive experiments on them. The experimental results show the superiority of our proposed CAGR by comparing it with state-of-the-art group recommender models.
The intermolecular interactions between proteins and ligands occur through site-specific amino acid residues in the proteins, and the identification of these key residues plays a critical role in both interpreting protein function and facilitating drug design based on virtual screening. In general, the information about the ligands-binding residues on proteins is unknown, and the detection of the binding residues by the biological wet experiments is time consuming. Therefore, many computational methods have been developed to identify the protein-ligand binding residues in recent years. We propose GraphPLBR, a framework based on Graph Convolutional Neural (GCN) networks, to predict protein-ligand binding residues (PLBR). The proteins are represented as a graph with residues as nodes through 3D protein structure data, such that the PLBR prediction task is transformed into a graph node classification task. A deep graph convolutional network is applied to extract information from higher-order neighbors, and initial residue connection with identity mapping is applied to cope with the over-smoothing problem caused by increasing the number of graph convolutional layers. To the best of our knowledge, this is a more unique and innovative perspective that utilizes the idea of graph node classification for protein-ligand binding residues prediction. By comparing with some state-of-the-art methods, our method performs better on several metrics.
Football (soccer) stands as the world's most popular sport, enthralling millions of fans globally. Within the dynamic sphere of modern football, gaining comprehensive insights into the nuanced technical and physical demands placed on players is pivotal for performance optimization. This paper introduces an innovative deep learning-powered image classification algorithm for recognizing football player activities directly from videos and images. Our pioneering approach harnesses the synergistic capabilities of convolutional neural networks (CNNs) and graph convolutional networks (GCNs) to decipher intricate spatial-temporal patterns in player poses and motions. The methodology employs a hybrid CNN and GCN architecture. The CNN leverages consecutive convolutional and pooling layers to automatically extract discriminative visual features from input frames capturing player poses. The GCN models' skeletal joints as graph nodes with bones as edges, performing graph convolutions to aggregate spatial and temporal information from neighboring body parts. This enables capturing localized pose dynamics. The complementary CNN and GCN outputs are fused through fully connected layers to classify player activities based on both visual appearances and pose configurations. The model is trained end to end on richly annotated football video data using a multi-class cross-entropy loss. Data augmentation and regularization techniques enhance robustness. Extensive experiments validate the proposed architecture's effectiveness, achieving 97.4% accuracy, 96% precision, 95.5% recall, 95.4% F1-score, 0.90 Matthews correlation, and 93% specificity in classifying 17 complex football activities significantly higher than previous benchmarks. Detailed ablation studies confirm the contributions of the CNN, GCN, and fused model components. The work represents a major advance in leveraging deep neural networks for accurate and granular analysis of sports performances.
With the development of deep learning, fatigue detection technology for drivers has achieved remarkable achievements. Although the image-based approach achieves good accuracy, it inevitably leads to greater model complexity, which is unsuitable for mobile terminal devices. Luckily, human skeletal data significantly reduces the impact of noise and input data volume while retaining valid information, and it can better deal with real-world driving scenarios with the benefit of robustness in complex driving situations. This paper proposes a lightweight multi-scale spatio-temporal attention graph convolutional network (MS-STAGCN) to efficiently utilize skeleton data to identify driver states by aggregating locally and globally valid face information, which achieves good performance even for lightweight design. The experimental results show that the method achieves 92.4% accuracy on the NTHU-DDD dataset, which can be applied to fatigue detection tasks of the driver in real-world driving scenarios in the future.
This article focuses on the task of detecting human-object interactions (HOI) in videos, with the goal of identifying objects interacting with humans and predicting human-object interaction classes. Two frame-works are proposed which detect human-object interactions in videos by modeling the trajectory of objects and human skeleton. The first framework (knowledge-based spatial-temporal HOI) treats the entire scene to be a HOI graph made up of the human skeleton and objects. It has fewer parameters and a higher possibility for knowledge embedding. The second framework (hierarchical spatial-temporal HOI) constructs a HOI graph after obtaining the feature of the human skeleton and objects. It outperforms the competition in terms of performance and generalization. Experimental results in CAD-120 dataset and SYSU-HOI dataset show that the proposed frameworks are more advanced than the state-of-the-art methods, with smaller parameters and shorter inference time. Such results confirm that the proposed frameworks effectively reduce parameters and inference time while maintaining detection accuracy in HOI videos.(c) 2022 Published by Elsevier B.V.
Due to the widespread applications in real-world scenarios, metro ridership prediction is a crucial but challenging task in intelligent transportation systems. However, conventional methods either ignore the topological information of metro systems or directly learn on physical topology, and cannot fully explore the patterns of ridership evolution. To address this problem, we model a metro system as graphs with various topologies and propose a unified Physical-Virtual Collaboration Graph Network (PVCGN), which can effectively learn the complex ridership patterns from the tailor-designed graphs. Specifically, a physical graph is directly built based on the realistic topology of the studied metro system, while a similarity graph and a correlation graph are built with virtual topologies under the guidance of the inter-station passenger flow similarity and correlation. These complementary graphs are incorporated into a Graph Convolution Gated Recurrent Unit (GC-GRU) for spatial-temporal representation learning. Further, a Fully-Connected Gated Recurrent Unit (FC-GRU) is also applied to capture the global evolution tendency. Finally, we develop a Seq2Seq model with GC-GRU and FC-GRU to forecast the future metro ridership sequentially. Extensive experiments on two large-scale benchmarks (e.g., Shanghai Metro and Hangzhou Metro) well demonstrate the superiority of our PVCGN for station-level metro ridership prediction. Moreover, we apply the proposed PVCGN to address the online origin-destination (OD) ridership prediction and the experiment results show the universality of our method. Our code and benchmarks are available at https://github.com/HCPLab-SYSU/PVCGN.
State-of-the-art 2D image compression schemes rely on the power of convolutional neural networks (CNNs). Although CNNs offer promising perspectives for 2D image compression, extending such models to omnidirectional images is not straightforward. First, omnidirectional images have specific spatial and statistical properties that can not be fully captured by current CNN models. Second, basic mathematical operations composing a CNN architecture, e.g., translation and sampling, are not well-defined on the sphere. In this paper, we study the learning of representation models for omnidirectional images and propose to use the properties of HEALPix uniform sampling of the sphere to redefine the mathematical tools used in deep learning models for omnidirectional images. In particular, we: i) propose the definition of a new convolution operation on the sphere that keeps the high expressiveness and the low complexity of a classical 2D convolution; ii) adapt standard CNN techniques such as stride, iterative aggregation, and pixel shuffling to the spherical domain; and then iii) apply our new framework to the task of omnidirectional image compression. Our experiments show that our proposed on-the-sphere solution leads to a better compression gain that can save 13.7% of the bit rate compared to similar learned models applied to equirectangular images. Also, compared to learning models based on graph convolutional networks, our solution supports more expressive filters that can preserve high frequencies and provide a better perceptual quality of the compressed images. Such results demonstrate the efficiency of the proposed framework, which opens new research venues for other omnidirectional vision tasks to be effectively implemented on the sphere manifold.
Inspections on current graph neural networks suggest us to reconsider the computational aspect of the final aggregation. We consider that such aggregations perform a prediction smoothing and impute their potential drawbacks to be the inter-class interference implied by the underlying graphs. We aim at weak-ening the inter-class connections so that aggregations focus more on intra-class relations and producing smooth predictions according to weakening results. We apply a metric learning module to learn new edge weights and combine entropy losses to ensure the correspondence between the predictions and the learnt distances so that the weights of inter-class edges are reduced and predictions are smoothed ac-cording to the modified graph. Experiments on four citation networks and a Wiki network show that in comparison with other state-of-the-art graph neural networks, the proposed algorithm can improve the classification accuracy. (c) 2021 Elsevier Ltd. All rights reserved.
The location recommendation of an air-quality-monitoring station is a prerequisite for inferring the air-quality distribution in urban areas. How to use a limited number of monitoring equipment to accurately infer air quality depends on the location of the monitoring equipment. In this paper, our main objective was how to recommend optimal monitoring-station locations based on existing ones to maximize the accuracy of a air-quality inference model for inferring the air-quality distribution of an entire urban area. This task is challenging for the following main reasons: (1) air-quality distribution has spatiotemporal interactions and is affected by many complex external influential factors, such as weather and points of interest (POIs), and (2) how to effectively correlate the air-quality inference model with the monitoring station location recommendation model so that the recommended station can maximize the accuracy of the air-quality inference model. To solve the aforementioned challenges, we formulate the monitoring station location as an urban spatiotemporal graph (USTG) node recommendation problem in which each node represents a region with time-varying air-quality values. We design an effective air-quality inference model-based proposed high-order graph convolution (HGCNInf) that could capture the spatiotemporal interaction of air-quality distribution and could extract external influential factor features. Furthermore, HGCNInf can learn the correlation degree between the nodes in USTG that reflects the spatiotemporal changes in air quality. Based on the correlation degree, we design a greedy algorithm for minimizing information entropy (GMIE) that aims to mark the recommendation priority of unlabeled nodes according to the ability to improve the inference accuracy of HGCNInf through the node incremental learning method. Finally, we recommend the node with the highest priority as the new monitoring station location, which could bring about the greatest accuracy improvement to HGCNInf.
Self-supervised learning (SSL) is a promising method for gaining perception and common sense from unlabelled data. Existing approaches to analyzing human body skeletons address the problem similar to SSL models for image and video understanding, but pixel data is far more challenging than coordinates. This paper presents ATOM, an SSL model designed for skeleton-based data analysis. Unlike video-based SSL approaches, ATOM leverages atomic movements within skeleton actions to achieve a more fine-grained representation. The pro-posed architecture predicts the action order at the frame level, leading to improved perceptions and represen-tations of each action. ATOM outperforms state-of-the-art approaches in two well-known datasets (NTU RGB + D and NTU-120 RGB + D), and its weight transferability enables performance improvements on supervised and semi-supervised tasks, up to 4.4% (3.3% p.p.) and 14.1% (6.3% p.p.), respectively, in Top-1 Accuracy.
Electroencephalography (EEG) sensors are flexible and non-invasive sensoring devices for the measurement of electrical brain activity which is extensively used in some areas of clinical practice and psychological/psychiatric research, such as epilepsy, sleep, emotion, and brain computer interfaces. Although EEG sensor do not provide actual brain localizations of the activity sources, they allow to study brain functional connectivity. In this paper we review current application of a specific family of computational methods, the Graph Neural Networks (GNN) to the analysis of EEG data. GNNs appear to be well suited to EEG data modeling as they deal with signals whose domain is defined by a graph instead of a regular lattice in Euclidean space. Readings of EEG electrodes fall in this category, hence the increasing research activity on the application of GNNs to EEG data.
Aiming at the problems of diversification, complexity and islanding of power operation and inspection data and the high dependence of operation and inspection operations on expert experience and normative information, the key technology research of intelligent judgment of defect types of power operation inspection equipment is carried out. For the field of power operation and inspection, the defect text classification algorithm based on graph convolutional neural network is proposed. And the practical tests in a large defect text network diagram built by main transformer defect reports are performed. And the proposed model achieves better classification results than 7 benchmark models in the defect text classification task. Specifically, the Accuracy, Weighed-Precision, and Weighed-F1 indicators reach 73.39, 72.42, and 72.21 respectively, which improves the model's ability to identify defect types to a greater extent and plays an important role in improving the intelligence and digitalization of power operation and inspection work.
Greedy routing efficiently achieves routing solutions for vehicular networks due to its simplicity and reliability. However, the existing greedy routing algorithms have mainly considered simple routing metrics only, e.g., distance based on the local view of an individual vehicle. This consideration is insufficient for analysing dynamic and complicated vehicular communication scenarios which inevitably degrades the overall routing performance. Software-Defined Vehicular Network (SDVN) and Graph Convolutional Network (GCN) can overcome these limitations. Thus, this paper presents a novel GCN-based greedy routing algorithm (NGGRA) in the hybrid SDVN. The SDVN control plane trains the GCN decision model based on the globally collected data. Vehicles with transmission requirements can adopt this model for inferring and making the routing decisions. The proposed node-importance-based graph convolutional network (NiGCN) model analyses multiple correlated metrics to accurately evaluate the dynamic vehicular network is available at: https://github.com/a824899245/NiGCN. Meanwhile, the SDVN architecture offers a global view for model training and routing computation. Extensive simulation results demonstrate that NiGCN outperforms popular GCN models in training efficiency and accuracy. In addition, NGGRA can improve the packet delivery ratio and substantially reduce delay compared with its counterparts.
Transformer has achieved outstanding performance in many fields such as computer vision benefiting from its powerful and efficient modelling ability and long-range feature extraction capability complementary to convolution. However, on the one hand, the lack of CNN's innate inductive biases, such as translation invariance and local sensitivity, makes Transformer require more data for learning. On the other hand, labelled hyperspectral samples are scarce due to the time-consuming and costly annotation task. To this end, we propose a semi-supervised hierarchical Transformer model for HSI classification to improve the classification performance of the Transformer with limited labelled samples. In order to perturb the samples more fully and extensively to improve the model performance, two different data augmentation methods are used to perturb the unlabelled samples, and two sets of augmented samples are obtained respectively. The pseudo-label obtained on the original unlabelled sample is used to simultaneously supervise the augmented sample obtained on this unlabelled sample. Among them, only the pseudo-labels above the threshold are retained. To further improve the model stability and classification accuracy, hierarchical patch embedding is proposed to eliminate the mutual interference between pixels. Extensive experiments on three well-known hyperspectral datasets validate the effectiveness of the proposed semi-supervised Transformer model. The experiments show that the model achieves excellent classification accuracy even when there are only 10 labelled samples in each category, which can effectively improve the classification performance of Transformer under small-scale labelled samples.
Introduction: In the field of power systems, power load type prediction is a crucial task. Different types of loads, such as domestic, industrial, commercial, etc., have different energy consumption patterns. Therefore, accurate prediction of load types can help the power system better plan power supply strategies to improve energy utilization and stability. However, this task faces multiple challenges, including the complex topology of the power system, the diversity of time series data, and the correlation between data. With the rapid development of deep learning methods, researchers are beginning to leverage these powerful techniques to address this challenge. This study aims to explore how to optimize deep learning models to improve the accuracy of load type prediction and provide support for efficient energy management and optimization of smart grids.Methods: In this study, we propose a deep learning method that combines graph convolutional networks (GCN) and sequence-to-sequence (Seq2Seq) models and introduces an attention mechanism. The methodology involves multiple steps: first, we use the GCN encoder to process the topological structure information of the power system and encode node features into a graph data representation. Next, the Seq2Seq decoder takes the historical time series data as the input sequence and generates a prediction sequence of the load type. We then introduced an attention mechanism, which allows the model to dynamically adjust its attention to input data and better capture the relationship between time series data and graph data.Results: We conducted extensive experimental validation on four different datasets, including the National Grid Electricity Load Dataset, the Canadian Electricity Load Dataset, the United States Electricity Load Dataset, and the International Electricity Load Dataset. Experimental results show that our method achieves significant improvements in load type prediction tasks. It exhibits higher accuracy and robustness compared to traditional methods and single deep learning models. Our approach demonstrates advantages in improving load type prediction accuracy, providing strong support for the future development of the power system.Discussion: The results of our study highlight the potential of deep learning techniques, specifically the combination of GCN and Seq2Seq models with attention mechanisms, in addressing the challenges of load type prediction in power systems. By improving prediction accuracy and robustness, our approach can contribute to more efficient energy management and the optimization of smart grids.
Maximum utilization of the full solar spectrum has been considered as a holy grail in the field of photocatalysis and has emerged important in the recent years, as the world needs to move towards renewable energy sources and also to maintain environmental health. In the search for a sustainable solution, we have come up with a strategic combination of materials, which can be active under all the three regions, namely ultraviolet (UV), visible and near infrared (NIR) of the sunlight. Specifically, we have developed a series of nanocomposites comprising of two dimensional nanosheets of zinc oxide (ZnO) and graphitic carbon nitride (GCN), and successfully coupled them with upconversion nanoparticles (UCNP). These nanocomposites have been successfully utilized for the photocatalytic chromium (Cr(VI)) reduction. The prepared nanocomposites exhibit an excellent photocatalytic activity toward reduction of Cr(VI) under different light region. A plausible mechanism for the photocatalytic process has been proposed based on the detailed study. This work is expected to pave way for the strategic design and development of many photocatalytic systems, which can utilize sunlight to the maximum extent. (C) 2020 Elsevier Ltd. All rights reserved.
Hyperspectral image classification plays a crucial role in various remote sensing applications. However, existing methods often struggle with the challenge of unknown classes, leading to decreased classification accuracy and limited generalization. In this paper, we propose a novel deep learning framework called IADMRN, which addresses the issue of unknown class handling in hyperspectral image classification. IADMRN combines the strengths of dense connection blocks and attention mechanisms to extract discriminative features from hyperspectral data. Furthermore, it employs a multi-scale deconvolution image reconstruction sub-network to enhance feature reconstruction and provide additional information for classification. To handle unknown classes, IADMRN utilizes an extreme value theory-based model to calculate the probability of unknown class membership. Experimental results on the three public datasets demonstrate that IADMRN outperforms state-of-the-art methods in terms of classification accuracy for both known and unknown classes. Experimental results show that the proposed methods outperform several state-of-the-art methods, which outperformed DCFSL by 8.47%, 6.57%, and 4.25%, and outperformed MDL4OW by 4.35%, 4.08%, and 2.47% on the Salinas, University of Pavia, and Indian Pines datasets, respectively. The proposed framework is computationally efficient and showcases the ability to effectively handle unknown classes in hyperspectral image classification tasks. Overall, IADMRN offers a promising solution for accurate and robust hyperspectral image classification, making it a valuable tool for remote sensing applications.
Structural damage detection plays an important part in structural health monitoring for engineering structures. However, monitored signals are easily polluted by noise and the damaged data are difficult to obtain. In this work, a novel structural damage detection approach using multisensor spatial-temporal graph-based features and deep graph convolutional networks (DGCNs) is presented. The spatial-temporal graph is constructed by the graph theory based on continuous wavelet transform (CWT) of vibration signals. Then, the multisensor spatial-temporal graph-based feature is extracted based on the Laplacian matrix derived from the spatial-temporal graph of the multisensor data. To overcome the limitation of small data size which obstructed the use of the artificial neural network and convolutional neural network, a DGCN is utilized to classify the damage type of the monitored structure. The extracted multisensor spatial-temporal graph-based feature vector is used to represent the node of the global graph as the input of the DGCN. The node with the same condition of the structure can be classified by using the well-trained DGCN. Experiments of the International Association for Structural Control (IASC)-American Society of Civil Engineers (ASCE) SHM benchmark structure and Qatar steel frame structure in the laboratory are performed to verify the effectiveness of the proposed approach. The experimental results show that the DGCN method can be used to detect structural damage by learning from the constructed global graphs. Comparative experiments demonstrate that the proposed approach performs better than the conventional approach, especially for the limited dataset and noise-polluted case.
Brain disease propagation is associated with characteristic alterations in the structural and functional connectivity networks of the brain. To identify disease-specific network representations, graph convolutional networks (GCNs) have been used because of their powerful graph embedding ability to characterize the non-Euclidean structure of brain networks. However, existing GCNs generally focus on learning the discriminative region of interest (ROI) features, often ignoring important topological information that enables the integration of connectome patterns of brain activity. In addition, most methods fail to consider the vulnerability of GCNs to perturbations in network properties of the brain, which considerably degrades the reliability of diagnosis results. In this study, we propose an adversarially trained persistent homology-based graph convolutional network (ATPGCN) to capture disease-specific brain connectome patterns and classify brain diseases. First, the brain functional/structural connectivity is constructed using different neuroimaging modalities. Then, we develop a novel strategy that concatenates the persistent homology features from a brain algebraic topology analysis with readout features of the global pooling layer of a GCN model to collaboratively learn the individual-level representation. Finally, we simulate the adversarial perturbations by targeting the risk ROIs from clinical prior, and incorporate them into a training loop to evaluate the robustness of the model. The experimental results on three independent datasets demonstrate that ATPGCN outperforms existing classification methods in disease identification and is robust to minor perturbations in network architecture. Our code is available at https://github.com/CYB08/ATPGCN.
Water pollution has serious consequences for human health and water ecosystems, and accurate forecasting of water quality changes can aid in the early detection and treatment of such pollution. To better simulate the characteristics of water quality data, the development of a water quality prediction model must consider the non-smoothness of the data as well as the relationship between upstream and downstream water quality. Firstly, Optimal Variational Mode Decomposition (OVMD) technology is used to pre-process water quality monitoring data through linear decomposition into multiple components, with the components acting as a unit of prediction to reduce the difficulty of prediction. Secondly, to reflect the impact of upstream and downstream water quality relationships, comprehensive prediction modeling is carried out on the temporal and spatial correlation of water quality data between monitoring stations. Graph Attention Networks (GAT) are embedded in the Gated Recurrent Unit's (GRU) reset gate and update gate, and adaptive aggregation of data spatial characteristics of each site based on each station is used to achieve a multi-step prediction of water quality indicators. Finally, the predicted values of each component are then fused to form the final predicted values. Validation at 13 monitoring stations along the Mulan River demonstrated the effectiveness of the integrated prediction model.The results showed that, under different prediction steps, the Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) values of the GAT-GRU water quality prediction model were reduced by about 11-20% (ammonia nitrogen, NH3-N) and 8-18% (total phosphorus, TP) compared with the GCN (Graph Convolutional Networks)-GRU, and the Nash-Sutcliffe efficiency coefficient (NSE) value was increased by about 20% (NH3-N) and 13% (TP), respectively. The RMSE and MAE values of the OVMD-GAT-GRU water quality prediction model were further reduced by about 52-57% (NH3-N) and 25-35% (TP) compared with GAT-GRU, and the NSE value was increased by about 19-43% (NH3-N) and 15-33% (TP), respectively. As the prediction steps increased, the advantages of OVMD-GAT-GRU over GAT-GRU and GCN-GRU became more pronounced. These results demonstrate that OVMD-GAT-GRU exhibits superior prediction performance, robustness, accuracy, and adaptability to water quality indicators. The development of the OVMD-GAT-GRU water quality prediction model can provide significant assistance in the prevention and management of water pollution.
Group activity recognition is a significant and challenging task in computer vision. The solution of group activity prediction can be classified with traditional hand-crafted features, RGB video features, and skeleton data-based deep learning architectures, such as Graph Convolutional Networks (GCNs), Recurrent Neural Networks (RNNs), and Long Short-Term Memory (LSTMs). However, they rarely explore pose information and rarely use relational networks to reason about group activity behavior. In this work, we leverage minimal prior knowledge about the skeleton information to reason about the interactions from group activity. The objective is to obtain discriminative representations and filter out some ambiguous actions to enhance the performance of group activity recognition. Our contribution is a proposed Attention Relation Network (ARN) that fuses the attention mechanisms and joint vector sequences into the relation network. The skeleton joints vector sequences are previously unexplored pose information and assign greater significance attributed to individuals who are more relevant for distinguishing the group activity behavior. First, our model focuses on the specified edge-level information (encompassing both edge and edge motion data) within the skeleton dataset, considering directionality, to analyze the spatiotemporal aspects of the action. Second, recognizing the inherent motion directionality, we establish diverse directions for skeleton edges and extract distinct motion features (including translation and rotation information) aligned with these various orientations, thereby augmenting the utilization of motion attributes related to the action. We also introduce a representation of human motion achieved by combining relational networks and examining their integrated characteristics. Extensive experiments were tested in the Hockey and UT-interaction datasets to evaluate our method, obtaining competitive performance to the state-of-the-art. Results demonstrate the modeling potential of a skeleton-based method for group activity recognition.
In fighting the COVID-19 pandemic, the main challenges include the lack of prior research and the urgency to find effective solutions. It is essential to accurately and rapidly summarize the relevant research work and explore potential solutions for diagnosis, treatment and prevention of COVID-19. It is a daunting task to summarize the numerous existing research works and to assess their effectiveness. This paper explores the discovery of new COVID-19 research approaches based on dynamic link prediction, which analyze the dynamic topological network of keywords to predict possible connections of research concepts. A dynamic link prediction method based on multi-granularity feature fusion is proposed. Firstly, a multi-granularity temporal feature fusion method is adopted to extract the temporal evolution of different order subgraphs. Secondly, a hierarchical feature weighting method is proposed to emphasize actively evolving nodes. Thirdly, a semantic repetition sampling mechanism is designed to avoid the negative effect of semantically equivalent medical entities on the real structure of the graph, and to capture the real topological structure features. Experiments are performed on the COVID-19 Open Research Dataset to assess the performance of the model. The results show that the proposed model performs significantly better than existing state-of-the-art models, thereby confirming the effectiveness of the proposed method for the discovery of new COVID-19 research approaches.
In this study, a framework for the prediction of thermophysical properties based on transfer learning from existing estimation models is explored. The predictive capabilities of conventional group-contribution methods and traditional machinelearning approaches rely heavily on the availability of experimental datasets and their uncertainty. Through the use of a pretraining scheme, which leverages the knowledge established by other estimation methods, improved prediction models for thermophysical properties can be obtained after fine-tuning networks with more accurate experimental data. As our experiments show, for the case of critical properties of compounds, this pipeline not only improves the performance of the models on commonly found organic structures but can also help these models generalize to less explored areas of chemical space, where experimental data is scarce, such as inorganics and heavier organic compounds. Transfer learning from estimation models data also allows for graph-based deep learning models to create more flexible molecular features over a bigger chemical space, which leads to improved predictive capabilities and can give insights into the relationship between molecular structures and thermophysical properties. The generated molecular features can discriminate behavior discrepancy between isomers without the need of additional parameters. Also, this approach shows better robustness to outliers in experimental datasets.
Mobile CrowdSensing (MCS) has recently become a promising data acquisition paradigm, which recruits a large number of users to collect data from the target sensing areas. Obviously, with the increase of sensing scale and the decrease of sensing granularity, traditional MCS cannot fully cover the required sensing areas especially the inaccessible areas. As a variant, Sparse MCS can utilize the spatiotemporal correlations in sensing data to infer the whole sensing map only by sensing a few subareas. However, in many real-world scenarios, such as traffic congestion prediction or parking occupancy detection, inferring the current unsensed data may not be the final goal. By comparison, it is more important to get the future information through the sparse sensed data. In this paper, we turn attention from inferring the current unsensed data to predicting the future unknown data and propose an urban inference and prediction framework in Sparse MCS. To deal with the sparse sensed data, we first present a bipartite-graph-based matrix completion algorithm with spatiotemporal constraints to accurately recover the current full map. Then, by exploiting spatiotemporal correlations based on the inferred full map, we present a Graph Convolutional Networks (GCN) with spatiotemporal attention to predict the future maps. Furthermore, we design a spatiotemporal iterative method to repeatedly update the spatiotemporal attentions and constraints, in order to connect the urban inference and prediction to improve the accuracy of the whole framework. Extensive experiments have been conducted on two types of typical urban sensing tasks with four real-world data sets, which verify the effectiveness of our proposed algorithms in improving the inference and prediction accuracy with the sparse sensed data.
Remote sensing image retrieval (RSIR) refers to finding images from an image database that contain the same instance as the query image, which is an essential task in remote sensing applications. Traditional depth-based hashing algorithms usually convert the image library into a hash matrix with a specified number of digits. On the one hand, the quality of hash matrices generated by traditional methods is low and cannot guarantee good clustering between pictures of the same class. On the other hand, the ability to extract features using backbone networks must be improved. This paper proposes a deep hashing model called adaptive hash code balancing (AHCB) to solve two existing problems. The model introduces a balanced binary method to maximize the hash value entropy so that the generated hash has better clustering. Graph convolutional networks(GCNs) are introduced to automatically detect relevant data points in the graph, perform back-propagation, and propagate the updated network feedback to the feature extraction layer to improve the ability to extract features. It enables the model to learn the intrinsic data structure between remote sensing images. Experimental results on three public datasets show that the proposed method outperforms the current state-of-the-art deep hashing remote sensing image retrieval algorithms by a large margin.
Knowledge graphs (KGs) provide a wealth of prior knowledge for the research on social networks. Cross-lingual entity alignment aims at integrating complementary KGs from different languages and thus benefits various knowledge-driven social network studies. Recent entity alignment methods often take an embedding-based approach to model the entity and relation embedding of KGs. However, these studies mostly focus on the information of the entity itself and its structural features but ignore the influence of multiple types of data in KGs. In this paper, we propose a new embedding-based framework named multiview highway graph convolutional network (MHGCN), which considers the entity alignment from the views of entity semantic, relation semantic, and entity attribute. To learn the structural features of an entity, the MHGCN employs a highway graph convolutional network (GCN) for entity embedding in each view. In addition, the MHGCN weights and fuses the multiple views according to the importance of the embedding from each view to obtain a better entity embedding. The alignment entities are identified based on the similarity of entity embeddings. The experimental results show that the MHGCN consistently outperforms the state-of-the-art alignment methods. The research also will benefit knowledge fusion through cross-lingual KG entity alignment.
Catalytic properties of noble-metal nanoparticles (NPs) are largely determined by their surface morphology. The latter is probed by surface-sensitive spectroscopic techniques in different spectra regions. A fast and precise computational approach enabling the prediction of surface-adsorbate interaction would help the reliable description and interpretation of experimental data. In this work, we applied Machine Learning (ML) algorithms for the task of adsorption-energy approximation for CO on Pd nanoclusters. Due to a high dependency of binding energy from the nature of the adsorbing site and its local coordination, we tested several structural descriptors for the ML algorithm, including mean Pd-C distances, coordination numbers (CN) and generalized coordination numbers (GCN), radial distribution functions (RDF), and angular distribution functions (ADF). To avoid overtraining and to probe the most relevant positions above the metal surface, we utilized the adaptive sampling methodology for guiding the ab initio Density Functional Theory (DFT) calculations. The support vector machines (SVM) and Extra Trees algorithms provided the best approximation quality and mean absolute error in energy prediction up to 0.12 eV. Based on the developed potential, we constructed an energy-surface 3D map for the whole Pd-55 nanocluster and extended it to new geometries, Pd-79, and Pd-85, not implemented in the training sample. The methodology can be easily extended to adsorption energies onto mono- and bimetallic NPs at an affordable computational cost and accuracy.
The use of dyes and segments has increased widely in recent years, but it poses a serious health risk to eco-systems. In this work, TiO2 and two-dimensional g-C3N4 nanosheets (g-CN) were fabricated through co -precipitation and thermal polymerization technique, respectively. The g-CN-TiO2 photocatalyst (1: 3, 2: 2, 3: 1) in various weight percentages was prepared using a simple impregnation process. The photocatalytic behaviour of the g-CN, TiO2 NPs, and different weight percentages of g-CN-TiO2 photocatalyst was evaluated against methylene blue (MB) dye under UV-visible light illumination. Compared to pristine and other weight percentages of the g-CN-TiO2 nanocomposite, the optimized g-CN-TiO2 nanocomposite (3:1) showed promoted performance against MB dye. The enriched catalytic efficiency can be accredited to the low amount of TiO2 nanoparticles deposited on gCN nanosheets, possibly due to the boosted transport properties of the electron-hole pairs. The enriched photocatalytic behaviour can be attributed to the development of the Z-scheme system be-tween TiO2 and g-CN. The current study is an outstanding demonstration of the development of maximum catalytic efficiency for destroying hazardous chemical dyes.
We here introduce, for the first time, a topological carbon nitride (TCN) with built-in crystalline-amorphous phases. Topologically anchored dual complementary phases allow localized photon absorption of different wavelengths, and provide a twinned photocatalyst interface to facilitate geminate charge carrier pair separation. These unique attributes, which are absent in widely used graphitic carbon nitride (GCN) and amorphous carbon nitride (ACN) photocatalysts, are highly desirable for precious metal (i.e. Pt) cocatalyst-free hydrogen production via water-splitting. Our results are substantiated with both experiments and simulations.
Chemically fixing CO2 into the fine chemicals is a sustainable route to the utilization of CO2 and meets the requirements of green chemistry. Generally, an important intermediate, high-valued cyclic carbonates, is produced by catalyzed cycloaddition of CO2 with epoxides during the CO2 fixation. However, most of the catalysts for cycloaddition can hardly meet the standards of the green chemistry, including highly efficient, low cost, easily recoverable and recyclable etc. Therefore, in this work, an environmentally friendly composite Zn-CN/C catalyst for the cycloaddition of styrene oxide and CO2 was successfully prepared by a facile method. To this end, zinc bromide was immobilized by graphitic carbon nitride (gCN) and then supported on carbon fibers. Meanwhile, the crystal structure, types of chemical bonding, surface morphologies, and electronic transmission of the prepared catalyst were also investigated. Furthermore, the catalytic performance was evaluated by the cycloaddition reactions of styrene oxide and CO2, a satisfactory result of the moderate yield of 50-90% with a good selectivity (> 99%) was obtained. Finally, a credible mechanism of the reaction was proposed.
Stocks that are fundamentally connected with each other tend to move together. Considering such common trends is believed to benefit stock movement forecasting tasks. However, such signals are not trivial to model because the connections among stocks are not physically presented and need to be estimated from volatile data. Motivated by this observation, we propose a framework that incorporates the inter-connection of firms to forecast stock prices. To effectively utilize a large set of fundamental features, we further design a novel pipeline. First, we use variational autoencoder (VAE) to reduce the dimension of stock fundamental information and then cluster stocks into a graph structure (fundamentally clustering). Second, a hybrid model of graph convolutional network and long-short term memory network (GCN-LSTM) with an adjacency graph matrix (learnt from VAE) is proposed for graph-structured stock market forecasting. Experiments on minute-level U.S. stock market data demonstrate that our model effectively captures both spatial and temporal signals and achieves superior improvement over baseline methods. The proposed model is promising for other applications in which there is a possible but hidden spatial dependency to improve time-series prediction.
Background: Event extraction is essential for natural language processing. In the biomedical field, the nested event phenomenon (event A as a participating role of event B) makes extracting this event more difficult than extracting a single event. Therefore, the performance of nested biomedical events is always underwhelming. In addition, previous works relied on a pipeline to build an event extraction model, which ignored the dependence between trigger recognition and event argument detection tasks and produced significant cascading errors. Objective: This study aims to design a unified framework to jointly train biomedical event triggers and arguments and improve the performance of extracting nested biomedical events. Methods: We proposed an end-to-end joint extraction model that considers the probability distribution of triggers to alleviate cascading errors. Moreover, we integrated the syntactic structure into an attention-based gate graph convolutional network to capture potential interrelations between triggers and related entities, which improved the performance of extracting nested biomedical events. Results: The experimental results demonstrated that our proposed method achieved the best F1 score on the multilevel event extraction biomedical event extraction corpus and achieved a favorable performance on the biomedical natural language processing shared task 2011 Genia event corpus. Conclusions: Our conditional probability joint extraction model is good at extracting nested biomedical events because of the joint extraction mechanism and the syntax graph structure. Moreover, as our model did not rely on external knowledge and specific feature engineering, it had a particular generalization performance.
Spatial-temporal event prediction is a particular task for multivariate time series forecasting. Therefore, the complex entangled dynamics of space and time need to be considered. This task is an essential but crucial loop in future smart cities construction, which can be widely applied in urban traffic management, disaster monitoring and mobility analysis. In recent years, video-like spatial-temporal modelling has been the most common approach in many deep learning models. However, the video-like modelling approach cannot consider some latent region-wise correlations other than geographic spatial distance information. To overcome the limitation, we propose a novel neural network framework, Adaptive Dual-View WaveNet (ADVW-Net), for the urban spatial-temporal event prediction. By integrating the spatial representations from Convolutional Neural Network (CNN) and that from adaptive Graph convolutional neural network (GCN), our proposed model can capture not only the geographic correlations but also some latent region-wise dependencies from the input data. In addition, the effective architecture, WaveNet, can be transferred to region-wise spatial-temporal prediction scenarios for long-range temporal dependencies learning. Experimental results on three urban datasets demonstrate the superior performance of our proposed model.(c) 2021 Elsevier Inc. All rights reserved.
The recently proposed one-to-one label assignment rules have made it possible for the detector to get rid of its dependence on NMS. However, its performance is inferior to conventional one-to-many label assignment trained detector due to insufficient supervision caused by reduced foreground information. In this paper, to combine the advantages of these two kinds of label assignment rules, we assign two sets of positive samples by one-to-many and one-to-one label assignment rules respectively to train the detector. Furthermore, we introduce the graph convolutional network (GCN) to construct a NMS-aware alignment module. The NMS-aware alignment module is devised to bridge the gap between the two sets of positive samples and generate a mask to select out best detections, which plays the role of NMS. It also gets rid of the limitation of processing the grid-like data structure and effectively aggregates information from the duplicate predictions. Extensive experiments on the COCO dataset show the effectiveness of our method and the proposed method achieves competitive performance against the recent NMS-free detec-tors. Especially, our proposed method is compatible with both anchor-based and anchor-free or one-stage and two-stage architectures. The code will be made public soon. (c) 2022 Elsevier B.V. All rights reserved.
Aspect-based sentiment analysis (ABSA) is a fine-grained task that detects the sentiment polarities of particular aspect words in a sentence. With the rise of graph convolution networks (GCNs), current ABSA models mostly use graph-based methods. These methods construct a dependency tree for each sentence, and regard each word as a unique node. To be more specific, they conduct classification using aspect representations instead of sentence representations, and update them with GCNs. However, this kind of method relies too much on the quality of the dependency tree and may lose the global sentence information, which is also helpful for classification. To deal with these, we design a new ABSA model AG-VSR. Two kinds of representations are proposed to perform the final classification, Attention-assisted Graph-based Representation (A2GR) and Variational Sentence Representation (VSR). A2GR is produced by the GCN module, which inputs a dependency tree modified by the attention mechanism. Furthermore, VSR is sampled from a distribution learned by a VAE-like encoder-decoder structure. Extensive experiments show that our model AG-VSR achieves competitive results. Our code and data have been released in https://github.com/wangbing1416/VAGR.(c) 2022 Elsevier B.V. All rights reserved.
Fe-ZrO2 imbedded g-C3N4 was successfully prepaid by solvo-thermal method for the photo-degradation of anti-diabetic drug, acarbose (ACB). The synthesized material were characterized with the help of FT-IR-Spectroscopy, X-ray diffraction, UV-vis-Spectroscopy, X-ray photoelectron spectroscopy, transmission electron microscopy, HPLC-MS and scanning electron microscopy. These characterization results indicated that the target materials was well prepared and photo-catalytically active. The target catalyst (Fe-ZrO2/g-C3N4) showed very high photo-degradation rate against acarbose (ACB) and rhodamine (RhB). Presence of heterojunction between FZ and GCN increased the surface area and light absorbance capability. HPLC-MS scrutiny indicated that photo-degradation process, under visible light, split the ACB into lot of intermediates and finally degraded completely. (C) 2018 The Society of Powder Technology Japan. Published by Elsevier B.V. and The Society of Powder Technology Japan. All rights reserved.
Spatiotemporal PM2.5 forecasting technology plays an important role in urban traffic environment management and planning. In order to establish a satisfactory high-precision PM2.5 prediction model, a new multidata-driven spatiotemporal PM2.5 forecasting model is proposed in this paper. The overall modelling framework consists of three main parts. In part I, the graph convolutional network uses an adjacency matrix to effectively aggregate spatiotemporal pollutant data from different nodes and extract the most valuable feature information for target point modeling from the original data. In part II, the extracted feature information is used as the input of the gated recursive unit and the long short-term memory network to construct the prediction model. In part III, the Q-learning algorithm builds the best ensemble PM2.5 forecasting model by analyzing the processing ability and analysis ability of different predictors. Based on the analysis of multiple cases, the following conclusions can be drawn: (1) Graphic convolutional networks can effectively analyze the spatiotemporal correlation of PM2.5 data and achieve better performance than traditional convolutional neural networks. (2) Q-learning can adaptively optimize the ensemble weight coefficient and achieve better results than the traditional optimization algorithm. (3) The proposed GCN-LSTM-GRU-Q model can achieve better results than the 24 benchmark models.
The recommendation system is an important and widely used technology in the era of Big Data. Current methods have fused side information into it to alleviate the sparsity problem, one of the key problems of recommendation systems. However, not all the side information can be obtained with high quality, and the specific methods based on side information are not universal. In addition, side information has not been mined by the existing graph-based methods. To address these problems, we propose a Dynamic evolution of Multi-Graph Collaborative Filtering (DMGCF) model to mine and reuse side information. Specifically, we first construct user graph and item graph based on user-item bipartite graph and embeddings to exploit inter-user and inter-item relationships. The two new graphs simulate side information in latent space. Next, we perform a dual-path graph convolution network (GCN) on these three graphs for collaborative filtering. Then, a novel dynamic evolution mechanism is proposed to update and promote the embeddings and graphs collaboratively during the learning process, which produces better embeddings, user and item relationships, as well as the rating scores. We conduct a series of experiments on real-world datasets, and experimental results show the effectiveness of our approach. (C) 2021 Elsevier B.V. All rights reserved.
Targeted therapy for one for a set of genes has made it possible to apply precision medicine for different patients due to the existence of tumor heterogeneity. However, how to regulate those genes are still problematic. One of the natural regulators of genes is microRNAs. Thus, a better understanding of the miRNA-gene interaction mechanism might contribute to future diagnosis, prevention, and cancer therapy. The interactions between microRNA and genes play an essential role in molecular genetics. The in-vivo experiments validating the relationships between them are time-consuming, money-costly, and labor-intensive. With the development of high-throughput technology, we dealt with tons of biological data. However, extracting features from tremendous raw data and making a mathematical model is still a challenging topic. Machine learning and deep learning algorithms have become powerful tools in dealing with biological data. Inspired by this, in this paper, we propose a model that combines features/embedding extraction methods, deep learning algorithms, and a voting system. We leverage doc2vec to generate sequential embedding from molecular sequences. The role2vec, GCN, and GMM for geometrical embedding were generated from the complex network from similarity and pair-wise datasets. For the deep learning algorithms, we leveraged LSTM and Bi-LSTM according to different embedding and features. Finally, we adopted a voting system to balance results from different data sources. The results have shown that our voting system could achieve a higher AUC than the existing benchmark. The case studies demonstrate that our model could reveal potential relationships between miRNAs and genes. The source code, features, and predictive results can be downloaded at https://github.com/Xshelton/SRG-vote.
The software engineering community is working to develop reliable metrics to improve software quality. It is estimated that understanding the source code accounts for 60% of the software maintenance effort. Cognitive informatics is important in quantifying the degree of difficulty or the efforts made by developers to understand the source code. Several empirical studies were conducted in 2003 to assign cognitive weights to each possible basic control structure of software, and these cognitive weights are used by several researchers to evaluate the cognitive complexity of software systems. In this paper, an effort has been made to categorize the Control Flow Graphs (CFGs) nodes according to their node features. In our case, we extracted seven unique features from the program, and each unique feature was assigned an integer value that we evaluated through Cognitive Complexity Measures (CCMs). We then incorporated CCMs' results as a node feature value in CFGs and generated the same based on the node connectivity for a graph. In order to obtain the feature representation of the graph, a node vector matrix is then created for the graph and passed to the Graph Convolutional Network (GCN). We prepared our data sets using GCN output and then built Deep Neural Network Defect Prediction (DNN-DP) and Convolutional Neural Network Defect Prediction (CNN-DP) models to predict software defects. The Python programming language is used, along with Keras and TensorFlow. Three hundred twenty Python programs were written by our talented UG and PG students, and all experiments were carried out during laboratory classes. Together with three skilled lab programmers, they compiled and ran each individual program and detected defect/no-defect programs before categorizing them into three different classes, namely Simple, Medium, and Complex programs. Accuracy, Receiver Operating Characteristics (ROC), Area Under Curve (AUC), F-measure, Precision and hyper-parameter tuning procedures are used to evaluate the approaches. The experimental results show that the proposed models outperformed state-of-the-art methods such as Nave Bayes (NB), Decision Tree (DT), Support Vector Machine (SVM), and Random Forest (RF) in all evaluation criteria.
Population growth, climate change, and global warming have led researchers to be interested in utilizing ecofriendly methods for the nitrogen reduction process. It has found that nitrogen molecule can be converted into ammonia in ambient conditions using photocatalysts under visible light. In the present work, a novel visible light active nanocomposite was fabricated, in which different percentages of Ni3V2O8 nanoparticles (10, 15, 20, and 30%) were decorated on graphitic carbon nitride nanosheets (abbreviated as NGCN/NiVO). Then, morphology, textural, optical properties, and crystal structure of the photocatalysts were studied in detail. The results displayed that the NGCN/NiVO (20%) photocatalyst has significant catalytic performance in the ammonia generation process in comparison with the NGCN and GCN, which is 2.3 and 8 times higher, respectively. The stability of NGCN/NiVO (20%) nanocomposite, as a vital parameter, was evaluated for five runs. Also, the impact of electron scavengers, solvent, and pH of media was examined. Finally, a possible mechanism for the considerable enhancement of nitrogen photofixation efficiency was suggested.
With an increasing number of biomedical ontologies being evolved independently, matching these ontologies to solve the interoperability problem has become a critical issue in biomedical applications. Traditional biomedical ontology matching methods are mostly based on rules or similarities for concepts and properties. These approaches require manually designed rules that not only fail to address the heterogeneity of domain ontology terminology and the ambiguity of multiple meanings of words, but also make it difficult to capture structural information in ontologies that contain a large amount of semantics during matching. Recently, various knowledge graph (KG) embedding techniques utilizing deep learning methods to deal with the heterogeneity in knowledge graphs (KGs), have quickly gained massive attention. However, KG embedding focuses mainly on entity alignment (EA). EA tasks and ontology matching (OM) tasks differ dramatically in terms of matching elements, semantic information and application scenarios, etc., hence these methods cannot be applied directly to biomedical ontologies that contain abstract concepts but almost no entities. To tackle these issues, this paper proposes a novel approach called BioOntGCN that directly learns embeddings of ontology-pairs for biomedical ontology matching. Specifically, we first generate a pairwise connectivity graph (PCG) of two ontologies, whose nodes are concept-pairs and edges correspond to property-pairs. Subsequently, we learn node embeddings of the PCG to predicate the matching results through following phases: 1) A convolutional neural network (CNN) to extract the similarity feature vectors of nodes; 2) A graph convolutional network (GCN) to propagate the similarity features and obtain the final embeddings of concept-pairs. Consequently, the biomedical ontology matching problem is transformed into a binary classification problem. We conduct systematic experiments on real-world biomedical ontologies in Ontology Alignment Evaluation Initiative (OAEI), and the results show that our approach significantly outperforms other entity alignment methods and achieves stateof-the-art performance. This indicates that BioOntGCN is more applicable to ontology matching than the EA method. At the same time, BioOntGCN substantially achieves superior performance compared with previous ontology matching (OM) systems, which suggests that BioOntGCN based on the representation learning is more effective than the traditional approaches.
Graphitic Carbon Nitride (g-C3N4) has extensive application prospect of photodynamic therapy (PDT), which can be attributed to the biocompatibility and photosensitivity. However, it suffers from the near-ultraviolet absorption edge and low reactive oxygen species (ROS) release rate. This work exhibits an atomic-thickness water-soluble g-C3N4 with alkali Zn (2+) and K(+ )modification (MCN), whose absorption edge is tuned from 460 nm for GCN to the entire visible-light region (663 nm), and bandgap is reduced to 1.94 eV. Both K+- bridging intercalation and the in-plane Zn-N significantly enhance the photocatalytic performance, as well as inhibit the overexpression of glutathione (GSH) significantly. The synergistic effect make that the release rate of ROS is about 45.16 % (7.95 % for pristine g-C3N4), accomplishing a considerable inactivation efficiency of malignant melanoma A375. This work fundamentally releases the limitation of g-C3N4 as a PDT photosensitizer, revealing its multifunctional promise to cancer therapy.
The current trend in improving the energy efficiency of cooling systems in buildings focuses on utilizing the thermal comfort state of the occupants as the real-time temperature control criterion. This new trend puts forward new requirements on the accuracy and efficiency of thermal sensation recognition. This paper focuses on developing the capability to automatically evaluate and detect thermal sensations from human behavior from surveillance video. The proposed approach is based solely on the real-time visual status of humans and assumes that the thermal-adaptive behavior of people contains a variety of information that allows for inferences about the temperature comfort of a room. To this end, we develop a technique to apply thermal-adaptive behavior recognition to thermal sensation inference based on a spatial temporal graph convolutional network (ST-GCN). The approach can recognize 16 thermal-adaptive behaviors, which collected from two questionnaires were conducted at Shandong Normal University, in surveillance videos in real time. Based on the collected data, we release a video dataset of thermal adaptive behaviors and extensively evaluate the proposed approach on the newly collected thermal adaptive behavior video benchmark. The experimental results show that the median prediction accuracy of thermal sensation is up to 78% when all actions are considered, which demonstrates the effectiveness of the approach. (c) 2021 Elsevier B.V. All rights reserved.
Selective production of aromatic aldehydes is an important challenge in the synthesis of fine chemicals. This study presents a viable strategy for the production of benzaldehyde using a magnetic recoverable photocatalyst. Graphitic carbon nitride was submitted to a thermal post-treatment, for partial exfoliation (g-CN-T) and combined with magnetic nanoparticles of Fe3O4. The composite containing 18 wt.% of Fe3O4 shows a remarkable magnetic response. The efficiency of this composite was evaluated in the selective photocatalytic conversion of benzyl alcohol into benzaldehyde. A good compromise was observed in terms of selectivity for benzaldehyde formation and ability of recovery at the end of the photocatalytic reaction by the application of a magnetic field. Reutilization experiments using this hybrid material revealed a slight decrease of efficiency after the first run only. Moreover, hydrogen was generated during the photocatalytic production of benzaldehyde. Thus, the combination of gCN-T and magnetic nanoparticles provided an impetus to design a photocatalyst with easy and inexpensive features for selective synthesis of organic compounds.
Graph Neural Network (GNN) has received tremendous attention due to their power in learning graph representations by modeling the topological structure and aggregating feature information. However, the scalar node representations learned from GNN may not be sufficient to effectively preserve the attributes of the node/graph features, resulting in suboptimal graph representation. Repeated averaging gathers too much noise, which makes the features of nodes in different classes over-mixed and leads to the problem of over smoothing. Inspired by the concept of capsule network proposed by Hinton, we propose a new framework for graph classification, named CapsualGNN, which takes full advantage of Graph Neural Network and Capsule Network. Specifically, we firstly represent nodes as groups of capsules, in which each capsule extracts distinctive features of its corresponding node. Then, we exploit routing mechanism to capture important information and properties at the graph level by the generated multiple embeddings for each graph, and utilize attention mechanism to focus on important features. Finally, to solve the problem of over smoothing, we introduce class residual connection for GCN. In addition, we also introduce parameter for distinguishing self-connected nodes and other nodes. We evaluate the framework by using six graph datasets on biological information and social networks, and demonstrate that CapsualGNN outperforms other SOTA techniques on the task of graph classification. (c) 2021 Elsevier Inc. All rights reserved.
Few-shot object detection methods have made prodigious progress in recent years. However, these methods are designed for optical images at a single scale, which leads to significantly degraded detection performance due to object scale variation of remote sensing images. In this letter, we propose a few-shot object detection method for the problem of scale variation in remote sensing images. More specifically, our model contains two main components: a context-aware pixel aggregation (CPA) that allows the model to adapt to objects at different scales through different scale convolution and a context-aware feature aggregation (CFA) that enhances context awareness to obtain more semantic information through a graph convolution network (GCN). Experiments on the DIOR dataset demonstrate that our model can achieve a satisfying detection performance on remote sensing images, and our model performs significantly better than the state-of-the-art model.
Image retrieval is one of the most critical foundations for many content-based search applications. However, the image retrieval methods have to balance demands on both training accuracy and generalization effectiveness. In this paper, we propose a graph convolution network (GCN) to improve retrieval robustness by integrating the constructs of normalized residual network (NRN) model and feature dropout (FD) operations. The normalized residual networks use skip connection and normalize vectors in each layer to enhance the learning and strengthen the generalization ability. The feature dropout step randomly discards a portion of features in the network to prevent the model from overfitting. We tested our proposed model on several benchmark datasets and the experiment results showed an improvement of 1-3 mAP in comparison with the state-of-the-art Guided Similarity Separation (GSS) algorithm.
Speech emotion recognition is a key branch of affective computing. Nowadays, it is common to detect emotional diseases through speech emotion recognition. Various detection methods of emotion recognition, such as LTSM, GCN, and CNN, show excellent performance. However, due to the robustness of the model, the recognition results of the above models will have a large deviation. So in this article, we use black boxes to combat sample attacks to explore the robustness of the model. After using three different black-box attacks, the accuracy of the CNN-MAA model decreased by 69.38% at the best attack scenario, while the word error rate (WER) of voice decreased by only 6.24%, indicating that the robustness of the model does not perform well under our black-box attack method. After adversarial training, the model accuracy only decreased by 13.48%, which shows the effectiveness of adversarial training against sample attacks. Our code is available in Github.
Neural networks and deep learning have been successfully applied to tackle problems in drug discovery with increasing accuracy over time. There are still many challenges and opportunities to improve molecular property predictions with satisfactory accuracy even further. Here, we proposed a deep-learning architecture model, namely Bidirectional long short-term memory with Channel and Spatial Attention network (BCSA), of which the training process is fully data-driven and end to end. It is based on data augmentation and SMILES tokenization technology without relying on auxiliary knowledge, such as complex spatial structure. In addition, our model takes the advantages of the long- and short-term memory network (LSTM) in sequence processing. The embedded channel and spatial attention modules in turn specifically identify the prime factors in the SMILES sequence for predicting properties. The model was further improved by Bayesian optimization. In this work, we demonstrate that the trained BSCA model is capable of predicting aqueous solubility. Furthermore, our proposed method shows noticeable superiorities and competitiveness in predicting oil-water partition coefficient, when compared with state-of-the-art graphs models, including graph convoluted network (GCN), message-passing neural network (MPNN), and AttentiveFP.
Graph convolutional neural networks (GCNs) embed nodes in a graph into Euclidean space, which has been shown to incur a large distortion when embedding real-world graphs with scale-free or hierarchical structure. Hyperbolic geometry offers an exciting alternative, as it enables embeddings with much smaller distortion. However, extending GCNs to hyperbolic geometry presents several unique challenges because it is not clear how to define neural network operations, such as feature transformation and aggregation, in hyperbolic space. Furthermore, since input features are often Euclidean, it is unclear how to transform the features into hyperbolic embeddings with the right amount of curvature. Here we propose Hyperbolic Graph Convolutional Neural Network (HGCN), the first inductive hyperbolic GCN that leverages both the expressiveness of GCNs and hyperbolic geometry to learn inductive node representations for hierarchical and scale-free graphs. We derive GCNs operations in the hyperboloid model of hyperbolic space and map Euclidean input features to embeddings in hyperbolic spaces with different trainable curvature at each layer. Experiments demonstrate that HGCN learns embeddings that preserve hierarchical structure, and leads to improved performance when compared to Euclidean analogs, even with very low dimensional embeddings: compared to state-of-the-art GCNs, HGCN achieves an error reduction of up to 63.1% in ROC AUC for link prediction and of up to 47.5% in F1 score for node classification, also improving state-of-the art on the Pubmed dataset.
Urban ride-hailing demand prediction is a long-term but challenging task for online car-hailing system decision, taxi scheduling and intelligent transportation construction. Accurate urban ridehailing demand prediction can improve vehicle utilization and scheduling, reduce waiting time and traffic congestion. Existing traffic flow prediction approaches mainly utilize region-based situation awareness image or station-based graph representation to capture traffic spatial dynamic while we observe that combination of situation awareness image and graph representation are also critical for accurate forecasting. In this paper, we propose the Multiple Spatio-Temporal Information Fusion Networks (MSTIF-Net), a novel deep learning approach to better fuse multiple situation awareness information and graphs representation. MSTIF-Net model integrates structures of Graph Convolutional Neural Networks (GCN), Variational Auto-Encoders (VAE) and Sequence to Sequence Learning (Seq2seq) model to obtain the joint latent representation of urban ride-hailing situation that contain both Euclidean spatial features and non-Euclidean structural features, and capture the spatio-temporal dynamics. We evaluate the proposed model on two real-world large scale urban traffic datasets and the experimental studies demonstrate MSTIF-Net has achieved superior performance of urban ride-Hailing demand prediction compared with some traditional state-of-art baseline models.
Link prediction, which is used to identify the potential relationship between nodes, is an important issue in network science. In existing studies, the traditional methods based on the structural similarity of nodes make it challenging to complete the task of link prediction in large-scale or sparse networks. Although emerging methods based on deep learning can solve this problem, most of the work mainly completes the link prediction through the similarity of the representation vector of network structure information. Many empirical studies show that link formation is affected by node attributes, and similarity is not the only criterion for the formation of links in reality. Accordingly, this paper proposed a two-stage deep-learning model for link prediction (i.e, TDLP), where the node representation vector of the network structure and attributes was obtained in the first stage, while link prediction was realized through supervised learning in the second stage. The empirical results on real networks showed that our model significantly outperforms the traditional methods (e.g., CN and RA), as well as newly proposed deep-learning methods (e.g., GCN and VGAE). This study not only proposed a deep-learning framework for link prediction from the perspective of structure and attribute fusion and link distribution capture, but also lays a methodological foundation for practical applications based on link prediction.
The graph convolution algorithm currently suffers from the drawback of not fusing point cloud information and point cloud topology structure information based on visual selectivity features and using absolute quantities like distance as features, resulting in the algorithm losing geometric invariance. This information serves as the foundation for the "Graph Convolution Algorithm Based on Visual Selectivity and Application of Point Cloud Analysis". In order to propose a graph convolutional kernel and its design method based on visual selectivity, the algorithm analyzes the global characteristics of the point cloud "close in the vicinity and sparse in the distance," the local selectivity of the point cloud topology structure in the neighborhood, and the consistency between features and visual selectivity of primates. By combining point cloud information with point cloud topology structure information features, a graph convolution computation method was built, and the algorithm's geometric invariance was confirmed. The recognition and semantic segmentation performances of the approach in this study were verified using the ModelNet40 and ShapeNetPart data sets in comparison to the PointNet, PointNet++, DGCNN, KPConv, and 3D-GCN algorithms. The experimental design demonstrates that the algorithm presented in this research is accurate and practical, has geometric invariance, and performs better at semantic segmentation and recognition than conventional algorithms.
The recent advancement in spatial transcriptomics technology has enabled multiplexed profiling of cellular transcriptomes and spatial locations. As the capacity and efficiency of the experimental technologies continue to improve, there is an emerging need for the development of analytical approaches. Furthermore, with the continuous evolution of sequencing protocols, the underlying assumptions of current analytical methods need to be re-evaluated and adjusted to harness the increasing data complexity. To motivate and aid future model development, we herein review the recent development of statistical and machine learning methods in spatial transcriptomics, summarize useful resources, and highlight the challenges and opportunities ahead.
Time-series transcriptomes of a biological process obtained under different conditions are useful for identifying the regulators of the process and their regulatory networks. However, such data are 3D (gene expression, time, and condition), and there is currently no method that can deal with their full complexity. Here, we developed a method that avoids time-point alignment and normalization between conditions. We applied it to analyze time-series transcriptomes of developing maize leaves under light-dark cycles and under total darkness and obtained eight time-ordered gene coexpression networks (TO-GCNs), which can be used to predict upstream regulators of any genes in the GCNs. One of the eight TO-GCNs is light-independent and likely includes all genes involved in the development of Kranz anatomy, which is a structure crucial for the high efficiency of photosynthesis in C-4 plants. Using this TO-GCN, we predicted and experimentally validated a regulatory cascade upstream of SHORTROOT1, a key Kranz anatomy regulator. Moreover, we applied the method to compare transcriptomes from maize and rice leaf segments and identified regulators of maize C-4 enzyme genes and RUBISCO SMALL SUBUNIT2. Our study provides not only a powerful method but also novel insights into the regulatory networks underlying Kranz anatomy development and C-4 photosynthesis.
Graph neural networks (GNNs) have demonstrated a remarkable ability in the task of semi-supervised node classification. However, most existing GNNs suffer from the nonrobustness issues, which poses a great challenge for applying GNNs into sensitive scenarios. Some researchers concentrate on constructing an ensemble model to mitigate the nonrobustness issues. Nevertheless, these methods ignore the interaction among base models, leading to similar graph representations. Moreover, due to the deterministic propagation applied in most existing GNNs, each node highly relies on its neighbors, leaving the nodes to be sensitive to perturbations. Therefore, in this paper, we propose a novel framework of graph ensemble learning based on knowledge passing (called GEL) to address the above issues. In order to achieve interaction, we consider the predictions of prior models as knowledge to obtain more reliable predictions. Moreover, we design a multilayer DropNode propagation strategy to reduce each node's dependence on particular neighbors. This strategy also empowers each node to aggregate information from diverse neighbors, alleviating oversmoothing issues. We conduct experiments on three benchmark datasets, including Cora, Citeseer, and Pubmed. GEL outperforms GCN by more than 5% in terms of accuracy across all three datasets and also performs better than other state-of-the-art baselines. Extensive experimental results also show that the GEL alleviates the nonrobustness and oversmoothing issues.
Multi-hop reading comprehension focuses on one type of factoid question, where a system needs to properly integrate multiple pieces of evidence to correctly answer a question. Previous work approximates global evidence with local coreference information, encoding coreference chains with DAG-styled GRU layers within a gated-attention reader. However, coreference is limited in providing information for rich inference. We introduce a new method for better connecting global evidence, which forms more complex graphs compared to DAGs. To perform evidence integration on our graphs, we investigate two recent graph neural networks, namely graph convolutional network (GCN) and graph recurrent network (GRN). Experiments on two standard datasets show that richer global information leads to better answers. Our approach shows highly competitive performances on these datasets without deep language models (such as ELMo).
Unmanned aerial vehicles (UAVs) in the role of flying anchor nodes have been proposed to assist the localisation of terrestrial Internet of Things (IoT) sensors and provide relay services in the context of the upcoming 6G networks. This paper considered the objective of tracing a mobile IoT device of unknown location, using a group of UAVs that were equipped with received signal strength indicator (RSSI) sensors. The UAVs employed measurements of the target's radio frequency (RF) signal power to approach the target as quickly as possible. A deep learning model performed clustering in the UAV network at regular intervals, based on a graph convolutional network (GCN) architecture, which utilised information about the RSSI and the UAV positions. The number of clusters was determined dynamically at each instant using a heuristic method, and the partitions were determined by optimising an RSSI loss function. The proposed algorithm retained the clusters that approached the RF source more effectively, removing the rest of the UAVs, which returned to the base. Simulation experiments demonstrated the improvement of this method compared to a previous deterministic approach, in terms of the time required to reach the target and the total distance covered by the UAVs.
Carbon-based-materials, owing to their wide availability and low cost, have been utilized for a variety of applications including heterogeneous catalysis. Various carbonaceous materials have been used as supports for transition metals or other materials. These support materials have shown their potential for development of green and sustainable approaches to heterogeneous catalysis. In this review, we discuss the utilization of carbon-based materials as supports for heterogeneous catalysts, especially in organic transformations. We have focused our discussions predominantly on four categories of carbonaceous supports, namely graphene (including, graphene oxide (GO) and reduced graphene oxide (RGO)), graphitic carbon nitride (GCN), carbon nanotubes (CNT) and activated carbon (AC) for various organic transformation reactions. Several approaches for the synthesis of these materials along with their application as heterogeneous catalysts for organic transformation reactions have been elaborated in detail. In addition, different aspects of organic synthesis, including hydrogenation, oxidation, reduction, condensation, and multi-component reactions, catalyzed by these materials have been discussed. Furthermore, organic transformations leading to the sustainable synthesis of valuable products from biomass have also been discussed. Finally, after a brief summary, the future perspectives of this very interesting class of materials are provided.
Extraction of traffic features constitutes a key research direction in traffic safety planning. In previous traffic tasks, road network features are extracted manually. In contrast, Network Representation Learning aims to automatically learn low-dimensional node representations. Enlightened by feature learning in Natural Language Processing, representation learning of urban nodes is studied as a supervised task in this paper. Following this line of thinking, a deep learning framework, called StreetNode2VEC, is proposed for learning feature representations for nodes in the road network based on travel routes, and then model parameter calibration is performed. We explain the effectiveness of features from visualization, similarity analysis, and link prediction. In visualization, the features of nodes naturally present a clustered pattern, and different clusters correspond to different regions in the road network. Meanwhile, the features of nodes still retain their spatial information in similarity analysis. The proposed method StreetNode2VEC obtains a AUC score of 0.813 in link prediction, which is greater than that obtained from Graph Convolutional Network (GCN) and Node2vec. This suggests that the features of nodes can be used to effectively and credibly predict whether a link should be established between two nodes. Overall, our work provides a new way of representing road nodes in the road network, which have potential in the traffic safety planning field.
Although deep learning-based methods have been successfully applied to polarimetric synthetic aperture radar (PolSAR) image classification tasks, most of the available techniques are not suitable to deal with PolSAR data on irregular domains, e.g., superpixel graphs, because they are naturally designed as grid-based architectures in Euclidean space. To overcome this limitation and achieve robust PolSAR image classification, this article proposes the multiscale evolving weighted graph convolutional network, where weighted graphs based on superpixel technique and Wishart-derived distance are constructed to enable efficient handling of graphical PolSAR data representations. In this article, we derive a new architectural design named graph evolving module that combines pairwise latent feature similarity and kernel diffusion to refine the graph structure in each scale. Finally, we propose a graph integration module based on self-attention to perform robust hierarchical feature extraction and learn an optimal linear combination of various scales to exploit effective feature propagation on multiple graphs. We validate the superiority of proposed approach on classification performance with four real-measured datasets and demonstrate significant improvements compared to state-of-the-art methods. Additionally, the proposed method has shown strong generalization capacity across datasets with similar land covers.
Learning brain effective connectivity networks (ECN) from functional magnetic resonance imaging (fMRI) data has gained much attention in recent years. With the successful applications of deep learning in numerous fields, several brain ECN learning methods based on deep learning have been reported in the literature. However, current methods ignore the deep temporal features of fMRI data and fail to fully employ the spatial topological relationship between brain regions. In this article, we propose a novel method for learning brain ECN based on spatiotemporal graph convolutional models (STGCM), named STGCMEC, in which we first adopt the temporal convolutional network to extract the deep temporal features of fMRI data and utilize the graph convolutional network to update the spatial features of each brain region by aggregating information from neighborhoods, which makes the features of brain regions more discriminative. Then, based on such features of brain regions, we design a joint loss function to guide STGCMEC to learn the brain ECN, which includes a task prediction loss and a graph regularization loss. The experimental results on a simulated dataset and a real Alzheimer's disease neuroimaging initiative (ADNI) dataset show that the proposed STGCMEC is able to better learn brain ECN compared with some state-of-the-art methods.
Recently, advanced techniques in deep learning such as recurrent neural network (GRU, LSTM and Bi-LSTM) and auto-encoding (attention-based transformer and BERT) have achieved great successes in multiple application domains including text summarization. Recent state-of-the-art encoding-based text summarization models such as BertSum, PreSum and DiscoBert have demonstrated significant improvements on extractive text summarization tasks. However, recent models still encounter common problems related to the language-specific dependency which requires the supports of the external NLP tools. Besides that, recent advanced text representation methods, such as BERT as the sentence-level textual encoder, also fail to fully capture the representation of a full-length document. To address these challenges, in this paper we proposed a novel semantic-ware embedding approach for extractive text summarization, called as: SE4ExSum. Our proposed SE4ExSum is an integration between the use of feature graph-of-words (FGOW) with BERTbased encoder for effectively learning the word/sentence-level representations of a given document. Then, the graph convolutional network (GCN) based encoder is applied to learn the global document's representation which is then used to facilitate the text summarization task. Extensive experiments on benchmark datasets show the effectiveness of our proposed model in comparing with recent state-of-the-art text summarization models.
Vibration signals always contain noise and irregularities, which makes spectrum analysis difficult to extract high-level features. Recently, graph theory has been applied to spectrum analysis to improve the performance of feature extraction. By converting the raw data into graphs, hidden structural and topological information can be obtained. In this article, a spatial-temporal graph-based feature extraction, called SuperGraph, for rotating machinery fault diagnosis is proposed. Specifically, graph theory-based spectrum analysis is used to construct the spatial-temporal graph. Then, the Laplacian matrix-based feature vector is extracted from the constructed spatial-temporal graph. By this means, the spatial-temporal graph is converted into the one-dimensional (1-D) vector for further constructing SuperGraph, where each node of the SuperGraph represents a spatial-temporal graph and the SuperGraph is composed of many local graphs. In the local graph, only the same type of nodes are connected to form a fully connected graph. Thus, the task of graph classification can be transformed into classifying the nodes in the SuperGraph. After graph convolutional network is established for learning and obtaining deep features, the label of nodes is identified from a soft m (LE model. Experiments are conducted on two benchmarking datasets and a practical experimental platform to verify effectiveness of the proposed fault diagnosis method.
The rational design and synthesis of a non-noble-metal electrocatalyst for the hydrogen evolution reaction (HER) and oxygen evolution reaction (OER) with good conductivity, high efficiency, and excellent stability are major challenges in the field of renewable energy. Therefore, we developed a simple and effective method to grow ZIF-67 in situ on graphitic carbon nitride (GCN) and then annealed it to generate nitrogen-doped carbon (NC) loaded with CO@C nanoparticles (Co@C/NC). Benefiting from this in situ growth method, after annealing, a large number of N atoms on the surface of NC nanosheets anchor more metal Co to form more catalytic Co-N active sites. At the same time, the Co@C/NC composites use NC nanosheets as the matrix, which can improve the electrochemical double-layer capacitance and conductivity of the composites. As demonstrated in electrochemical measurements, the OER and HER overpotentials of Co@C/NC composites at a current density of 10 mA cm(-2) were only 300 and 175.4 mV in 1.0 M KOH, respectively. The preparation method is suitable for synthesizing various metal and carbon composite electrocatalysts. It provides ideas for designing and manufacturing high-performance non-noble-metal dual-function OER/HER catalysts.
Background and objective Oculopharyngeal muscular dystrophy (OPMD) is a genetic disorder caused by an abnormal expansion of GCN triplets within the PABPN1 gene. Previous descriptions have focused on lower limb muscles in small cohorts of patients with OPMD, but larger imaging studies have not been performed. Previous imaging studies have been too small to be able to correlate imaging findings to genetic and clinical data. Methods We present cross-sectional, T1-weighted muscle MRI and CT-scan data from 168 patients with genetically confirmed OPMD. We have analysed the pattern of muscle involvement in the disease using hierarchical analysis and presented it as heatmaps. Results of the scans were correlated with genetic and clinical data. Results Fatty replacement was identified in 96.7% of all symptomatic patients. The tongue, the adductor magnus and the soleus were the most commonly affected muscles. Muscle pathology on MRI correlated positively with disease duration and functional impairment. Conclusions We have described a pattern that can be considered characteristic of OPMD. An early combination of fat replacement in the tongue, adductor magnus and soleus can be helpful for differential diagnosis. The findings suggest the natural history of the disease from a radiological point of view. The information generated by this study is of high diagnostic value and important for clinical trial development.
Graph Neural Networks (GNNs) have been widely used for graph learning tasks. The main aspect of GNN's layer-wise message passing is conducting attribute/feature propagation on graph. Most existing GNNs generally conduct feature propagation across all feature dimensions. However, in many real applications, attributes usually contain irrelevant and redundant noise. In this case, attribute/feature selection is de-sired to extract meaningful features and eliminate noisy ones for GNN's layer-wise propagation. Based on this observation, in this paper, we combine I; 2 , 1 /I; 1-norm regularized attribute selection and GNNs together and propose a novel Attribute selection guided GNNs (AsGNNs) for graph data representation. AsGNNs aim to adaptively select some desired meaningful features/attributes that best serve GNNs. More-over, an effective optimization framework has also been derived to train the proposed AsGNNs. The pro-posed AsGNNs provide a general framework which can incorporate any GNNs to conduct feature selection for layer-wise propagation. In this paper, we implement AsGNNs on both graph convolutional network (GCN) and graph attention network (GAT) and develop AsGCN and AsGAT for graph learning. Experimen-tal results on several benchmark datasets demonstrate the effectiveness of the proposed AsGNNs (AsGCN, AsGAT) on semi-supervised learning tasks.(c) 2022 Elsevier Ltd. All rights reserved.
Portfolio management is a decision-making process of periodically reallocating a certain amount of funds into a portfolio of assets, with the objective of maximizing the profits constrained to a given risk level. Due to its nature of learning from dynamic interactions and planning for long-run performance, reinforcement learning (RL) recently has received much attention in portfolio management. However, most of existing RL-based PM approaches in general only consider price changes of portfolio assets and the implicit correlations between price changes, while ignoring the rich relations between companies in the market, such as two assets in the same sector or two companies have a supplier-customer relation, which are very important for trading decision making. To address these limitations, in this paper, we propose GPM, a novel graph convolutional network-based reinforcement learning framework for portfolio management, which first employs Relational Graph Convolutional Network (R-GCN) to extract asset relational features, and then combines relational features with multi-scale temporal features to make trading decisions for better performance. We also introduce softmax with temperature to increase portfolio diversity, which leads to further increase in profits. Experimental results on two real-world datasets: NASDAQ and NYSE, validate the effectiveness of GPM over state-of-the-art PM methods. Further, more experiments are conducted to evaluate GPM with different graph neural networks and different number of network layers, to explore proper settings for different markets. (c) 2022 Elsevier B.V. All rights reserved.
A ternary dual Z-scheme composite gCN/ZnFe2O4/Bi2S3 (ZFO/BS) was synthesized via a facile microwave assisted process and its photocatalytic potential was explored towards visible light driven removal of 2,4,6-triboundFe(2+/3+)|(surf.),Zn+/2+|(surf.)andBi(3+/4+)|(surf.) were effective towards charge carrier channelization and evolution cholorophenol (TCP) with subsequent peroxymonosulfate (PMS) activation. Surface of reactive species. Highest catalytic activity was experienced for the catalyst with 10 wt% Bi2S3 (ZFO/BS(10)) and 98.9% TCP was removed with 0.25 gL-1 catalyst and 1.0 gL-1 PMS, under 60 mins visible light irradiation (intensity: 80 W). Construction of dual Z-scheme heterojunction was studied using XPS and the mechanism of e(-)/h(+) separation was elucidated. In-depth radical scavenging and EPR analysis confirmed the coexistence and relative contributions of various reactive radicals towards degradation. Plausible TCP degradation pathway was designed based on intermediate analysis. This study elucidates the superiority of dual Z-scheme ternary heterojunction towards separation of photogenerated charge carriers and mineralization of various emerging contaminants.
With the rapid development of intelligent operation and management in metro systems, accurate network-scale passenger flow prediction has become an essential component in real-time metro management. Although numerous novel methods have been applied in this field, critical barriers still exist in integrating travel behaviors and comprehensive spatiotemporal dependencies into prediction. This study constructs the metro system as a knowledge graph and proposes a split-attention relational graph convolutional network (SARGCN) to address these challenges. Breaking the limitations of physical metro networks, we develop a metro topological graph construction method based on the historical origin-destination (OD) matrix to involve travel behaviors. Then, we design a metro knowledge graph construction method to incorporate land-use features. To adapt prior knowledge of metro systems, we subsequently propose the SARGCN model for network-scale metro passenger flow pre-diction. This model integrates the relational graph convolutional network (R-GCN), split-attention mechanism, and long short-term memory (LSTM) to explore the spatiotemporal correlations and dependence between pas-senger inflow and outflow. According to the model validation conducted on the metro systems in Shenzhen and Hangzhou, China, the SARGCN model outperforms the advanced baselines. Furthermore, quantitative experi-ments also reveal the effectiveness of its component and the constructed metro knowledge graph.
Knowledge graphs such as DBpedia, Freebase or Wikidata always contain a taxonomic backbone that allows the arrangement and structuring of various concepts in accordance with hypo-hypernym ("class-subclass") relationship. With the rapid growth of lexical resources for specific domains, the problem of automatic extension of the existing knowledge bases with new words is becoming more and more widespread. In this paper, we address the problem of taxonomy enrichment which aims at adding new words to the existing taxonomy. We present a new method which allows achieving high results on this task with little effort. It uses the resources which exist for the majority of languages, making the method universal. We extend our method by incorporating deep representations of graph structures like node2vec, Poincare embeddings, GCN etc. that have recently demonstrated promising results on various NLP tasks. Furthermore, combining these representations with word embeddings allows us to beat the state of the art. We conduct a comprehensive study of the existing approaches to taxonomy enrichment based on word and graph vector representations and their fusion approaches. We also explore the ways of using deep learning architectures to extend taxonomic backbones of knowledge graphs. We create a number of datasets for taxonomy extension for English and Russian. We achieve state-of-the-art results across different datasets and provide an in-depth error analysis of mistakes.
Graph clustering, aiming to partition nodes of a graph into various groups via an unsupervised approach, is an attractive topic in recent years. To improve the representative ability, several graph auto-encoder (GAE) models, which are based on semisupervised graph convolution networks (GCN), have been developed and they have achieved impressive results compared with traditional clustering methods. However, all existing methods either fail to utilize the orthogonal property of the representations generated by GAE or separate the clustering and the training of neural networks. We first prove that the relaxed k-means will obtain an optimal partition in the inner-product distance used space. Driven by theoretical analysis about relaxed k-means, we design a specific GAE-based model for graph clustering to be consistent with the theory, namely Embedding GAE (EGAE). The learned representations are well explainable so that the representations can be also used for other tasks. To induce the neural network to produce deep features that are appropriate for the specific clustering model, the relaxed k-means and GAE are learned simultaneously. Meanwhile, the relaxed k-means can be equivalently regarded as a decoder that attempts to learn representations that can be linearly constructed by some centroid vectors. Accordingly, EGAE consists of one encoder and dual decoders. Extensive experiments are conducted to prove the superiority of EGAE and the corresponding theoretical analyses.
In EGFR-treatment naive NSCLC patients, high-level MET amplification is detected in approximately 2-3% and is considered as adverse prognostic factor. Currently, clinical trials with two different inhibitors, capmatinib and tepotinib, are under way both defining different inclusion criteria regarding MET amplification from proven amplification only to defining an exact MET copy number. Here, 45 patient samples, including 10 samples without MET amplification, 5 samples showing a low-level MET amplification, 10 samples with an intermediate-level MET amplification, 10 samples having a high-level MET amplification by a MET/CEN7 ratio >= 2.0 and 10 samples showing a high-level MET amplification with GCN >= 6, were evaluated by MET FISH, MET IHC, a ddPCR copy number assay, a NanoString nCounter copy number assay and an amplicon-based parallel sequencing. The MET IHC had the best concordance with MET FISH followed by the NanoString copy number assay, the ddPCR copy number assay and the custom ampliconbased parallel sequencing assays. The concordance was higher in the high-level amplified cohorts than in the low- and intermediate-level amplified cohorts. In summary, currently extraction-based methods cannot replace the MET FISH for the detection of low-level, intermediate-level and high-level MET amplifications, as the number of false negative results is very high. Only for the detection of high-level amplified samples with a gene copy number >= 6 extraction-based methods are a reliable alternative. (C) 2019 The Authors. Published by Elsevier B.V. on behalf of Research Network of Computational and Structural Biotechnology.
This paper studies the methodology of inferring bullish or bearish sentiments in the financial domain. The task aims to predict a real value to represent the sentiment intensity concerning a target (company or stock symbol) in a text. Previous researches have proved the validity of using deep neural networks to automatically learn semantic and syntactic information for sentiment prediction. Despite the promising performance, these approaches implicitly obtain the target-sentiment representation by a sentence-level vector, lacking explicitly modeling the semantic relatedness between a target and its context. In this paper, we tackle the task by a novel semantic and syntactic enhanced neural model (SSENM), which incorporates dependency graph and context words to guide a target representation. In particular, we devise a self-attentive mechanism to capture semantic contextual information and an edge-enhanced graph convolutional network (E-GCN) to aggregate node-to-node features. In addition, the existing FSA is limited in size, which is prone to the overfitting problem for modern neural models. We further develop a Manifold Mixup strategy to generate pseudo data in training. We perform extensive experiments on two public benchmarks, SemEval2017task5 and FiQA challenges. Results show that our model outperforms the state-of-the-art model by 2% wcs scores on SemEval2017task5 and 3% R-2 scores on FiQA, respectively. Finally, we present detailed analysis to indicate the effectiveness of each proposed component.
In the skeleton-based action recognition, mining information from the joints and limbs of human skeletons plays a key role. Previous studies treated the skeleton data as vectors and could not explicitly capture the joint interactions (e.g., RNN-based methods), or modeled the joint interactions in a local manner and may lose important cues without global response mapping (e.g., CNN and GCN (Graph Convolution Network) based methods). In this work, we address these problems by considering the potential relations of all the node pairs and edge pairs on the skeleton graphs. A dilation group-specific convolution module is proposed to aggregate relation messages of all the unit pairs on the skeleton graphs. By enumerating all the pair relations, the joint interactions could be learned explicitly and globally. It is then enhanced by introducing the attention pooling including temporal attention, spatial attention and channel attention. By stacking such several blocks, the relation messages of the node pairs are augmented by multi-layer propagation. Finally, the late fusion of four streams is used to combine the predictions of different inputs including node pairs, edge pairs and corresponding frame differences. The proposed method, termed cony-relation network, achieves competitive performance on two large scale datasets, NTU RGB+D and Kinetics. (C) 2019 Elsevier B.V. All rights reserved.
Orexin-1 receptor (OX1R) has been proved to play an important role in the regulation of emotions, addiction, panic, or anxiety, and thus been a promising drug target for the treatments of drug addiction, anxiety, and depression, pain, and obesity. In this work, GRU-based deep neural network combined with transfer learning was successfully used to build a molecular generation model of OX1R antagonists by using 2,066,376 drug-like molecules from ChEMBL database and 11525 known OX1R antagonists. The results showed that the GRU-based generation model can accurately grasp the SMILES grammar of the drug-like molecules and tend to generate potential OX1R antagonists after transfer learning. Then, graph convolutional network (GCN) with multi-head attention mechanism followed by a cascade of traditional ligand, receptor, and rule-based virtual screening was performed to screen potent OX1R antagonists from the generated molecules, which results in 23 de novo potential OX1R antagonists with good drug-like and druggability properties. Overall, this paper integrates the advantages of traditional and data-driven drug design methods and provides important references for the lead compound discovery of OX1R antagonists.
Knowledge graphs (KGs) play a vital role in natural language processing (NLP), which can serve several downstream tasks. Because different views of KGs are usually constructed independently, the multi-view knowledge graph fusion (MVKGF) becomes a hotspot. Although multi-view learning studied very well in past decades, MVKGF is still not well tackled because of the heterogeneous relations and the multi-view KGs. To overcome MVKGF, entity alignment is the most studied. Existing entity alignment methods are dominated by embedding based methods, such as TransE and Graph Neural Networks (GNNs), where the alignment is achieved by measuring the similarities between entity embeddings. However, most previous approaches suffer from the issues of the diverse knowledge facts and the complex neighboring structures. In this paper, we propose a novel K nowledge-aware A ttentional G raph N eural N etwork (KAGNN) model to carefully incorporate both knowledge facts and neighboring structures. In particular, a knowledge-aware attention mechanism is designed to preserve the original semantics and determine the importance of each knowledge fact. Furthermore, a three-layered GCN with highway gates is adopted to learn better entity representations from the neighboring structure information. Thus, our model can be regarded as a multi-view extension of GNN. We validate our model on three cross-lingual datasets and the results show our model beats the state-of-the-art baselines by a large margin.
Deformation twinning is an important mechanism of the plastic deformation of materials. The density of twins also affects the properties of the material. At present, the research methods of deformation twinning mainly depend on in situ EBSD, numerically investigated analysis and the finite element method. The application of machine learning methods to material microstructure research can shorten the time taken for material analysis. Machine learning methods are faced with the problem of the effective representation of the microstructure. We present a deformation twinning research method based on the representation of grain morphology features in a knowledge graph. We construct an autoencoder to extract grain morphology characteristics for building a grain knowledge graph. Then, a graph convolutional network (GCN) and fully connected network are developed to extract grain knowledge graph features and predict the twin density of materials subjected to specific tensile deformation. We use Mg-2Zn-3Li alloy as an experimental example to predict the twin density on three indexes of average grain size, twin boundaries density and average grain surface. The R-2 score of the prediction result on the twin boundaries density is up to 0.510, and the R-2 score of the average grain size and average grain surface is over 0.750. Therefore, the proposed method for deformation twinning research is effective and feasible.
Event Causality Extraction (ECE) plays an essential role in many Natural Language Processing (NLP), such as event prediction and dialogue generation. Recent research in NLP treats ECE as a sequence labeling problem. However, these methods tend to extract the events and their relevant causality using a single collapsed model, which usually focuses on the textual contents while ignoring the intra-element transitions inside events and inter-event causality transition association across events. In general, ECE should condense the complex relationship of intra-event and the causality transition association among events. Therefore, we propose a novel dual-channel enhanced neural network to address this limitation by taking both global event mentions and causality transition association into account. To extract complete event mentions, a Textual Enhancement Channel(TEC) is constructed to learn important intra-event features from the training data with a wider perception field. Then the Knowledge Enhancement Channel(KEC) incorporates external causality transition knowledge using a Graph Convolutional Network (GCN) to provide complementary information on event causality. Finally, we design a dynamic fusion attention mechanism to measure the importance of the two channels. Thus, our proposed model can incorporate both semantic-level and knowledge-level representations of events to extract the relevant event causality. Experimental results on three public datasets show that our model outperforms the state-of-the-art methods.(c) 2022 Elsevier B.V. All rights reserved.
Background: Since dementia is preventable with early interventions, biomarkers that assist in diagnosing early stages of dementia, such as mild cognitive impairment (MCI), are urgently needed. Methods: Multiomics analysis of amnestic MCI (aMCI) peripheral blood (n = 25) was performed covering the tran-scriptome, microRNA, proteome, and metabolome. Validation analysis for microRNAs was conducted in an inde-pendent cohort (n = 12). Artificial intelligence was used to identify the most important features for predicting aMCI. Findings: We found that hsa-miR-4455 is the best biomarker in all omics analyses. The diagnostic index tak-ing a ratio of hsa-miR-4455 to hsa-let-7b-3p predicted aMCI patients against healthy subjects with 97% over-all accuracy. An integrated review of multiomics data suggested that a subset of T cells and the GCN (general control nonderepressible) pathway are associated with aMCI. Interpretation: The multiomics approach has enabled aMCI biomarkers with high specificity and illuminated the accompanying changes in peripheral blood. Future large-scale studies are necessary to validate candidate biomarkers for clinical use. (c) 2022 The Author(s). Published by Elsevier Masson SAS. This is an open access article under the CC BY-NC -ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)
In this work, we first applied metal-free polymeric catalysts to drive the photocatalytic denitrification (PCDN) reaction under visible light. We developed a hydrothermal-transverse thermal stripping method to prepare Cl/S co-doped metal-free carbon nitride nanotubes as the photocatalysts (Cl/S-TCN). With larger specific surface area, stronger light response intensity and wider light absorption range, the PCDN performance of Cl/S-TCN was 19 times higher than that of carbon nitride (GCN, obtained by direct calcination of melamine) under visible light. In hole scavenger experiments, the PCDN reaction was dominated by photo-generated electrons (e(-)) over Cl/S-TCN in acidic solutions. DFT calculations showed that surface Cl and S dopants preferentially adsorbed the O atoms in NO3- and delivered photoinduced-e(-) to N atoms through O atoms, ultimately breaking the N-O bond. Such reaction pathway was rarely reported in previous studies. Hence, this work contributes to the first insight into PCDN catalyzed by atomically modified metal-free photocatalyst under visible light.
INTRODUCTION AN IMPORTANCE: Testicular epidermoid cysts (TECs) are rare benign testicular neoplasms. Recently, testicular epidermoid cysts (TECs) are listed as teratoma of prepubertal type, however it is still difficult to differentiate the epidermoid cyst from malign testicular tumor. Therefore, we would like to report testicular epidermoid cyst at our institution. CASE PRESENTATION: A 67-year-old man from Indonesia, presented with chronical painless mass of testis since one year ago. On physical examination obtained normal penile structure with descended testicles, palpable intrascrotal mass with size of 10*7*5cm, firm consistency, immobile, without any tenderness, and no lymphadenophaty in groin. Scrotal USG showed intratesticular mass, homogenous parenchym, showed no vascularization during Doppler examination. Histopathological examination revealed the specimen of right scrotum with size of 12.5cm*8.5cm*6.1cm with red-brownish colored, during lamellation, obtained encapsulated mass with size of 12.2cm*7.9cm*6cm, hollowed space filled with porridge-like texture with capsule thickness of 0.1-0.3cm. CLINICAL DISCUSSION: Epidermoid cysts are benign lesions occurring on the skin usually, however, it rarely occurs in intratesticular area. Most of the cases (60%) presented with the typical onion-ring phenomenon. Histopathological findings commonly revealed typical well-defined cyst lined by a fibrous membrane. No skin appendages are found in the cyst's lumen and no germ cell neoplasm (GCN) is present in the adjacent testicular parenchyma. CONCLUSION: All testicular masses are considered malignant until proven otherwise. It is necessary to do accurate diagnosis for the prevention of unnecessary radical orchiectomy.
Aspect-based sentiment analysis aims to determine sentiment polarities toward specific aspect terms within the same sentence or document. Most recent studies adopted attention-based neural network models to implicitly connect aspect terms with context words. However, these studies were limited by insufficient interaction between aspect terms and opinion words, leading to poor performance on robustness test sets. In addition, we have found that robustness test sets create new sentences that interfere with the original information of a sentence, which often makes the text too long and leads to the problem of long-distance dependence. Simultaneously, these new sentences produce more non-target aspect terms, misleading the model because of the lack of relevant knowledge guidance. This study proposes a knowledge guided multi-granularity graph convolutional neural network (KMGCN) to solve these problems. The multi-granularity attention mechanism is designed to enhance the interaction between aspect terms and opinion words. To address the long-distance dependence, KMGCN uses a graph convolutional network that relies on a semantic map based on fine-tuning pre-trained models. In particular, KMGCN uses a mask mechanism guided by conceptual knowledge to encounter more aspect terms (including target and non-target aspect terms). Experiments are conducted on 12 SemEval-2014 variant benchmarking datasets, and the results demonstrated the effectiveness of the proposed framework.
Graph convolution networks (GCNs), with their efficient ability to capture high-order connectivity in graphs, have been widely applied in recommender systems. Stacking multiple neighbor aggregation is the major operation in GCNs. It implicitly captures popularity features because the number of neighbor nodes reflects the popularity of a node. However, existing GCN-based methods ignore a universal problem: users' sensitivity to item popularity is differentiated, but the neighbor aggregations in GCNs actually fix this sensitivity through graph Laplacian normalization, leading to suboptimal personalization. In this work, we propose to model multigrained popularity features and jointly learn them together with high-order connectivity to match the differentiation of user preferences exhibited in popularity features. Specifically, we develop a Joint Multigrained Popularity-aware Graph Convolution Collaborative Filtering model, short for JMP-GCF, which uses a popularity-aware embedding generation to construct multigrained popularity features and uses the idea of joint learning to capture the signals within and between different granularities of popularity features that are relevant for modeling user preferences. In addition, we propose a multistage stacked training strategy to speed up model convergence. We conduct extensive experiments on three public datasets to show the state-of-the-art performance of JMP-GCF. The complete codes of JMP-GCF are released at https://github.com/kangliu1225/JMP-GCF.
A series of visible-light-driven g-C3N4 nanosheet/carbon dots/Ag6Si2O7 (signify as GCNNS/CD/ASO) photocatalysts are achieved by a facile precipitation procedure. Among ternary nanocomposites, the GCNNS/CD/ASO (10%) photocatalyst demonstrated the highest performance for degradation of RhB that was nearly 37.4, 10.7, and 4.3 times premier than the bare GCN, GCNNS, and binary GCNNS/CD photocatalysts, respectively. The photocatalytic ability of the GCNNS/CD/ASO (10%) nanocomposite can be assigned to the rapid segregation of generated e(-)/h(+) pairs, because CD act as electron mediator among GCNNS and ASO semiconductors. Furthermore, the h(+), center dot O-2(-), and center dot OH species were obtained as the oxidative species in the photocatalytic system by the scavenging tests. In addition, the degradation intermediates were identified by gas chromatography-mass spectroscopy (GC-MS). Also, through investigating the electrochemical properties, the photocatalytic mechanism based on the energy bands was offered to display the increased e(-)/h(+) pairs separation and migration, which cause the excellent photocatalytic ability. This work highlights the potential application of extremely effective CD and Ag6Si2O7 anchored GCNNS in environmental applications. (C) 2019 Taiwan Institute of Chemical Engineers. Published by Elsevier B.V. All rights reserved.
The visual analysis of histopathological images is the gold standard for diagnosing breast cancer, yet a strenuous and an intricate task that requires years of pathologist training. Therefore, automating this task using computer-aided diagnosis (CAD) is highly expected. This paper proposes a new transfer learning-based approach to automated classification of breast cancer from histopathological images, including magnification dependent (MD) and magnification independent (MI) binary and eight-class classifications. We apply the deep neural network ResNet-18 to this problem, which is pre-trained on ImageNet, a large dataset of common images. We then design our transfer learning method to refine the network on histopathological images. Our transfer learning method is based on block-wise fine-tuning strategy; in which we make the last two residual blocks of the deep network model more domain-specific to our target data. It substantially helps to avoid over-fitting and speed up the training. Furthermore, we strengthen the adaptability of the proposed approach by using global contrast normalization (GCN) based on the target's data values and three-fold data augmentation on training data. The experimental results of MD and MI binary and eight-class classifications on the publicly available BreaKHis dataset demonstrate that our approach is promising and effective, outperforming recent state-of-the-art MD and MI counterparts by a fair margin.
A high efficiency hybrid electrocatalyst (Co3O4-rGO-gC(3)N(4)) was developed via a facile method of doping cobalt oxide (Co3O4) on reduced graphene oxide (rGO) supported by graphitic carbon nitride (GCN, g-C3N4). The synthesized composite was tested for supercapacitance and hydrogen evolution reaction (HER) activity. The results demonstrate excellent supercapacitance properties based on tests with two electrode configurations to produce capacitance of 675 F g(-1) at a current density of 1 A g(-1). The electrode showed excellent capacitance retention ability (85.4%), cycling stability (93%), high energy density (28.3 W h kg(-1)) and power density (0.8 kW kg(-1)). The composite exhibited excellent electrocatalytic activity for hydrogen evolution reaction (HER) with a Tafel slope of 65 mV.dec(-1), a low onset overpotential of 75 mV and an overpotential of -180 mV at a current density of 10 mA cm(-2). The performance of the doped hybrid was found to be superior to those reported for other metallic and non-metallic materials.
In this study, we reported a novel type-I heterojunction between red phosphorus and graphitic carbon nitride under vacuum condition, which is a novel synthesis process. For preparing the red phosphorus composites, the vacuum condition is appropriate to prevent it from self-ignition. The prepared materials were analyzed with different analytic techniques for the confirmation of their heterojunctions and structure formation. The introduction of red phosphorus into graphitic carbon nitride, reduce the structural defects and increase the charge separation ability. After medication, the synthesized composite shows an enhanced photocatalytic activity against acute toxicity category-III non-color (MTSM, Metsulfuron methyl) and color (RhB), organic pollutants. The photocatalytic degradation mechanism (Mott-Schottky and VB-XPS) study reveal that red phosphorus/graphitic carbon nitride possess type-I heterojunction with enhanced catalytic behavior, due to the effective transformation of photo-generated electrons from CB of GCN to CB of RP with the help of heterojunctions and due to unmoved photo holes on VBs. Synthesized composites also maintained their performance after reused them in three cyclic form.
Graph convolutional network (GCN) has been widely used in handling various graph data analysis tasks. For graph classification tasks, existing work on graph classification mainly focuses on two aspects of graph similarity: physical structure and practical property. In this paper, we consider the problem of graph classification from a new perspective, namely structural properties. Graph similarity is defined based on structural properties such as maximum clique, minimum vertex coverage, and minimum dominating set of graphs. To capture these structural features, we design an adaptive motif to mine the higher-order connectivity information among nodes. Furthermore, to obtain the unique down-sampling in graph pooling stage, we propose a de-correlation pooling approach. Our extensive experiments on several artificially generated datasets show that our proposed model can effectively classify graphs with similar structural property. It is also experimentally compared with the baseline approach to demonstrate the effectiveness of our adaptive motif GCNs.
With the development of society and the improvement of people's material level, more and more people like to travel by airplane. If we can predict the passenger flow of an airline in advance, it can be used as an important decision-making basis for its flight route planning, crew scheduling planning and ticket price formulation in the process of management and operation. However, due to the high complexity of aviation network, the existing traffic prediction methods generally have the problem of low prediction accuracy. In order to overcome this problem, this paper makes full use of graph convolutional neural network and long-short memory network to construct a prediction system with short-term prediction ability. Specifically, this paper uses the graph convolutional neural network as a feature extraction tool to extract the key features of air traffic data, and solves the problem of long term and short term dependence between data through the long term memory network, then we build a high-precision air traffic prediction system based on it. Finally, we design a comparison experiment to compare the algorithm with the traditional algorithms. The results show that the algorithm we proposed in this paper has a higher accuracy in air flow prediction according to the lower loss function value.
Oculopharyngeal muscular dystrophy (OPMD) is a rare late onset genetic disease leading to ptosis, dysphagia and proximal limb muscles at later stages. A short abnormal (GCN) triplet expansion in the polyA-binding protein nuclear 1 (PABPN1) gene leads to PABPN1-containing aggregates in the muscles of OPMD patients. Here we demonstrate that treating mice with guanabenz acetate (GA), an FDA-approved antihypertensive drug, reduces the size and number of nuclear aggregates, improves muscle force, protects myofibers from the pathology-derived turnover and decreases fibrosis. GA targets various cell processes, including the unfolded protein response (UPR), which acts to attenuate endoplasmic reticulum (ER) stress. We demonstrate that GA increases both the phosphorylation of the eukaryotic translation initiation factor 2 alpha subunit and the splicing of Xbp1, key components of the UPR. Altogether these data show that modulation of protein folding regulation is beneficial for OPMD and promote the further development of GA or its derivatives for treatment of OPMD in humans. Furthermore, they support the recent evidences that treating ER stress could be therapeutically relevant in other more common proteinopathies.
Motivation: The functional changes of the genes, RNAs and proteins will eventually be reflected in the metabolic level. Increasing number of researchers have researched mechanism, biomarkers and targeted drugs by metabolites. However, compared with our knowledge about genes, RNAs, and proteins, we still know few about diseases-related metabolites. All the few existed methods for identifying diseases-related metabolites ignore the chemical structure of metabolites, fail to recognize the association pattern between metabolites and diseases, and fail to apply to isolated diseases and metabolites. Results: In this study, we present a graph deep learning based method, named Deep-DRM, for identifying diseases-related metabolites. First, chemical structures of metabolites were used to calculate similarities of metabolites. The similarities of diseases were obtained based on their functional gene network and semantic associations. Therefore, both metabolites and diseases network could be built. Next, Graph Convolutional Network (GCN) was applied to encode the features of metabolites and diseases, respectively. Then, the dimension of these features was reduced by Principal components analysis (PCA) with retainment 99% information. Finally, Deep neural network was built for identifying true metabolite-disease pairs (MDPs) based on these features. The 10-cross validations on three testing setups showed outstanding AUC (0.952) and AUPR (0.939) of Deep-DRM compared with previous methods and similar approaches. Ten of top 15 predicted associations between diseases and metabolites got support by other studies, which suggests that Deep-DRM is an efficient method to identify MDPs.
Electrochemical sensing of acetaminophen (ACT) was made using un-doped mesoporous (average pore size 33.2 nm) carbon nitride (mGCN) modified glassy carbon electrode (GCE) in physiological buffer (PBS, pH 7.4). GCN was prepared by pyrolysis of agriculture urea precursor and characterized using XRD, UV-visible, FTIR, XPS and HRTEM techniques and observed 3D mesoporous structure. The electrochemical methods CV, EIS, and DPV were employed to explore the behaviour of mesoporous carbon nitride thin film modified electrode and its acet-aminophen electrochemical sensing. The sensor showed a linear range from 0.1 to 1400 mu M with sensitivity and limit of detection 0.0180 mA cm-2 mM-1 and 93.22 nM. Practical electrochemical sensing of ACT was demonstrated using unprocessed pharmaceutical tablet, body fluids (urine, blood serum), and herbal (ayurvedic Ocimumtenuifrum and Coleus amboinicus plants) samples. These electrochemical data were very well corrob-orated with results obtained from UV-Visible detection.
In electricity markets, locational marginal price (LMP) forecasting is particularly important for market participants in making reasonable bidding strategies, managing potential trading risks, and supporting efficient system planning and operation. Unlike existing methods that only consider LMPs' temporal features, this paper tailors a spectral graph convolutional network (GCN) to greatly improve the accuracy of short-term LMP forecasting. A three-branch network structure is then designed to match the structure of LMPs' compositions. Such kind of network can extract the spatial-temporal features of LMPs, and provide fast and high-quality predictions for all nodes simultaneously. The attention mechanism is also implemented to assign varying importance weights between different nodes and time slots. Case studies based on the IEEE-118 test system and real-world data from the PJM validate that the proposed model outperforms existing forecasting models in accuracy, and maintains a robust performance by avoiding extreme errors.
CRISPR/Cas9 is a powerful genome-editing technology that has been widely applied in targeted gene repair and gene expression regulation. One of the main challenges for the CRISPR/Cas9 system is the occurrence of unexpected cleavage at some sites (off-targets) and predicting them is necessary due to its relevance in gene editing research. Very few deep learning models have been developed so far to predict the off-target propensity of single guide RNA (sgRNA) at specific DNA fragments by using artificial feature extract operations and machine learning techniques; however, this is a convoluted process that is difficult to understand and implement for researchers. In this research work, we introduce a novel graph-based approach to predict off-target efficacy of sgRNA in the CRISPR/Cas9 system that is easy to understand and replicate for researchers. This is achieved by creating a graph with sequences as nodes and by using a link prediction method to predict the presence of links between sgRNA and off-target inducing target DNA sequences. Features for the sequences are extracted from within the sequences. We used HEK293 and K562 t datasets in our experiments. GCN predicted the off-target gene knockouts (using link prediction) by predicting the links between sgRNA and off-target sequences with an auROC value of 0.987.
A cost-effective, scalable, eco-friendly, flexible smart apparel was fabricated by casting method employing polypyrrole(PPy) with biodegradable polyvinyl alcohol on cotton fabric. Different concentration of PPy is embedded in PVA. The X-ray diffraction pattern affirmed the interaction between PVA and PPy. Optical absorption spectra showed two peaks corresponding to PVA and the excitonic peak of PPy higher concentration of GCN exhibited a low bandgap harvesting the visible and IR part of the solar regime. High optical (0.104 S/cm) and electrical conductivity (2.3928 x 10-3) were attained for the higher concentration of PPy which might be attributed to the availability of the more defect centers in between the HUMO and LUMO of PVA. The room temperature photoluminescence exhibited enhanced blue emission at 379 nm for a higher concentration of PPy in PVA thin film due to the charge transfer mechanism. As 5PPy possesses, higher PL emission and higher electrical conductivity, it was taken further to fabricate smart apparel in cotton cloth. The fabricated smart apparels can be used to manufacture flexible, lightweight, eco-friendly optoelectronic devices.
In the context of low-carbon globalization, green development has become the common pursuit of all countries and the theme of China's development in the new era. Fine particulate matter (PM2.5) is one of the main challenges affecting air quality, and how to accurately predict PM2.5 plays a pivotal role in environmental governance. However, traditional data-driven approaches and deep learning methods for prediction rarely consider spatiotemporal features. Furthermore, different regions always have various implicit or hidden states, which have rarely been considered in the off-the-shelf model. To solve these problems, this study proposed a novel Spatial-Temporal Matrix Factorization Generative Adversarial Network (ST MFGAN) to capture spatiotemporal correlations and overcome the regional diversity problem at the same time. Specifically, Generative Adversarial Network (GAN) composed of graph Convolutional Network (GCN) and Long-Short-Term Memory (LSTM) network is used to generate a large amount of reliable spatiotemporal data, and matrix factorization network is used to decompose the vector output by GAN into multiple sub-networks. PM2.5 are finally combined and jointly predicted by the fusion layer. Extensive experiments show the superiority of the newly designed method.
Recognition of partial discharge (PD) patterns in gas insulated switchgear (GIS), as a basis of fault diagnosis, provides essential information for the condition assessment of GIS. However, traditional recognition methods are limited to handcrafted feature extraction or are extremely sensitive to the quantity and quality of datasets. Therefore, this article proposes a knowledge-driven algorithm, composed of the feature space and the knowledge space, to automatically extract PD features and improve the performance on noised, insufficient, and imbalanced datasets. First, the deep residual network (ResNet) in feature space extracts features from raw signals. Second, in knowledge space, the graph convolutional network (GCN) extracts additional information from the knowledge graph, which compensates for the missing information of original datasets. Finally, the algorithm recognizes patterns by ranking similarities between feature vectors and knowledge vectors. Verified by the comparison experiment, the proposed algorithm outperforms traditional methods with the accuracy of 99.58% on the experimental dataset and 95.67% on the online-detected dataset. Moreover, the accuracy of the proposed algorithm achieves 88.79% and 7037% on noised and insufficient datasets, respectively, while the F-measure is higher than those of the comparison methods by 12.95% similar to 18.69% on imbalanced datasets.
Multi-topic sentiment analysis, which aims to identify the topics and classify their corre-sponding sentiment, is of great value in understanding consumers' behaviour and improv-ing services. Because of the high cost of manual annotation of the datasets, topic model -based approaches that model the joint distributions of both topics and sentiments have been studied previously. Some studies proposed models that leverage the prior knowledge derived from the pre-trained word embeddings and have proven effective. However, most of the existing models are based on the assumption that words and topics are conditionally independent, ignoring the dependency relations among them. Additionally, the fine-tuning of the pre-trained word embeddings to incorporate the contextual information is also neglected in these models. This could result in the ambiguous representations of topics. In this paper, we propose a novel weakly-supervised graph-based joint sentiment topic model (W-GJST) that integrates an edge-gated graph convolutional network (E-GCN) into a joint sentiment-topic model. An importance sampling-based training method is proposed to learn the contextual representations of topics and words efficiently. Additionally, a self -training multi-topic classifier is designed for the multi-label topic identification. Experiments on two benchmark datasets demonstrate the superiority of the proposed W-GJST compared to the baseline models in terms of topic modelling, topic identification and topic-sentiment identification. (c) 2022 Elsevier Inc. All rights reserved.
Cu catalysts with different defect types are widely applied in CO2 activation and conversion, however, the underlying role of Cu surface defect types in tuning the activity and selectivity is still unclear due to the complexity of surface defect types. This work constructed a series of Cu catalysts including the perfect surface, as well as the point and line defect surfaces to reveal the role of Cu surface defect types on CO2 activation and conversion using theoretical calculations. The results show that Cu defect types can effectively tune the activity and selectivity of CO2 activation and conversion; the line defect Cu surfaces have higher CO2 activation activity than the point defect and perfect surfaces. Both the line defect Cu(111)(LD) and (511)(LD) surfaces are screened out to present the highest activity toward C-1 and C-2 species formation, respectively. Moreover, Cu surfaces with different defects present an inverted volcano-type curve between d-band center and CO2 activation activity, both Cu(111)(LD) and (511)(LD) with excellent activity are attributed to the moderate d-band center. Further, the generalized coordination number (GCN) of Cu surface is proposed and confirmed as an effective descriptor to predict the activity of CO2 activation on different Cu surfaces. The results can provide the valuable structural information for the design and prediction of Cu catalysts with excellent activity and selectivity in CO2 activation and conversion.
Luminal A is the most common breast cancer molecular subtype in women worldwide. These tumors have characteristic yet heterogeneous alterations at the genomic and transcriptomic level. Gene co-expression networks (GCNs) have contributed to better characterize the cancerous phenotype. We have previously shown an imbalance in the proportion of intra-chromosomal (cis-) over inter-chromosomal (trans-) interactions when comparing cancer and healthy tissue GCNs. In particular, for breast cancer molecular subtypes (Luminal A included), the majority of high co-expression interactions connect gene-pairs in the same chromosome, a phenomenon that we have called loss of trans- co-expression. Despite this phenomenon has been described, the functional implication of this specific network topology has not been studied yet. To understand the biological role that communities of co-expressed genes may have, we constructed GCNs for healthy and Luminal A phenotypes. Network modules were obtained based on their connectivity patterns and they were classified according to their chromosomal homophily (proportion of cis-/trans- interactions). A functional overrepresentation analysis was performed on communities in both networks to observe the significantly enriched processes for each community. We also investigated possible mechanisms for which the loss of trans- co-expression emerges in cancer GCN. To this end we evaluated transcription factor binding sites, CTCF binding sites, differential gene expression and copy number alterations (CNAs) in the cancer GCN. We found that trans- communities in Luminal A present more significantly enriched categories than cis- ones. Processes, such as angiogenesis, cell proliferation, or cell adhesion were found in trans- modules. The differential expression analysis showed that FOXM1, CENPA, and CIITA transcription factors, exert a major regulatory role on their communities by regulating expression of their target genes in other chromosomes. Finally, identification of CNAs, displayed a high enrichment of deletion peaks in cis- communities. With this approach, we demonstrate that network topology determine, to at certain extent, the function in Luminal A breast cancer network. Furthermore, several mechanisms seem to be acting together to avoid trans- co-expression. Since this phenomenon has been observed in other cancer tissues, a remaining question is whether the loss of long distance co-expression is a novel hallmark of cancer.
Despite the great promise of the physics-informed neural networks (PINNs) in solving forward and inverse problems, several technical challenges are present as roadblocks for more complex and realistic applications. First, most existing PINNs are based on point-wise formulation with fully-connected networks to learn continuous functions, which suffer from poor scalability and hard boundary enforcement. Second, the infinite search space over-complicates the non-convex optimization for network training. Third, although the convolutional neural network (CNN)-based discrete learning can significantly improve training efficiency, CNNs struggle to handle irregular geometries with unstructured meshes. To properly address these challenges, we present a novel discrete PINN framework based on graph convolutional network (GCN) and variational structure of PDE to solve forward and inverse partial differential equations (PDEs) in a unified manner. The use of a piecewise polynomial basis can reduce the dimension of search space and facilitate training and convergence. Without the need of tuning penalty parameters in classic PINNs, the proposed method can strictly impose boundary conditions and assimilate sparse data in both forward and inverse settings. The flexibility of GCNs is leveraged for irregular geometries with unstructured meshes. The effectiveness and merit of the proposed method are demonstrated over a variety of forward and inverse computational mechanics problems governed by both linear and nonlinear PDEs.(c) 2021 Elsevier B.V. All rights reserved.
Convolution neural networks (CNNs) and graph representation learning are two common methods for hyperspectral image (HSI) classification. Recently, graph convolutional neural networks, a combination of CNN and graph representation learning, have shown great potential in the HSI classification problem. However, the existing graph convolution network (GCN)-based methods have many problems, such as overdependence on the adjacency matrix, usage of a single modal feature, and lower accuracy than the mature CNN method. In this article, we propose a feature fusion hypergraph neural network ((FHNN)-H-2) for HSI classification. (FHNN)-H-2 first generates hyperedges from features of different modalities to construct a hypergraph representing multimodal features in HSI. Then, the HSI and the extracted hypergraph are input into the hypergraph convolutional neural network for learning. In addition, we propose three feature fusion strategies. The first strategy is the most basic spatial and spectral feature fusion. The second strategy fuses the spectral features extracted by a pretrained multilayer perceptron (MLP) with the spatial features to reduce the redundant information of the original spectral features. The third strategy uses the fusion of CNN features, spectral features, and spatial features to explore the capabilities of (FHNN)-H-2. Sufficient experiments on four datasets have proved the effectiveness of (FHNN)-H-2.
Partial label learning (PLL) is a weakly supervised learning framework where each training instance is associated with more than one candidate label, and only one of them is the true label. Most of the existing PLL algorithms directly disambiguate the candidate labels according to the instance feature sim-ilarity, but fail to discover the latent semantic relationship over the entire dataset. In this paper, method GraphDPI, an innovative deep partial label disambiguation by graph representation via mutual information maximization , is proposed. This method can capture the semantic clusters with the most unique infor-mation in the latent space and automatically adapt to different feature distributions. Specifically, a new sampling method based on the graph is proposed to estimate mutual information, extending GCN to the field of weakly supervised learning. Therefore, the graph representation of the data can contain more distinguishing information to disambiguate candidate labels by maximizing the mutual information of the local graph representation and the global one. Furthermore, the triplet loss is introduced to fully ex-ploit the relationship between instances and extract the latent embedding representation over the entire dataset. It thereby can make the model output as large as possible on the inter-class variation and as small as possible on the intra-class variation. Finally, the candidate labels can be disambiguated by the difference between semantic clusters. Experiments reveal the overwhelming performances of GraphDPI.(c) 2022 Published by Elsevier Ltd.
Complex and diverse microbial communities have certain impacts on human health, and specific drugs are needed to treat diseases caused by microbes. However, most of the discovery of associations between microbes and drugs is through biological experiments, which are time-consuming and expensive. Therefore, it is crucial to develop an effective and computational model to detect novel microbe-drug associations. In this study, we propose a model based on Multiple Kernel fusion on Graph Convolutional Network, called MKGCN, for inferring novel microbe-drug associations. Our model is built on the heterogeneous network of microbes and drugs to extract multi-layer features, through Graph Convolutional Network (GCN). Then, we respectively calculate the kernel matrix by embedding features on each layer, and fuse multiple kernel matrices based on the average weighting method. Finally, Dual Laplacian Regularized Least Squares is used to infer new microbe-drug associations by the combined kernel in microbe and drug spaces. Compared with the existing tools for detecting biological bipartite networks, our model has excellent prediction effect on three datasets via three types of cross-validation. Furthermore, we also conduct a case study of the SARS-Cov-2 virus and make a deduction about drugs that may be able to associate with COVID-19. We have proved the accuracy of the prediction results through the existing literature. (c) 2021 Published by Elsevier B.V.
Graph clustering based on embedding aims to divide nodes with higher similarity into several mutually disjoint groups, but it is not a trivial task to maximumly embed the graph structure and node attributes into the low dimensional feature space. Furthermore, most of the current advanced methods of graph nodes clustering adopt the strategy of separating graph embedding technology and clustering algorithm, and ignore the potential relationship between them. Therefore, we propose an innovative end to-end graph clustering framework with joint strategy to handle the complex problem in a non-Euclidean space. In terms of learning the graph embedding, we propose a new variational graph auto-encoder algorithm based on the Graph Convolution Network (GCN), which takes into account the boosting influence of joint generative model of graph structure and node attributes on the embedding output. On the basis of embedding representation, we implement a self-training mechanism through the construction of auxiliary distribution to further enhance the prediction of node categories, thereby realizing the unsupervised clustering mode. In addition, the loss contribution of each cluster is normalized to prevent large clusters from distorting the embedding space. Extensive experiments on real-world graph datasets validate our design and demonstrate that our algorithm has highly competitive in graph clustering over state-of-theart methods. (c) 2021 Elsevier Ltd. All rights reserved.
We propose a spherical kernel for efficient graph convolution of 3D point clouds. Our metric-based kernels systematically quantize the local 3D space to identify distinctive geometric relationships in the data. Similar to the regular grid CNN kernels, the spherical kernel maintains translation-invariance and asymmetry properties, where the former guarantees weight sharing among similar local structures in the data and the latter facilitates fine geometric learning. The proposed kernel is applied to graph neural networks without edge-dependent filter generation, making it computationally attractive for large point clouds. In our graph networks, each vertex is associated with a single point location and edges connect the neighborhood points within a defined range. The graph gets coarsened in the network with farthest point sampling. Analogous to the standard CNNs, we define pooling and unpooling operations for our network. We demonstrate the effectiveness of the proposed spherical kernel with graph neural networks for point cloud classification and semantic segmentation using ModelNet, ShapeNet, RueMonge2014, ScanNet and S3DIS datasets. The source code and the trained models can be downloaded from https://github.com/hlei-ziyan/SPH3D-GCN.
Traffic prediction has drawn increasing attention for its ubiquitous real-life applications in traffic management, urban computing, public safety, and so on. Recently, the availability of massive trajectory data and the success of deep learning motivate a plethora of deep traffic prediction studies. However, the existing neural-network-based approaches tend to ignore the correlations between multiple types of moving objects located in the same spatio-temporal traffic area, which is suboptimal for traffic prediction analytics. In this paper, we propose a multi-source deep traffic prediction framework over spatio-temporal trajectory data, termed as MDTP. The framework includes two phases: spatio-temporal feature modeling and multi-source bridging. We present an enhanced graph convolutional network (GCN) model combined with long short-term memory network (LSTM) to capture the spatial dependencies and temporal dynamics of traffic in the feature modeling phase. In the multi-source bridging phase, we propose two methods, Sum and Concat, to connect the learned features from different trajectory data sources. Extensive experiments on two real-life datasets show that MDTP i) has superior efficiency, compared with classical time-series methods, machine learning methods, and state-of-the-art neural-network-based approaches; ii) offers a significant performance improvement over the single-source traffic prediction approach; and iii) performs traffic predictions in seconds even on tens of millions of trajectory data. we develop MDTP+, a user-friendly interactive system to demonstrate traffic prediction analysis.
In this work, we benchmark a variety of single- and multi-task graph neural network (GNN) models against lower-bar and higher-bar traditional machine learning approaches employing human engineered molecular features. We consider four GNN variants - Graph Convolutional Network (GCN), Graph Attention Network (GAT), Message Passing Neural Network (MPNN), and Attentive Fingerprint (AttentiveFP). So far deep learning models have been primarily benchmarked using lower-bar traditional models solely based on fingerprints, while more realistic benchmarks employing fingerprints, whole-molecule descriptors and predictions from other related endpoints (e. g., LogD7.4) appear to be scarce for industrial ADME datasets. In addition to time-split test sets based on Genentech data, this study benefits from the availability of measurements from an external chemical space (Roche data). We identify GAT as a promising approach to implementing deep learning models. While all the deep learning models significantly outperform lower-bar benchmark traditional models solely based on fingerprints, only GATs seem to offer a small but consistent improvement over higher-bar benchmark traditional models. Finally, the accuracy of in vitro assays from different laboratories predicting the same experimental endpoints appears to be comparable with the accuracy of GAT single-task models, suggesting that most of the observed error from the models is a function of the experimental error propagation.
As urban traffic pollution continues to increase, there is an urgent need to build traffic emission monitoring and forecasting system for the urban traffic construction. The traffic emission monitoring and forecasting system's core is the prediction of traffic emission's evolution. And the traffic flow prediction on the urban road network contributes greatly to the prediction of traffic emission's evolution. Due to the complex non-Euclidean topological structure of traffic networks and dynamic heterogeneous spatial-temporal correlations of traffic conditions, it is difficult to obtain satisfactory prediction results with less computation cost. To figure these issues out, a novel deep learning traffic flow forecasting framework is proposed in this paper, termed as Ensemble Attention based Graph Time Convolutional Networks (EAGTCN). More specifically, each component of our model contains two major blocks: (1) the global spatial patterns are captured by the spatial blocks which are fused by the Graph Convolution Network (GCN) and spatial ensemble attention layer; (2) the temporal patterns are captured by the temporal blocks which are composed by the Time Convolution Net (TCN) and temporal ensemble attention layers. Experiments on two real-world datasets demonstrate that our model obtains more accurate prediction results than the state-of-the-art baselines at less computation expense especially in the long-term prediction situation.
Intelligent fault diagnosis has made significant progress, thanks to machine learning, particularly deep-learning algorithms. However, most machine-learning algorithms treat samples as independent and ignore the correlations between samples that contain valuable information for creating discriminative features. In recent years, graph neural networks have increased diagnostic performance by capturing the correlation between samples according to establishing the inherent structure of data, but they also suffer from two shortcomings. First, a simple graph only represents pairwise relationships of samples and cannot depict complex higher-order structures. Second, the generated graph structure is insufficient to characterize the data without an explicit structure. To address the above two issues, this article proposes a multiresolution hypergraph neural network, a novel algorithm that can discover higher-order complex relationships between samples, and mine the structure hidden in data by establishing and fusing hypergraph structures at multiple resolutions. Experiments are conducted on three datasets to demonstrate the effectiveness of the proposed algorithm.
Graph neural networks (GNNs) build on the success of deep learning models by extending them for use in graph spaces. Transfer learning has proven extremely successful for traditional deep learning problems, resulting in faster training and improved performance. Despite the increasing interest in GNNs and their use cases, there is little research on their transferability. This research demonstrates that transfer learning is effective with GNNs, and describes how source tasks and the choice of GNN impact the ability to learn generalisable knowledge. We perform experiments using real-world and synthetic data within the contexts of node classification and graph classification. To this end, we also provide a general methodology for transfer learning experimentation and present a novel algorithm for generating synthetic graph classification tasks. We compare the performance of GCN, GraphSAGE and GIN across both synthetic and real-world datasets. Our results demonstrate empirically that GNNs with inductive operations yield statistically significantly improved transfer. Further, we show that similarity in community structure between source and target tasks support statistically significant improvements in transfer over and above the use of only the node attributes.
Recent advances on aerial image semantic segmentation mainly employ the domain adaption to transfer knowledge from the source domain to the target domain. Despite the remarkable achievement, most methods focus on the global marginal distribution alignment to reduce the domain shift between source and target domains, leading to a wrong mapping of the well-aligned features. In this article, we propose an effective unsupervised domain adaptation approach, which relies on a novel entropy guided adversarial learning algorithm, for aerial image semantic segmentation. In specific, we perform local feature alignment between domains by learning a self-adaptive weight from the target prediction probability map to measure the interdomain discrepancy. To exploit the meaningful structure information among semantic regions, we propose to utilize the graph convolutions for long-range semantic reasoning. Comprehensive experimental results on the benchmark dataset of aerial image semantic segmentation and natural scenes demonstrate the superior performance of the proposed method compared to the state-of-the-art methods.
Traffic forecasting is an important prerequisite for the application of intelligent transportation systems in urban traffic networks. The existing works adopted RNN and CNN/GCN, among which GCRN is the state-of-the-art work, to characterize the temporal and spatial correlation of traffic flows. However, it is hard to apply GCRN to the large-scale road networks due to high computational complexity. To address this problem, we propose abstracting the road network into a geometric graph and building a Fast Graph Convolution Recurrent Neural Network (FastGCRNN) to model the spatial-temporal dependencies of traffic flow. Specifically, we use FastGCN unit to efficiently capture the topological relationship between the roads and the surrounding roads in the graph with reducing the computational complexity through importance sampling, combine GRU unit to capture the temporal dependency of traffic flow, and embed the spatiotemporal features into Seq2Seq based on the Encoder-Decoder framework. Experiments on large-scale traffic data sets illustrate that the proposed method can greatly reduce computational complexity and memory consumption while maintaining relatively high accuracy.
The development of social media has caused a boom in information sharing, but it also provides an ideal platform for publishing and spreading rumors. On social media platforms, there are a lot of comments, which contain the user's most direct views and reactions to the post. They can be utilized as clues to detect rumors. Recently, some methods are proposed to detect rumors through post and comments which usually focus on content information. However, except for this, other information such as reply structure, mutual selection information between post and comments, topic drift within comments also can help detect rumors. In this paper, we propose a novel model, PostCom2DR, for rumor detection. In PostCom2DR, a reply graph between post and comments is first created. Then a bilevel GCN and self-attention mechanism are built to learn the representation of comments. Secondly, a post-comment co-attention mechanism is introduced to selectively fuse information, and this helps the model focus on more relevant information. Through the above modules, we can get the global representation of post and comments. In addition, a 1D CNN is built to capture the local topic drift on time series inside the comments. Finally, we concatenate the global representation and local representation for rumor detection. Extensive experiments conducted on Chinese and English datasets show that PostCom2DR significantly outperforms other state-of-the-art models on both rumor detection and early detection.
Graph convolutional neural networks have established significant success in solving various machine learning and computer vision problems. For skeleton-based action recognition, graph convolutional neural networks are the most suitable choice since human skeleton resembles to a graph. Stacking body skeletons over the length of video sequence results in a very complex spatio-temporal graph of many nodes and edges. Modeling the graph convolutional network directly with such a complex graph curtails the performance due to the redundancy of insignificant nodes and edges in the graph. Also for skeleton based action recognition, the long-term contextual information is of central importance and many current architectures may fail to capture such contextual information. Therefore in order to alleviate these problems, we propose graph sparsification technique using edge effective resistance to better model the global context information and to eliminate redundant nodes and edges in the graph. Furthermore, we incorporate self-attention graph pooling to retain local properties and graph structures while pooling operation. To the best of our knowledge, we are the first to apply graph sparsification using edge effective resistance for skeleton-based action recognition and our proposed method is confirmed to be effective on action recognition, which achieves state-of-the-art results on publicly available datasets: UTD-MHAD, J-HMDB, NTU-RGB + D-60, NTU-RGB + D-120 and Kinetics dataset. (C) 2020 Elsevier B.V. All rights reserved.
The vehicle HVAC (heating, ventilating, and air conditioning) system aims to keep passengers thermal comfort and reduce energy consumption. One effective measure is to use temperature prediction to optimize HVAC systems. This paper aimed to comprehensively investigate the potential of machine learning methods applied to cockpit temperature prediction and proposed a deep learning method considering the Spatio-temporal correlation of the temperature field. Specifically, this study constructs a topological description of the temperature field inspired by the spatial and temporal correlations revealed by the Navier-Stokes equations. The Graph Convolutional Network (GCN) is used to capture the topological structure to obtain spatial features, and the Gated Recurrent Unit (GRU) is used to capture the dynamic change of node attribute to obtain temporal features. Finally, the GCGRU model can extract Spatiotemporal features of the temperature field. The experimental results show that the prediction method using Spatio-temporal features for the temperature field is feasible. The prediction performance is better than all the baseline methods and has the robustness to the data noise. This work is enlightening and may have a further reference to the feasibility study of the vehicle cabin air temperature prediction model. (c) 2022 Elsevier B.V. All rights reserved.
Choosing useful indexes for a relational database is important for efficient query optimiza-tion. However, current methods tend to use the cost estimated by the optimizer in the database management system (DBMS) to measure the benefits of the index and, due to inaccurate cost estimates, do not bring to the most optimal solution. In addition, existing reinforcement learning methods treat the creation of different indexes as independent actions, ignoring the relationships among indexes, which may bring to unnecessary train-ing costs. To address these problems, we propose DeepIndex, an automatic index selector with a learning-based cost estimator to improve the quality of index selection. To accu-rately estimate the benefit of an index, we design a learning-based cost estimator to predict the execution time of queries on certain indexes. In particular, we treat query plans as graphs and develop a model based on graph convolutional network (GCN) to learn features from queries and indexes. After that, we design a reinforcement-learning-based index selection model considering the relationships among indexes and combine our cost estima-tor to select indexes. Extensive experiments on two benchmark workloads JOB and TPC-DS show that our model performs better than state-of-the-art models with the lowest storage costs, and our lowest relative execution cost outperforms the baselines by 38.59% on JOB and 10.42% on TPC-DS.(c) 2022 Elsevier Inc. All rights reserved.
We present a Multi-actor Activity Detection Framework (MADF) to model the interactive relationship among multiple actors for activity detection in extended videos. MADF can detect 3 groups of multi-actor activities with different kinds of actors, which involves three stages: detection, classification and post-processing. In the detection stage, both interaction proposals and actor proposals are generated in each video clip, in order to eliminate irrelevant background in the scene. In the classification stage, 3 different classification networks are proposed to classify the 3 groups of activities. And further, for person-object interaction, an attention mechanism is adopted to help the person-object classification network to pay more attention to the small-scale objects; for person-person interaction, a suppression module is used to improve the accuracy of the person-person activity detection; for person-vehicle interaction, a spatial-temporal graph convolution network (GCN) module is embedded to model the fine-grained relationship between the person and vehicle in the person-vehicle classification network, with a proposed Mutually Exclusive Category Loss (MECLoss) helping this network distinguish mutually exclusive activities. At last, we use the off-the-shelf post-processing methods to re-score the proposals for more stable results. The proposed system achieves a great progress on our baseline and achieves the state-of-the-art results in TRECVID 2021 ActEV challenge.
Cross-media association mining based on heterogeneous information network(HIN) has received widespread attention. However, video is described by only a few words, leading to the lack of association between visual and textual information. As a result, the heterogeneous graph is inevitably incomplete, which brings great challenges to event mining. Fortunately, topological relationships can infer correlations between similar nodes. In view of this, a novel framework of web video event mining based on attention graph structure learning is proposed to generate a new adjacency matrix, which reconstructs the association among nodes. First, a novel heterogeneous network is constructed, while each relation subgraph is produced separately. Then, in each relational subgraph, feature graphs are generated by feature similarity, which can capture potential relationships between nodes. Simultaneously, semantic graph is also created by learning semantic structures to describe complex heterogeneous interactions between node semantics. Next, these graphs are fused by channel attention to reconstruct the correlation among nodes. Finally, graph convolutional network(GCN) is applied for web video event mining. Experiments on web videos from YouTube demonstrate that our proposed method is more effective than the state-of-the-art methods with significant improvement. (C) 2022 Published by Elsevier B.V.
Photocatalytic CO2 reduction to fuels is recognized as a favorable solution to solve the energy crisis and greenhouse effect simultaneously. Herein, to improve the photoreduction efficiency of CO2, a direct Z-scheme NiTiO3/g-C3N4 (NT/GCN) photocatalyst is constructed by a facile calcination method. The highest yield of CH3OH (13.74.mol.g(-1).h(-1)) can be obtained at the optimized NT/GCN40 without any sacrificial agent and cocatalyst, almost 3.29 times higher compared with g-C3N4. Simultaneously, mechanism study by the band potential estimation and electron spin resonance (ESR) analysis provide evidences that the enhanced photoactivity is ascribed to the Z-scheme. This unique structure can enhance the spatial separation of hole-electron pairs, suppress the recombination of charge carriers and remain the strong redox ability. Moreover, this direct Z-scheme NT/GCN40 composite shows good reusability. This work may present a novel way for the design and manufacture of Z-scheme photocatalysts for energy conversion and environmental remediation.
Herein, a novel composite photocatalyst was prepared by the vapor deposition of g-C3N4 on TiO2 nanosquare, dominated with {001} facets. The deposition method is robust, convenient, and effective. The surface topography and structure of the composites were analyzed by XRD, XPS, SEM, and TEM. The mechanism for enhanced photocatalysis was studied using PL, PC, UV-vis-NIR-DRS, TRPL, EIS and EPR. The photocatalytic activities of the fabricated composites were evaluated by the degradation of methylene blue (MB) and hexavalent chromium ions (Cr6+) under visible light irradiation. The photodegradation of MB and Cr6+ was completed in 50 and 40 min, respectively. Based on a pseudo-first-order kinetic model (ln(C-0/C) = kt), the measured the degradation rate constant for MB using gCN/TO5 was 4.6 and 35.9 times higher than that of pure g-C3N4 and TiO2, respectively. Similar results were found for the Cr6+ degradation. The outstanding photocatalytic performance of the g-C3N4 on TiO2 composite was ascribed to the presence of the TiO2/g-C3N4 heterojunctions, which effectively improved the separation of the photoexcited electrons and holes hence the enhancement of visible-light photoactivity. Overall, this work showed a convenient and efficient method for fabricating the visible light photocatalysts with established possible mechanisms for the photoactivity of the hybrid photocatalytic composite material.
The human cerebral cortex is folded into two fundamentally anatomical units: gyri and sulci. Previous studies have demonstrated the genetical, structural, and functional differences between gyri and sulci, providing a unique perspective for revealing the relationship among brain function, cognition, and behavior. While previous studies mainly focus on the functional differences between gyri and sulci under resting or task-evoked state, such characteristics under naturalistic stimulus (NS) which reflects real-world dynamic environments are largely unknown. To address this question, this study systematically investigates spatio-temporal functional connectivity (FC) characteristics between gyri and sulci under NS using a spatio-temporal graph convolutional network model. Based on the public Human Connectome Project dataset of 174 subjects with four different runs of both movie-watching NS and resting state 7T functional MRI data, we successfully identify unique FC features under NS, which are mainly involved in visual, auditory, emotional and cognitive control, and achieve high discriminative accuracy 93.06 % to resting state. Moreover, gyral regions as well as gyro-gyral connections consistently participate more as functional information exchange hubs than sulcal ones among these networks. This study provides novel insights into the functional brain mechanism under NS and lays a solid foundation for accurately mapping the brain anatomy-function relationship.
Monocular depth estimation is a foundation task of three-dimensional (3D) reconstruction which is used to improve the accuracy of environment perception. Because of the simpler hardware requirement, it is more suitable than other multi-view methods. In this study, a new monocular depth estimation algorithm based on graph convolution network (GCN) is proposed. The pixel-wise depth relationship is introduced into conventional convolution neural network (CNN) to make up the disadvantage of processing non-Euclidian data. And the remaining depth topological graph information on the spatial latent variables are extracted based on a multi-scale reconstruction strategy. The final results on NYU-v2 depth dataset and KITTI depth dataset demonstrate that our algorithm improves the quality of monocular depth estimation, especially there are several little objects coexisting in the scenes.
In joint entity and relation extraction, the input document is divided into multiple potential entity regions and context regions, where the characteristics of entities and their relations can often be reflected in the context. Therefore, an effective joint modeling method designed toward the features of different regions can lead to superior performance of joint entity and relation extraction. Previous works tend to implement in-depth modeling only for potential entity regions, ignoring the importance of contextual information for joint entity and relation extraction. In this paper, we propose a Region-based Hypergraph Network (RHGN) for joint entity and relation extraction. The RHGN introduces the concept of regional hypernodes for the first time, and proposes a cooperative method of GCN and BiLSTM to generate hypernodes for each region. Then, a region-based relation hypergraph is constructed for fairly and efficiently aggregate the features of all regions in the sentence. In order to initialize and update the features of the edges and hypernodes in the hypergraph, a Sequence-Enhanced Graph (SEG) unit is designed. Finally, we perform comparison experiments with existing competitive models on three public datasets: the CoNLL04, SciERC and ADE datasets. Experimental results demonstrate that our model achieves a significant improvement over the previous models on both entity recognition and relation extraction, and it also shows superior performance for dataset with nested entities. Extensive additional experiments further confirm the effectiveness of our approach. (C) 2021 Elsevier B.V. All rights reserved.
In recent years, object detection has shown excellent results on a large number of annotated data, but when there is a discrepancy between the annotated data and the real test data, the performance of the trained object detection model is often degraded when it is directly transferred to the real test dataset. Compared with natural images, remote sensing images have great differences in appearance and quality. Traditional methods need to re-label all image data before interpretation, which will consume a lot of manpower and time. Therefore, it is of practical significance to study the Cross-Domain Adaptation Object Detection (CDAOD) of remote sensing images. To solve the above problems, our paper proposes a Rotation-Invariant and Relation-Aware (RIRA) CDAOD network. We trained the network at the image-level and the prototype-level based on a relation aware graph to align the feature distribution and added the rotation-invariant regularizer to deal with the rotation diversity. The Faster R-CNN network was adopted as the backbone framework of the network. We conducted experiments on two typical remote sensing building detection datasets, and set three domain adaptation scenarios: WHU 2012 -> WHU 2016, Inria (Chicago) -> Inria (Austin), and WHU 2012 -> Inria (Austin). The results show that our method can effectively improve the detection effect in the target domain, and outperform competing methods by obtaining optimal results in all three scenarios.
Citation recommendation is an effective and efficient way to facilitate authors finding desired references. This paper presents a novel neural network based model, called gated relational probabilistic stacked denoising autoencoder with localized author (GRSLA) embedding, for global citation recommendation task. Our model is comprised of two modules with different neural network architecture. For each citing and cited papers, we use a gated paper embedding module, which is extended from probabilistic stacked denoising autoencoder (PSDAE) by adding gated units, to obtain their paper vectors. The added gated units are able to utilize text information of cited paper to refine the vector representation of citing paper in multiple semantic levels. For an author in papers, we first apply topic model to obtain his/her semantic neighbors, and then use a localized author embedding (LAE) module to excavate author vector representation from semantic and explicit neighbors. Unlike most graph convolutional network (GCN) based methods, the LAE module is able to avoid computing global Laplacian in whole graph by taking limited neighbors. Moreover, the LAE module can also be stacked to absorb more neighbors, which makes our model have high extendibility. Based on the generation process of GRSLA, we also derive a learning algorithm of our model by maximum a posteriori (MAP) estimation. We conduct experiments on the AAN, DBLP and CORD-19 datasets, and the results show that GRSLA model works well than previous global citation recommendation methods.
Intelligent Transportation Systems (ITS) aim to make transportation smarter, safer, reliable, and environmentally friendly without detrimentally affecting the service quality. ITS can face security issues due to their complex, dynamic, and non-linear properties. One of the most critical security problems is attacks that damage the infrastructure of the entire ITS. Attackers can inject malware code that triggers dangerous actions such as information theft and unwanted system moves. The main objective of this study is to improve the performance of malware detection models using Graph Attention Networks. To detect malware attacks addressing ITS, a Graph Attention Network (GAN)-based framework is proposed in this study. The inputs to this framework are the Application Programming Interface (API)-call graphs obtained from malware and benign Android apk files. During the graph creation, network metrics and the Node2Vec model are utilized to generate the node features. A GAN-based model is combined with different types of node features during the experiments and the performance is compared against Graph Convolutional Network (GCN). Experimental results demonstrated that the integration of the GAN and Node2Vec models provides the best performance in terms of F-measure and accuracy parameters and, also, the use of an attention mechanism in GAN improves the performance. Furthermore, node features generated with Node2Vec resulted in a 3% increase in classification accuracy compared to the features generated with network metrics.</p>
Ab initio studies were conducted to evaluate the performance of hydrogen storage by Mg decorated graphite carbon nitride (g-CN, heptazine structure). In our calculations, we found that each unit of this material can accommodate one Mg atom. Partial charges from Mg were transferred to the pristine material, making itself more electropositive. This is favorable for hydrogen storage, as the adsorbed H-2 molecules can be easily polarized, and the electrostatic interactions can be enhanced. The configurations of the Mg-decorated gCN with multiple adsorbed H-2 molecules were presented in this study, and the related adsorption mechanisms were also discussed in details. Each unit can adsorb at most 7 H-2 molecules with adsorption energies ranging from-0.276 eV to-0.130 eV. In addition, besides Mg, we also noticed that the nitrogen atoms also perform well in hydrogen adsorption. For this novel material, its highest capacity of hydrogen storage can reach to 7.8 wt%, highly surpassing the target value of 5.5 wt% set by the U.S. department of energy (DOE)[1]. The computational results provided in this study indicates a promising prospect for alkali metal functionalized 2D materials in energy storage; and through decent explo- rations, the performance of this class of materials can be largely improved. (c) 2021 Hydrogen Energy Publications LLC. Published by Elsevier Ltd. All rights reserved.
Sea surface temperature (SST) is an important index to detect ocean changes, predict SST anomalies, and prevent natural disasters caused by abnormal changes, dynamic variation of which have a profound impact on the whole marine ecosystem and the dynamic changes of climate. In order to better capture the dynamic changes of ocean temperature, it's vitally essential to predict the SST in the future. A new spatio-temporal attention graph convolutional network (STAGCN) for SST prediction was proposed in this paper which can capture spatial dependence and temporal correlation in the way of integrating gated recurrent unit (GRU) model with graph convolutional network (GCN) and introduced attention mechanism. The STAGCN model adopts the GCN model to learn the topological structure between ocean location points for extracting the spatial characteristics from the ocean position nodes network. Besides, capturing temporal correlation by learning dynamic variation of SST time series data, a GRU model is introduced into the STAGCN model to deal with the prediction problem about long time series, the input of which is the SST data with spatial characteristics. To capture the significance of SST information at different times and increase the accuracy of SST forecast, the attention mechanism was used to obtain the spatial and temporal characteristics globally. In this study, the proposed STAGCN model was trained and tested on the East China Sea.Experiments with different prediction lengths show that the model can capture the spatio-temporal correlation of regional-scale sea surface temperature series and almost uniformly outperforms other classical models under different sea areas and different prediction levels, in which the root mean square error is reduced by about 0.2 compared with the LSTM model.
Fault diagnosis for rolling bearings has been an important engineering problem for decades. To detect the damaged bearing surface, engineers analyze the features from the extracted vibration signals of the machine. As artificial intelligence rapidly develops and provides favorable effects in data analytics, using deep-learning technology to attack fault diagnosis problems has attracted increasing research interest in recent years. However, most existing methods do not provide satisfactory performance in mining the relationship between the signals. Even graph convolutional networks (GCNs) that can perform well in non-Euclidean spaces have limitations, since it only considers extracting features from a single scale, ignoring the potential relationship between signals at various scales. For salvation, we propose a multiscale graph convolutional network (MS-GCN) for this specific problem. In MS-GCN, we put forward a multiscale feature extraction module, which extracts the features of vibration signals two times under diverse receptive field ranges, ensuring that the regularities of signal features can be fully discovered. In addition, we devise a multiscale graph iteration module, which incorporates two single-scale graph iteration modules and a cross-scale graph iteration module, which can fully retain local features based on extensive mining of global information. We also propose a mutual fusion module based on the Bayesian method, which forcibly manipulates various features as a prior and achieves a convincing result. The horizontal visibility graph (HVG) method is used to construct graph models at multiple scales, which can better capture the hidden information of signal vibrations. In experiments, we verify the proposed model on the CWRU dataset to evaluate the method's performance. The results show that our model significantly improved accuracy compared with other state-of-the-art methods.
Convolutional neural networks (CNNs) have made significant progress in the field of cloud detection in remote sensing images thanks to their powerful feature representation capabilities. Existing methods typically aggregate low-level features containing details and high-level features containing semantics to make full use of both features to accurately detect cloud regions. However, CNNs are still limited in their ability to reason about the relationships between features, while not being able to model context well. To overcome this problem, this paper designs a novel feature interaction graph convolutional network model that extends the feature fusion process of convolutional neural networks from Euclidean space to non-Euclidean space. The algorithm consists of three main components: remote sensing image feature extraction, feature interaction graph reasoning, and high-resolution feature recovery. The algorithm constructs a feature interaction graph reasoning (FIGR) module to fully interact with low-level and high-level features and then uses a residual graph convolutional network to infer feature higher-order relationships. The network model effectively alleviates the problem of a semantic divide in the feature fusion process, allowing the aggregated features to fuse valuable details and semantic information. The algorithm is designed to better detect clouds with complex cloud layers in remote sensing images with complex cloud shape, size, thickness, and cloud-snow coexistence. Validated on publicly available 38-Cloud and SPARCS datasets and the paper's own Landsat-8 cloud detection dataset with higher spatial resolution, the proposed method achieves competitive performance under different evaluation metrics. Code is available at https://github.com/HaiLei-Fly/CloudGraph.
In the era of Internet of Things (IoT), intelligent recommendation is playing an important role in our daily life. How to provide personalized information to users is the core concern of Internet content service providers. To improve the recommendation quality, it is a hot topic to go beyond merely user-item interaction records and take social relations into account in IoT. Recently, emerged graph neural networks (GNNs) shine a light on simulating the recursive social diffusion process, to refine user embedding learning. Nevertheless, two key issues have not been well studied in previous studies: 1) they usually model user preference and social influence within a same semantic space and fail to simultaneously inject high-order connectivity information reflected in both user-item interaction graph and user-user social graph and 2) they typically rely on negative sampling to optimize a recommendation model, which makes them highly sensitive to the design of the sampler and hardly makes full use of GPU's computing ability. In light of this, we propose a novel framework for item recommendation, namely, an efficient adaptive graph convolutional network (EAGCN). Specifically, we introduce a space-adaptive graph convolutional module, which could jointly explore the propagation process of user interest and social influence. Furthermore, a user-specific gating mechanism is designed to aggregate user representations from both spaces. To make EAGCN practical in social IoT, we devise a fast nonsampling leaner to optimize EAGCN's parameters with better leveraging matrix computing of GPU. Extensive experiments under four scenarios show that our solution consistently and significantly outperforms strong baseline methods in both model effectiveness and training efficiency.
Pixel-based semantic segmentation models fail to effectively express geographic objects and their topological relationships. Therefore, in semantic segmentation of remote sensing images, these models fail to avoid salt-and-pepper effects and cannot achieve high accuracy either. To solve these problems, object-based models such as graph neural networks (GNNs) are considered. However, traditional GNNs directly use similarity or spatial correlations between nodes to aggregate nodes' information, which rely too much on the contextual information of the sample. The contextual information of the sample is often distorted, which results in a reduction in the node classification accuracy. To solve this problem, a knowledge and geo-object-based graph convolutional network (KGGCN) is proposed. The KGGCN uses superpixel blocks as nodes of the graph network and combines prior knowledge with spatial correlations during information aggregation. By incorporating the prior knowledge obtained from all samples of the study area, the receptive field of the node is extended from its sample context to the study area. Thus, the distortion of the sample context is overcome effectively. Experiments demonstrate that our model is improved by 3.7% compared with the baseline model named Cluster GCN and 4.1% compared with U-Net.
Graph convolutional networks (GCN) have been widely utilized in Alzheimer's disease (AD) classification research due to its ability to automatically learn robust and powerful feature representations. Inter-patient relationships are effectively captured by constructing patients magnetic resonance imaging (MRI) data as graph data, where nodes represent individuals and edges denote the relationships between them. However, the performance of GCNs might be constrained by the construction of the graph adjacency matrix, thereby leading to learned features potentially overlooking intrinsic correlations among patients, which ultimately causes inaccurate disease classifications. To address this issue, we propose an Alzheimer's disease Classification network based on MRI utilizing diffusion maps for multi-scale feature fusion in graph convolution. This method aims to tackle the problem of features neglecting intrinsic relationships among patients while integrating features from diffusion mapping with different neighbor counts to better represent patients and achieve an accurate AD classification. Initially, the diffusion maps method conducts diffusion information in the feature space, thus breaking free from the constraints of diffusion based on the adjacency matrix. Subsequently, the diffusion features with different neighbor counts are merged, and a self-attention mechanism is employed to adaptively adjust the weights of diffusion features at different scales, thereby comprehensively and accurately capturing patient characteristics. Finally, metric learning techniques enhance the similarity of node features within the same category in the graph structure and bring node features of different categories more distant from each other. This study aims to enhance the classification accuracy of AD, by providing an effective tool for early diagnosis and intervention. It offers valuable information for clinical decisions and personalized treatment. Experimentation on the publicly accessible Alzheimer's disease neuroimaging initiative (ADNI) dataset validated our method's competitive performance across various AD-related classification tasks. Compared to existing methodologies, our approach captures patient characteristics more effectively and demonstrates superior generalization capabilities.
Skeletal muscle atrophy is a common condition in aging, diabetes, and in long duration spaceflights due to microgravity. This article investigates multi-modal gene disease and disease drug networks via link prediction algorithms to select drugs for repurposing to treat skeletal muscle atrophy. Key target genes that cause muscle atrophy in the left and right extensor digitorum longus muscle tissue, gastrocnemius, quadriceps, and the left and right soleus muscles are detected using graph theoretic network analysis, by mining the transcriptomic datasets collected from mice flown in spaceflight made available by GeneLab. We identified the top muscle atrophy gene regulators by the Pearson correlation and Bayesian Markov blanket method. The gene disease knowledge graph was constructed using the scalable precision medicine knowledge engine. We computed node embeddings, random walk measures from the networks. Graph convolutional networks, graph neural networks, random forest, and gradient boosting methods were trained using the embeddings, network features for predicting links and ranking top gene-disease associations for skeletal muscle atrophy. Drugs were selected and a disease drug knowledge graph was constructed. Link prediction methods were applied to the disease drug networks to identify top ranked drugs for therapeutic treatment of skeletal muscle atrophy. The graph convolution network performs best in link prediction based on receiver operating characteristic curves and prediction accuracies. The key genes involved in skeletal muscle atrophy are associated with metabolic and neurodegenerative diseases. The drugs selected for repurposing using the graph convolution network method were nutrients, corticosteroids, anti-inflammatory medications, and others related to insulin.
With the advancement of the user application service demands, the IoT system tends to offload the tasks to the edge server for execution. Most of the current studies on edge computation offloading ignore the dependencies between components of the application. The few pieces of research on edge computing offloading which focus on the topology of application are primarily applied in single-user scenarios. Unlike previous work, our work mainly solves dependent task offloading with edge computing in multiuser scenarios, which is more in line with reality. In this article, the dependent task offloading problem is modeled as a Markov decision process (MDP) first. Then, we propose an actor-critic mechanism with two embedding layers for directed acyclic graphs (DAGs)-based multiple dependent tasks computation offloading, namely, ACED, by jointly considering the topology of the application and the channel interference between several users. Finally, the results of simulations also show the priorities of the proposed ACED algorithm.
Connected and automated vehicles (CAVs) have become one of the essential approaches to effectively resolve problems such as traffic safety, road congestion, and energy consumption. However, due to the spatial-temporal interaction of the mixed traffic environment, the driving behaviors of traffic participants are continuously transmitted in time and space. This makes it difficult for the existing decision-making system of CAVs to make accurate judgments and effective strategies. In this study, a rate graph convolution Q-learning network (Rate GQN) is proposed to train a discrete strategy that can improve the comprehensive performance of CAVs in scenarios with spatial-temporal interaction. Firstly, the Rate algorithm is proposed to impose a ratio on the estimates of Q-values from the previous learning process, which improves the stability and performance of the algorithm by reducing the approximate error variance of the target value. Secondly, the traffic Scenario is modeled as a graph structure. And graph convolutional networks are adopted to extract the features information of graph structure to help the CAVs grasp the dynamic traffic interaction information quickly and accurately. Additionally, an internal dynamic multi-objective reward function is presented to improve the comprehensive performance of CAVs, including safety, efficiency, energy saving, and comfort. Finally, comparison and ablation experiments are constructed in a task-based traffic scenario (station stop and traffic light passing). The simulation results show that our Rate GQN method has faster training speed, a more stable training process, and better overall performance than the deep Q-learning network (DQN) and algorithms of the comparison group.
The purpose of text classification is to label the text with known labels. In recent years, the method based on graph neural network (GNN) has achieved good results. However, the existing methods based on GNN only regard the text as the set of co-occurring words, without considering the position information of each word in the statement. At the same time, the method mainly extracts the node features in the graph, and the edge features between the nodes are not used enough. To solve these problems, a new text classification method, graph convolutional network using positions and edges, is proposed. In the word embedding section, a positional encoding input representation is employed to enable the neural network to learn the relative positional information among words. Meanwhile, the dimension of the adjacency matrix is increased to extract the multi-dimensional edge features. Through experiments on multiple text classification datasets, the proposed method is shown to be superior to the traditional text classification method, and has achieved a maximum improvement of more than 4%.
Applying deep learning concepts from image detection and graph theory has greatly advanced protein-ligand binding affinity prediction, a challenge with enormous ramifica-tions for both drug discovery and protein engineering. We build upon these advances by designing a novel deep learning architecture consisting of a 3-dimensional convolutional neural network utilizing channel-wise attention and two graph convolu-tional networks utilizing attention-based aggregation of node features. HAC-Net (Hybrid Attention-Based Convolutional Neural Network) obtains state-of-the-art results on the PDBbind v.2016 core set, the most widely recognized benchmark in the field. We extensively assess the generalizability of our model using multiple train-test splits, each of which maximizes differences between either protein structures, protein sequences, or ligand extended -connectivity fingerprints of complexes in the training and test sets. Furthermore, we perform 10-fold cross-validation with a similarity cutoff between SMILES strings of ligands in the training and test sets and also evaluate the performance of HAC-Net on lower -quality data. We envision that this model can be extended to a broad range of supervised learning problems related to structure -based biomolecular property prediction. All of our software is available as an open-source repository at https://github.com/gregory-kyro/HAC-Net/, and the HACNet Python package is available through PyPI.
With the rapid development of unmanned aerial vehicles (UAVs), object re-identification (Re-ID) based on the UAV platforms has attracted increasing attention, and several excellent achievements have been shown in the traditional scenarios. However, object Re-ID in aerial imagery acquired from the UAVs is still a challenging task, which is mainly due to the reason that variable locations and diverse viewpoints in UAVs platform are always resulting in more appearance ambiguities among the intra-objects and inter-objects. To address the above issues, in this paper, we proposed an adaptively attention-driven cascade part-based graph embedding framework (AAD-CPGE) for UAV object Re-ID. The AAD-CPGE aims to optimally fuse node features and their topological characteristics on the multi-scale structured graphs of parts-based objects, and then adaptively learn the most correlated information for improving the object Re-ID performance. Specifically, we first executed GCNs on the parts-based cascade node feature graphs and topological feature graphs for acquiring multi-scale structured-graph feature representations. After that, we designed a self-attention-based module for adaptive node and topological features fusion on the constructed hierarchical parts-based graphs. Finally, these learning hybrid graph-structured features with the most correlation discriminative capability were applied for object Re-ID. Several experimental verifications on three widely used UAVs-based benchmark datasets were carried out, and comparison with some state-of-the-art object Re-ID approaches validated the effectiveness and benefits of our proposed AAD-CPGE Re-ID framework.
Organic crystal structures exert a profound impact on the physicochemical properties and biological effects of organic compounds. Quantum mechanics (QM)-based crystal structure predictions (CSPs) have somewhat alleviated the dilemma that experimental crystal structure investigations struggle to conduct complete polymorphism studies, but the high computing cost poses a challenge to its widespread application. The present study aims to construct DeepCSP, a feasible pure machine learning framework for minute-scale rapid organic CSP. Initially, based on 177,746 data entries from the Cambridge Crystal Structure Database, a generative adversarial network was built to conditionally generate trial crystal structures under selected feature constraints for the given molecule. Simultaneously, a graph convolutional attention network was used to predict the density of stable crystal structures for the input molecule. Subsequently, the distances between the predicted density and the definition-based calculated density would be considered to be the crystal structure screening and ranking basis, and finally, the density-based crystal structure ranking would be output. Two such distinct algorithms, performing the generation and ranking functionalities, respectively, collectively constitute the DeepCSP, which has demonstrated compelling performance in marketed drug validations, achieving an accuracy rate exceeding 80% and a hit rate surpassing 85%. Inspiringly, the computing speed of the pure machine learning methodology demonstrates the potential of artificial intelligence in advancing CSP research.
Convolutional neural networks (CNNs) have achieved remarkable performance in driver drowsiness detection based on the extraction of deep features of drivers' faces. However, the performance of driver drowsiness detection methods decreases sharply when complications, such as illumination changes in the cab, occlusions and shadows on the driver's face, and variations in the driver's head pose, occur. In addition, current driver drowsiness detection methods are not capable of distinguishing between driver states, such as talking versus yawning or blinking versus closing eyes. Therefore, technical challenges remain in driver drowsiness detection. In this article, we propose a novel and robust two-stream spatial-temporal graph convolutional network (2s-STGCN) for driver drowsiness detection to solve the above-mentioned challenges. To take advantage of the spatial and temporal features of the input data, we use a facial landmark detection method to extract the driver's facial landmarks from real-time videos and then obtain the driver drowsiness detection result by 2s-STGCN. Unlike existing methods, our proposed method uses videos rather than consecutive video frames as processing units. This is the first effort to exploit these processing units in the field of driver drowsiness detection. Moreover, the two-stream framework not only models both the spatial and temporal features but also models both the first-order and second-order information simultaneously, thereby notably improving driver drowsiness detection. Extensive experiments have been performed on the yawn detection dataset (YawDD) and the National TsingHua University drowsy driver detection (NTHU-DDD) dataset. The experimental results validate the feasibility of the proposed method. This method achieves an average accuracy of 93.4% on the YawDD dataset and an average accuracy of 92.7% on the evaluation set of the NTHU-DDD dataset.
Considering the drawbacks of iron-based Fenton process, this work was aimed at designing of an efficient photo-Fenton like process via coupling of CuO/g-C3N4 photocatalyst with H2O2. The photo-Fenton like catalytic process was used for degradation of 2, 4-dimethyl phenol (DMP). The X% CuO/g-C(3)N(4 )Z-shceme photocatalyst samples were fabricated by thermal calcination method, varing the CuO percentage (X = 2 %, 4 % and 8 %) loaded on g-C3N4. A lab-scale photoreactor was used to assess and select the optimal removal efficiency for DMP degradation. The photocatalyst was characterized by advanced spectral techniques. Coupling of CuO/GCN system with H2O2 significantly improved photocatalytic activity via photo-Fenton process. The kinetics of photo-degradation was found to exhibit pseudo-first order reaction rules. The rate of photodegradation was strongly influenced by pH and different concentrations of H2O2. 4%CuO/g-C3N4/H2O2 system proved to be the most efficient and exhibited much higher photo removal efficiency than CuO/g-C3N4 system and permitted attaining 99 % degradation of DMP in reaction time of 120 min. The successful implementation of this work was effective and of significance for the economical decomposition process of pollutants present in water under visible light irradiation. Overall, utilization of the studied system leads to high catalytic efficiency in a relatively short degradation period, which is of immense potential in water purification. (C) 2020 Institution of Chemical Engineers. Published by Elsevier B.V. All rights reserved.
In the era of the Internet and big data, online social media platforms have been developing rapidly, which accelerate rumors circulation. Rumor detection on social media is a worldwide challenging task due to rumor's feature of high speed, fragmental information and extensive range. Most existing approaches identify rumors based on single-layered hybrid features like word features, sentiment features and user characteristics, or multimodal features like the combination of text features and image features. Some researchers adopted the hierarchical structure, but they neither used rumor propagation nor made full use of its retweet posts. In this paper, we propose a novel model for rumor detection based on Graph Neural Networks (GNN), named Hierarchically Aggregated Graph Neural Networks (HAGNN). This task focuses on capturing different granularities of high-level representations of text content and fusing the rumor propagation structure. It applies a Graph Convolutional Network (GCN) with a graph of rumor propagation to learn the text-granularity representations with the spreading of events. A GNN model with a document graph is employed to update aggregated features of both word and text granularity, it helps to form final representations of events to detect rumors. Experiments on two real-world datasets demonstrate the superiority of the proposed method over the baseline methods. Our model achieves the accuracy of 95.7% and 88.2% on the Weibo dataset Ma et al. 2017 and the CED dataset Song et al. IEEE Trans Knowl Data Eng 33(8):3035-3047, 2019 respectively.
The classification and recognition of the shapes of buildings in map space play an important role in spatial cognition, cartographic generalization, and map updating. As buildings in map space are often represented as the vector data, research was conducted to learn the feature representations of the buildings and recognize their shapes based on graph neural networks. Due to the principles of graph neural networks, it is necessary to construct a graph to represent the adjacency relationships between the points (i.e., the vertices of the polygons shaping the buildings), and extract a list of geometric features for each point. This paper proposes a deep point convolutional network to recognize building shapes, which executes the convolution directly on the points of the buildings without constructing the graphs and extracting the geometric features of the points. A new convolution operator named TriangleConv was designed to learn the feature representations of each point by aggregating the features of the point and the local triangle constructed by the point and its two adjacency points. The proposed method was evaluated and compared with related methods based on a dataset consisting of 5010 vector buildings. In terms of accuracy, macro-precision, macro-recall, and macro-F1, the results show that the proposed method has comparable performance with typical graph neural networks of GCN, GAT, and GraphSAGE, and point cloud neural networks of PointNet, PointNet++, and DGCNN in the task of recognizing and classifying building shapes in map space.
Aiming at the problems of complex background, diverse shapes, and object occlusion in aerial images, a cascade reasoning graph network (CRGN) is proposed for multi-fitting detection on transmission lines. First of all, for these three problems mentioned above, co-occurrence knowledge, semantic knowledge, and spatial knowledge were constructed to represent the co-relation of objects by analyzing the characteristics of the transmission line fittings. Next, the Supervised Graph Learning (SGL), Graph Attention network (GAT), and Graph Convolutional Network (GCN) were employed to reason corresponding knowledge. In addition, to generate more accurate proposals for the graph reasoning module, resampling was carried out through the cascade network. Finally, the enhanced features were fused with the original visual features to recognize and position the fittings. Test results show that CRGN can improve the detection effect of multi-fittings on the transmission line, especially for some hard-detection fittings.
This study reports the synthesis of a highly efficient visible-light-driven photocatalyst for hydrogen evolution and H2O2 production by manipulating the electronic band structure and surface properties of g-C3N4. Boron and caesium co-doped g-C3N4 porous and wrinkled nanosheets were nobly synthesized by using recrystallization of melamine in water in the presence of boric acid and CsCl followed by calcination and thermal etching. The prepared nanosheets showed an extremely porous and wrinkled structure with high surface area and edge sites. The optimized B, Cs co-doped g-C3N4 nanosheets exhibited a stable hydrogen evolution rate of 1,120 mu molg-1h-1 in the presence of triethanolamine, which is 7.7 times higher than that of the bulk. Moreover, this optimized structure showed a greatly increased hydrogen peroxide production rate of 113 mu molg-1h-1 compared to that (19 mu molg-1h- 1) of the bulk GCN-B. Meanwhile, the optimized structure showed a high photooxidation ability toward RhB oxidation. This outstanding improvement in photocatalytic performance is attributed to the enhanced charge carrier mobility in the pi-conjugated structure and increased accessible reaction sites for photocatalytic reactions originated from the synergetic effect of co-doping and formation of the porous and wrinkled nanosheets.
In the User and Entity Behaviour Analytics (UEBA), unknown malicious behaviours are often difficult to be automatically detected due to the lack of labelled data. Most of the existing methods also fail to take full advantage of the threat intelligence and incorporate the impact of the behaviour patterns of the benign users. To address this issue, this paper proposes a Generalised Zero-Shot Learning (GZSL) method based on hyper-spherical Variational Auto-Encoders (VAEs). Compared to the VAEs, the authors' proposed method is more robust and suitable for capturing data with richer and more nuanced structures. The authors' method analyses the unknown malicious behaviours by projecting them and their semantic attributes to shared space. These are then matched by the cosine similarity. The authors further use a Graph Convolutional Network (GCN) to reduce the impact of different user behaviour patterns before projection. The experimental results indicate that the proposed method is efficient in the analysis of unknown malicious behaviours.
Lung cancer is the leading cause of cancer death globally, killing 1.8 million people yearly. Over 85% of lung cancer cases are non-small cell lung cancer (NSCLC). Lung cancer running in families has shown that some genes are linked to lung cancer. Genes associated with NSCLC have been found by next-generation sequencing (NGS) and genome-wide association studies (GWAS). Many papers, however, neglected the complex information about interactions between gene pairs. Along with its high cost, GWAS analysis has an obvious drawback of false-positive results. Based on the above problem, computational techniques are used to offer researchers alternative and complementary low-cost disease-gene association findings. To help find NSCLC-related genes, we proposed a new network-based machine learning method, named deepRW, to predict genes linked to NSCLC. We first constructed a gene interaction network consisting of genes that are related and irrelevant to NSCLC disease and used deep walk and graph convolutional network (GCN) method to learn gene-disease interactions. Finally, deep neural network (DNN) was utilized as the prediction module to decide which genes are related to NSCLC. To evaluate the performance of deepRW, we ran tests with 10-fold cross-validation. The experimental results showed that our method greatly exceeded the existing methods. In addition, the effectiveness of each module in deepRW was demonstrated in comparative experiments.
The real-world recommender system needs to be regularly retrained to keep with the new data. In this work, we consider how to efficiently retrain graph convolution network (GCN)-based recommender models that are state-of-the-art techniques for the collaborative recommendation. To pursue high efficiency, we set the target as using only new data for model updating, meanwhile not sacrificing the recommendation accuracy compared with full model retraining. This is nontrivial to achieve since the interaction data participates in both the graph structure for model construction and the loss function for model learning, whereas the old graph structure is not allowed to use in model updating. Toward the goal, we propose a causal incremental graph convolution (IGC) approach, which consists of two new operators named IGC and colliding effect distillation (CED) to estimate the output of full graph convolution. In particular, we devise simple and effective modules for IGC to ingeniously combine the old representations and the incremental graph and effectively fuse the long- and short-term preference signals. CED aims to avoid the out-of-date issue of inactive nodes that are not in the incremental graph, which connects the new data with inactive nodes through causal inference. In particular, CED estimates the causal effect of new data on the representation of inactive nodes through the control of their collider. Extensive experiments on three real-world datasets demonstrate both accuracy gains and significant speed-ups over the existing retraining mechanism.
In recent years, traffic flow prediction has been extensively explored in Intelligent Transportation Systems, which is beneficial for reducing traffic jams and accidents as well as optimizing traffic network resources. Most of the previous methods divide cities into equal-sized grids and predict flows within one grid. However, we believe that each area is not independent, and there are interactions between areas. And the interaction between areas belonging to different attributes is more regular. Therefore, we propose a Multi-Attribute Graph Convolutional Network (MAGCN) for regional traffic flow prediction. Based on the attributes to which the areas belong, we divide cities into unequal-sized grids, and then a matrix is constructed using the flow of Functional area-based Origin-Destination pairs. GCN and dilated causal convolution allow the model to capture the spatial correlation and temporal dependence between functional regions while overcoming the under-fitting of local peaks. Extensive experimental results and evaluation metrics on two real-world datasets show that the MAGCN outperforms the baselines and has a higher accuracy for traffic flow prediction.
Metro passenger flow prediction is a strategically necessary demand in an intelligent transportation system to alleviate traffic pressure, coordinate operation schedules, and plan future constructions. Graph-based neural networks have been widely used in traffic flow prediction problems. Graph Convolutional Neural Networks (GCN) captures spatial features according to established connections but ignores the high-order relationships between stations and the travel patterns of passengers. In this paper, we utilize a novel representation to tackle this issue - hypergraph. A dynamic spatio-temporal hypergraph neural network to forecast passenger flow is proposed. In the prediction framework, the primary hypergraph is constructed from metro system topology and then extended with advanced hyperedges discovered from pedestrian travel patterns of multiple time spans. Furthermore, hypergraph convolution and spatio-temporal blocks are proposed to extract spatial and temporal features to achieve node-level prediction. Experiments on historical datasets of Beijing and Hangzhou validate the effectiveness of the proposed method, and superior performance of prediction accuracy is achieved compared with the state-of-the-arts.
As a typical unsupervised machine learning task, clustering is always a hot research topic. Motivated by deep learning approaches, deep clustering has become prevalent in recent years, and achieves appealing performance. Most of current deep clustering methods focus on learning a new discriminative represen-tation to enhance separability of original data, i.e., autoencoder, multilayer perceptrons and deep belief networks. However, the structure information which is very important in unsupervised learning, attracts little attention in previous deep feature representation learning clustering works. In this paper, a dynamic graph evolution based graph convolutional network (DGE-GCN) is introduced for clustering task, in which the data structural information and learned latent features are integrated into a unified network for deep clustering. Instead of using a fixed graph during the graph convolution process, we design a dynamic graph evolution strategy to refine the initial graph which could be not accurate. In addition, the latent representations learned by an autoencoder are embedded for refining the graph in a layer-wise man-ner. In such a manner, the latent features can help improve the graph structure, while the refined graph can in turn constrain the autoencoder to learn more discriminative features. In order to unify the graph convolutional network branch and autoencoder branch, a dual self-supervised mechanism is designed to guide the parameter learning of the whole network architecture. Comprehensive experiments demon-strate that the proposed network consistently performs better than several state-of-the-art methods on various benchmark datasets.(c) 2022 Elsevier B.V. All rights reserved.
Exploiting the inner-shot and inter-shot dependencies is essential for key-shot based video summarization. Current approaches mainly devote to modeling the video as a frame sequence by recurrent neural networks. However, one potential limitation of the sequence models is that they focus on capturing local neighborhood dependencies while the high-order dependencies in long distance are not fully exploited. In general, the frames in each shot record a certain activity and vary smoothly over time, but the multi-hop relationships occur frequently among shots. In this case, both the local and global dependencies are important for understanding the video content. Motivated by this point, we propose a reconstructive sequence-graph network (RSGN) to encode the frames and shots as sequence and graph hierarchically, where the frame-level dependencies are encoded by long short-term memory (LSTM), and the shot-level dependencies are captured by the graph convolutional network (GCN). Then, the videos are summarized by exploiting both the local and global dependencies among shots. Besides, a reconstructor is developed to reward the summary generator, so that the generator can be optimized in an unsupervised manner, which can avert the lack of annotated data in video summarization. Furthermore, under the guidance of reconstruction loss, the predicted summary can better preserve the main video content and shot-level dependencies. Practically, the experimental results on three popular datasets (i.e., SumMe, TVsum and VTW) have demonstrated the superiority of our proposed approach to the summarization task.
Generating person images has been a promising approach to enhance the input richness for re-identification (reID) tasks in recent works. A key challenge is that the generated data often contains noise, which is caused by identity inconsistency between the generated person and the original input and failure cases in generative adversarial networks (GAN). Directly training using generated images may greatly affect learning good feature embeddings, resulting in unsatisfactory reID performance. This work presents a two-stage framework that can generate high-quality person images and purify failure cases for reID training. Experimental results demonstrate that our proposed generative model can produce person images with superior appearance consistency comparing with other state-of-the-art methods. Furthermore, we show that our method yields a significant improvement in re-identification (reID) task on public datasets with insufficient training data.
Deep-learning-based salient object detection (SOD) has achieved significant success in recent years. The SOD focuses on the context modeling of the scene information, and how to effectively model the context relationship in the scene is the key. However, it is difficult to build an effective context structure and model it. In this article, we propose a novel SOD method called dynamic and adaptive graph convolutional network (DAGCN) that is composed of two parts, adaptive neighborhood-wise graph convolutional network (AnwGCN) and spatially restricted K-nearest neighbors (SRKNN). The AnwGCN is novel adaptive neighborhood-wise graph convolution, which is used to model and analyze the saliency context. The SRKNN constructs the topological relationship of the saliency context by measuring the non-Euclidean spatial distance within a limited range. The proposed method constructs the context relationship as a topological graph by measuring the distance of the features in the non-Euclidean space, and conducts comparative modeling of context information through AnwGCN. The model has the ability to learn the metrics from features and can adapt to the hidden space distribution of the data. The description of the feature relationship is more accurate. Through the convolutional kernel adapted to the neighborhood, the model obtains the structure learning ability. Therefore, the graph convolution process can adapt to different graph data. Experimental results demonstrate that our solution achieves satisfactory performance on six widely used datasets and can also effectively detect camouflaged objects. Our code will be available at: https://github.com/ CSIM-LUT/DAGCN.git.
This paper proposes an unsupervised multi-source domain adaptation algorithm with graph convolution network and multi-alignment in mixed latent space, which leverages domain labels, data structure, and category labels in a unified network but improves domain-invariant semantic representation by several innovations. Specifically, a novel data structure alignment is proposed to exploit the inherent properties of different domains while using current domain alignment and classification result alignment. Through this design, category consistency can be considered in both latent space, and domain and structure discrepancy between different source domains and the target domain can be eliminated. Moreover, we also use category alignment based on both CNN and GCN features to optimize category decision boundary. Experiment results show that the proposed method brings sufficient improvement especially for adaptation tasks with large shift in data distribution.
Accurate urban travel demand forecasting can help organize traffic flow, improve traffic utilization, reduce passenger waiting time, etc. It plays an important role in intelligent transportation systems. Most of the existing research methods construct static graphs from a single perspective or two perspectives, without considering the dynamic impact of time changes and various factors on traffic demand. Moreover, travel demand is also affected by regional functions such as weather, etc. To address these issues, we propose an urban travel demand prediction framework based on dynamic multi-view coupled graph convolution (DMV-GCN). Specifically, we dynamically construct demand similarity graphs based on node features to model the dynamic correlation of demand. Then we combine it with the predefined geographic similarity graph, functional similarity graph, and road similarity graph. We use coupled graph convolution network and gated recurrent units (GRU), to model the spatio-temporal correlation in traffic. We conduct extensive experiments over two large real-world datasets. The results verify the superior performance of our proposed approach for the urban travel demand forecasting task.
Because of the advantages of graphs in visualizing the relationship between individuals, complex networks have been widely used and greatly developed. In real-world applications of Dempster-Shafer evidence theory, there are usually thousands of sensors collecting information. It is easy to be overwhelmed by the mass of information and ignore the connections between them. The rise of the semisupervised learning method graph convolutional network makes it possible to address this issue. In this article, inspired by complex network, the basic probability assignment function, the base function of evidence theory, is modeled in a novel form of the network graph. Some typical issues of evidence theory, such as conflicting evidence, multiclass evidence clustering, and computational complexity for large-scale fusion are systematically addressed in the framework of the proposed network model. What's more, a new combination rule is presented from the point view of the graph. The empirical results of experiments on real data set demonstrate the potential and feasibility of complex networks in traditional evidence theory.
Zero-shot action recognition (ZSAR) aims to recognize novel actions that have not been seen in the training stage. However, ZSAR always suffers from serious domain shift problem, which causes poor performance. This is because: 1) Videos contain complicated intrinsic structures, including cross-sample visual correlations and cross-category semantic relationships, which make it challenging to generalize domain shift over categories and transfer knowledge across videos. 2) Existing methods do not disentangle unique and shared information underlying unseen videos during embedding. They are always weakly adaptive to novel categories and easily shift unseen videos to irrelevant action prototypes. In this paper, we propose a novel Coupling Adversarial Graph Embedding (CAGE) method for ZSAR, which formulates an effective visual-to-semantic embedding to alleviate the domain shift problem. Our model implements in a transductive setting that assumes accessing to a full set of unseen videos. Firstly, a structured graph is built for expressing both seen and unseen videos, which integrally captures visual and semantic relationships between them. Then, an effective visual-to-semantic embedding is formulated based on graph convolutional network (GCN), which is generalized to disjoint action categories and optimized for label propagation. In addition, a couple of adversarial constraints are proposed to characterize unique information of unseen videos and purify shared information across categories, which further improve the adaptability and discriminability of our model. Experiments on Olympic sports, HMDB51 and UCF101 datasets show that our model achieves impressive performance on ZSAR task. (C) 2021 Elsevier B.V. All rights reserved.
As a multi-label classification task, audio tagging aims to predict the presence or absence of certain sound events in an audio recording. Existing works in audio tagging do not explicitly consider the probabilities of the co-occurrences between sound events, which is termed as the label dependencies in this study. To address this issue, we propose to model the label dependencies via a graph-based method, where each node of the graph represents a label. An adjacency matrix is constructed by mining the statistical relations between labels to represent the graph structure information, and a graph convolutional network (GCN) is employed to learn node representations by propagating information between neighboring nodes based on the adjacency matrix, which implicitly models the label dependencies. The generated node representations are then applied to the acoustic representations for classification. Experiments on Audioset show that our method achieves a state-of-the-art mean average precision (mAP) of 0.434.
With the rapid development of edge computing, online social network services are growing explosively. Social influence plays a critical role in the propagation of social network information. Influence maximization is a key issue in social network analysis. Temporal-aware influence maximization has been emerging in recent years. It integrates temporal information into the classical influence maximization. The purpose for temporal-aware influence maximization is to identify the optimal users in a network that can influence the most individuals under a certain time constraint. Although each node activation is treated equally within a finite time window in existing studies. In reality, the time required for each user to get influenced varies. In contrast, because temporal-aware influence maximization is NP-hard, a number of studies have proposed approximate algorithms based on sample instances to estimate the expected influence spread of nodes. However, these methods require significant computational overheads. Therefore, this study presents learning-based time-decaying influence maximization. Specifically, this study first presents the time-decaying influence maximization, where each user has a utility score that monotonically decreases over time. Subsequently, it develops AttenLSTM-GCN to generate node embeddings that capture structural-temporal information. Then, it adopts Q-learning algorithm to predict the time-decaying influence of nodes. Based on these algorithms, the solution of time-decaying influence maximization can be obtained. Experimental studies on real world networks demonstrate that the proposed model achieves more significant accelerations and high-quality solutions than advanced algorithms.
In this research, Bi4O5I2 and AgI nanoparticles were anchored over g-C3N4 nanosheets (denoted as NGCN/Bi4O5I2/AgI) to preparation highly impressive visible-light-driven samples. The synthesized nanocomposites were investigated by X-ray diffraction (XRD), Fourier transform-infrared (FT-IR), scanning electron microscopy (SEM), high resolution transmission electron microscopy (HRTEM), X-ray photoelectron spectroscopy (XPS), thermogravimetric analysis (TGA), UV-vis diffuse reflectance spectroscopy (DRS), energy dispersive analysis of X-rays (EDX), electrochemical impedance spectroscopy (EIS), photocurrent density, Brunauer-Emmett-Teller (BET), and photoluminescence (PL) analyses. Among the ternary photocatalysts, the NGCN/Bi4O5I2/AgI (20%) photocatalyst illustrated the highest photoactivity in degradation of rhodamine B (RhB), which was approximately 58.4, 15.2, and 12.8 times higher than the GCN, NGCN, and NGCN/Bi4O5I2 (20%) samples, respectively. Furthermore, the center dot O-2(-) was discovered as the main species in the respective system by the quenching tests. Also, by studying the electrochemical properties, a cascade photocatalytic mechanism was suggested based on the energy bands to describe the enhanced charge carriers migration and separation, which caused impressive photocatalytic performances in degradations of four hazardous contaminants. This study highlights the rational anchoring of Bi4O5I2 and AgI nanoparticles over NGCN to prepare highly efficient photocatalysts for wastewater remediation. (C) 2020 The Society of Powder Technology Japan. Published by Elsevier B.V. and The Society of Powder Technology Japan. All rights reserved.
The development of effective sorbents is of great significance for realizing the immobilization of gaseous elemental mercury from coal-fired flue gas. Herein, CuS/CeO2 composite sorbent was synthesized by a simple precipitation method for the removal of elemental mercury from flue gas. The ability of CuS/CeO2 to capture mercury at different temperatures and different flue gas components (HCl, SO2, O2 and NO) were tested. It indicates that CuS/CeO2 exhibits excellent Hg0 removal performance both at 60-150 degrees C and in different flue gas components. Moreover, the equilibrium adsorption capacity of CuS/CeO2 was 32.304 mg g-1 at 120 degrees C, which was 59.8 times that of CuS/GCN and 190 times that of ZnS modified activated carbon. Density functional theory (DFT) calculations further verified that the synergistic relationship between defect oxygen and unsaturated sulfur sites on the surface promotes the Hg0 removal performance of CuS/CeO2. By virtue of these advantages, CuS/ CeO2 is a prodigious candidate for the effective mercury removal from various types of industrial flue gases. This work may open-up new approaches for the development of heavy metal sorbents through the inter-doping of metal sulfides with transition metal oxides to enhance surface active sites to tune the adsorption capacity.
Lameness is common in dairy cows. Methods that used RGB-based images to detect lameness in dairy cows always have low accuracy and poor robustness because of the complex background environment involved. In this study, a lameness detection method for dairy cows based on multiple features, including RGB, optical flow and skeletons, was proposed. The network was divided into three branches according to different inputs: for Branch1 and Branch3, a convolutional neural network (CNN) was used to predict lameness according to the input images and optical flow, and for Branch2, a spatial temporal graph convolutional network (ST-GCN) was used to predict lameness according to the cows' skeletons. Finally, the weight was adjusted, and the prediction scores of these three branches were fused to complete the lameness detection process. In this research, 680 different videos were used for training and testing. The segmentation ratio of the train set and test set was 6:1. The best ACC was 97.20% when the weight of the RGB, optical flow and skeletons was 1:0.5:0.5. To verify the robustness of the method, the gamma transform was used to adjust the brightness of the image to simulate a change in illumination. Under different illumination settings, the maximum error of the method was 2.65%, which was significantly lower than other methods without skeletons. The results showed that the proposed method was effective for the detection of early-stage lameness, severe lameness, and non-lameness of dairy cows.(c) 2022 IAgrE. Published by Elsevier Ltd. All rights reserved.
Long gamma-ray burst GRB 191016A was a bright and slow rising burst that was detected by the Swift satellite and followed up by ground based Liverpool Telescope (LT). LT follow up started 2411 s after the Swift Burst Alert Telescope (BAT) trigger using imager IO:O around the time of the late optical peak. From 3987-7687 s, we used the LT polarimeter RINGO3 to make polarimetric and photometric observations of the GRB simultaneously in the V, R, and I bands. The combined optical light curve shows an initial late peak followed by a decline until 6147 s, 6087 s, and 5247 s for I, R, and V filters respectively followed by a flattening phase. There is evidence of polarization at all phases including polarization (P = 14.6 +/- 7.2 per cent) which is coincident with the start of the flattening phase. The combination of the light curve morphology and polarization measurement favours an energy injection scenario where slower magnetized ejecta from the central engine catches up with the decelerating blast wave. We calculate the minimum energy injection to be Delta E/E > 0.36. At a later time, combining the optical light curve from Burst Observer and Optical Transient Exploring System (BOOTES) (reported via GCN) and IO:O we see evidence of a jet break with jet opening angle 2 degrees.
Gene co-expression networks (GCN) present undirected relations between genes to understand molecular structures behind the diseases, including cancer. The utilization of various biological datasets and gene network inference (GNI) algorithms can reveal meaningful gene-gene interactions of GCNs. This study applies three GNI algorithms on mRNA gene expression, RNA-Seq, and miRNA-target genes datasets to infer GCNs of breast and prostate cancers. To evaluate the performance of the GCNs, we utilize overlap analysis via literature data, topological assessment, and Gene Ontology-based biological assessment. The results emphasize how the selection of biological datasets and GNI algorithms affect the performance results on different evaluation criteria. GCNs on microarray gene expression data slightly outperform in overlap analysis. Also, GCNs on RNA-Seq and gene expression datasets follow scale-free topology. The biological assessment results are close to each other on all biological datasets. C3NET algorithm-based GCNs did not contain any biological assessment modules; therefore, it is not optimal for biological assessment. GNI algorithms' selection did not change the overlap analysis and topological assessment results. Our primary objective is to compare the performance results of biological datasets and GNI algorithms based on different evaluation criteria. For this purpose, we developed the GNIAP R package that enables users to select different GNI algorithms to infer GCNs. The GNIAP R package also provides literature-based overlap analysis, and topological and biological analyses on GCNs. Users can access the GNIAP R package via . [GRAPHICS] .
Author summary The recognition of circRNA-disease association is the key of disease diagnosis and treatment, and it is of great significance for exploring the pathogenesis of complex diseases. Computational methods can predict the potential disease-related circRNAs quickly and accurately. Based on the hypothesis that circRNA with similar function tends to associate with similar disease, GCNCDA model is proposed to effectively predict the potential association between circRNAs and diseases by combining FastGCN algorithm. The performance of the model was verified by cross-validation experiments, different feature extraction algorithm and classifier models comparison experiments. Furthermore, 16, 15 and 17 of the top 20 candidate circRNAs with the highest prediction scores in disease including breast cancer, glioma and colorectal cancer were respectively confirmed by relevant literature and databases. It is anticipated that GCNCDA model can give priority to the most promising circRNA-disease associations on a large scale to provide reliable candidates for further biological experiments. Numerous evidences indicate that Circular RNAs (circRNAs) are widely involved in the occurrence and development of diseases. Identifying the association between circRNAs and diseases plays a crucial role in exploring the pathogenesis of complex diseases and improving the diagnosis and treatment of diseases. However, due to the complex mechanisms between circRNAs and diseases, it is expensive and time-consuming to discover the new circRNA-disease associations by biological experiment. Therefore, there is increasingly urgent need for utilizing the computational methods to predict novel circRNA-disease associations. In this study, we propose a computational method called GCNCDA based on the deep learning Fast learning with Graph Convolutional Networks (FastGCN) algorithm to predict the potential disease-associated circRNAs. Specifically, the method first forms the unified descriptor by fusing disease semantic similarity information, disease and circRNA Gaussian Interaction Profile (GIP) kernel similarity information based on known circRNA-disease associations. The FastGCN algorithm is then used to objectively extract the high-level features contained in the fusion descriptor. Finally, the new circRNA-disease associations are accurately predicted by the Forest by Penalizing Attributes (Forest PA) classifier. The 5-fold cross-validation experiment of GCNCDA achieved 91.2% accuracy with 92.78% sensitivity at the AUC of 90.90% on circR2Disease benchmark dataset. In comparison with different classifier models, feature extraction models and other state-of-the-art methods, GCNCDA shows strong competitiveness. Furthermore, we conducted case study experiments on diseases including breast cancer, glioma and colorectal cancer. The results showed that 16, 15 and 17 of the top 20 candidate circRNAs with the highest prediction scores were respectively confirmed by relevant literature and databases. These results suggest that GCNCDA can effectively predict potential circRNA-disease associations and provide highly credible candidates for biological experiments.
Objective. To extend the highly successful U-Net Convolutional Neural Network architecture, which is limited to rectangular pixel/voxel domains, to a graph-based equivalent that works flexibly on irregular meshes; and demonstrate the effectiveness on electrical impedance tomography (EIT). Approach. By interpreting the irregular mesh as a graph, we develop a graph U-Net with new cluster pooling and unpooling layers that mimic the classic neighborhood based max-pooling important for imaging applications. Main results. The proposed graph U-Net is shown to be flexible and effective for improving early iterate total variation (TV) reconstructions from EIT measurements, using as little as the first iteration. The performance is evaluated for simulated data, and on experimental data from three measurement devices with different measurement geometries and instrumentations. We successfully show that such networks can be trained with a simple two-dimensional simulated training set, and generalize to very different domains, including measurements from a three-dimensional device and subsequent 3D reconstructions. Significance. As many inverse problems are solved on irregular (e.g. finite element) meshes, the proposed graph U-Net and pooling layers provide the added flexibility to process directly on the computational mesh. Post-processing an early iterate reconstruction greatly reduces the computational cost which can become prohibitive in higher dimensions with dense meshes. As the graph structure is independent of 'dimension', the flexibility to extend networks trained on 2D domains to 3D domains offers a possibility to further reduce computational cost in training.
Recently, the major environmental pollution produced by the release of wastewater in liquid type is one of the most extensive forms of foremost pollution in water ecosystems. In this article, the Bi2O3/g-C3N4 nanocomposite with a direct Z-scheme was effectively obtained by a facile hydrothermal system. The crystal structures, surface morphology, chemical composition, and the optical belongings of the as-obtained composite catalysts were examined by Power XRD, FT-IR spectra, High-resolution XPS spectra, FE-SEM images with EDX spectra, High -resolution TEM images, UV-Vis DRS, and PL spectra respectively. Furthermore, the photocatalytic perfor-mance was assessed by the degradation of aqueous Rhodamine B (Rh B) dye under visible-light exposure. The Bi2O3/g-C3N4 composite photocatalysts (PCs) showed the maximum photo-degradation efficiency through a rate constant value of 0.0149 min-1, which is 4.9 and 5.3 folds superior to Bi2O3, and GCN, respectively. The better GBO2 nanocomposite PCs showed a superior photocatalytic degradation performance (>82%) of aqueous Rh B dye after five successive recycles. Moreover, based on these outcomes of the radical scavenging test, a direct and effective Z-scheme photocatalytic charger transfer mechanism was also projected. Finally, the reusability of the as-obtained Bi2O3/g-C3N4 nanocomposite has better stability and reusability, which was a favourable applicant for wastewater handling.
Abstract Footpad dermatitis is an inflammation of the skin that affects the surface of the sole of the foot; the skin of the tarsal joint and; in severe cases; the bone of the pectoral keel. It is a multicausal pathology in which the environment; nutrition and intestinal integrity are involved. It affects animal welfare and generates economic losses due to confiscation during slaughtering. The objective of this work was to evaluate the plantar lesions in 40-day-old Cobb 500 chickens; housed in two production systems: new litter (NL) and litter used in four periods (UL). It was observed that 77% of the animals housed in NL did not present lesions; and 23% presented lesions of grade 1 or 2. On the other hand; 28% of the animals housed in UL did not present lesions; while 72% presented lesions of grade 1 or 2. The percentages of lesions found in both groups were significantly different (p<0.001); pointing out that animals located on UL are 8.6 times more likely to present lesions of greater degree than those housed on a new bed.
Objective Systemic lupus erythematosus (SLE) features high frequency of cardiovascular disease (CVD) and fluctuating complement levels. The clinical trial Atherosclerosis Prevention in Pediatric Lupus Erythematosus (APPLE) aimed to evaluate whether atorvastatin treatment reduced the progression of atherosclerosis in 221 patients with childhood-onset SLE (cSLE), using carotid intima media thickness (CIMT) as surrogates. We leveraged APPLE biorepository and trial data to investigate the relationship between complement and CVD in cSLE. Methods Gene copy numbers (GCNs) for total C4, C4A and C4B were measured by TaqMan-based real-time PCR and Southern blotting, and analysed with laboratory and clinical parameters through Student's t-test and chi(2) analyses. Effects of total C4, C4A and C4B GCNs on the response to placebo or atorvastatin treatment and progression of CIMT were examined by regression analyses. Results At baseline, C4 protein levels strongly correlated with GCNs of total C4 (p=1.8x10(-6)). Each copy of C4 gene increased mean serum C4 by 3.28 mg/dL. Compared with those without hypertension (N=142), individuals with hypertension demonstrated significantly elevated serum levels for C4 and C3 at baseline and serially (C4: P=5.0x10(-25); C3: P=5.84x10(-20)). Individuals with >= 2 C4B genes had 2.5 times the odds of having hypertension (p=0.016) and higher diastolic blood pressure (p=0.015) compared with those with C4B deficiency. At the study end, subjects with >= 2 C4B and atorvastatin treatment had significantly slower increase in CIMT compared with those treated with placebo (p=0.018). Conclusions cSLE with hypertension had elevated serum levels of C4 and C3 and higher GCN of C4B; cSLE with >= 2 C4B genes would benefit from statins therapy to prevent atherosclerosis.
To explore the prognostic related factors and mechanisms of gastric cancer (GC), we performed the systematic analysis with integrated bioinformatics tools based on multiple on-line datasets. With univariate COX analysis, we screened out 37 survival hazardous genes in GC. Further GO assays disclosed that the signatures related with extracellular matrix and structure, and the functions of "cell adhesion molecule binding" and "integrin binding" were the vital mechanisms of disease progression, and tissue inhibitor of metalloproteinase-2 (TIMP2) was the potential biomarker for prognosis. Based on GSEA, GSVA and GCN, TIMP2 was demonstrated to interact with multiple integrin pathways and involve in the regulation of EMT, cell adhesion, and angiogenesis of GC. The associations of TIMP2 expression with reduced OS and RFS of patients were declared by Kaplan-Meier analysis, and further confirmed by 1000 internal bootstrap replications and external KM plotter analysis. With multi-variate COX regression and time-dependent ROC analysis, we validated the prediction independency and capacity of TIMP2 for prognosis. The relationships of TIMP2 with clinicopathological characteristics were also uncovered. Taken together, our findings identify TIMP2 as the novel candidate biomarker for poorer outcome of GC patients, and revealed the underlying functions of TIMP2 and the potential mechanisms for GC progression.
Noncoding RNAs (ncRNAs) have recently attracted considerable attention due to their key roles in biology. The ncRNA-proteins interaction (NPI) is often explored to reveal some biological activities that ncRNA may affect, such as biological traits, diseases, etc. Traditional experimental methods can accomplish this work but are often labor-intensive and expensive. Machine learning and deep learning methods have achieved great success by exploiting sufficient sequence or structure information. Graph Neural Network (GNN)-based methods consider the topology in ncRNA-protein graphs and perform well on tasks like NPI prediction. Based on GNN, some pairwise constraint methods have been developed to apply on homogeneous networks, but not used for NPI prediction on heterogeneous networks. In this paper, we construct a pairwise constrained NPI predictor based on dual Graph Convolutional Network (GCN) called NPI-DGCN. To our knowledge, our method is the first to train a heterogeneous graph-based model using a pairwise learning strategy. Instead of binary classification, we use a rank layer to calculate the score of an ncRNA-protein pair. Moreover, our model is the first to predict NPIs on the ncRNA-protein bipartite graph rather than the homogeneous graph. We transform the original ncRNA-protein bipartite graph into two homogenous graphs on which to explore second-order implicit relationships. At the same time, we model direct interactions between two homogenous graphs to explore explicit relationships. Experimental results on the four standard datasets indicate that our method achieves competitive performance with other state-of-the-art methods. And the model is available at https://github.com/zhuoninnin1992/NPIPredict
Tactic recognition in sports videos is a challenging task. To address this, we present a novel spatio-temporal relation modeling approach, which captures both detailed player interactions and long-range group dynamics in tactics. In spatial modeling, we propose an Adaptive Graph Convolutional Network (A-GCN), and it represents individual and common patterns of data through local and global graphs to learn diverse player interactions. In temporal modeling, we propose an Attentive Temporal Convolutional Network (A-TCN) and with spatial configurations as input, it builds group dynamics and is robust to redundant content by considering sequence dependencies. Due to adaptive interaction and attentive dynamics modeling, our approach is able to comprehensively describe team cooperation over time in a tactic. We extensively evaluate the proposed approach on the Volleyball dataset and a newly collected VolleyTactic dataset, and the experimental results show its advantage.
Cervical cancer causes the fourth most cancer-related deaths of women worldwide. Early detection of cervical intraepithelial neoplasia (CIN) can significantly increase the survival rate of patients. In this paper, we propose a deep learning framework for the accurate identification of LSIL+ (including CIN and cervical cancer) using time-lapsed colposcopic images. The proposed framework involves two main components, i.e., key-frame feature encoding networks and feature fusion network. The features of the original (pre-acetic-acid) image and the colposcopic images captured at around 60s, 90s, 120s and 150s during the acetic acid test are encoded by the feature encoding networks. Several fusion approaches are compared, all of which outperform the existing automated cervical cancer diagnosis systems using a single time slot. A graph convolutional network with edge features (E-GCN) is found to be the most suitable fusion approach in our study, due to its excellent explainability consistent with the clinical practice. A large-scale dataset, containing time-lapsed colposcopic images from 7,668 patients, is collected from the collaborative hospital to train and validate our deep learning framework. Colposcopists are invited to compete with our computer-aided diagnosis system. The proposed deep learning framework achieves a classification accuracy of 78.33%-comparable to that of an in-service colposcopist-which demonstrates its potential to provide assistance in the realistic clinical scenario.
In photoelectric countermeasure systems, the infrared imaging of missiles is critical for automatic recognition and tracking technology of aerial targets. However, complex and newly emerging infrared interference signals severely hinder the recognition performance and lock the target ability of infrared thermal imaging systems. Although considerable progress has been achieved in the development of machine vision systems for missile detection, their performance and robustness should be improved. The brain can detect learned objects in various nonideal situations (partial occlusion and various perspectives). A novel graph network learning framework was developed for object recognition. This brain-inspired anti-interference recognition model can be used for detecting aerial targets composed of various spatial relationships. A spatially correlated skeletal graph model was used to represent the prototype using the graph convolutional network. Furthermore, a novel anti-occlusion framework based on a multisemantic skeleton graph model was proposed to overcome the discontinuity of target features caused by occlusion. In this method, the location of occluded key points was inferred by learning high-order relationships and node topology information. In this study, local image features were considered as graph nodes and a high-order relationship learning module was proposed to transfer relational information between nodes. In this module, the degree of connection between target keypoints was learned to automatically suppress the delivery of meaningless features. Second, a high-order topology learning module that simultaneously learns topological information and embeds local features was proposed to directly predict node similarity scores. Finally, extensive experiments were conducted on the constructed aerial target flight infrared dataset to validate the effectiveness of the proposed model.
The uncontrolled dumping of synthetic dyes into water sources has posed severe hazards to the ecosystem. For decades, several materials with low cost and high efficiency have been investigated for dye degradation. Photocatalytic degradation is regarded as a successful strategy since it utilizes sunlight to transform harmful pollutants into nontoxic compounds without using oxidative agents. The photocatalytic potentials of CeO2/g-C3N4 (CG) were investigated in this work using a simplistic ultrasonication process. Here, the amount of CeO2 was fixed, and g-C3N4 was varied in the ratio (1:x, where x = 1, 2, and 3) and abbreviated as CG1, CG2, and CG3. Characterization techniques such as Fourier transforms-infrared spectroscopy, thermal gravimetric analysis (TGA), powdered X-ray diffraction, ultraviolet-visible spectroscopy, etc. were used to characterize structural analysis, optical properties, particle size, and chemical bonds of the prepared nanocomposites. The photocatalytic results showed that CG2 effectively degraded rose bengal (RB) and crystal violet (CV) dyes when exposed to visible light irradiation as compared to pure GCN and CeO2. The antibacterial activity analysis further supported the potential application of prepared photocatalyst as a disinfectant agent against both gram-positive (Staphylococcus aureus and Bacillus cereus) and gram-negative (Salmonella abony and Escherichia coli) pathogenic strains of bacteria.
Session-based recommendation (SBR) is a challenging task, aiming at recommending items according to the behavior of anonymous users. Previous research efforts mainly focus on capturing sequential transitions between consecutive items via recurrent neural networks (RNN) or modeling the complex transitions between non-adjacent items based on graph neural networks (GNN). Although these works have achieved encouraging performance on solving the session-based recommendation problem, few efforts have been dedicated to exploring the rich information related to the shifts of user interests within the transition relationships, which is the research gap we attempt to bridge in this work. In this paper, we propose a novel model, named Time Enhanced Graph Neural Networks (TE-GNN), which attempts to capture the complex user interest shift patterns within sessions. In TE-GNN, we construct a Time Enhanced Session Graph (TES-Graph) where transition relationships between items are treated adaptively with respect to the degree of user interest drift. In addition, a novel Temporal Graph Convolutional Network (T-GCN) is designed to learn item embeddings based on the TES-Graph. Moreover, we also introduce a Temporal Interest Attention Network (TIAN) to model the complex transition of items with a common user interest. Extensive experiments have been conducted on four widely used benchmark datasets, i.e., Diginetica, Tmall, Nowplaying, and Retailrocket, and the results show that our proposed approach TE-GNN significantly outperforms previous state-of-the-art baseline methods. The implementation of TE-GNN is available in https://github.com/GuTang1997/TE-GNN.(c) 2022 Elsevier B.V. All rights reserved.
Person re-identification (ReID) is an important topic of computer vision. Existing works in this field focus primarily on learning a feature extractor that maps the pedestrian images into a feature space, in which feature vectors corresponding to the same identity are close to each other. In this paper, we propose the adjacency-aware Graph Convolutional Network (AAGCN) to smooth the intra-class features and thus reduce the intra-class variance. Specifically, our AAGCN takes the features learned by a backbone as the input nodes; it first establishes the connections or adjacency relations for the intra-class features, then the adjacent nodes (i.e., the intra-class features) would be smoothed thanks to the property of low-pass filtering of Graph Convolutional Network (GCN). In this paper, we propose two methods, i.e., the Mahalanobis Neighborhood Adjacency (MNA) and Non-Linear Mapping (NLM), to learn the adjacency relations for the intra-class features. The MNA defines the adjacency weight between two nodes as the negative exponent of the Mahalanobis distance between their corresponding features, therefore it aims to learn a small Mahalanobis distance between the intra-class features and a large Mahalanobis distance between the inter-class ones. The NLM enables the non-linear mapping from the features of the nodes to their corresponding adjacency weights. The experimental results on both visible ReID and visual-infrared ReID verify the effectiveness of our method, for instance, our model achieves 95.7% rank-1 and 93.1% mAP on Market1501, as well as 58.6% rank-1 and 60.0% mAP on SYSU. (c) 2021 Published by Elsevier B.V.
Many fully automatic segmentation models have been created to solve the difficulty of brain tumor segmentation, thanks to the rapid growth of deep learning. However, few approaches focus on the long-range relationships and contextual interdependence in multimodal Magnetic Resonance (MR) images. In this paper, we propose a novel approach for brain tumor segmentation called the dual graph reasoning unit (DGRUnit). Two parallel graph reasoning modules are included in our proposed method: a spatial reasoning module and a channel reasoning module. The spatial reasoning module models the long-range spatial dependencies between distinct regions in an image using a graph convolutional network (GCN). The channel reasoning module uses a graph attention network (GAT) to model the rich contextual interdependencies between different channels with similar semantic representations. Our experimental results clearly demonstrate the superior performance of the proposed DGRUnit. The ablation study shows the flexibility and generalizability of our model, which can be easily integrated into a wide range of neural networks and further improve them. When compared to several state-of-the-art methods, experimental results show that the proposed approach significantly improves both visual inspection and quantitative metrics for brain tumor segmentation tasks.
Hand pose estimation in 3D space from a single RGB image is a highly challenging problem due to self-geometric ambiguities, diverse texture, viewpoints, and self-occlusions. Existing work proves that a network structure with multi-scale resolution subnets, fused in parallel can more effectively shows the spatial accuracy of 2D pose estimation. Nevertheless, the features extracted by traditional convolutional neural networks cannot efficiently express the unique topological structure of hand key points based on discrete and correlated properties. Some applications of hand pose estimation based on traditional convolutional neural networks have demonstrated that the structural similarity between the graph and hand key points can improve the accuracy of the 3D hand pose regression. In this paper, we design and implement an end-to-end network for predicting 3D hand pose from a single RGB image. We first extract multiple feature maps from different resolutions and make parallel feature fusion, and then model a graph-based convolutional neural network module to predict the initial 3D hand key points. Next, we use 2D spatial relationships and 3D geometric knowledge to build a self-supervised module to eliminate domain gaps between 2D and 3D space. Finally, the final 3D hand pose is calculated by averaging the 3D hand poses from the GCN output and the self-supervised module output. We evaluate the proposed method on two challenging benchmark datasets for 3D hand pose estimation. Experimental results show the effectiveness of our proposed method that achieves state-of-the-art performance on the benchmark datasets.
With the development of smart phones, malicious applications for the Android platform have increased dramatically. The existing Android malicious code analysis methods majorly focus on detection based on signatures, inter-component communication, and other configuration information features. Such methods ignore the effect of the semantic features of the malicious code. Even a few such studies that exist are based on the statistical features of the code for malicious code detection. To address these shortcomings, we (1) use the code semantic structure features to reflect deep semantic information, (2) propose a preprocessing method of APK files to generate graphics that reflect the code semantic features, and (3) introduce the advanced graphical semantics for a graph convolutional network (GCN) model to automatically identify and learn semantics and extract features for malicious code detection. Experiments on a dataset confirm that the proposed method can achieve 95.8% detection accuracy. Compared with the existing methods that adopt configuration information features or statistical features of codes, our method shows higher accuracy.
Background: Lung cancer is cancer with the highest incidence in the world, and there is obvious heterogeneity within its tumor. The emergence of single-cell sequencing technology allows researchers to obtain cell-type-specific expression genes at the single-cell level, thereby obtaining information regarding the cell status and subpopulation distribution, as well as the communication behavior between cells. Many researchers have applied this technology to lung cancer research, but due to the shortcomings of insufficient sequencing depth, only a small part of the gene expression can be detected. Researchers can only roughly compare whether a few thousand genes are significant in different cell types. Methods: To fully explore the expression of all genes in different cell types, we propose a method to predict cell-type-specific genes. This method infers cell-type-specific genes based on the expression levels of genes in different tissues and cells and gene interactions. At present, biological experiments have discovered a large number of cell-type-specific genes, providing a large number of available samples for the application of deep learning methods. Results: Therefore, we fused Graph Convolutional Network (GCN) with Convolutional Neural Network(CNN) to build, model, and inferred cell-type-specific genes of lung cancer in 8 cell types. Conclusion: This method further analyzes and processes single-cell data and provides a new basis for research on heterogeneity in lung cancer tumor, microenvironment, invasion and metastasis, treatment response, drug resistance, etc.
Cognitive radio (CR) is a critical technique to solve the conflict between the explosive growth of traffic and severe spectrum scarcity. Reasonable radio resource allocation with CR can effectively achieve spectrum sharing and co-channel interference (CCI) mitigation. In this paper, we propose a joint channel selection and power adaptation scheme for the underlay cognitive radio network (CRN), maximizing the data rate of all secondary users (SUs) while guaranteeing the quality of service (QoS) of primary users (PUs). To exploit the underlying topology of CRNs, we model the communication network as dynamic graphs, and the random walk is used to imitate the users' movements. Considering the lack of accurate channel state information (CSI), we use the user distance distribution contained in the graph to estimate CSI. Moreover, the graph convolutional network (GCN) is employed to extract the crucial interference features. Further, an end-to-end learning model is designed to implement the following resource allocation task to avoid the split with mismatched features and tasks. Finally, the deep reinforcement learning (DRL) framework is adopted for model learning, to explore the optimal resource allocation strategy. The simulation results verify the feasibility and convergence of the proposed scheme, and prove that its performance is significantly improved.
Sea Surface Temperature (SST) prediction is a hot topic that has received tremendous popularity in recent years. Existing methods for SST prediction usually select one sea area of interest and conduct SST prediction by learning the spatial and temporal dependencies and patterns in historical SST data. However, global SST is a unified system of high regionality, and the SST in different sea areas shows different changing patterns due to the influence of various factors, e.g., geographic location, ocean currents and sea depth. Without a good understanding of such regionality of SST, we cannot quantitatively integrate the regionality information of SST into SST prediction models to make them adaptive to different SST patterns around the world and improve the prediction accuracy. To address this issue, we proposed the Multi-Stage Spatio-Temporal Clustering (MuSTC) method to quantitatively identify sea areas with similar SST patterns. First, MuSTC sequentially learns the representation of long-term SST with a deep temporal encoder and calculates the spatial correlation scores between grid ocean regions with self-attention. Then, MuSTC clusters grid ocean regions based on the original SST data, encoded long-term SST representation and spatial correlation scores, respectively, to obtain the sea areas with similar SST patterns from different perspectives. According to the experiments in three ocean areas, i.e., the North Pacific Ocean (NPO), the South Atlantic Ocean (SAO) and the North Atlantic Ocean (NAO), the clustering results generally match the distribution of ocean currents, which demonstrates the effectiveness of our MuSTC method. In addition, we integrate the clustering results into two representative spatio-temporal prediction models, i.e., Spatio-Temporal Graph Convolutional Networks (STGCN) and Adaptive Graph Convolutional Recurrent Network (AGCRN), to conduct SST prediction. According to the results of experiments, the integration of regionality information leads to the reduction of Root Mean Square Error (RMSE) by 1.95%, 1.39% and 1.28% in NPO, SAO and NAO, respectively, using the STGCN model, and the reduction of RMSE by 4.94%, 0.74% and 1.43% by using the AGCRN model. Such results indicate that the integration of regionality information could notably improve the prediction accuracy of SST.
The goal of temporal knowledge graph embedding (TKGE) is to represent the entities and relations in a given temporal knowledge graph (TKG) as low-dimensional vectors (i.e., embeddings), which preserve both semantic information and temporal dynamics of the factual information. In this paper, we posit that the intrinsic difficulty of existing TKGE methods lies in the lack information in KG snapshots with timestamps, each of which contains the facts that co-occur at specific timestamp. To address this challenge, we propose a novel self-supervised TKGE approach, THOR (Three-tower grapH cOnvolution netwoRks (GCNs)), which extracts latent knowledge from TKGs by jointly leveraging both temporal and atemporal dependencies between entities and the structural dependency between relations. THOR learns the embeddings of entities and relations, obtained from three-tower GCNs by (1) maximizing the likelihood of the facts in a TKG and (2) addressing the lack of information in a TKG based on the auxiliary supervision signals each entity. Our experiments on three real-world datasets demonstrate that THOR significantly outperforms 17 competitors in terms of TKG completion tasks. THOR yields up to 9.37% higher accuracy than the best competitor.
Identifying the binding residues of protein-peptide complexes is essential for understanding protein function mechanisms and exploring drug discovery. Recently, many computational methods have been developed to predict the interaction sites of either protein or peptide. However, to our knowledge, no prediction method can simultaneously identify the interaction sites on both the protein and peptide sides. Here, we propose a deep graph convolutional network (GCN)-based method called GraphPPepIS to predict the interaction sites of protein-peptide complexes using protein and peptide structural information. We also propose a companion method, SeqPPepIS, for assisting with the lack of structural information and the flexibility of peptides. SepPPepIS replaces the peptide structural features in GraphPPepIS by learning features from peptide sequences. We performed a comprehensive evaluation of the benchmark data sets, and the results show that our two methods outperform state-of-the-art methods on the accurate interaction sites of both protein and peptide sides. We show that our methods can help improve protein- peptide docking. For docking data sets, our methods maintain robust performance in identifying binding sites, thereby enhancing the prediction of peptide binding poses. Finally, we visualized the analysis of protein and peptide graph embedding to demonstrate the learning ability of graph convolution in predicting interaction sites, which was mainly obtained through the shared parameters of a protein graph and peptide graph.
Accurate and efficient traffic prediction is the key to the realization of intelligent transportation system (ITS), which helps to alleviate traffic congestion and reduce traffic accidents. Due to the complex dynamic spatial-temporal dependence between traffic networks, traffic prediction is extremely challenging. In previous studies, convolution neural network (CNN) and graph convolution network (GCN) were used to model spatial correlation. However, the non-Euclidean correlation of road network reduces the effect of convolution operator modeling. In addition, only considering the traffic interaction around the concerned points simplifies the influence of traffic network. In order to address the above problems, this article proposes an end-to-end global spatial-temporal graph attention network (GST-GAT), which uses the "global interaction + node query" to model the dynamic spatial-temporal correlation of traffic. In the encoder, the long short-term memory (LSTM) component flexibly transforms the traffic dynamic spatial-temporal graph into feedforward differentiable features. Global traffic interaction is proposed to summarize traffic network context changes and integrate all node features at each moment through a forward calculation. Then, each node computes the influence of traffic global interaction on a single node in parallel, and the spatial-temporal interaction information is adaptive fused by gating fusion mechanism. Finally, the end-to-end network structure is used to train the rich mixed feature coding to generate the traffic prediction status of each node. Experiments on public transportation data sets show that GST-GAT performs better than previous work in terms of accuracy and inference speed.
Due to the harmful impact of fabricated information on social media, many rumor verificationtechniques have been introduced in recent years. Advanced techniques like multi-task learning(MTL), shared-private models suffer from many strategic limitations that restrict their capabilityof veracity identification on social media. These models are often reliant on multiple tasksfor the primary targeted objective. Even the most recent deep neural network (DNN) modelslike VRoC, Hierarchical-PSV, StA-HiTPLAN etc. based on VAE, GCN, Transformer respectivelywith improved modification are able to perform good on veracity identification task butwith the help of additional auxiliary information, mostly. However, their rise is still notsubstantial with respect to the proposed model even though the proposed model is notusing any additional information. To come up with an improved DNN model architecture,we introduceglobally Discrete Attention Representations from Transformers(gDART).Discrete-Attention mechanism ingDARTis capable of capturing multifarious correlations veiledamong the sequence of words which existing DNN models including Transformer often overlook.Our proposed framework uses aBranch-CoRRAttentionNetworkto extract highly informativefeatures in branches, and employsFeature Fusion Network Componentto identify deepembedded features and use them to make enhanced identification of veracity of an unverifiedclaim. Moreover, to achieve its goal,gDARTis not dependent on any costly auxiliary resourcebut on anunsupervised learningprocess. Extensive experiments reveal thatgDARTmarks aconsiderable performance gain in veracity identification task over state-of-the-art models on tworeal world rumor datasets.gDARTreports a gain of 36.76%, 40.85% on standard benchmarkmetrics
Motivation: Single-cell RNA sequencing (scRNA-seq) data, annotated by cell type, is useful in a variety of downstream biological applications, such as profiling gene expression at the single-cell level. However, manually assigning these annotations with known marker genes is both time-consuming and subjective.Results: We present a Graph Convolutional Network (GCN)-based approach to automate the annotation process. Our process builds upon existing labeling approaches, using state-of-the-art tools to find cells with highly confident label assignments through consensus and spreading these confident labels with a semi-supervised GCN. Using simulated data and two scRNA-seq datasets from different tissues, we show that our method improves accuracy over a simple consensus algorithm and the average of the underlying tools. We also compare our method to a nonparametric neighbor majority approach, showing comparable results. We then demonstrate that our GCN method allows for feature interpretation, identifying important genes for cell type classification. We present our completed pipeline, written in PyTorch, as an end-to-end tool for automating and interpreting the classification of scRNA-seq data.
Solvent effects are notoriously difficult to describe for metallic nanoparticles (NPs). Here, we introduce GAL21 which is the first pairwise additive force field that is specifically designed to modulate the near chemisorption energy of water as a function of the coordination numbers of the metallic atoms. We find a quadratic dependence to be most suitable for capturing the dependence of the adsorption energy of water on the generalized coordination number (GCN) of the metal atoms. GAL21 has been fitted against DFT adsorption energies for Cu, Ag, Au, Ni, Pd, Pt, and Co on 500 configurations and validated on about 3000 configurations for each metal, constructed on five surfaces with GCNs varying from 2.5 to 11.25. Depending on the metals, the root mean square deviation is found between 0.7 kcal mol(-1) (Au) to 1.6 kcal mol(-1) (Ni). Using GAL21, as implemented in the open-source code CP2K, we then evaluate the solvation energy of Au-55 and Pt-55 NPs in water using thermodynamic integration. The solvation free energy is found to be larger for Pt than for Au and systematically larger than 200 kcal mol(-1), demonstrating the large impact of solvent on the surface energetics of NPs. Still, given that the amorphous NPs are both, the most stable and the most solvated ones, we do not predict a change in the preferred morphology between the gas-phase and in water. Finally, based on a linear regression on three sizes of NPs (from 38 to 147), the solvation energy for Au and Pt surface atoms is found to be -5.2 and -9.9 kcal mol(-1), respectively. Published under an exclusive license by AIP Publishing.
High-precision water quality prediction plays a vital role in preventing and controlling river pollution. However, river water's highly nonlinear and complex spatio-temporal dependencies pose significant challenges to water quality prediction tasks. In order to capture the spatial and temporal characteristics of water quality data simultaneously, this paper combines deep learning algorithms for river water quality prediction in the river network area of Jiangnan Plain, China. A water quality prediction method based on graph convolutional network (GCN) and long short-term memory neural network (LSTM), namely spatio-temporal graph convolutional network model (ST-GCN), is proposed. Specifically, the spatio-temporal graph is constructed based on the spatio-temporal correlation between river stations, the spatial features in the river network are extracted using GCN, and the temporal correlation of water quality data is obtained by integrating LSTM. The model was evaluated using R-2, MAE, and RMSE, and the experimental results were 0.977, 0.238, and 0.291, respectively. Compared with traditional regression models and general deep learning models, this model has significantly improved prediction accuracy, better stability, and generalization ability. The ST-GCN model can achieve high-precision water quality prediction in different river sections and provide technical support for water environment management.
Video captioning aims at automatically generating a natural language caption to describe the content of a video. However, most of the existing methods in the video captioning task ignore the relationship between objects in the video and the correlation between multimodal features, and they also ignore the effect of caption length on the task. This study proposes a novel video captioning framework (ORMF) based on the object relation graph and multimodal feature fusion. ORMF uses the similarity and Spatio-temporal relationship of objects in video to construct object relation features graph and introduce graph convolution network (GCN) to encode the object relation. At the same time, ORMF also constructs a multimodal features fusion network to learn the relationship between different modal features. The multimodal feature fusion network is used to fuse the features of different modals. Furthermore, the proposed model calculates the length loss of the caption, making the caption get richer information. The experimental results on two public datasets (Microsoft video captioning corpus [MSVD] and Microsoft research-video to text [MSR-VTT]) demonstrate the effectiveness of our method.
Pose estimation in crowded scenes is key to understanding human behavior in real-life applications. Most existing CNN-based pose estimation methods often depend on the appearance of visible parts as cues to localize human joints. However, occlusion is typical in crowded scenes, and invisible body parts have no valid features for joint localization. Introducing prior information about the human pose structure to infer the locations of occluded parts is a natural solution to this problem. In this paper, we argue that learning structural information based on human joints alone is not enough to address human body variations and could be prone to overfitting. From a perspective on the human pose as a dual representation of joints and limbs, we propose a pose refinement network, coined as dual graph network (DGN), to jointly learn its structural information of body joints and limbs by incorporating the cooperative constraints between two branches. Specifically, our DGN has two coupled graph convolutional network (GCN) branches to model the structure information of joints and limbs. Each stage in the branch is composed of a feature aggregator and a GCN module for inter-branch information fusion and intra-branch context extraction, respectively. In addition, to enhance the modeling capacity of GCN, we design an adaptive GCN layer (AGL) embedded in the GCN module to handle each pose instance based on its graph structure. We also propose a heatmap-guided sampling to leverage the features of the body parts to provide rich visual features for the inference of occluded parts. We perform extensive experiments on five challenging datasets to demonstrate the effectiveness of our DGN on pose estimation. Our DGN obtains significant performance improvement from 67.9 to 72.4 mAP in the CrowdPose dataset with the same CNN-based pose estimator and training strategy as the OPEC-Net. It shows that, compared to the OPEC-Net only considering joints, our DGN has a clear advantage due to the joint consideration of both joints and limbs. Meanwhile, our DGN is also helpful for pose estimation in general datasets (i.e., COCO and Pose track) with less occlusion and mutual interference, demonstrating the generalization power of DGN on refining human poses.
Predicting the future price trends of stocks is a challenging yet intriguing problem given its critical role to help investors make profitable decisions. In this paper, we present a collaborative temporal-relational modeling framework for end-to-end stock trend prediction. Different from existing studies relying on the pairwise correlations between stocks, we argue that stocks are naturally connected as a collective group, and introduce two heterogeneous hypergraphs to separately characterize the stock group-wise re-lationships of industry-belonging and fund-holding. A novel hypergraph tri-attention network (HGTAN) is proposed to augment the hypergraph convolutional networks with a hierarchical organization of intra-hyperedge, inter-hyperedge, and inter-hypergraph attention modules. In this manner, HGTAN adaptively determines the importance of nodes, hyperedges, and hypergraphs during the information propagation among stocks, so that the potential synergies between stock movements can be fully exploited. Experi-mental evaluation and investment simulation on real-world stock data demonstrate the effectiveness of our approach.& COPY; 2023 Elsevier Ltd. All rights reserved.
Time series imputation is essential for real-world applications. Though the emergence of Generative Adversarial Networks (GANs) and Graph Convolution Networks (GCNs) provides more possibilities to improve imputation performance, how to achieve the optimal latent code and precisely model the properties of incomplete time series remain a challenge. In GAN-based methods, an effective latent code of incomplete time series is necessary for precise reconstruc-tion. To acquire the optimal latent code, we introduce GAN inversion to invert the input to the latent space of a pretrained GAN. The inverted latent code contains rich properties of original observations and thus can better reconstruct the target sample. To model the temporal irregu-larity due to the presence of missing values, the decay connection is exploited to quantify the influence that dependencies between adjacent observations should decrease as the time lags between them increase. We incorporate the quantification into the adjacent matrix of the GCN to better aggregate adjacent information of incomplete time series. With the adoption of decay connection, the resulting latent code through GAN inversion can further produce faithful reconstruction. Quantitative and qualitative experiments conducted on several time series data -sets show that our proposal achieves state-of-the-art or competitive imputation performance.
With the advent of deep learning algorithms, fully automated radiological image analysis is within reach. In spine imaging, several atlas- and shape-based as well as deep learning segmentation algorithms have been proposed, allowing for subsequent automated analysis of morphology and pathology. The first "Large Scale Vertebrae Segmentation Challenge" (VerSe 2019) showed that these perform well on normal anatomy, but fail in variants not frequently present in the training dataset. Building on that experience, we report on the largely increased VerSe 2020 dataset and results from the second iteration of the VerSe challenge (MICCAI 2020, Lima, Peru). VerSe 2020 comprises annotated spine computed tomography (CT) images from 300 subjects with 4142 fully visualized and annotated vertebrae, collected across multiple centres from four different scanner manufacturers, enriched with cases that exhibit anatomical variants such as enumeration abnormalities (n = 77) and transitional vertebrae (n = 161). Metadata includes vertebral labelling information, voxel-level segmentation masks obtained with a human-machine hybrid algorithm and anatomical ratings, to enable the development and benchmarking of robust and accurate segmentation algorithms.
Node classification for highly imbalanced graph data is challenging, with existing graph neural networks (GNNs) typically utilizing a balanced class distribution to learn node embeddings on graph data. However, when dealing with an imbalanced class distribution, they tend to bias the nodes of the majority classes while the nodes of the minority classes are under-represented. To overcome this challenge, this work introduces a novel GNN-based Imbalanced Node Classification Model (GNNINCM) that is appropriate for class-imbalanced graph data, comprising two cooperative modules: Embedding Clustering-based Optimization (ECO) and Graph Reconstruction-based Optimization (GRO). ECO first employs a two-layer graph convolutional network (GCN) to obtain node embeddings and then performs clustering analysis to enhance the representative nature of the node embeddings and ease classification. Moreover, GRO employs an inner product decoder to reconstruct graph structure and minimize information loss. In particular, we design a hard sample strategy and integrate it into ECO and GRO to ensure that the embeddings of the hard nodes are correctly represented. Furthermore, we propose a Hard Sample-based Knowledge Distillation Method (HSKDM) to train multiple GNNINCM models simultaneously and improve the overall classification performance. Experiments on three well-known class-imbalanced graph datasets demonstrate that GNN-INCM outperforms current stateof-the-art methods in node classification tasks and that HSKDM can substantially improve the overall classification performance. (c) 2022 Elsevier B.V. All rights reserved.
The study of cosmic gamma ray bursts (GRBs) is one of the main goals of the Lomonosov space mission. The main advantage of this mission is simultaneous multiwavelength observations of GRBs covering the optical, X-ray and gamma-ray ranges. The mission payload includes the GRB monitor BDRG, wide-field optical cameras SHOK, and the UFFO instrument. Data are recorded mainly by the event trigger provided by the BDRG instrument, which measures the spectral and temporal properties of the burst in the energy range 10-3000 keV. The BDRG instrument also provides estimation of the source coordinates by comparing the readings of three differently directed detectors with an accuracy of several degrees. Wide-field SHOK optical cameras have a field of view of 20A degrees x 40A degrees. They fix a set of images with a frequency of about five frames per second prior to the trigger and another set immediately after the trigger. The UFFO instrument includes the UBAT telescope with a coded mask for measurements in hard X-ray and soft gamma-ray ranges and an optical telescope with a slewing mirror (SMT) that can be directed on the GRB source for a time 1 s for measuring GRB prompt emission in the early stages. In response to an BDRG trigger signal, the real-time data on a detected GRB are transmitted to the Earth via Globalstar network to the Gamma-ray Coordinates Network (GCN) and ground-based observatories. During observations on the Lomonosov satellite, 20 gamma-ray bursts were detected and catalogued. Several gamma-ray bursts were also detected in the Vernov satellite experiment. An example of such an event is given.
Traffic forecasting constitutes a task of great importance in intelligent transport systems. Owing to the non-Euclidean structure of traffic data, the complicated spatial correlations, and the dynamic temporal dependencies, it is challenging to predict traffic accurately. Despite the fact that few prior studies have considered the interconnections between multiple traffic nodes at the same timestep, the majority of studies fail to capture the dependencies among multiple nodes at different timesteps. Furthermore, most existing work generates shallow graphs based solely on the distance between traffic nodes, which limits their representation competence and declines their power in capturing complex correlations. In particular, inspired by the recent breakthroughs in the generative adversarial network (GAN) and the power of the graph convolution network (GCN) in handling non-Euclidean data, this paper puts forward an adversarial multi-graph convolutional neural network model, named TFGAN, to address the abovementioned problems. We integrate the unsupervised model elasticity with the supervision provided by supervised training to help the GAN generator model generates accurate traffic predictions. To improve the representation and model the implicit correlations effectively, multiple GCNs are constructed within the generator based on various perspectives, such as similarity, correlation, and spatial distance. Meanwhile, GRU and self-attention are applied after each graph to capture the dynamic temporal dependencies across nodes. The comprehensive experiments on three different traffic variables (traffic flow, speed, and travel time) using six real-world traffic datasets demonstrate that TFGAN outperforms the related state-of-the-art models and achieves significant results. (C) 2022 Elsevier B.V. All rights reserved.
The representation of 3D data is the key issue for shape analysis. However, most of the existing representations suffer from high computational cost and structure information loss. This paper presents a novel sequential slice representation with an attention-embedding network, named RSSNet, for 3D point cloud recognition and retrieval in road environments. RSSNet has two main branches. Firstly, a sequential slice module is designed to map disordered 3D point clouds to ordered sequence of shallow feature vectors. A gated recurrent unit (GRU) module is applied to encode the spatial and content information of these sequential vectors. The second branch consists of a key-point based graph convolution network (GCN) with an embedding attention strategy to fuse the sequential and global features to refine the structure discriminability. Three datasets were used to evaluate the proposed method, one acquired by our mobile laser scanning (MLS) system and two public datasets (KITTI and Sydney Urban Objects). Experimental results indicated that the proposed method achieved better performance than recognition and retrieval state-of-the-art methods. RSSNet provided recognition rates of 98.08%, 95.77% and 70.83% for the above three datasets, respectively. For the retrieval task, RSSNet obtained excellent mAP values of 95.56%, 87.16% and 69.99% on three datasets, respectively.
In recent years, convolution neural networks (CNNs) and graph convolution networks (GCNs) have been widely used in hyperspectral image classification (HSIC). CNNs can effectively extract the spatial spectral features of hyperspectral images (HSIs), while GCNs can quickly capture the structural features of HSIs, which makes the effective combination of the two is beneficial to improve classification performance of hyperspectral images. However, the high redundancy of feature information and the problem of small sample are still the major challenges of HSIC. In order to alleviate these problems, in this paper, a new graph and double pyramid attention network based on linear discrimination of spectral interclass slices (GDPA_LDSICS) is proposed. First, a linear discrimination of spectral inter class slices (LDSICS) module is designed. The LDSICS module can effectively eliminate a lot of redundancy in spectral dimension, which is conducive to subsequent feature extraction. Then, the spatial spectral deformation (SSD) module is constructed, which can effectively correlate the spatial spectral information closely. Finally, in order to alleviate the problem of small sample, a double branch structure of CNN and GCN is developed. On the CNN branch, a double pyramid attention (DPA) structure is designed to model context semantics to avoid information loss caused by long-distance feature extraction. On the GCN branch, an adaptive dynamic encoding (ADE) method is proposed, which can more effectively capture the topological structure of spatial spectral features. Experiments on four open datasets show that the GDPA_LDSICS can provide better classification performance and generalization performance than other most advanced methods.
Water Cherenkov detectors like Super-Kamiokande, and the next generation Hyper-Kamiokande are adding gadolinium to their water to improve the detection of neutrons. By detecting neutrons in addition to the leptons in neutrino interactions, an improved separation between neutrino and anti-neutrinos, and reduced backgrounds for proton decay searches can be expected. The neutron signal itself is still small and can be confused with muon spallation and other background sources. In this paper, machine learning techniques are employed to optimize the neutron capture detection capability in the new intermediate water Cherenkov detector (IWCD) for Hyper-K. In particular, boosted decision tree (XGBoost), graph convolutional network (GCN), and dynamic graph convolutional neural network (DGCNN) models are developed and benchmarked against a statistical likelihood-based approach, achieving up to a 10% increase in classification accuracy. Characteristic features are also engineered from the datasets and analyzed using SHAP (SHapley Additive exPlanations) to provide insight into the pivotal factors influencing event type outcomes. The dataset used in this research consisted of roughly 1.6 million simulated particle gun events, divided nearly evenly between neutron capture and a background electron source. The current samples used for training are representative only, and more realistic samples will need to be made for the analyses of real data. The current class split is 50/50, but there is expected to be a difference between the classes in the real experiment, and one might consider using resampling techniques to address the issue of serious imbalances in the class distribution in real data if necessary.
Due to the interaction of many factors in the stock market, stock price prediction has always been a challenging problem in the field of machine learning. In particular, the mutation factors of the stock market often have a great impact on subsequent predictions. The existing prediction models seldom consider the impacts of other stocks in the stock market and mutation points on the prediction accuracy of target stocks. Therefore, this paper presents a new knowledge graph and deep learning method combined with a stock price prediction network focusing on related stocks and mutation points. First, the target stock price features are obtained through the ConvLSTM network. Second, the knowledge graph is used to mine the hidden relationships between stocks to find the stocks relevant to the target stock to obtain the market information vector and the market information features through the ConvLSTM network. Then, we find the mutation points according to the price change range, construct the mutation point distance weight matrix according to the distance from each trading day to the mutation points, and obtain the mutation point information features through the graph convolutional network (GCN). Finally, the features of market information, mutation point information and target stock price are fused to jointly predict the future stock price. The experimental results on the A share of Shenzhen from 2010 to 2019 show that the algorithm has good robustness and that the prediction accuracy is effectively improved. (C) 2022 The Authors. Published by Elsevier B.V. on behalf of King Saud University.
Conventionally, cold-start limitations are managed by leveraging side information such as social-trust relationships. However, the relationships between users in social networks are complex, uncertain, and sparse. Therefore, it is necessary to extract beneficial social connections to make the recommendation models cold-start resistant. Towards this end, we propose a novel recommendation model called Variational Cold-start Resistant Recommendation (CORE-VAE). More concretely, we employ a social-aware similarity function and a graph convolutional network (GCN) to generate robust social-aware user representations that account for the complexities, uncertainties, and sparse nature of the social-trust network. Subsequently, these powerful social-aware representations aid us in producing cold-start resistant rating vectors for all users. To explore the rich user rating information, we propose an expressive variational autoencoder (VAE) model. Unlike earlier VAE-based CF models, CORE-VAE utilizes a novel prior distribution and a well-designed skip-generative network to alleviate the posterior collapse issue considerably. Besides, CORE-VAE can also capture the latent space's uncertainty and ensure that observations and their accompanying latent variables have high mutual information. Overall, these novel techniques dramatically help produce better latent representations for generating more accurate recommendations. We show that CORE-VAE outperforms numerous competitive baseline models on real-world datasets through comprehensive empirical evaluation and analysis. (C) 2022 Elsevier Inc. All rights reserved.
Region-level passenger demand prediction plays an important role in the coordination of travel demand and supply in the urban public transportation system. The complex urban road network structure leads to irregular shapes and arrangements of regions, which poses a challenge for capturing the spatio-temporal correlation of demand generated in different regions. In this study, we propose a multi-community spatio-temporal graph convolutional network (MC_STGCN) framework to predict passenger demand at a multi-region level by exploring spatio-temporal correlations among regions. Specifically, the gated recurrent unit (GRU) is applied to encode the temporal correlation in regions into a vector. On the other hand, the spatial correlations among regions are encoded into two graphs through the graph convolutional network (GCN): geographically adjacent graph and functional similarity graph. Then, a prediction module based on the Louvain algorithm is used to accomplish the passenger demand prediction of multi-regions. The two real-world taxi order data collected in Shenzhen City and New York City are used in model validation and comparison. The numerical results show that the MC_STGCN model outperforms both classical time-series prediction methods and deep learning approaches. Moreover, in order to better illustrate the superiority of the proposed model, we further discuss the improvement of prediction performance though spatio-temporal correlation modeling and analyzing, the effectiveness of community detection compared with random classification of regions, and the advantages of regional level prediction compared with grid-based prediction models.
In this study, novel core-shell catalyst with a new ternary heterostructure was synthesized (Fe-0@POCN/CQDs) for the degradation of tetracycline (TC). The TEM results showed that the Fe-0 particles were wrapped in POCN material and many nano CQDs were uniformly dispersed in the material. The new ternary nanocomposite exhibits excellent photocatalytic activity for the removal of TC, which was approximately 4.76 times higher than that of GCN. The enhancement of photocatalytic activity was attributed to the effective heterojunction as well as the multiply synergistic effects of POCN combined with Fe-0 and CQDs, which was beneficial for retardation of recombination rate of photogenerated electron-hole pairs and generation of more free radicals for the oxidation of TC. Besides, the reactive oxygen species (ROS) of h(+), center dot O-2(-) and center dot OH played pivotal roles in the degradation of TC by Fe-0@POCN/CQDs during the photocatalytic reaction. At the same times, sulfate radical (SOT) and hydroxyl radical (center dot OH) highlighted the dominant role in the degradation process compared with other free radicals under persulfate hybrid mixture system (PS system), which was further confirmed by radical scavenger experiments and electron spin resonance (ESR) analysis. The response surface methodology (RSM) study indicated that the optimal removal parameters of tetracycline could reach 97.57% within 30 min under PS system. In addition, the possible degradation pathway intermediates of TC were studied by HPLC-MS and the reaction catalytic activity mechanism of Fe-0@POCN/CQDs/persulfate system was discussed. (C) 2020 Published by Elsevier Ltd.
Understanding human intentions during interactions has been a long-lasting theme, that has applications in human-robot interaction, virtual reality and surveillance. In this study, we focus on full-body human interactions with large-sized daily objects and aim to predict the future states of objects and humans given a sequential observation of human-object interaction. As there is no such dataset dedicated to full-body human interactions with large-sized daily objects, we collected a large-scale dataset containing thousands of interactions for training and evaluation purposes. We also observe that an object's intrinsic physical properties are useful for the object motion prediction, and thus design a set of object dynamic descriptors to encode such intrinsic properties. We treat the object dynamic descriptors as a new modality and propose a graph neural network, HO-GCN, to fuse motion data and dynamic descriptors for the prediction task. We show the proposed network that consumes dynamic descriptors can achieve state-of-the-art prediction results and help the network better generalize to unseen objects. We also demonstrate the predicted results are useful for human-robot collaborations.
Open-set domain adaptation (OSDA), which allows the target domain to store invisible class samples in the source domain, has recently received significant attention. In this paper, we propose a new unsupervised OSDA classification framework using an evidential network and multi-binary classifier and consider their jointly selected samples as a pseudo-labelled sample set of an unknown class. Specifically, this study designed an evidential network based on the D-S evidence theory to predict the degree of belief that a sample belongs to an unknown class. By selecting samples with high -uncertainty, false positive samples can be removed, which improves the reliability of unknown sample selection. Then, to better explore the intra-class relationship, an open-set graph convolutional network (OSGC) is proposed to extract distinguishable features of known and unknown samples in a weighted adversarial adaptation manner. Moreover, this paper presents a graph collaborative learning strategy to retrain the unknown recognition module (URM) with high confidence pseudo-labelled samples, which is predicted by the graph convolution network (GCN), where the target known class distribution is learned. Experimental results show that the proposed method outperforms state-of-the-art OSDA algorithms on three benchmark datasets and maintains a high recognition accuracy for unknown classes over a wide range of openness. (C) 2022 Elsevier B.V. All rights reserved.
Proteins are the essential biological macromolecules required to perform nearly all biological processes, and cellular functions. Proteins rarely carry out their tasks in isolation but interact with other proteins (known as protein-protein interaction) present in their surroundings to complete biological activities. The knowledge of protein-protein interactions (PPIs) unravels the cellular behavior and its functionality. The computational methods automate the prediction of PPI and are less expensive than experimental methods in terms of resources and time. So far, most of the works on PPI have mainly focused on sequence information. Here, we use graph convolutional network (GCN) and graph attention network (GAT) to predict the interaction between proteins by utilizing protein's structural information and sequence features. We build the graphs of proteins from their PDB files, which contain 3D coordinates of atoms. The protein graph represents the amino acid network, also known as residue contact network, where each node is a residue. Two nodes are connected if they have a pair of atoms (one from each node) within the threshold distance. To extract the node/residue features, we use the protein language model. The input to the language model is the protein sequence, and the output is the feature vector for each amino acid of the underlying sequence. We validate the predictive capability of the proposed graph-based approach on two PPI datasets: Human and S. cerevisiae. Obtained results demonstrate the effectiveness of the proposed approach as it outperforms the previous leading methods. The source code for training and data to train the model are available at https://github.com/JhaKanchan15/PPI_GNN.git.
Relation extraction is a necessary step in obtaining information from clinical medical records. In the medical domain, there have been several studies on relation extraction in modern medicine clinical notes written in English. However, very limited relation extraction research has been conducted on clinical notes written in Chinese, especially traditional Chinese medicine (TCM) clinical records (e.g., herb-symptom, herb-disease). Instead of independently extracting each relation from a single sentence or text, we propose to globally and reasonably extract multiple types of relations from the Chines clinical records with a novel heterogeneous graph representation learning method. Specifically, we first construct multiple view medical entity graphs based on the co-occurring relations, knowledge obtained from the clinic, and domain texts with the corresponding information of two medical entities from the Chinese clinical records, in which each edge is a candidate relation; we then build a Graph Convolutional Network (GCN)-based representation learning with the attention mechanism to simultaneously infer the existence of all the edges via classification. The experimental data were obtained from the Chinese medical records and literature provided by previous work. The main experimental results on Chinese clinical records show that our proposed model's precision, recall, and F1-score reach 10.2%, 13.5%, 12.6%, demonstrating significant improvements over state-of-the-art.
In this study, we address the problems encountered by incremental face clustering. Without the benefit of having observed the entire data distribution, incremental face clustering is more challenging than static dataset clustering. Conventional methods rely on the statistical information of previous clusters to improve the efficiency of incremental clustering; thus, error accumulation may occur. Therefore, this study proposes to predict the summaries of previous data directly from data distribution via supervised learning. Moreover, an efficient framework to cluster previous summaries with new data is explored. Although learning summaries from original data costs more than those from previous clusters, the entire framework consumes just a little bit more time because clustering current data and generating summaries for new data share most of the calculations. Experiments show that the proposed approach significantly outperforms the existing incremental face clustering methods, as evidenced by the improvement of average F-score from 0.644 to 0.762. Compared with state-of-the-art static face clustering methods, our method can yield comparable accuracy while consuming much less time.
Streamflow forecasting over gauged and ungauged basins play a vital role in water resources planning, especially under the changing climate. Increased availability of large sample hydrology data sets, together with recent advances in deep learning techniques, has presented new opportunities to explore temporal and spatial patterns in hydrological signatures for improving streamflow forecasting. The purpose of this study is to adapt and benchmark several state-of-the-art graph neural network (GNN) architectures, including ChebNet, Graph Convolutional Network (GCN), and GraphWaveNet, for end-to-end graph learning. We explicitly represent river basins as nodes in a graph, learn the spatiotemporal nodal dependencies, and then use the learned relations to predict streamflow simultaneously across all nodes in the graph. The efficacy of the developed GNN models is investigated using the Catchment Attributes and MEteorology for Large-sample Studies (CAMELS) data set under two settings, fixed graph topology (transductive learning), and variable graph topology (inductive learning), with the latter applicable to prediction in ungauged basins (PUB). Results indicate that GNNs are generally robust and computationally efficient, achieving similar or better performance than a baseline model trained using the long short-term memory (LSTM) network. Further analyses are conducted to interpret the graph learning process at the edge and node levels and to investigate the effect of different model configurations. We conclude that graph learning constitutes a viable machine learning-based method for aggregating spatiotemporal information from a multitude of sources for streamflow forecasting
Ovarian carcinomas (OCs) represent a heterogeneous group of neoplasms consisting of several entities with pathogenesis, molecular profiles, multiple risk factors, and outcomes. OC has been regarded as the most lethal cancer among women all around the world. There are at least five main types of OCs classified by the fifth edition of the World Health Organization of tumors: high-/low-grade serous carcinoma, mucinous carcinoma, clear cell carcinoma, and endometrioid carcinoma. With the improved knowledge of genome-wide association study (GWAS) and expression quantitative trait locus (eQTL) analyses, the knowledge of genomic landscape of complex diseases has been uncovered in large measure. Moreover, pathway analyses also play an important role in exploring the underlying mechanism of complex diseases by providing curated pathway models and information about molecular dynamics and cellular processes. To investigate OCs deeper, we introduced a novel disease susceptible gene prediction method, XGBG, which could be used in identifying OC-related genes based on different omics data and deep learning methods. We first employed the graph convolutional network (GCN) to reconstruct the gene features based on both gene feature and network topological structure. Then, a boosting method is utilized to predict OC susceptible genes. As a result, our model achieved a high AUC of 0.7541 and an AUPR of 0.8051, which indicates the effectiveness of the XGPG. Based on the newly predicted OC susceptible genes, we gathered and researched related literatures to provide strong support to the results, which may help in understanding the pathogenesis and mechanisms of the disease.
Forecasting the trajectories of neighbor vehicles is a crucial step for decision making and motion planning of autonomous vehicles. This paper proposes a graph-based spatial-temporal convolutional network (GSTCN) to predict future trajectory distributions of all neighbor vehicles using past trajectories. This network tackles spatial interactions using a graph convolutional network (GCN), and captures temporal features with a convolutional neural network (CNN). The spatial-temporal features are encoded and decoded by a gated recurrent unit (GRU) network to generate future trajectory distributions. Besides, we propose a weighted adjacency matrix to describe the intensities of mutual influence between vehicles, and the ablation study demonstrates the effectiveness of our scheme. Our network is evaluated on two real-world freeway trajectory datasets: I-80 and US-101 in the Next Generation Simulation (NGSIM). Comparisons in three aspects, including prediction errors, model sizes, and inference speeds, show that our network can achieve state-of-the-art performance.
Network representation learning endeavors to learn low-dimensional dense representations for nodes in a network. With the rapid development of online social platforms, the analysis of social networks has become increasingly significant. Although network representation learning can facilitate the social network analysis, most existing algorithms merely exploit the explicit structure among nodes to obtain the node representations. Besides, traditional network representation learning techniques ignore the influence of nodes in a network when generating the representations of nodes. Motivated by this, we innovatively propose an influence-aware graph neural network (IAGNN) framework, which can learn the latent feature representations of nodes by incorporating both node influence and global structure information into the embedding process for encoding graph-structured data. The generated low-dimensional dense representations of the nodes in a network can be used for subsequent tasks such as user classification and user behavior prediction. Specifically, we assign different weights to each node according to different types of topology between their neighbors, and integrate with the basic influence of each node to generate an intermediate matrix with influence information. The intermediate matrix is encoded into low-dimensional and dense vector spaces by leveraging the attention mechanism and the graph convolution operation. Extensive experiments are conducted on five datasets, and IAGNN achieves an average accuracy of 3% higher than the comparison algorithms on the node classification and link prediction tasks. The experimental results demonstrate that our model can significantly outperform the state-of-the-art network embedding methods such as GCN, GAT, GraphSage, AGNN on node classification and link prediction tasks. (c) 2021 Elsevier B.V. All rights reserved.
Cumulative experimental studies have demonstrated the critical roles of microRNAs (miRNAs) in the diverse fundamental and important biological processes, and in the development of numerous complex human diseases. Thus, exploring the relationships between miRNAs and diseases is helpful with understanding the mechanisms, the detection, diagnosis, and treatment of complex diseases. As the identification of miRNA-disease associations via traditional biological experiments is time-consuming and expensive, an effective computational prediction method is appealing. In this study, we present a deep learning framework with variational graph auto-encoder for miRNA-disease association prediction (VGAE-MDA). VGAE-MDA first gets the representations of miRNAs and diseases from the heterogeneous networks constructed by miRNA-miRNA similarity, disease-disease similarity, and known miRNA-disease associations. Then, VGAE-MDA constructs two sub-networks: miRNA-based network and disease-based network. Combining the representations based on the heterogeneous network, two variational graph auto-encoders (VGAE) are deployed for calculating the miRNA-disease association scores from two subnetworks, respectively. Lastly, VGAE-MDA obtains the final predicted association score for a miRNA-disease pair by integrating the scores from these two trained networks. Unlike the previous model, the VGAE-MDA can mitigate the effect of noises from random selection of negative samples. Besides, the use of graph convolutional neural (GCN) network can naturally incorporate the node features from the graph structure while the variational autoencoder (VAE) makes use of latent variables to predict associations from the perspective of data distribution. The experimental results show that VGAE-MDA outperforms the state-of-the-art approaches in miRNA-disease association prediction. Besides, the effectiveness of our model has been further demonstrated by case studies.
Accurate traffic flow forecasting is a prerequisite guarantee for the realization of intelligent transportation, but due to the complex spatiotemporal characteristics of traffic flow, its forecasting has always been difficult. Deep learning can learn the deep spatiotemporal characteristics of traffic flow from a large amount of data. Deep learning can learn the deep spatiotemporal characteristics of traffic flow from a large amount of data. This paper establishes a novel combination forecasting model GGCN-SA based on deep learning for traffic flow to effectively capture the spatiotemporal characteristics of traffic flow and improve forecasting accuracy. The model captures the spatial correlation of the road traffic network through the graph convolutional network (GCN), captures the time dependence of the traffic flow through the gated recursive unit (GRU), and further introduces the soft attention mechanism (Soft Attention) to aggregate different neighborhoods Spatio-temporal information within the range to enhance the model's ability to characterize the temporal and spatial characteristics of traffic flow. A large number of experiments have been conducted on the METR-LA and SZ-taxi data sets. The experimental results show that the GGCN-SA model proposed in this paper has better forecasting performance compared with the baseline methods.
Determining the properties of chemical molecules is essential for screening candidates similar to a specific drug. These candidate molecules are further evaluated for their target binding affinities, side effects, target missing probabilities, etc. Conventional machine learning algorithms demonstrated satisfying prediction accuracies of molecular properties. A molecule cannot be directly loaded into a machine learning model, and a set of engineered features needs to be designed and calculated from a molecule. Such hand-crafted features rely heavily on the experiences of the investigating researchers. The concept of graph neural networks (GNNs) was recently introduced to describe the chemical molecules. The features may be automatically and objectively extracted from the molecules through various types of GNNs, e.g., GCN (graph convolution network), GGNN (gated graph neural network), DMPNN (directed message passing neural network), etc. However, the training of a stable GNN model requires a huge number of training samples and a large amount of computing power, compared with the conventional machine learning strategies. This study proposed the integrated framework XGraphBoost to extract the features using a GNN and build an accurate prediction model of molecular properties using the classifier XGBoost. The proposed framework XGraphBoost fully inherits the merits of the GNN-based automatic molecular feature extraction and XGBoost-based accurate prediction performance. Both classification and regression problems were evaluated using the framework XGraphBoost. The experimental results strongly suggest that XGraphBoost may facilitate the efficient and accurate predictions of various molecular properties. The source code is freely available to academic users at https://github.com/chenxiaowei-vincent/XGraphBoost.git.
Autism spectrum disorder (ASD) is a neuro-developmental disorder that affects the social abilities of patients. Studies have shown that a small number of abnormal functional connections (FCs) exist in the cerebral hemisphere of ASD patients. The identification of these abnormal FCs provides a biological ground for the diagnosis of ASD. In this paper, we propose a combined deep feature selection (DFS) and graph convolutional network method to classify ASD. Firstly, in the DFS process, a sparse one-to-one layer is added between the input and the first hidden layer of a multilayer perceptron, thus each functional connection (FC) feature can be weighted and a subset of FC features can be selected accordingly. Then based on the selected FCs and the phenotypic information of subjects, a graph convolutional network is constructed to classify ASD and typically developed controls. Finally, we test our proposed method on the ABIDE database and compare it with some other methods in the literature. Experimental results indicate that the DFS can effectively select critical FC features for classification according to the weights of input FC features. With DFS, the performance of GCN classifier can be improved dramatically. The proposed method achieves state-of-the-art performance with an accuracy of 79.5% and an area under the receiver operating characteristic curve (AUC) of 0.85 on the preprocessed ABIDE dataset; it is superior to the other methods. Further studies on the top-ranked thirty FCs obtained by DFS show that these FCs are widespread over the cerebral hemisphere, and the ASD group appears a significantly higher number of weak connections compared to the typically developed group.
As an essential part of the modern intelligent traffic management system, traffic speed prediction is a challenging task. In recent studies, deep neural networks (LSTM and WaveNet) and graph neural networks (GCN and GNN) have been extensively investigated on traffic networks evaluation, which is better than statistical-based models (MA and ARIMA). However, the demerits existing in these deep learning forecasting process include (1) carry out vehicle speed as an individual input and insufficient ability to handle the other related factors, such as the number of equivalent lanes, accident occurrence, and toll data; (2) inadequate capability of considering both linear and nonlinear components as a whole; (3) unstable performance on forecasting task given various heterogeneous series. Therefore, we propose a hybrid end-to-end model to combine both spatio-temporal features and other effective features. First, a heterogeneous graph attention network approach (HetGAT) was proposed, and a temporal dilated convolution architecture (TCN) was adopted to simulate the impacts on traffic flow of the multi-scale context of temporal factors. Then, a weighted graph attention network (GAT) encodes input temporal features, and a decoder predicts the output speed sequence via a freeway network structure. Based on the end-to-end architecture, we integrate multiple Spatio-temporal factors effectively for the prediction. To validate the efficiency of the proposed model, three sets of field-captured data were employed to run the test. Compared with conventional sequence analysis models and deep prediction models, experimental results demonstrated the superiority of HetGAT for all cases with regards to MAE, MAPE, and RMSE.
In this paper, we derived a high-efficiency formula for calculating the precision of carrier phase relative positioning, analyzed the various factors that affect the positioning accuracy using the carrier phase, and proposed the concept of using a frequency dilution of precision to describe the quantitative effect of different frequency combinations on the positioning precision. To this end, we computed and plotted the global spatial distribution map of the relative positioning dilution of precision for single-day solution, half-hour solution, and single-epoch solution of the global positioning system (GPS), regional Beidou navigation satellite system (BDS2), future global Beidou navigation satellite system (BDS3), and their fusion systems. Using processing software with autonomous intellectual property rights (GCN and VENUS/ARSNet), we solved the measurement data and examined the positioning precision of the single-day solution and single-epoch solution of GPS and BDS2. The analysis demonstrated that the B1/B2 frequency positioning precision of BDS2 was better than that of L1/L2 frequency positioning of GPS, but the positioning precision of the BDS2 is worse than that of GPS over most of the service region of the BDS2. Further, the positioning precision of BDS3 is better than that of GPS in the Asia-Pacific region, while it is the opposite in other regions. Based on these conclusions, we put forth some optimization recommendations regarding the signal frequency of the navigation system and GPS measurement standards to serve as references for optimizing the system performance and formulating standards.
Zero-shot learning (ZSL) models use semantic representations of visual classes to transfer the knowledge learned from a set of training classes to a set of unknown test classes. In the context of generic object recognition, previous research has mainly focused on developing custom architectures, loss functions, and regularization schemes for ZSL using word embeddings as semantic representation of visual classes. In this paper, we exclusively focus on the affect of different semantic representations on the accuracy of ZSL. We first conduct a large scale evaluation of semantic representations learned from either words, text documents, or knowledge graphs on the standard ImageNet ZSL benchmark. We show that, using appropriate semantic representations of visual classes, a basic linear regression model outperforms the vast majority of previously proposed approaches. We then analyze the classification errors of our model to provide insights into the relevance and limitations of the different semantic representations we investigate. Finally, our investigation helps us understand the reasons behind the success of recently proposed approaches based on graph convolution networks (GCN) which have shown dramatic improvements over previous state-of-the-art models.
Land type survey is an important task of land resources survey and the basis of scientific management of land resources. With the increasingly prominent problems of population, resources, and environment, there is an urgent need for a fast and accurate classification method of large-scale land use and land cover based on remote sensing data. Traditional machine learning classification methods based on pixel classification achieved sufficient results and are widely used, such as maximum likelihood classification and random forests method. However, with the development of the novel technology of deep learning, in practical application, for multi-classified land resources, how to use the fast and effective classification method of low and medium resolution RS images needs further research. This paper takes the land resource classification of the Tonghe medium resolution RS dataset of the third land survey in China as an example to screen and compare traditional machine learning classification methods and semantic segmentation models FC-DenseNet56, GCN, BiSeNet, U-Net, DeepLabV3, AdapNet, and PSPNet, which aim to select the optimal feature extraction model. The results show that the classification accuracy of the U-Net model can reach 93.62%, which is more accurate and effective than traditional machine learning methods and other semantic segmentation models. It is suitable for multi-classification tasks of land cover resources in low and medium resolution RS images and shows a superior effect in practical application. Besides, the conclusion of this study can provide a demonstration for large-scale land cover resources investigation using low and medium resolution RS images.
Current state-of-the-art sequence labeling models are typically based on sequential architecture such as Bi-directional LSTM (BiLSTM). However, the structure of processing a word at a time based on the sequential order restricts the full utilization of non-sequential features, including syntactic relationships, word co-occurrence relations, and document topics. They can be regarded as the corpus-level features and critical for sequence labeling. In this paper, we propose a Corpus-Aware Graph Aggregation Network. Specifically, we build three types of graphs, i.e., a word-topic graph, a word co-occurrence graph, and a word syntactic dependency graph, to express different kinds of corpus-level non-sequential features. After that, a graph convolutional network (GCN) is adapted to model the relations between words and non-sequential features. Finally, we employ a label-aware attention mechanism to aggregate corpus-aware non-sequential features and sequential ones for sequence labeling. The experimental results on four sequence labeling tasks (named entity recognition, chunking, multilingual sequence labeling, and target-based sentiment analysis) show that our model achieves state-of-the-art performance.
Solving partial differential equations of complex physical systems is a computationally expensive task, especially in Computational Fluid Dynamics(CFD). This drives the application of deep learning methods in solving physical systems. There exist a few deep learning models that are very successful in predicting flow fields of complex physical models, yet most of these still exhibit large errors compared to simulation. Here we introduce AMGNET, a multi-scale graph neural network model based on Encoder-Process-Decoder structure for flow field prediction. Our model employs message passing of graph neural networks at different mesh graph scales. Our method has significantly lower prediction errors than the GCN baseline on several complex fluid prediction tasks, such as airfoil flow and cylinder flow. Our results show that multi-scale representation learning at the graph level is more effective in improving the prediction accuracy of flow field.
In this work, we propose a new patch-based framework called VPU for the video-based point cloud upsampling task by effectively exploiting temporal dependency among multiple consecutive point cloud frames, in which each frame consists of a set of unordered, sparse and irregular 3D points. Rather than adopting the sophisticated motion estimation strategy in video analysis, we propose a new spatio-temporal aggregation (STA) module to effectively extract, align and aggregate rich local geometric clues from consecutive frames at the feature level. By more reliably summarizing spatio-temporally consistent and complementary knowledge from multiple frames in the resultant local structural features, our method better infers the local geometry distributions at the current frame. In addition, our STA module can be readily incorporated with various existing single frame-based point upsampling methods (e.g., PU-Net, MPU, PU-GAN and PU-GCN). Comprehensive experiments on multiple point cloud sequence datasets demonstrate our video-based point cloud upsampling framework achieves substantial performance improvement over its single frame-based counterparts.
The catalytic conversion of biomass-derived chemicals to value added products is currently a topic of high importance, as it addresses the problems pertaining to both energy and the environment. In this regard, it is pertinent to design and develop catalysts using low cost and Earth abundant materials, which could perform these biomass conversion reactions in environment friendly green solvents. Keeping these aspects in mind, we have designed and developed a heterogeneous catalyst, sulfonated graphitic carbon nitride (S-GCN), which possesses amphoteric properties by having both Bronsted base and Bronsted acid sites. Subsequently, we have used this catalyst for the conversion of different biomass-derived saccharides (glucose, fructose, cellobiose, sucrose and starch) to a highly selective value added product, 5-hydroxymethylfurfural (5-HMF), which is a platform chemical for biodiesel and other fuels. All the reactions have been performed in green solvents, such as water, ethanol, isopropyl alcohol and dimethyl carbonate, and good yields have been obtained. The detailed optimization of the reaction conditions (temperature, time and catalyst amount) has also been performed, in addition to the calculation of green metric parameters. Furthermore, the synthesized 5-HMF can also be transformed to various other value added products, such as 2,5-bis(hydroxymethyl)furan, 5-(chloromethyl)furfural and 5-(bromomethyl)furfural. Moreover, the catalyst showed easy separation and good recyclability and also maintained structural integrity, which makes it a sustainable catalyst with high efficiency for the conversion of biomass-derived chemicals to value added products.
Identification of new drug-target interactions (DTIs) is an important but a time-consuming and costly step in drug discovery. In recent years, to mitigate these drawbacks, researchers have sought to identify DTIs using computational approaches. However, most existing methods construct drug networks and target networks separately, and then predict novel DTIs based on known associations between the drugs and targets without accounting for associations between drug-protein pairs (DPPs). To incorporate the associations between DPPs into DTI modeling, we built a DPP network based on multiple drugs and proteins in which DPPs are the nodes and the associations between DPPs are the edges of the network. We then propose a novel learning-based framework, 'graph convolutional network (GCN)-DTI', for DTI identification. The model first uses a graph convolutional network to learn the features for each DPP. Second, using the feature representation as an input, it uses a deep neural network to predict the final label. The results of our analysis show that the proposed framework outperforms some state-of-the-art approaches by a large margin.
Scene graph generation (SGG) is built on top of detected objects to predict object pairwise visual relations for describing the image content abstraction. Existing works have revealed that if the links between objects are given as prior knowledge, the performance of SGG is significantly improved. Inspired by this observation, in this article, we propose a relation regularized network (R2-Net), which can predict whether there is a relationship between two objects and encode this relation into object feature refinement and better SGG. Specifically, we first construct an affinity matrix among detected objects to represent the probability of a relationship between two objects. Graph convolution networks (GCNs) over this relation affinity matrix are then used as object encoders, producing relation-regularized representations of objects. With these relation-regularized features, our R2-Net can effectively refine object labels and generate scene graphs. Extensive experiments are conducted on the visual genome dataset for three SGG tasks (i.e., predicate classification, scene graph classification, and scene graph detection), demonstrating the effectiveness of our proposed method. Ablation studies also verify the key roles of our proposed components in performance improvement.
Expressway section speed can visually reflect the section operation condition, and accurate short time section speed prediction has a wide range of applications in path planning and traffic guidance. However, existing expressway speed prediction data have defects, such as sparse density and incomplete object challenges. Thus, this paper proposes a framework for a combined expressway traffic speed prediction model based on wavelet transform and spatial-temporal graph convolutional network (WSTGCN) of the Electronic Toll Collection (ETC) gantry transaction data. First, the framework pre-processes the ETC gantry transaction data to construct the section speeds. Then wavelet decomposition and single-branch reconstruction are performed on the section speed sequences, and the spatial features are captured by graph convolutional network (GCN) for each reconstructed single-branch sequence, and the temporal features are extracted by connecting the gated recurrent unit (GRU). The experiments use the ETC gantry transaction data of the expressway from Quanzhou to Xiamen. The results indicate that the WSTGCN model makes notable improvements compared to the model of the baseline for different prediction ranges.
Human activities embedded in crowdsourced data, such as social media trajectory, represent individual daily styles and patterns, which are valuable in many applications. However, the accurate identification of human activity types (HATs) from social media is challenging, possibly because interactions between posts and users at different time are overlooked. To fill this gap, we propose a novel model that introduces the interactions hidden in social media and synthesizes Graph Convolutional Network (GCN) for identifying HAT. The model first characterizes interactions among words, posts, dates, and users, and then derives a Time Gated Human Activity Graph Convolutional Network (TG-HAGCN) to predict the HATs of social media trajectory. To examine the proposed model performance, we built a new dataset including interactions between post content, post time, and users from the open Yelp dataset. Experimental results show that exploiting interactions hidden in social media to recognize HATs achieves state-of-the-art performance with high accuracy. The study indicates that interactions among social media promotes ability of machine learning on social media data mining and intelligent applications, and offers a reference solution for how to fuse multi-type heterogeneous data in social media.
Accurate subway passenger flow prediction is crucial to operation management and line scheduling. It can also promote the construction of intelligent transportation systems (ITS). Due to the complex spatial features and time-varying traffic patterns of subway networks, the prediction task is still challenging. Thus, a hybrid neural network model, GCTN (graph convolutional and comprehensive temporal neural network), is proposed. The model combines the Transformer network and long short-term memory (LSTM) network to capture the global and local temporal dependency. Besides, it uses a graph convolutional network (GCN) to capture the spatial features of the subway network. For the sake of the stability and accuracy for long-term passenger flow prediction, we enhance the influence of the station itself and the global station and combine the convolutional neural networks (CNN) and Transformer. The model is verified by the passenger flow data of the Shanghai Subway. Compared with some typical data-driven methods, the results show that the proposed model improves the prediction accuracy in different time intervals and exhibits superiority in prediction stability and robustness. Besides, the model has a better performance in the peak value and the period when passenger flow changes quickly.
Motivated by potential financial gain, companies may hire fraudster groups to write fake reviews to either demote competitors or promote their own businesses. Such groups are considerably more successful in misleading customers, as people are more likely to be influenced by the opinion of a large group. To detect such groups, a common model is to represent fraudster groups' static networks, consequently overlooking the longitudinal behavior of a reviewer, thus, the dynamics of coreview relations among reviewers in a group. Hence, these approaches are incapable of excluding outlier reviewers, which are fraudsters intentionally camouflaging themselves in a group and genuine reviewers happen to coreview in fraudster groups. To address this issue, we propose "FGDT", a framework for "fraudster group detection through temporal relations." FGDT first capitalizes on the effectiveness of the HIN-recurrent neural network (RNN) in both reviewers' representation learning while capturing the collaboration between reviewers. The HIN-RNN models the coreview relations of reviewers in a group in a fixed time window of 28 days. We refer to this as spatial relation learning representation to signify the generalizability of this work to other networked scenarios. Then, we use an RNN on the spatial relations to predict the spatio-temporal relations of reviewers in the group. In the third step, a graph convolution network (GCN) refines the reviewers' vector representations using these predicted relations. These refined representations are then used to remove outlier reviewers. The average of the remaining reviewers' representation is then fed to a simple fully connected layer to predict if the group is a fraudster group or not. Exhaustive experiments of FGDT showed a 5% (4%), 12% (5%), and 12% (5%) improvement over three of the most recent approaches on precision, recall, and F1-value over the Yelp (Amazon) dataset, respectively.
WRKY transcription factor (TF) is plant specific genes and play essential roles involved in biotic and abiotic stress tolerance. Gene co-expression network (GCN) analysis is effective tool for the interpretation of transcriptomic data. In this study, a co-expression network of 152 WRKY genes using publicly available microarray data (GSE78242) was constructed under low phosphate (Pi) treatment in soybean (Glycine max). A total of 149 nodes and 641 edges were obtained from CGN and seven seed genes were identified. Particularly, Glyma.19G094100 and Glyma.16G054400 seed genes (orthologue to Arabidopsis WRKY75) were found to have a direct connection to P deficiency. Promotor analyses of seed genes revealed the variations in the number of cis-regulatory elements (CREs) ranging from 80 to 137 with a total of 835 CREs. The methylation profile of Glyma.04G218700 (orthologue to Arabidopsis WRKY51) was found higher than other seed genes. As a result, our findings can be used as a scientific basis to cope with P deficiency in soybean as well as abiotic stress tolerance. In addition, these findings of this study may prove the crop improvement studies in future, especially genetically engineered soybean plants.
Ovarian cancer is one of the three most malignant tumors of the female reproductive system. At present, researchers do not know its pathogenesis, which makes the treatment effect unsatisfactory. Metabolomics is closely related to drug efficacy, safety evaluation, mechanism of action, and rational drug use. Therefore, identifying ovarian cancer-related metabolites could greatly help researchers understand the pathogenesis and develop treatment plans. However, the measurement of metabolites is inaccurate and greatly affects the environment, and biological experiment is time-consuming and costly. Therefore, researchers tend to use computational methods to identify disease-related metabolites in large scale. Since the hypothesis that similar diseases are related to similar metabolites is widely accepted, in this paper, we built both disease similarity network and metabolite similarity network and used graph convolutional network (GCN) to encode these networks. Then, support vector machine (SVM) was used to identify whether a metabolite is related to ovarian cancer. The experiment results show that the AUC and AUPR of our method are 0.92 and 0.81, respectively. Finally, we proposed an effective method to prioritize ovarian cancer-related metabolites in large scale.
In this study, the diatomite (DE) was firstly dispersed by the electron beam bombardment (EB) to form the modified diatomite (MDE), using as the carrier of the Fe doped carbon nitride (FGCN). The MDE/FGCN demonstrates broader light adsorption in the visible region and low recombination of photogenerated electron-hole, according to the results of spectroscopy techniques. Reduction of hexavalent chromium (Cr(VI)) in the aqueous solution was used to illustrate the photocatalytic ability of MDE/FGCN. Results showed that the MDE/FGCN-1:3 (Fe, 10%) composites with EB dose of 30 kGy exhibited stronger reduction efficiency with 98.3% of Cr(VI) in 100 min, which was almost 16.92 times higher than that of pure GCN for the reaction rate. Additionally, lower pH values could promote the Cr(VI) reduction, and the MDE/FGCN displayed great stability after four runs. Lastly, the electron and heat effects of EB were creatively used to analyze the dispersion mechanism of MDE. The higher photocatalytic ability of MDE/FGCN could be attributed not only the dispersion of MDE but also the charge trapping by Fe. This study will broaden the application of physical irradiation in the modification of carriers for the photocatalyst, which can be applied in the treatment of environmental pollutants.
Exploiting deep learning techniques for traffic flow prediction has become increasingly widespread. Most existing studies combine CNN or GCN with recurrent neural network to extract the spatio-temporal features in traffic networks. The traffic networks can be naturally modeled as graphs which are effective to capture the topology and spatial correlations among road links. The issue is that the traffic network is dynamic due to the continuous changing of the traffic environment. Compared with the static graph, the dynamic graph can better reflect the spatio-temporal features of the traffic network. However, in practical applications, due to the limited accuracy and timeliness of data, it is hard to generate graph structures through frequent statistical data. Therefore, it is necessary to design a method to overcome data defects in traffic flow prediction. In this paper, we propose a long-term traffic flow prediction method based on dynamic graphs. The traffic network is modeled by dynamic traffic flow probability graphs, and graph convolution is performed on the dynamic graphs to learn spatial features, which are then combined with LSTM units to learn temporal features. In particular, we further propose to use graph convolutional policy network based on reinforcement learning to generate dynamic graphs when the dynamic graphs are incomplete due to the data sparsity i sue. By testing our method on city-bike data in New York City, it demonstrates that our model can achieve stable and effective long-term predictions of traffic flow, and can reduce the impact of data defects on prediction results. (c) 2021 Elsevier Inc. All rights reserved.
Aiming at the sparsity of short text features, lack of context, and the inability of word embedding and external knowledge bases to supplement short text information, this paper proposes a text, word and POS tag-based graph convolutional network (TWPGCN) performs short text classification. This paper builds a T-W graph of text and words, a W-W graph of words and words, and a W-P graph of words and POS tags, and uses Graph Convolutional Network (GCN) to learn its feature and performs feature fusion. TWPGCN only focuses on the structural information of text graph, and does not require pre-training word embedding as initial node features, which improves classification accuracy, increases computational efficiency, and reduces computational difficulty. Experimental results show that TWPGCN outperforms state-of-the-art models on five publicly available benchmark datasets. The TWPGCN model is suitable for short text or ultra-short text, and the composition method in the model can also be extended to more fields.
Fluoroquinolone antibiotics attract increasing attention in the water treatment field because of the potential adverse effects on aquatic ecosystems and human health. The graphitic carbon nitride (g-C3N4) based photocatalysis has been demonstrated as an economically feasible and environmentally benign process to control these persistent contaminants. In this study, a new visible-light-driven of reduced graphene oxide (rGO) and nanoscale zero-valent iron (nZVI) co-modified g-C3N4-based photocatalyst was synthesized via ultrasonication-assisted chemisorption method. The optimized nZVI-loaded rGO/g-C3N4 (10% IGCN) showed a reaction rate enhancement of 2.12 similar to 3.69-fold and 1.20 similar to 1.68-fold for the degradation of ofloxacin (OFL), norfloxacin (NOR), and ciprofloxacin (CIP) compared to that of carbon-doped g-C3N4 (MCB0.07) and rGO-supported g-C3N4 (7.5% GCN) under the irradiation of simulated visible light, respectively. The enhanced photocatalytic activity can be ascribed to the synergistic effect of nZVI and rGO to improve the separation of charge carriers and boost the harvest of visible light. The degradation mechanisms were explored by scavenger tests and X-ray photoelectron spectroscopy (XPS), indicating that holes (h(+)) played a dominant role in the decomposition of OFL, NOR, and CIP. The piperazine ring and C-N between the piperazine ring and benzene were the primary attack sites of h(+). In addition, the ring-opening oxidation of benzene (C=C bond) connected by the C-F bond may also be an essential step. This study shed light on the degradation mechanism of OFL, NOR, and CIP under visible light irradiation of the 10% IGCN and provided theoretical support for the practical application of photocatalysis in treating antibiotics-containing water.
Motivation: The use of drug combinations, termed polypharmacy, is common to treat patients with complex diseases or co-existing conditions. However, a major consequence of polypharmacy is a much higher risk of adverse side effects for the patient. Polypharmacy side effects emerge because of drug-drug interactions, in which activity of one drug may change, favorably or unfavorably, if taken with another drug. The knowledge of drug interactions is often limited because these complex relationships are rare, and are usually not observed in relatively small clinical testing. Discovering polypharmacy side effects thus remains an important challenge with significant implications for patient mortality and morbidity. Results: Here, we present Decagon, an approach for modeling polypharmacy side effects. The approach constructs a multimodal graph of protein-protein interactions, drug-protein target interactions and the polypharmacy side effects, which are represented as drug-drug interactions, where each side effect is an edge of a different type. Decagon is developed specifically to handle such multimodal graphs with a large number of edge types. Our approach develops a new graph convolutional neural network for multirelational link prediction in multimodal networks. Unlike approaches limited to predicting simple drug-drug interaction values, Decagon can predict the exact side effect, if any, through which a given drug combination manifests clinically. Decagon accurately predicts polypharmacy side effects, outperforming baselines by up to 69%. We find that it automatically learns representations of side effects indicative of co-occurrence of polypharmacy in patients. Furthermore, Decagon models particularly well polypharmacy side effects that have a strong molecular basis, while on predominantly non-molecular side effects, it achieves good performance because of effective sharing of model parameters across edge types. Decagon opens up opportunities to use large pharmacogenomic and patient population data to flag and prioritize polypharmacy side effects for follow-up analysis via formal pharmacological studies.
Complex networks contain numerous unlabeled data. Extracting the information in these data and obtaining appropriate node representation poses a significant challenge. Recently, contrastive learning has gained wide acceptance as one of the most important methods in self -supervised learning. It has shown exceptional ability in capturing both the attribute and structural information in network, that provides a new way for network representation. In this paper, we propose the enhanced contrastive representation in network (ECRN). First, we recognize the issue that contrastive learning ignores the network structure in calculating the similarity of the joint distribution. To address the problem, ECRN proposes a feature combination method with additional structure information. Second, we retain the connection relationship of nodes in the low-dimensional embedding by constraining each layer of neural network. Third, we propose a new graph neural network framework, which independently compares each layer, and realizes hierarchical contrastive learning. ECRN obtains information-rich node representations by accumulating representations in each layer, enhancing the performance of downstream tasks. We tested the ECRN model on real datasets and compared its performance with well-known algorithms. Experiments show that the ECRN outperforms state-of-art methods in link prediction, clustering, and node classification tasks.
Bundle recommendation aims to recommend a bundle of items for a user to consume as a whole. Related work can be divided into two categories: 1) to recommend the platform's prebuilt bundles to users; 2) generate personalized bundles for users. In this work, we propose two graph neural network models, a BGCN model (short for Bundle Graph Convolutional Network) for prebuilt bundle recommendation, and a BGGN model (short for Bundle Graph Generation Network) for personalized bundle generation. First, BGCN unifies the user-item interaction, the user-bundle interaction and the bundle-item affiliation into a heterogeneous graph. With item nodes as the bridge, graph convolutional propagation between user and bundle nodes makes the learned representations capture the item-level semantics. Second, BGGN re-constructs bundles into graphs based on the item co-occurrence pattern and the user's supervision signal. The complex and high-order item-item relationships in the bundle graph are explicitly modeled through graph generation. Empirical results demonstrate the substantial performance gains of BGCN and BGGN, which outperforms the state-of-the-art baselines by 10.77% to 23.18% and 20.90% to 64.52%, respectively. We have released the datasets and codes at this link: https://github.com/cjx0525/BGCN.
Vertex classification is an important graph mining technique and has important applications in fields such as social recommendation and e-Commerce recommendation. Existing classification methods fail to make full use of the graph topology to improve the classification performance. To alleviate it, we propose a Dual Graph Wavelet neural Network composed of two identical graph wavelet neural networks sharing network parameters. These two networks are integrated with a semisupervised loss function and carry out supervised learning and unsupervised learning on two matrixes representing the graph topology extracted from the same graph dataset, respectively. One matrix embeds the local consistency information and the other the global consistency information. To reduce the computational complexity of the convolution operation of the graph wavelet neural network, we design an approximate scheme based on the first type Chebyshev polynomial. Experimental results show that the proposed network significantly outperforms the state-of-the-art approaches for vertex classification on all three benchmark datasets and the proposed approximation scheme is validated for datasets with low vertex average degree when the approximation order is small.
The mainstream object detectors usually treat each region separately, which overlooks the important global context information and the associations between object categories. Existing methods model global context via attention mechanism, which requires ad hoc design and prior knowledge. Some works combine CNN features with label dependencies learned from a pre-defined graph and word embeddings, which ignore the gap between visual features and textual corpus and are usually task-specific (depend on RoIPool/RoIAlign). In order to get rid of the previous specific settings, and enable different types of detectors to refine detection results with the help of prior knowledge, in this paper, we propose KROD (Knowledge-guided Reasonable Object Detection), which consists of the GKM (Global Category Knowledge Mining) module and CRM (Category Relationship Knowledge Mining) module, to improve detection performance by mimicking the processes of human reasoning. For a given image, GKM introduces global category knowledge into the detector by simply attaching a multi-label image classification branch to the backbone. Meanwhile, CRM input the raw detection outputs to the object category co-occurrence based knowledge graph to further refine the original results, with the help of GCN (Graph Convolutional Network). We also propose a novel loss-aware module to distinctively correct the classification probability of different detected boxes. Without bells and whistles, extensive experiments show that the proposed KROD can improve different baseline models (both anchor-based and anchor-free) by a large margin (1.2% similar to 1.8% higher AP) with marginal loss of efficiency on MS COCO.
Dynamic link prediction is a critical task in network research that seeks to predict future network links based on the relative behavior of prior network changes. However, most existing methods overlook mutual interactions between neighbors and long-distance interactions and lack the interpretability of the model's predictions. To tackle the above issues, in this paper, we propose a temporal group-aware graph diffusion network(TGGDN). First, we construct a group affinity matrix to describe mutual interactions between neighbors, i.e., group interactions. Then, we merge the group affinity matrix into the graph diffusion to form a group-aware graph diffusion, which simultaneously captures group interactions and long-distance interactions in dynamic networks. Additionally, we present a transformer block that models the temporal information of dynamic networks using self-attention, allowing the TGGDN to pay greater attention to task-related snapshots while also providing interpretability to better understand the network evolutionary patterns. We compare the proposed TGGDN with state-of-the-art methods on five different sizes of real-world datasets ranging from 1k to 20k nodes. Experimental results show that TGGDN achieves an average improvement of 8.3% and 3.8% in terms of ACC and AUC on all datasets, respectively, demonstrating the superiority of TGGDN in the dynamic link prediction task.
Transcatheter aortic valve replacement (TAVR) has recently emerged as an effective treatment for patients with severe symptomatic aortic stenosis. Accurate prediction of postoperative conduction disturbance after TAVR is crucial for successful surgery planning. Most current risk prediction models for conduction disturbance rely on monomodal data methods, such as images. However, predicting conduction disturbance based on multimodal features becomes a challenge. We propose a new memory-augmented graph neural network (MemGCN) to deal with this challenge. The GCN in the proposed network is constructed by taking the patient's image features as nodes' features and creating the edges based on the patient's clinical features, thus effectively fusing the patients' images and clinical feature information. Moreover, the traditional GCN model trains feature extractors and GCNs independently due to limited computing resources, which can negatively impact the feature learning process. We introduce the memory bank and propose a local update learning algorithm to address this issue. Specifically, the proposed method connects the feature extractors and GCN through a memory bank. The CNN module extracts patients' features from their ECG images and updates the memory bank. The GCN constructs the graph using the patients' characteristics in the memory bank as node features. In this way, the node features are cached in the memory bank and gradually updated at each optimization iteration so that the feature extractors and GCN are optimized jointly. The experiments on a real-world TAVR dataset show the proposed method's superior performance. It improves the prediction accuracy by over 4% compared to the traditional GCN model. Furthermore, to demonstrate the applicability of our proposed method to other multimodal data analysis tasks, we evaluate the performance of the proposed method on an ocular disease intelligent recognition benchmark. The proposed method achieves competitive prediction performance.
Graph attention network (GAT) is a promising framework for message passing on graphs, but how to exploit rich, high-order structural information in the attention mechanism is still an open challenge. Furthermore, increasing the attention range to more than one-hop neighbors can negatively affect the performance of GAT, reflecting the over-smoothing risk of graph neural networks in general. In this paper, we propose an "adaptive structural fingerprint" model to fully exploit complex graph topology in graph attention networks. The key idea is to contextualize each node with its "structural fingerprint" that can automatically adjust to the local graph topology and edge connections in the neighborhood of the node. By doing this, structural interactions between the nodes can be evaluated more accurately and better confined to relevant neighbors, thus contributing to an improved attention mechanism and clearer cluster boundary. Furthermore, our approach provides a useful platform for different subspace of node features and various spatial scale of graph structures to "cross-talk" with each other through multi-head attention, which is more flexible than existing attention mechanism using a fixed, minimal spatial attention scale. Encouraging results are observed on a number of benchmark data sets including citation and social networks. (C) 2022 Published by Elsevier B.V.
Most of knowledge graph completion (KGC) models are designed for static KGs where entity and relation sets are fixed. These approaches are inherently transductive because they simply predict the plausibility of facts whose entities and relations had to previously appear in the training phase. However, since entities and relations are constantly added, removed, or changed over time, KGC models should be able to generalize to out-of-KG entities and relations in evolving KGs, which are more suited to real-world scenarios. Moreover, incorporating global graph-structured information into KGC models is another challenging issue. To overcome these issues, this paper proposes a novel Inductive KG Embedding (IKGE) model for open-world KGC, which accommodates out-of-KG entities and relations. Unlike training individual unique embeddings, the proposed model fundamentally learns an embedding generator function to elaborately generate fact embeddings in an inductive manner. Specifically, the feature information of each fact is extracted as a vector from its entity-related and relation-related side information via an attention mechanism. Then, to score a given fact, our neighborhood feature aggregator hierarchically accumulates the feature information of multi-hop neighbors. Experimental results show that IKGE outperforms existing approaches in both transductive and inductive setups by successfully aggregating neighborhood features.(c) 2021 Elsevier Inc. All rights reserved.
Accurate forecasting of traffic flows remains a significant challenge owing to its complex spatiotemporal dependencies. Although existing methods capture some spatiotemporal dependencies and stack them in a channel dimension, long-range sequences, implicit patterns, hidden fine-grained features and multi-scaled spatiotemporal dependencies are often ignored, which makes it difficult to represent the spatiotemporal dependencies comprehensively. To overcome these limitations, a novel deep learning model named Graph Spatiotemporal Channel Unet (U-shaped network) is proposed to achieve accurate and reliable traffic flow forecasting. First, a new temporal encoder-decoder module with causal convolution and transposed convolution is proposed, which can efficiently alleviate the gradient explosion/vanishing in capturing long-range sequences during encoding and decoding. Secondly, a new channel self-attention mechanism is proposed, which can efficiently capture the implicit patterns and hidden fine-grained features between channels and enhance the representation ability of the spatiotemporal dependencies. Thirdly, a new U-shaped multi-scaled spatiotemporal graph convolutional network is proposed to effectively capture the multi-scaled spatiotemporal dependencies. Experiments on two real-world datasets show that the proposed model outperforms baseline models and achieves accurate traffic flow forecasting.
Graph neural networks have revealed powerful potential in ranking recommendation. Existing methods based on bipartite graphs for ranking recommendation mainly focus on homogeneous graphs and usually treat user and item nodes as the same kind of nodes, however, the user-item bipartite graph is always heterogeneous. Additionally, various types of nodes have varying effects on recommendations, and a good node representation can be learned by successfully differentiating the same type of nodes. In this paper, we develop a nodepersonalized multi -graph convolutional network (NP-MGCN) for ranking recommendation. It consists of a node importance awareness block, a graph construction module, and a node information propagation and aggregation framework. Specifically, a node importance awareness block is proposed to encode nodes using node degree information to highlight the differences between nodes. Subsequently, the Jaccard similarity and co -occurrence matrix fusion graph construction module is devised to acquire user-user and item-item graphs, enriching correlation information between users and between items. Finally, a composite hop node information propagation and aggregation framework, including single -hop and double -hop branches, is designed. The high -order connectivity is used to aggregate heterogeneous information for the single -hop branch, while the multi -hop dependency is utilized to aggregate homogeneous information for the double -hop branch. It makes user and item node embedding more discriminative and integrates the different nodes' heterogeneity into the model. Experiments on several datasets manifest that NP-MGCN achieves outstanding recommendation performance than existing methods.
Worldwide manufacturing industries are significantly affected by COVID-19 pandemic because of their production characteristics with low-cost country sourcing, globalization, and inventory level. To analyze the correlated time series, spatial-temporal model becomes more attractive, and the graph convolution network (GCN) is also commonly used to provide more information to the nodes and its neighbors in the graph. Recently, attention-adjusted graph spatio-temporal network (AGSTN) was proposed to address the problem of pre-defined graph in GCN by combining multi-graph convolution and attention adjustment to learn spatial and temporal correlations over time. However, AGSTN may show potential problem with limited small non-sensor data; particularly, convergence issue. This study proposes several variants of AGSTN and applies them to non-sensor data. We suggest data augmentation and regularization techniques such as edge selection, time series decomposition, prevention policies to improve AGSTN. An empirical study of worldwide manufacturing industries in pandemic era was conducted to validate the proposed variants. The results show that the proposed variants significantly improve the prediction performance at least around 20% on mean squared error (MSE) and convergence problem.
Previous studies have shown that incorporating sentiment knowledge (e.g., sentiment scores) is effective for aspect-based sentiment analysis (ABSA). However, sentiment knowledge is used to create static features, which cannot be propagated over an entire corpus. Unlike previous researchers, we designed a corpus-level sentiment knowledge fusion mechanism with storage, update, and sharing functions, which can help the model to better understand the sentiment information of various opinion words in the dataset. Specifically, we first constructed a dependency graph for each sentence and refined the weights of the edges by the relative distance between the aspect terms and context words. We then introduced two special sentiment knowledge nodes in the graph to establish connections with opinion words by leveraging external sentiment lexicons. We set these two nodes to be globally shared and updatable, which allowed the model to learn corpus-level and domain-specific sentiment knowledge. This knowledge can help the model to generate a better aspect representation that contains rich contextual information and sentiment knowledge. Extensive experiments were conducted on several public datasets, and the experimental results demonstrated the effectiveness of our method. We also analyzed the performance gains from using learned corpus-level sentiment knowledge to transfer across different datasets.
Predicting information diffusion helps grasp the overall preference of user interactions, facilitating applications such as public opinion analysis and online marketing. Existing approaches sample the information cascade network into several independent paths or subgraphs to learn cascade representations, resulting in information loss regarding the social influence of nodes and dynamics between cascades across different temporal stages. To address such problems, we design a deep learning-based model (named I3T) using Inter-and Intra-Path of Influence Transitivity to predict the incremental popularity of information diffusion in information networks. First, we leverage a graph neural network (GNN) to aggregate the node information of the local neighbors. Then, we sample the information cascade into a group of sequences using DeepWalk and update the node embedding with GNN and DeepWalk simultaneously, which embodies both the inter-path and intra-path of influence transitivity. Next, we exploit bi-directional long short-term memory (Bi-LSTM) to extract structural features and apply gated recurrent unit (GRU) to extract temporal features. Finally, we learn the structural factor weight under the temporal guidance of the attention mechanism. The results of comprehensive experiments conducted on two representative datasets demonstrate the preeminence of I3T over existing state-of-the-art approaches.
Visual relational reasoning is a central component in recent cross-modal analysis tasks, which aims at reasoning about the visual relationships between objects and their properties. These relationships provide rich semantics and help to enhance the visual representation for improving cross-modal learning. Previous works have succeeded in modeling latent visual relationships or rigid-categorized visual relationships. However, these kinds of methods leave out the problem of ambiguity inherent in the visual relationships because of the diverse relational semantics of different visual appearances. In this work, we explore to model the visual relationships by context-aware representations based on human prior knowledge. Based on such representations, we novelly propose a plug-and-play visual relational reasoning module to enhance image encoding. Specifically, we design an Anisotropic Graph Convolution to utilize the information of relation embeddings and relation directionality between objects for generating relation-aware image representations. We demonstrate the effectiveness of the relational reasoning module by applying it to both Visual Question Answering (VQA) and Cross-Modal Information Retrieval (CMIR) tasks. Extensive experiments are conducted on VQA 2.0 and CMPlaces datasets and superior performance is reported when comparing with state-of-the-art works. (C) 2020 Published by Elsevier B.V.
The problem of detecting key nodes in a network (i.e. nodes with the greatest ability to spread an infection) has been studied extensively in the past. Some approaches to key node detection compute node centrality, but there is no formal proof that central nodes also have the greatest spreading capacity. Other methods use epidemiological models (e.g., the SIR model) to describe the spread of an infection and rely on numerical simulations to find out key nodes; these methods are highly accurate but computationally expensive. To efficiently but accurately detect key nodes, we propose a novel deep learning method called Rank by Graph Convolutional Network, RGCN. Our method constructs a subnetwork around each node to estimate its spreading power; then RGCN applies a graph convolutional network to each subnetwork and the adjacency matrix of the network to learn node embeddings. Finally, a neural network is applied to the node embeddings to detect key nodes. Our RGCN method outperforms state-of-the-art approaches such as RCNN and MRCNN by 11.84% and 13.99%, respectively, when we compare the Kendall's s coefficient between the node ranking produced by each method with the true ranking obtained by SIR simulations.(c) 2023 The Author(s). Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
The rapidly growing information technologies such as cloud computing, edge computing, artificial intelligence offer cutting-edge technical means for virtual reality of industrial manufacturing process. An efficient and accurate method for situation awareness (SA) to monitor the process of marginal layer plays an essential role to enhance the safety of industrial equipment. In this study, a manufacturing life cycle is described and characterized as operation and remote controlling of industrial machineries. The edge servers are first employed to track physical devices. Then a novel unified adaptive deep classification framework for SA with semi-supervised classification method is developed to find unknown patterns in a huge amount of industrial data. Furthermore, a robust model based on the selection of adaptive local neighbor is proposed to find out an optimal weight and high similarity of neighbors. The combination of the proposed framework and model can realize real-time SA of modern manufacturing the execution system. Plentiful experiments have been conducted to demonstrate the high accuracy and reliability of the proposed framework.
Motor disorder is a typical symptom of Parkinson's disease (PD). Neurologists assess the severity of PD motor symptoms using the clinical rating scale, i.e., MDS-UPDRS. However, this assessment method is time-consuming and easily affected by the perception difference of assessors. In the recent outbreak of coronavirus disease 2019, telemedicine for PD has become extremely urgent for clinical practice. To solve these problems, we developed an automated and objective assessment method of the leg agility task in the MDS-UPDRS using videos and a graph neural network. In this study, a sparse adaptive graph convolutional network (SA-GCN) was proposed to achieve fine-grained quantitative assessment of skeleton sequences extracted from videos. Specifically, the sparse adaptive graph convolutional unit with a prior knowledge constraint was proposed to perform adaptive spatial modeling of physical and logical dependency for skeleton sequences, thus achieving the sparse modeling of the discriminative spatial relationships. Subsequently, a temporal context module was introduced to construct the remote context dependency in the temporal dimension, hence determining the global changes of the task. A multi-domain attention learning module was also developed to integrate the static spatial features and dynamic temporal features, and then to emphasize the salient feature selection in the channel domain, thereby capturing the multi-domain fine-grained information. Finally, the evaluation results using a dataset with 148 patients and 870 samples confirmed the effectiveness and reliability of our scheme, and the method outperformed other related state-of-the-art methods. Our contactless method provides a new potential tool for automated PD assessment and telemedicine.
Identifying protein complexes is an important issue in computational biology, as it benefits the understanding of cellular functions and the design of drugs. In the past decades, many computational methods have been proposed by mining dense subgraphs in Protein-Protein Interaction Networks (PINs). However, the high rate of false positive/negative interactions in PINs prevents accurately detecting complexes directly from the raw PINs. In this paper, we propose a denoising approach for protein complex detection by using variational graph auto-encoder. First, we embed a PIN to vector space by a stacked graph convolutional network (GCN), then decide which interactions in the PIN are credible. If the probability of an interaction being credible is less than a threshold, we delete the interaction. In such a way, we reconstruct a reliable PIN. Following that, we detect protein complexes in the reconstructed PIN by using several typical detection methods, including CPM, Coach, DPClus, GraphEntropy, IPCA and MCODE, and compare the results with those obtained directly from the original PIN. We conduct the empirical evaluation on four yeast PPI datasets (Gavin, Krogan, DIP and Wiphi) and two human PPI datasets (Reactome and Reactomekb), against two yeast complex benchmarks (CYC2008 and MIPS) and three human complex benchmarks (REACT, REACT uniprotkb and CORE COMPLEX human), respectively. Experimental results show that with the reconstructed PINs obtained by our denoising approach, complex detection performance can get obviously boosted, in most cases by over 5%, sometimes even by 200%. Furthermore, we compare our approach with two existing denoising methods (RWS and RedNemo) while varying different matching rates on separate complex distributions. Our results show that in most cases (over 2/3), the proposed approach outperforms the existing methods.
Graphs and networks are very common data structure for modelling complex systems that are composed of a number of nodes and topologies, such as social networks, citation networks, biological protein-protein interactions networks, etc. In recent years, machine learning has become an efficient technique to obtain representation of graph for downstream graph analysis tasks, including node classification, link prediction, and community detection. Different with traditional graph analytical models, the representation learning on graph tries to learn low dimensional embeddings by means of machine learning models that could be trained in supervised, unsupervised or semi-supervised manners. Compared with traditional approaches that directly use input node attributes, these embeddings are much more informative and helpful for graph analysis. There are a number of developed models in this respect, that are different in the ways of measuring similarity of vertexes in both original space and feature space. In order to learn more efficient node representation with better generalization property, we propose a task-independent graph representation model, called as graph deconvolutional network (GDN), and corresponding unsupervised learning algorithm in this paper. Different with graph convolution network (GCN) from the scratch, which produces embeddings by convolving input attribute vectors with learned filters, the embeddings of the proposed GDN model are desired to be convolved with filters so that reconstruct the input node attribute vectors as far as possible. The embeddings and filters are alternatively optimized in the learning procedure. The correctness of the proposed GDN model is verified by multiple tasks over several datasets. The experimental results show that the GDN model outperforms existing alternatives with a big margin. (C) 2020 Elsevier Inc. All rights reserved.
Photocatalytic activity of low band gap semiconductor largely restrained by high recombination rate of photogenerated charge carriers. To enhance the catalytic performance numerous protocols were adopted amongst which designing of novel hybrid via coupling of semiconductors are very intriguing from modest application point of view. Here, we report facile realization of type II heterojunctions embracing polymeric graphitic carbon nitride (g-C3N4/GCN) and all-inorganic cesium lead halide perovskite (CsPbBrCl2) for degradation complex organic effluents under visible-light illumination. Synthesized hybrid presented much improved performance in toxic cationic and anionic dyes degradation as compared to individual building units. Signature of favorable staggered gap junction's formation at interface was confirmed via Mott-Schottky analysis. Such kind of junctions delay the recombination of photogenerated electron holes and facilitates active radical generation at catalyst surface thereby ensures improved photocatalytic performance. Charge transfer process in heterojunction further illustrated via Density functional theory (DFT) based calculations. Several scavenger tests have been performed to examine the impact of different active radicals in the photocatalysis which suggests manifold performance improvement in the presence of very small concentrations of EDTA. A plausible photocatalytic mechanism in accordance with the type II junction has been proposed.
Electroencephalography (EEG)-based emotion computing has become one of the research hotspots of human-computer interaction (HCI). However, it is difficult to effectively learn the interactions between brain regions in emotional states by using traditional convolutional neural networks because there is information transmission between neurons, which constitutes the brain network structure. In this paper, we proposed a novel model combining graph convolutional network and convolutional neural network, namely MDGCN-SRCNN, aiming to fully extract features of channel connectivity in different receptive fields and deep layer abstract features to distinguish different emotions. Particularly, we add style-based recalibration module to CNN to extract deep layer features, which can better select features that are highly related to emotion. We conducted two individual experiments on SEED data set and SEED-IV data set, respectively, and the experiments proved the effectiveness of MDGCN-SRCNN model. The recognition accuracy on SEED and SEED-IV is 95.08 and 85.52%, respectively. Our model has better performance than other state-of-art methods. In addition, by visualizing the distribution of different layers features, we prove that the combination of shallow layer and deep layer features can effectively improve the recognition performance. Finally, we verified the important brain regions and the connection relationships between channels for emotion generation by analyzing the connection weights between channels after model learning.
Introduction The clinical syndrome of neonatal sepsis, comprising signs of infection, septic shock and organ dysfunction in infants <= 4weeks of age, is a frequent sequel to bloodstream infection and mandates urgent antimicrobial therapy. Bacterial characterisation and antimicrobial susceptibility testing is vital for ensuring appropriate therapy, as high rates of antimicrobial resistance (AMR), especially in low-income and middle income countries, may adversely affect outcome. Ho Chi Minh City (HCMC) in Vietnam is a rapidly expanding city in Southeast Asia with a current population of almost 8 million. There are limited contemporary data on the causes of neonatal sepsis in Vietnam, and we hypothesise that the emergence of multidrug resistant bacteria is an increasing problem for the appropriate management of sepsis cases. In this study, we aim to investigate the major causes of neonatal sepsis and assess disease outcomes by clinical features, antimicrobial susceptibility profiles and genome composition. Method and analysis We will conduct a prospective observational study to characterise the clinical and microbiological features of neonatal sepsis in a major children's hospital in HCMC. All bacteria isolated from blood subjected to whole genome sequencing. We will compare clinical variables and outcomes between different bacterial species, genome Gomposition and AMR gene content. AMR gene content will be assessed and stratified by species, years and contributing hospital departments. Genome sequences will be analysed to investigate phylogenetic relationships. Ethics and dissemination The study will be conducted in accordance with the principles of the Declaration of Helsinki and the International Council on Harmonization Guidelines for Good Clinical Practice. EthiGs approval has been provided by the Oxford Tropical Research Ethics Committee 35-16 and Vietnam Children's Hospital 1 Ethics Committee 73/GCN/BVND1. The findings will be disseminated at international conferences and peer reviewed journals.
Cancer has become one of the critical diseases threatening human life and health. The sensitivity difference of cancer drugs has always been a critical cause of the treatment come to nothing. Once drug resistance occurs, it will make the anticancer treatment or even various drugs ineffective. With the deepening of cancer research, a growing number of evidence shows that microRNA has a particular regulatory effect on the sensitivity of cancer drugs, which provides new research ideas. However, using traditional biological experiments to verify and discover the relations of microRNA-drug sensitivity is cumbersome and time-consuming, significantly slowing down cancer drug sensitivity's research progress. Therefore, this paper proposes a computational method (PDSM-LGCN) that spreads information through the high-order connection between cancer drug sensitivity and microRNA. At the same time, the model constructs an optimized-GCN as an embedding propagation layer to obtain the practical embeddings of microRNA and medicines. Finally, based on a collaborative filtering algorithm, the model brings the prediction score between microRNA and drug sensitivity. The results of fivefold cross-validation show that the AUC of PDSM-LGCN is 0.8872, and the AUPR is as high as 0.9026. At the same time, we also reproduced the five latest models of similar problems and compared the results. Our model has the best comprehensive effect among them. In addition, the reliability of PDSM-LGCN was further confirmed through the case study of Cisplatin and Doxorubicin, which can be used as a powerful tool for clinical and biological research.
Recently, many pre-trained text embedding models have been applied to effectively extract latent features from texts and achieve remarkable performance in various downstream tasks of sentiment analysis domain. However, these pre-trained text embedding models also encounter limitations related to the capability preserving the syntactical structure as well as the global long-range dependent relationships of words. Thus, they might fail to recognize the relevant syntactical features of words as valuable evidences for analyzing sentiment aspects. To overcome these limitations, we proposed a novel deep semantic contextual embedding technique for sentiment analysis, called as: SE4SA. Our proposed SE4SA is a multi-level text embedding model which enables to jointly exploit the long-range syntactical and sequential representations of texts. Then, these achieved rich semantic textual representations can support to have a better understanding on the sentiment aspects of the given text corpus, thereby resulting the better performance on sentiment analysis task. Extensive experiments in several benchmark datasets demonstrate the effectiveness or our proposed SE4SA model in comparing with recent state-of-the-art model.
Emerging graph neural networks (GNNs) have extended the successes of deep learning techniques against datasets like images and texts to more complex graph-structured data. By leveraging GPU accelerators, existing frameworks combine mini-batch and sampling for effective and efficient model training on large graphs. However, this setup faces a scalability issue since loading rich vertex features from CPU to GPU through a limited bandwidth link usually dominates the training cycle. In this article, we propose PaGraph, a novel, efficient data loader that supports general and efficient sampling-based GNN training on single-server with multi-GPU. PaGraph significantly reduces the data loading time by exploiting available GPU resources to keep frequently-accessed graph data with a cache. It also embodies a lightweight yet effective caching policy that takes into account graph structural information and data access patterns of sampling-based GNN training simultaneously. Furthermore, to scale out on multiple GPUs, PaGraph develops a fast GNN-computation-aware partition algorithm to avoid cross-partition access during data-parallel training and achieves better cache efficiency. Finally, it overlaps data loading and GNN computation for further hiding loading costs. Evaluations on two representative GNN models, GCN and GraphSAGE, using two sampling methods, Neighbor and Layer-wise, show that PaGraph could eliminate the data loading time from the GNN training pipeline, and achieve up to 4.8x performance speedup over the state-of-the-art baselines. Together with preprocessing optimization, PaGraph further delivers up to 16.0x end-to-end speedup.
Background: Accurate detection of bleeding events from electronic health records (EHRs) is crucial for identifying and characterizing different common and serious medical problems. To extract such information from EHRs, it is essential to identify the relations between bleeding events and related clinical entities (eg, bleeding anatomic sites and lab tests). With the advent of natural language processing (NLP) and deep learning (DL)-based techniques, many studies have focused on their applicability for various clinical applications. However, no prior work has utilized DL to extract relations between bleeding events and relevant entities. Objective: In this study, we aimed to evaluate multiple DL systems on a novel EHR data set for bleeding event-related relation classification. Methods: We first expert annotated a new data set of 1046 deidentified EHR notes for bleeding events and their attributes. On this data set, we evaluated three state-of-the-art DL architectures for the bleeding event relation classification task, namely, convolutional neural network (CNN), attention-guided graph convolutional network (AGGCN), and Bidirectional Encoder Representations from Transformers (BERT). We used three BERT-based models, namely, BERT pretrained on biomedical data (BioBERT), BioBERT pretrained on clinical text (Bio+Clinical BERT), and BioBERT pretrained on EHR notes (EhrBERT). Results: Our experiments showed that the BERT-based models significantly outperformed the CNN and AGGCN models. Specifically, BioBERT achieved a macro F1 score of 0.842, outperforming both the AGGCN (macro F1 score, 0.828) and CNN models (macro F1 score, 0.763) by 1.4% (P<.001) and 7.9% (P<.001), respectively. Conclusions: In this comprehensive study, we explored and compared different DL systems to classify relations between bleeding events and other medical concepts. On our corpus, BERT-based models outperformed other DL models for identifying the relations of bleeding-related entities. In addition to pretrained contextualized word representation, BERT-based models benefited from the use of target entity representation over traditional sequence representation
Collaborative filtering approach greatly promotes the development and application of personalized recommendation. In location-based social networks (LBSNs), the sparsity of check-in data is one of the main obstacles for traditional Point-of-Interest (POI) recommendation models. Graph convolutional network (GCN) is an efficient tool to overcome this kind of problems, which enhances the representational ability of embeddings by capture high-order connectivity of users and POIs. In real applications, social tie is a crucial factor for POI recommendation that ignored in most current graph-based methods. Moreover, most message aggregation functions fail to capture contextual information. To address these problems, a novel framework named Friends-aware Graph Collaborative Filtering (FG-CF) is proposed in this paper, which incorporates social information into a user-POI graph. Firstly, a user-POI correlation matrix is estimated by check-in data and social links, and then, user embedding is updated according to the user-POI correlation matrix. Secondly, interaction messages are constructed in a novel way by integrating nodes' ego embeddings, neighbors' embeddings and social embeddings. Thirdly, by aggregating previous state embeddings and non-linear combination of neighbor messages with interaction messages, a new message aggregation function is present to update user and POI embeddings. Fourthly, we concatenate embeddings from each additional interaction layer to get the final embeddings, and inner product is used to compute the preference score of a user to a targeted POI. Finally, extensive experiments on two largescale LBSN datasets demonstrate the superiority of our model over several state-of-the-art approaches.(c) 2022 Elsevier B.V. All rights reserved.
COVID-19 has become a matter of serious concern over the last few years. It has adversely affected numerous people around the globe and has led to the loss of billions of dollars of business capital. In this paper, we propose a novel Spatial-Temporal Synchronous Graph Transformer network (STSGT) to capture the complex spatial and temporal dependency of the COVID-19 time series data and forecast the future status of an evolving pandemic. The layers of STSGT combine the graph convolution network (GCN) with the self-attention mechanism of transformers on a synchronous spatial-temporal graph to capture the dynamically changing pattern of the COVID time series. The spatial-temporal synchronous graph simultaneously captures the spatial and temporal dependencies between the vertices of the graph at a given and subsequent time-steps, which helps capture the heterogeneity in the time series and improve the forecasting accuracy. Our extensive experiments on two publicly available real-world COVID-19 time series datasets demonstrate that STSGT significantly outperforms state-of-the-art algorithms that were designed for spatial-temporal forecasting tasks. Specifically, on average over a 12-day horizon, we observe a potential improvement of 12.19% and 3.42% in Mean Absolute Error (MAE) over the next best algorithm while forecasting the daily infected and death cases respectively for the 50 states of US and Washington, D.C. Additionally, STSGT also outperformed others when forecasting the daily infected cases at the state level, e.g., for all the counties in the State of Michigan. The code and models are publicly available at https://github.com/soumbane/STSGT.
Simple Summary The traditional process of drug development is lengthy, time-consuming, and costly, whereas very few drugs ever make it to the clinic. The use of computational methods to detect drug side effects greatly reduces the deficiencies in drug clinical trials. Prediction of drug-target interactions is a key step in drug discovery and repositioning. In this article, we proposed a novel method for the prediction of drug-target interactions based on large-scale graph representation learning. This method can be helpful to researchers in clinical trials and drug research and development. Identification of drug-target interactions (DTIs) is a significant step in the drug discovery or repositioning process. Compared with the time-consuming and labor-intensive in vivo experimental methods, the computational models can provide high-quality DTI candidates in an instant. In this study, we propose a novel method called LGDTI to predict DTIs based on large-scale graph representation learning. LGDTI can capture the local and global structural information of the graph. Specifically, the first-order neighbor information of nodes can be aggregated by the graph convolutional network (GCN); on the other hand, the high-order neighbor information of nodes can be learned by the graph embedding method called DeepWalk. Finally, the two kinds of feature are fed into the random forest classifier to train and predict potential DTIs. The results show that our method obtained area under the receiver operating characteristic curve (AUROC) of 0.9455 and area under the precision-recall curve (AUPR) of 0.9491 under 5-fold cross-validation. Moreover, we compare the presented method with some existing state-of-the-art methods. These results imply that LGDTI can efficiently and robustly capture undiscovered DTIs. Moreover, the proposed model is expected to bring new inspiration and provide novel perspectives to relevant researchers.
Context: Most defect prediction methods consider a series of traditional manually designed static code metrics. However, only using these hand-crafted features is impractical. Some researchers use the Convolutional Neural Network (CNN) to capture the potential semantic information based on the program's Syntax Trees (ASTs). In recent years, leveraging the dependency relationships between software modules to construct a software network and using network embedding models to capture the structural information have been helpful in defect prediction. This paper simultaneously takes the semantic and structural information into account and proposes a method called CGCN. Objective: This study aims to validate the feasibility and performance of the proposed method in software defect prediction. Method: Abstract Syntax Trees and a Class Dependency Network (CDN) are first generated based on the source code. For ASTs, symbolic tokens are extracted and encoded into vectors. The numerical vectors are then used as input to the CNN to capture the semantic information. For CDN, a Graph Convolutional Network (GCN) is used to learn the structural information of the network automatically. Afterward, the learned semantic and structural information are combined with different weights. Finally, we concatenate the learned features with traditional hand-crafted features to train a classifier for more accurate defect prediction. Results: The proposed method outperforms the state-of-the-art defect prediction models for both within-project prediction (including within-version and cross-version) and cross-project prediction on 21 open-source projects. In general, within-version prediction achieves better performance in the three prediction tasks.Conclusion: The proposed method of combining semantic and structural information can improve the performance of software defect prediction.
Zero-shot action recognition can recognize samples of unseen classes that are unavailable in training by exploring common latent semantic representation in samples. However, most methods neglected the connotative relation and extensional relation between the action classes, which leads to the poor generalization ability of the zero-shot learning. Furthermore, the learned classifier inclines to predict the samples of seen class, which leads to poor classification performance. To solve the above problems, we propose a two-stage deep neural network for zero-shot action recognition, which consists of a feature generation sub-network serving as the sampling stage and a graph attention sub-network serving as the classification stage. In the sampling stage, we utilize generative adversarial networks (GAN) trained by action features and word vectors of seen classes to synthesize the action features of unseen classes, which can balance the training sample data of seen classes and unseen classes. In the classification stage, we construct a knowledge graph (KG) based on the relationship between word vectors of action classes and related objects, and propose a graph convolution network (GCN) based on attention mechanism, which dynamically updates the relationship between action classes and objects, and enhances the generalization ability of zero-shot learning. In both stages, we all use word vectors as bridges for feature generation and classifier generalization from seen classes to unseen classes. We compare our method with state-of-theart methods on UCF101 and HMDB51 datasets. Experimental results show that our proposed method improves the classification performance of the trained classifier and achieves higher accuracy. (c) 2022 Elsevier Ltd. All rights reserved.
BACKGROUND: Eukaryotic initiation factor 2B (eIF2B) initiates and regulates translation initiation in eukaryotes. eIF2B gene mutations cause leukoencephalopathy called vanishing white matter disease (VWM) in humans and slow growth (Slg-) and general control derepression (Gcd-) phenotypes in Saccharomyces cerevisiae. RESULTS: To suppress eIF2B mutations, S. cerevisiae genomic DNA library was constructed in high-copy vector (YEp24) and transformed into eIF2B mutant S. cerevisiae strains. The library was screened for wild-type genes rescuing S. cerevisiae (Slg-) and (Gcd-) phenotypes. A genomic clone, Suppressor-I (Sup-I), rescued S. cerevisiae Slg- and Gcd- phenotypes (gcd7-201 gcn2∆). The YEp24/Sup-I construct contained truncated TAN1, full length EMC4, full length YGL230C, and truncated SAP4 genes. Full length EMC4 (chaperone protein) gene was sub-cloned into pEG (KG) yeast expression vector and overexpressed in gcd7-201 gcn2∆ strain which suppressed the Slg- and Gcd- phenotype. A GST-Emc4 fusion protein of 47kDa was detected by western blotting using alpha-GST antibodies. Suppression was specific to gcd7-201 gcn2∆ mutation in eIF2Bbeta and Gcd1-502 gcn2∆ in eIF2Bgamma subunit. Emc4p overexpression also protected the wild type and mutant (gcd7-201 gcn2∆, GCD7 gcn2∆, and GCD7 GCN2∆) strains from H2O2, ethanol, and caffeine stress. CONCLUSIONS: Our results suggest that Emc4p is involved in eIF2B-mediated translational regulation under stress and could provide an amenable tool to understand the eIF2B-mediated defects.
Natural product biosynthetic pathways are replete with enzymes repurposed for new catalytic functions. In some modular polyketide synthase (PKS) pathways, a GCN5-related N-acetyltransferase (GNAT)-like enzyme with an additional decarboxylation function initiates biosynthesis. Here, we probe two PKS GNAT-like domains for the dual activities of S-acyl transfer from coenzyme A (CoA) to an acyl carrier protein (ACP) and decarboxylation. The GphF and CurA GNAT-like domains selectively decarboxylate substrates that yield the anticipated pathway starter units. The GphF enzyme lacks detectable acyl transfer activity, and a crystal structure with an isobutyryl-CoA product analog reveals a partially occluded acyltransfer acceptor site. Further analysis indicates that the CurA GNAT-like domain also catalyzes only decarboxylation, and the initial acyl transfer is catalyzed by an unidentified enzyme. Thus, PKS GNAT-like domains are re-classified as GNAT-like decarboxylases. Two other decarboxylases, malonyl-CoA decarboxylase and EryM, reside on distant nodes of the superfamily, illustrating the adaptability of the GNAT fold.
Dimetridazole (DMZ) is an antimicrobial drug used to treat bacterial and protozoan infections in humans and poultry farms. An excessive dosage of DMZ can be life-threatening, as it has carcinogenic effects. Hence, ensuring that DMZ remains at a very low level in the environment is essential for day-to-day human life. Herein, we report the development of a novel biocomposite using kappa-carrageenan (kappa-CGN) functionalized with gadolinium tin oxide nanoparticles (NPs), kappa-CGN/GdSnO(2)NPs, for the effective electrochemical detection of DMZ. The biocomposites, kappa-GCN/GdSnO(2)NPs, were successfully synthesized by the sonochemical method, and their structural features were evaluated using various spectroscopic and microscopic techniques. A glassy carbon electrode was coated with the synthesized kappa-CGN/GdSnO(2)NPs, it was used as an electrode surface modifier material for the detection of DMZ, and it exhibited excellent electrocatalytic activity. In addition, the modified electrode showed many advantages, such as a lower detection limit (3.1 nM), wide linear range (0.019-708.8 mu M), good sensitivity (0.62 mu A mu M-1 cm(-2)), and high selectivity in the presence of co-interfering species. The designed kappa-CGN/GdSnO(2)NPs-based composite material can contribute to outstanding sensor performance in aquatic samples because of its repeatability, reproducibility, storage stability, and satisfactory accuracy. Therefore, kappa-CGN/GdSnO(2)NPs could be used to develop potential electrode modifier materials for electrochemical sensor applications and to detect toxic components, such as DMZ, in environmental aquatic samples.
Exploiting relationship among samples in cross-modal data plays a key role in the task of cross modal retrieval, but most of existing methods only extract the correlation from pairwise samples and ignore the relations of unpaired samples. Some graph regularization methods proposed a reasonable paradigm to exploit the correlation from multiple samples. However, limited by the traditional framework, the performance has much room to improve. Moreover, although some existing DNN-based methods achieve excellent performance, the requirement of massive labeled data is also a shortcoming. In this paper, we propose a novel semi-supervised method, named Semi-supervised Constrained Graph Convolutional Network (SCGCN), which adopts graph convolutional network to exploit correlation from batch samples of data with different modalities. For reducing the requirement of labeled data, we design a two stage training procedure: deep supervised learning stage and unsupervised learning stage. In deep supervised learning stage, we integrate two DNN-based semantic encoding networks and a shared classifier into Deep Cross-modal Semantic Encoding (DCSE) module which is trained by supervised learning with labeled data. From DCSE module, we learn a temporary modality-invariant space where the semantic embeddings of samples with different modalities are modality-invariant, and we also learn a classifier which can generate predicted label from the unlabeled data. In unsupervised learning stage, for fully exploiting the correlation from cross-modal data, we design a Constrained Graph Convolutional Network (CGCN) module which utilizes GCN to exploit the correlation and adopts both intra-modal discriminative loss and inter-modal pairwise similar loss to ensure the generated common representation modality-invariant and semantical discriminative. We perform extensive experiments on four conventional datasets and a large scale dataset to demonstrate the effectiveness of proposed approach.
Air pollution is a serious environmental problem that has attracted much attention. Air quality prediction can provide useful information for urban environmental governance decision-making and residents' daily health control. However, existing research methods have suffered from a weak ability to capture the spatial correlations and fail to model the long-term temporal dependencies of air quality. To overcome these limitations, we propose a multi-scale spatiotemporal graph convolution network (MST-GCN), which consists of a multi-scale block, several spatial-temporal blocks and a fusion block. We first divide the extracted features into several groups based on their domain categories, and represent the spatial correlations across stations as two graphs. Then we combine the grouped features and the constructed graphs in pairs to form a multi-scale block that feeds into spatial-temporal blocks. Each spatial-temporal block contains a graph convolution layer and a temporal convolution layer, which can model the spatial correlations and long-term temporal dependencies. To capture the group interactions, we use a fusion block to fuse multiple groups. Extensive experiments on a real-world dataset demonstrate that our model achieves the highest performance compared with state-of-the-art and baseline models for air quality prediction.
Zero-shot learning aims to recognize unseen categories by learning an embedding space between data samples and semantic representations. For the large-scale datasets with thousands of categories, embedding vectors of category labels are often used for semantic representation since it is difficult to define the semantic attributes of categories manually. Facing the problem of underutilization of prior knowledge during the construction of embedding vectors, this paper first constructs a novel knowledge graph as the supplement to the basic WordNet graph, and then proposes a fast hybrid model ARGCN-DKG, which means Attention based Residual Graph Convolutional Network on Different types of Knowledge Graphs. By introducing residual mechanism and attention mechanism, and integrating different knowledge graphs, the accuracy of knowledge transfer between different categories can be improved. Our model only use 2-layer GCN, the pretrained image features and category semantic features, so the training process could be done in minitues on single GPU, which could be one of the fastest training models for large-scale image recognition. Experiment results demonstrate that ARGCN-DKG model could get better results for large-scale datasets than the state-of-the-art model.
How to generalize and unify different few-shot learning tasks using neural network model is a difficult problem in the field of machine learning research. Aiming at the problem that the parameters of existing few-shot learning models cannot adapt with heterogeneous classification tasks, inspired by the human being recognition process, a hybrid neural network (HNN) model for large-scale heterogeneous classification tasks in few-shot learning is proposed. First, a meta-learning model is constructed, which uses a siamese graph convolutional network (SGCN) structure as bone network. The SGCN is trained by semi-supervised way with a small amount of incomplete labeled data. Then, random task slicing by group is performed according to the task size and meta-learning dimensions to ensure that the segmented task size matches the meta-learning model. Combined with the meta-learning model, a task discrimination network and object recognition network are constructed, to perform heterogeneous classification tasks while keeping the scale of HNN network parameters unchanged. Experimental results show that the HNN performs well under different datasets, and is suitable for large-scale heterogeneous tasks in few-shot learning without retraining.
Accurate and fine-grained individual air quality index (IAQI) prediction is the basis of air quality index (AQI), which is of great significance for air quality control and human health. Traditional approaches, such as time series, recurrent neural network or graph convolutional network, cannot effectively integrate spatial-temporal and meteorological factors and manage the dynamic edge relationship among scattered monitoring stations. In this paper, a ST-CCN-IAQI model is proposed based on spatial-temporal causal convolution networks. Both the spatial effects of multi-source air pollutants and meteorological factors were considered via spatial attention mechanism. Time-dependent features in the causal convolution network were extracted by stacked dilated convolution and time attention. All the hyper-parameters in ST-CCN-IAQI were tuned by Bayesian optimization. Shanghai air monitoring station data were employed with a series of baselines (AR, MA, ARMA, ANN, SVR, GRU, LSTM and ST-GCN). Final results showed that: (1) For a single station, the RMSE and MAE values of ST-CCN-IAQI were 9.873 and 7.469, decreasing by 24.95% and 16.87% on average, respectively. R-2 was 0.917, with an average 5.69% improvement; (2) For all nine stations, the mean RMSE and MAE of ST-CCN-IAQI were 9.849 and 7.527, respectively, and the R-2 value was 0.906. (3) Shapley analysis showed PM10, humidity and NO2 were the most influencing factors in ST-CCN-IAQI. The Friedman test, under different resampling, further confirmed the advantage of ST-CCN-IAQI. The ST-CCN-IAQI provides a promising direction for fine-grained IAQI prediction.
Point cloud data can be produced by many depth sensors, such as Light Detection and Ranging (LIDAR) and RGB-D cameras, and they are widely used in broad applications of robotic navigation and remote -sensing for the understanding of environment. Hence, new techniques for object representation and clas-sification based on 3D point cloud are becoming increasingly in high demand. Due to the irregularity of the object shape, the point cloud-based object recognition is a very challenging task, especially the pose variances of a point cloud will impose many difficulties. In this paper, we tackle the challenge of pose variances in object classification based on point cloud by developing a novel end-to-end pose robust graph convolutional network. Technically, we first represent the point cloud using the spherical system instead of the traditional Cartesian system for simplicity of computation and representation. Then a pose auxiliary network is constructed with an aim to estimate the pose changes in terms of rotation angles. Finally, a graph convolutional network is constructed for object classification against the pose variations of point cloud. The experimental results show the new model outperforms the existing approaches (such as PointNet and PointNet++) on the classification task when conducting experiments on both the Model-Net40 and the ShapeNetCore dataset with a series of random rotations of a 3D point cloud. Specifically, we obtain 73.02% accuracy for classification task on the ModelNet40 with delaunay triangulation algo-rithm, which is much better than the state of the art algorithms, such as PointNet and PointCNN. (c) 2021 Elsevier Ltd. All rights reserved.
Few-shot learning (FSL) for human-object interaction (HOI) aims at recognizing various relationships between human actions and surrounding objects only from a few samples. It is a challenging vision task, in which the diversity and interactivity of human actions result in great difficulty to learn an adaptive classifier to catch ambiguous interclass information. Therefore, traditional FSL methods usually perform unsatisfactorily in complex HOI scenes. To this end, we propose dynamic graph-in-graph networks (DGIG-Net), a novel graph prototypes framework to learn a dynamic metric space by embedding a visual subgraph to a task-oriented cross-modal graph for few-shot HOI. Specifically, we first build a knowledge reconstruction graph to learn latent representations for HOI categories by reconstructing the relationship among visual features, which generates visual representations under the category distribution of every task. Then, a dynamic relation graph integrates both reconstructible visual nodes and dynamic task-oriented semantic information to explore a graph metric space for HOI class prototypes, which applies the discriminative information from the similarities among actions or objects. We validate DGIG-Net on multiple benchmark datasets, on which it largely outperforms existing FSL approaches and achieves state-of-the-art results.
Sketch-based image retrieval (SBIR) is a long-standing research topic in computer vision. Existing methods mainly focus on category-level or instance-level image retrieval. This paper investigates the fine-grained scene-level SBIR problem where a free-hand sketch depicting a scene is used to retrieve desired images. This problem is useful yet challenging mainly because of two entangled facts: 1) achieving an effective representation of the input query data and scene-level images is difficult as it requires to model the information across multiple modalities such as object layout, relative size and visual appearances, and 2) there is a great domain gap between the query sketch input and target images. We present SceneSketcher-v2, a Graph Convolutional Network (GCN) based architecture to address these challenges. SceneSketcher-v2 employs a carefully designed graph convolution network to fuse the multi-modality information in the query sketch and target images and uses a triplet training process and end-to-end training manner to alleviate the domain gap. Extensive experiments demonstrate SceneSketcher-v2 outperforms state-of-the-art scene-level SBIR models with a significant margin.
Antibodies consisting of variable and constant regions, are a special type of proteins playing a vital role in immune system of the vertebrate. They have the remarkable ability to bind a large range of diverse antigens with extraordinary affinity and specificity. This malleability of binding makes antibodies an important class of biological drugs and biomarkers. In this article, we propose a method to identify which amino acid residues of an antibody directly interact with its associated antigen based on the features from sequence and structure. Our algorithm uses convolution neural networks (CNNs) linked with graph convolution networks (GCNs) to make use of information from both sequential and spatial neighbors to understand more about the local environment of target amino acid residue. Furthermore, we process the antigen partner of an antibody by employing an attention layer. Our method improves on the state-of-the-art methodology.
Human Action Recognition (HAR) has remained one of the most challenging tasks in computer vision. With the surge in data-driven methodologies, the depth modality has been effectively leveraged to solve this problem by many researchers over the years, mitigating many of the challenges of the two dimensional modalities. In this work, we investigate the methodologies and applications of 3D HAR primarily using the depth modality through a study of the end-to-end process of the state-of-the-art techniques . Challenges, future directions, availability of the datasets, and critical analysis regarding existing methods constitute a part of this paper. This survey aims to provide the reader with an up-to-date analysis in 3D HAR for those interested in further research.
Current human pose estimation methods mainly rely on designing efficient Convolutional Neural Networks (CNN) frameworks. These CNN architectures typically consist of high-to-low resolution sub-networks to learn semantic information, and then followed by low-to-high sub-networks to raise the resolution to locate the keypoints. Because low-level features have high resolution but less semantic information, while high-level features have rich semantic information but less high resolution details, so it is important to fuse different level features to improve the final performance. However, most existing models implement feature fusion by simply concatenate low-level and high-level features without considering the gap between spatial resolution and semantic levels. In this paper, we propose a new feature fusion method for human pose estimation. We introduce high level semantic information into low-level features to enhance feature fusion. Further, to keep both the high-level semantic information and high-resolution location details, we use Global Convolutional Network blocks to bridge the gap between low-level and high-level features. Experiments on MPII and LSP human pose estimation datasets demonstrate that efficient feature fusion can significantly improve the performance. The code is available at: https://github.com/tongjiangwei/FeatureFusion.
Recently, fine-grained image retrieval (FGIR) has become a hot topic in computer vision. Most of the advanced retrieval algorithms in this field mainly focus on the construction of loss function and the design of hard sample mining strategy. In this paper, we improve the performance of the FGIR algorithm from another perspective and propose an attention mechanism and context Information constraints-based image retrieval (AMCICIR) method for FGIR. It first applies an attention learning mechanism to gradually refine object location and extracts useful local features from coarse to fine. Then, it uses an improved graph convolutional network (GCN), where the adjacency matrix is dynamically adjusted with the current features and model retrieval performances during the model learning, to model the internal semantic interactions of the learned local features, so as to obtain a more discriminative and fine-grained image representation. Finally, various experiments are conducted on two fine-grained image datasets, CUB-200-2011 and Cars-196, and the experimental results show that the AMCICIR algorithm can outperform pervious state-of-the-art works remarkably.
Recently, skeleton-based action recognition has modeled the human skeleton as a graph convolution network (GCN), and has achieved remarkable results. However, most of the methods convolute directly on the whole graph, neglecting that the human skeleton is made up of multiple body parts, which cannot accomplish the task well. We recognize that the physical property of bones (i.e., length and direction) can provide identifiable information which helps effectively to build the multi-level network structure. As the existing methods treat the channel domain and the spatial domain with equal importance, many computing resources are wasted on neglectable features. In our paper, we modify the Convolution Block Attention Module (CBAM) and apply it to the adaptive network. By capturing the implicit weighted information in the channel domain and spatial domain, the network can focus more attention on the key channels and nodes. A new two-stream adaptive-attentional subgraph convolution network (2s-AASGCN) is proposed to extract features in the spatio-temporal domain. We validate 2s-AASGCN on two skeleton datasets, i.e., NTU-RGB+D60 and NTU-RGB+D120. Our model achieves excellent results on these two datasets.
The encoder-decoder framework is the main frame of image captioning. The convolutional neural network (CNN) is usually used to extract grid-level features of the image, and the graph convolutional neural network (GCN) is used to extract the image's region-level features. Grid-level features are poor in semantic information, such as the relationship and location of objects, while regional features lack fine-grained information about images. To address this problem, this paper proposes a fusion-features-based image-captioning model, which includes the fusion feature encoder and LSTM decoder. The fusion-feature encoder is divided into grid-level feature encoder and region-level feature encoder. The grid-level feature encoder is a convoluted neural network embedded in squeeze and excitation operations so that the model can focus on features that are highly correlated to the title. The region-level encoder employs node-embedding matrices to enable models to understand different node types and gain richer semantics. Then the features are weighted together by an attention mechanism to guide the decoder LSTM to generate an image caption. Our model was trained and tested in the MS COCO2014 dataset with the experimental evaluation standard Bleu-4 score and CIDEr score of 0.399 and 1.311, respectively. The experimental results indicate that the model can describe the image in detail.
Entity alignment refers to the process of discovering entities representing the same object in different knowledge graphs (KG). Recently, some studies have learned other information about entities, but they are aspect-level simple information associations, and thus only rough entity representations can be obtained, and the advantage of multi-faceted information is lost. In this paper, a novel node-level information strong fusion framework (SFEA) is proposed, based on four aspects: structure, attribute, relation and names. The attribute information and name information are learned first, then structure information is learned based on these two aspects of information through graph convolutional network (GCN), the alignment signals from attribute and name are already carried at the beginning of the learning structure. In the process of continuous propagation of multi-hop neighborhoods, the effect of strong fusion of structure, attribute and name information is achieved and the more meticulous entity representations are obtained. Additionally, through the continuous interaction between sub-alignment tasks, the effect of entity alignment is enhanced. An iterative framework is designed to improve performance while reducing the impact on pre-aligned seed pairs. Furthermore, extensive experiments demonstrate that the model improves the accuracy of entity alignment and significantly outperforms 13 previous state-of-the-art methods.
Background and objective: The Covid-19 pandemic significantly affects the global population's fitness and day-to-day life. The necessary action to fight against Covid is to have a fast, accurate and affordable diagnosis system. Most of the diagnostic systems available today have a low detection rate and are time consuming. Hence, there is a demand to design an affordable, accurate, and fast diagnostic system for Covid. The diagnostic system that uses the Convolutional Neural Network (CNN) does not consider the complex correlation of multimodal image data, thus misleading the diagnostic results. Graph Convolutional Network (GCN) provides a better solution for the complex representation of data, as it is modeled based on the pairwise relationship in the image features. Method: Diagnosis of Covid, Parasite, or Lung Tumor from X-ray images needs a more complex representative model. There is a demand to categorize the images grounded on highly complex features. To solve the issue mentioned earlier, this work proposes a Hypergraph- and convolutional neural network-based Fast and Accurate Diagnosis (FAT) system for Covid. The in-depth features are mined using a residual neural network from the X-ray images. The learning-based method optimizes a high-level correlation in the deep structures by constructing it as a hypergraph. Results: The proposed method is assessed based on the Covid dataset. The experimental outcomes show that the proposed system FAT provides the accuracy of 99.8%, sensitivity of 99.5%, and specificity of 99%. It outperforms all the current diagnosis systems for Covid. Conclusion: The proposed deep learning-based model is well suited for Covid diagnosis at the preliminary level. It allows diagnosing Covid by low radiation chest X-ray images with higher accuracy.
Nitrogen doped hierarchically porous 3D porous carbon-graphene/polyaniline (3D PC-g/PANi) hybrid nanocomposites are prepared by a simple in-situ polymerization process. 3D PC is synthesized using bio-waste Bombax malabaricum seeds as the carbon precursor and the interconnected 3D PC-g are prepared by a simple refluxing and activation process with a large specific surface area of 2418 m(2) g(-1). The specific capacitance (Cp) of 3D PC-g and 3D PC-g/PANi electrodes are 610 and 1198 F g(-1) in 1 M H2SO4, respectively at a very high current density of 2 A g(-1). Also, a symmetric supercapacitor (SSC) exhibits a high energy density (Ed) of 61 Wh kg(-1) and 117 Wh kg(-1) in 1 M H2SO4 and 0.5 M Na2SO4 electrolytes, respectively. It still persist a high power density (Pd) of 15 kW kg(-1) and 20 kW kg(-1) with an Ed of 49.1 Wh kg(-1) and 84.4 Wh kg(-1) at a very high current density of 30 A g(-1). Further, an asymmetric supercapacitor (ASC) based on 3D PC-g/PANi as positive and hierarchical porous N-doped porous carbon covered gC(3)N(4) nanosheets (N-P(gCN)-700) as a negative electrode is successfully fabricated, which exhibit a high Ed of 97.5 Wh kg(-1) in 0.5 M Na2SO4. The presented results are higher than most of earlier reported PANi based composite carbon electrode materials. Further, the assembled SSC and ASC devices exhibit 94% and 91% capacitance retention even after 10,000 cycles. Furthermore two ASC connected in series can power up red LED for 30 min after charging for 60 s. (C) 2019 Elsevier Ltd. All rights reserved.
GCN2 (general control nonderepressible 2) is a serine/threonine-protein kinase that controls messenger RNA translation in response to amino acid availability and ribosome stalling. Here, we show that GCN2 controls erythrocyte clearance and iron recycling during stress. Our data highlight the importance of liver macrophages as the primary cell type mediating these effects. During different stress conditions, such as hemolysis, amino acid deficiency or hypoxia, GCN2 knockout (GCN2(-/-)) mice displayed resistance to anemia compared with wild-type (GCN2(+/+)) mice. GCN2(-/-) liver macrophages exhibited defective erythrophagocytosis and lysosome maturation. Molecular analysis of GCN2(-/-) cells demonstrated that the ATF4-NRF2 pathway is a critical downstream mediator of GCN2 in regulating red blood cell clearance and iron recycling.
The kinetochore is a multi-protein complex that drives chromosome segregation in eukaryotes. It assembles onto centromere DNA and interacts with spindle microtubules during mitosis and meiosis. Although most eukaryotes have canonical kinetochore proteins, kinetochores of evolutionarily divergent kinetoplastid species consist of at least 20 unconventional kinetochore proteins (KKT1-20). In addition, 12 proteins (KKT-interacting proteins 1-12, KKIP1-12) are known to localize at kinetochore regions during mitosis. It remains unclear whether KKIP proteins interact with KKT proteins. Here, we report the identification of four additional kinetochore proteins, KKT22-25, in Trypanosoma brucei. KKT22 and KKT23 constitutively localize at kinetochores, while KKT24 and KKT25 localize from S phase to anaphase. KKT23 has a Gcn5-related N-acetyltransferase domain, which is not found in any kinetochore protein known to date. We also show that KKIP1 co-purifies with KKT proteins, but not with KKIP proteins. Finally, our affinity purification of KKIP2/3/4/6 identifies a number of proteins as their potential interaction partners, many of which are implicated in RNA binding or processing. These findings further support the idea that kinetoplastid kinetochores are unconventional.
Content-Based Image Retrieval (CBIR) is the cornerstone of today's image retrieval systems. The most distinctive retrieval approach used, involves the submission of an image-based query whereby the system is used in the extraction of visual characteristics like the shape, color, and texture from the images. Examination of the characteristics is done for ensuring the searching and retrieval of proportional images from the image database. Majority of the datasets utilized for retrieval lean towards to comprise colored images. The colored images are regarded as in RGB (Red, Green, Blue) form. Most colored images use the RGB image for classifying the images. The research presents the transformation of RGB to other color spaces, extraction of features using different color spaces techniques, Gabor filter and use Convolutional Neural Networks for retrieval to find the most efficient combination. The model is also known as Gabor Convolution Network. Even though the notion of the Gabor filter being induced in CNN has been suggested earlier, this work introduces an entirely different and very simple Gabor-based CNN which produces high recognition efficiency. In this paper, Gabor Convolutional Networks (GCNs or GaborNet), with different color spaces are used to examine which combination is efficient to retrieve natural images. An extensive experiment using Cifar 10 dataset was made and comparison of simple CNN, ResNet 50 and GCN model was also made. The models were evaluated through a several statistical analysis based on accuracy, precision, recall, F-Score, area under the curve (AUC), and receiving operating characteristic (ROC) curve. The results shows GaborNet model effectively retrieve images with 99.68% of AUC and 99.09% of Recall. The results also shows different images are effectively retrieved using different color space. Therefore research concluded it is very significance to transform images to different color space and use GaborNet for effective retrieval.
Sentiment Analysis is an essential research topic in the field of natural language processing (NLP) and has attracted the attention of many researchers in the last few years. Recently, deep neural network (DNN) models have been used for sentiment analysis tasks, achieving promising results. Although these models can analyze sequences of arbitrary length, utilizing them in the feature extraction layer of a DNN increases the dimensionality of the feature space. More recently, graph neural networks (GNNs) have achieved a promising performance in different NLP tasks. However, previous models cannot be transferred to a large corpus and neglect the heterogeneity of textual graphs. To overcome these difficulties, we propose a new Transformer-based graph convolutional network for heterogeneous graphs called Sentiment Transformer Graph Convolutional Network (ST-GCN). To the best of our knowledge, this is the first study to model the sentiment corpus as a heterogeneous graph and learn document and word embeddings using the proposed sentiment graph transformer neural network. In addition, our model offers an easy mechanism to fuse node positional information for graph datasets using Laplacian eigenvectors. Extensive experiments on four standard datasets show that our model outperforms the existing state-of-the-art models.
We apply a heterogeneous graph convolution network (GCN) combined with a multi-layer perceptron (MLP) denoted by GCNMLP to explore the potential side effects of drugs. Here the SIDER, OFFSIDERS, and FAERS are used as the datasets. We integrate the drug information with similar characteristics from the datasets of known drugs and side effect networks. The heterogeneous graph networks explore the potential side effects of drugs by inferring the relationship between similar drugs and related side effects. This novel in silico method will shorten the time spent in uncovering the unseen side effects within routine drug prescriptions while highlighting the relevance of exploring drug mechanisms from well-documented drugs. In our experiments, we inquire about the drugs Vancomycin, Amlodipine, Cisplatin, and Glimepiride from a trained model, where the parameters are acquired from the dataset SIDER after training. Our results show that the performance of the GCNMLP on these three datasets is superior to the non-negative matrix factorization method (NMF) and some well-known machine learning methods with respect to various evaluation scales. Moreover, new side effects of drugs can be obtained using the GCNMLP.
Named entity disambiguation (NED) finds the specific meaning of an entity mention in a particular context and links it to a target entity. With the emergence of multimedia, the modalities of content on the Internet have become more diverse, which poses difficulties for traditional NED, and the vast amounts of information make it impossible to manually label every kind of ambiguous data to train a practical NED model. In response to this situation, we present MMGraph, which uses multimodal graph convolution to aggregate visual and contextual language information for accurate entity disambiguation for short texts, and a self-supervised simple triplet network (SimTri) that can learn useful representations in multimodal unlabeled data to enhance the effectiveness of NED models. We evaluated these approaches on a new dataset, MMFi, which contains multimodal supervised data and large amounts of unlabeled data. Our experiments confirm the state-of-the-art performance of MMGraph on two widely used benchmarks and MMFi. SimTri further improves the performance of NED methods. The dataset and code are available at https://github.com/LanceZPF/NNED_MMGraph.
In this paper, we present a hybrid semantic affinity learning method (HSA) to capture and leverage the dependencies of categories for 3D semantic segmentation. Unlike existing methods that only use the cross-entropy loss to perform one-to-one supervision and ignore the semantic relations between points, our approach aims to learn the label dependencies between 3D points from a hybrid perspective. From a global view, we introduce the structural correlations among different classes to provide global priors for point features. Specifically, we fuse word embeddings of labels and scene-level features as category nodes, which are processed via a graph convolutional network (GCN) to produce the sample-adapted global priors. These priors are then combined with point features to enhance the rationality of semantic predictions. From a local view, we propose the concept of local affinity to effectively model the intra-class and inter-class semantic similarities for adjacent neighborhoods, making the predictions more discriminative. Experimental results show that our method consistently improves the performance of state-of-the-art models across indoor (S3DIS, ScanNet), outdoor (SemanticKITTI), and synthetic (ShapeNet) datasets.
Aspect-based sentiment analysis (ABSA) is a prominent and challenging issue in natural language processing tasks. It aims to analyze the emotion of the aspect words in given subjective sentences. A subjective sentence usually contains one or more aspect words, and there are potential associations between different aspect words. At present, many works in the literature ignore the potential relationship between aspect words. Therefore, in this paper, we propose an oriented inter-aspect modeling hierarchical network (IA-HiNET), which aims to mine and strengthen the relationship between different aspect words, and further realize the task of sentence-level sentiment analysis based on aspect words. Specifically, we introduce part-of-speech information and position information as a priori knowledge, and then construct a graph convolution network (GCN) based on sentence dependency to capture emotional cues related to aspect words. We design an aspect-oriented self-attention mechanism to map different aspect words with the same attribute into the same vector space to determine the correlation between different aspect words. Furthermore, we design a novel information gate mechanism to filter the emotional features unrelated to aspect words. The indicative importance between different aspect words is also used to assist the aspect-based sentence-level affective analysis task. We carry out experiments on four benchmark datasets, and excellent experimental results show the effectiveness of our model.
Among common tasks in natural language processing (NLP) domain, text classification is considered as an important primitive task which is widely applied in multiple disciplines. Recent advanced deep learning-based architectures such as sequence-to-sequence (seq2seq) with attention mechanism have demonstrated remarkable improvements in multiple NLP's tasks, including classification. However, recent seq2seq-based models still encounter challenges related to the limitation in effectively capturing long-range dependent relationships between words in a text corpus. Recent integrated graph neural network and textual graph transformer (TGT)-based models have demonstrated significant improvements in preserving the structural n-hop co-occurring relationships between words in a given text corpus. However, these models still suffer problems related to the thorough considerations on the sequential and contextual relations of words within a single document's graph. To meet these challenges, in this article we proposed a novel semantic-enhanced graph transformer-based textual representation learning approach, called as: SemTGT. Our proposed SemTGT can support to effectively learn both local rich-contextual and global long-range structural latent representations of texts for leveraging the performance of classification task. Extensive experiments in standard datasets demonstrate the effectiveness of our proposed SemTGT model in comparing with recent seq2seq-based and textual graph embedding-based baselines.
The pedestrian attribute recognition aims at generating the structured description of pedestrian, which plays an important role in surveillance. However, it is difficult to achieve accurate recognition results due to diverse illumination, partial body occlusion and limited resolutions. Therefore, this paper proposes a comprehensive relationship framework for comprehensively describing and utilizing relations among attributes, describing different type of relations in the same dimension, and implementing complex transfers of relations in a GCN manner. This framework is named Correlation Graph Convolutional Network (CGCN). Based on the proposed framework, the feature vectors are built to associate attributes with image features and generate different relation matrices through self-attention among different feature vectors, describing different attribute relations. Then, we conduct multi-layer transfer of attribute relations by means of graph convolution, realizing complex utilization of attribute relations. In addition, the relations among attributes are fully exploited and two types of relations, namely the explicit and implicit relations, are proposed to be integrate into the proposed comprehensive relationship framework. The experimental results on RAP and PETA demonstrate that the recognition performance of the proposed CGCN can obviously outperform the state-of-the-arts, and moreover, the CGCN can achieve a better synergy with different relations.
The problem of route planning on road network is essential to many Location-Based Services (LBSs). Road networks are dynamic in the sense that theweights of the edges in the corresponding graph constantly change over time, representing evolving traffic conditions. Thus, a practical route planning strategy is required to supply the continuous route optimization considering the historic, current, and future traffic condition. However, few existing works comprehensively take into account these various traffic conditions during the route planning. Moreover, the LBSs usually suffer from extensive concurrent route planning requests in rush hours, which imposes a pressing need to handle numerous queries in parallel for reducing the response time of each query. However, this issue is also not involved by most existing solutions. We therefore investigate a parallel traffic condition driven route planning model on a cluster of processors. To embed the future traffic condition into the route planning, we employ a GCN model to periodically predict the travel costs of roads within a specified time period, which facilitates the robustness of the route planning model against the varying traffic condition. To reduce the response time, a Dual-Level Path (DLP) index is proposed to support a parallel route planning algorithm with the filter-and-refine principle. The bottom level of DLP partitions the entire graph into different subgraphs, and the top level is a skeleton graph that consists of all border vertices in all subgraphs. The filter step identifies a global directional path for a given query based on the skeleton graph. In the refine step, the overall route planning for this query is decomposed into multiple sub-optimizations in the subgraphs passed through by the directional path. Since the subgraphs are independently maintained by different processors, the sub-optimizations of extensive queries can be operated in parallel. Finally, extensive evaluations are conducted to confirm the effectiveness and superiority of the proposal.
The goal of this work is to recognize words, phrases, and sentences being spoken by a talking face without given the audio. Current deep learning approaches for lip reading focus on exploring the appearance and optical flow information of videos. However, these methods do not fully exploit the characteristics of lip motion. In addition to appearance and optical flow, the mouth contour deformation usually conveys significant information that is complementary to others. However, the modeling of dynamic mouth contour has received little attention than that of appearance and optical flow. In this work, we propose a novel model of dynamic mouth contours called Adaptive Semantic-Spatio-Temporal Graph Convolution Network (ASST-GCN), to go beyond previous methods by automatically learning both the spatial and temporal information from videos. To combine the complementary information from appearance and mouth contour, a two-stream visual front-end network is proposed. Experimental results demonstrate that the proposed method significantly outperforms the state-of-the-art lip reading methods on several large-scale lip reading benchmarks.
Skeleton-based hand gesture recognition is an active research topic in computer graphics and computer vision and has a wide range of applications in VR/AR and robotics. Although the spatial-temporal graph convolutional network has been successfully used in skeleton-based hand gesture recognition, these works often use a fixed spatial graph according to the hand skeleton tree or use a fixed graph on the temporal dimension, which may not be optimal for hand gesture recognition. In this paper, we propose a two-stream graph attention convolutional network with spatial-temporal attention for hand gesture recognition. We adopt pose stream and motion stream as the two input streams for our network. In pose stream, we use the joint in each frame as the input; In motion stream, we use the joint offsets between neighboring frames as the input. We propose a new temporal graph attention module to model the temporal dependency and also use a spatial graph attention module to construct dynamic skeleton graph. For each stream, we adopt graph convolutional network with spatial-temporal attention to extract the features. Then, we concatenate the feature of the pose stream and motion stream for gesture recognition. We achieve the competitive performance on the main hand gesture recognition benchmark datasets, which demonstrates the effectiveness of our method.
In the task of skeleton-based action recognition, long-term temporal dependencies are significant cues for sequential skeleton data. State-of-the-art methods rarely have access to long-term temporal information, due to the limitations of their receptive fields. Meanwhile, most of the recent multiple branches methods only consider different input modalities but ignore the information in various temporal scales. To address the above issues, we propose a multi-scale temporal transformer (MTT) in this letter, for skeleton-based action recognition. Firstly, the raw skeleton data are embedded by graph convolutional network (GCN) blocks and multi-scale temporal embedding modules (MT-EMs), which are designed as multiple branches to extract features in various temporal scales. Secondly, we introduce transformer encoders (TE) to integrate embeddings and model the long-term temporal pattern. Moreover, we propose a task-oriented lateral connection (LaC) aiming to align semantical hierarchies. LaC distributes input embeddings to the downstream transformer encoders (TE), according to semantical levels. The classification headers aggregate results from TE and predict the action categories at last. The proposed method is shown efficiency and universality during experiments and achieves the state-of-the-art on three large datasets, NTU-RGBD 60, NTU-RGBD 120 and Kinetics-Skeleton 400.
Modulation in the constituent composition of heterojunction composite materials can efficiently separate photogenerated charge carriers and promote significant improvement towards visible light aided photocatalytic degradation of recalcitrant pollutants. Herein, a novel ternary heterojunction composite g-CN/CuFe2O4/MoS2 (CNCuMo) has been fabricated by improvising g-C3N4 as a fuel and the supporting matrix. The stable dual Zscheme heterojunction manifested superior visible light driven catalytic activity through efficient electron/hole (e-/h+) separation and generation of reactive species through peroxymonosulphate (PMS) activation. Various surface bound redox cycles play prominent roles in transport of photogenerated charge carriers, activation of adsorbed PMS species and generation of reactive radicals. Benefiting from their synergistic effects, visible light aided photocatalytic degradation of refractory antibiotic Ciprofloxacin (CIP) was studied. 98% CIP was degraded (with 74.8% mineralization) using 0.1 g/l of ternary composite with 10 wt% MoS2 (CNCuMo(10)) and 0.5 g/l of PMS, within 60 min of visible light irradiation. Scavenging experiments confirmed the simultaneous activity of both radical and non-radical species towards degradation. The system also exhibited satisfactory CIP degradation efficiency in various surface water matrixes. LCMS/MS analysis of the identified intermediates interpreted the probable degradation pathways of CIP molecules. Magnetic retrievability, recyclability for five cycles, good structural stability and low metal ion leaching tendency of the synthesized photocatalyst elucidate its potential application for degradation of emerging pollutants for water decontamination.
Gait recognition aims to identify people by the way they walk. Currently available gait recognition datasets mainly contain single-person gait data in relatively simple walking conditions, which limits research of robust gait recognition methods. In this paper, OG RGB+D dataset is presented to cope with this crucial limitation of other gait datasets. It includes the common walking conditions under occlusion in daily life, that is, those daily walking conditions in which people's normal walking patterns are occluded, including self-occlusion caused by views, occlusion caused by clothing or objects, and mutual occlusion between people. The dataset provides multi-modal data to support different types of methods, collected by multiple Azure Kinect DK sensors using synchronous data acquisition system (Multi-Kinect SDAS). Moreover, we propose a model-based gait recognition method SkeletonGait for gait recognition in walking conditions under occlusion, which learns discriminative gait features from human dual skeleton model composed of skeleton and anthropometric features through a siamese Spatio-Temporal Graph Convolutional Network (siamese ST-GCN). The experimental results show that SkeletonGait surpasses state-of-the-art methods in the case of severe occlusion. We believe that the introduction of our dataset will enable the community to apply, adapt, and develop various robust gait recognition methods. The dataset will be available at https://github.com/cvNXE/OG-RGB-D-gait-dataset.
Temporal action proposal generation is a fundamental yet challenging to locate the temporal action in untrimmed videos. Although current proposal generation methods can generate the precise boundary of actions, few focus on considering the relation of proposals. In this paper, we propose a unified framework to generate the temporal boundary proposals with a graph convolution network based on the boundary proposals' feature named Boundary Graph Convolutional Network (BGCN). BGCN draws inspiration from boundary methods and uses edge graph convolution relay on the boundary proposals' feature. First, we use a base layer to fusion the two-stream video features to get two-branches of base features. Then the two-branches of base features enter into the same structure of Proposal Features Graph Convolutional Network (PFGCN): Action PFGCN to extract the action classification score and Boundary PFGCN to extract the ending score and staring score. In proposal features graph convolutional network, we first densely sampled the proposals' feature from the video features. We construct a proposal feature graph, where each proposal feature as a node and their relations between proposals' features as an edge with edge convolution for graph convolution. After that, map the relations into a 2D map score. Experiments on popular benchmarks THUMOS14 demonstrate the superiority of BGCN over (44.8% versus 42.8% at tIoU 0.5) the state-of-the-art proposal generator (e.g., G-TAD, TAL-Net, and BMN) at any of tIoU thresholds from 0.3 to 0.7. On ActivityNet1.3, BGCN also got better results. Moreover, BGCN has high efficiency for action detection with less than 2 MB model size and fast inference time. GCN based on boundary generation for densely produce the action proposals Efficient and novel BGCN model has a great capability to learn the proposal features Has a lower model size for temporal action proposals generation Has fast inference time for temporal action proposals generation. (c) 2021 Elsevier B.V. All rights reserved.
Road traffic forecasting is crucial in Intelligent Transportation Systems (ITS). To achieve accurate results, it is necessary to model the dynamic nature and the complex non-linear dependencies governing traffic. The goal is particularly challenging when the prediction involves more than just one traffic variable. This paper proposes a novel multi-task learning model, called AST-MTL, to perform multi-horizon predictions of the traffic flow and speed at the road network scale. The strategy combines a multilayer fully-connected neural network (FNN) and a multi-head attention mechanism to learn related tasks while improving generalization performance. The model also includes the graph convolutional network (GCNs) and the gated recurrent unit network (GRUs) to extract the spatial and temporal features of traffic conditions. Our experiments employ new sets of GPS data, called OBU data, to perform traffic prediction in the freeway and urban contexts. The experimental results prove our model can effectively perform multi-horizon traffic forecasting for different types of roads and outperform state-of-the-art models.
Human action recognition has been an attractive research topic in recent years due to its wide range of applications. Among existing methods, the Graph Convolutional Network achieves remarkable results by exploring the graph nature of skeleton data in both spatial and temporal domains. Noise from the pose estimation error is an inherent issue that could seriously degrade action recognition performance. Existing graph-based methods mainly focus on improving recognition accuracy, whereas low-complexity models are required for application development on devices with limited computation capacity. In this paper, a lightweight model is proposed by pruning layers, adding Feature Fusion and Preset Joint Subset Selection modules. The proposed model takes advantages of the recent Graph-based convolution networks (GCN) and selecting informative joints. Two graph topologies are defined for the selected joints. Extensive experiments are implemented on public datasets to evaluate the performance of the proposed method. Experimental results show that the method outperforms the baselines on the datasets with serious noise in skeleton data. In contrast, the number of parameters in the proposed method is 5.6 times less than the baseline. The proposed lightweight models therefore offer feasible solutions for developing practical applications.
RNAs play crucial and versatile roles in cellular biochemical reactions. Since experimental approaches of determining their three-dimensional (3D) structures are costly and less efficient, it is greatly advantageous to develop computational methods to predict RNA 3D structures. For these methods, designing a model or scoring function for structure quality assessment is an essential step but this step poses challenges. In this study, we designed and trained a deep learning model to tackle this problem. The model was based on a graph convolutional network (GCN) and named RNAGCN. The model provided a natural way of representing RNA structures, avoided complex algorithms to preserve atomic rotational equivalence, and was capable of extracting features automatically out of structural patterns. Testing results on two datasets convincingly demonstrated that RNAGCN performs similarly to or better than four leading scoring functions. Our approach provides an alternative way of RNA tertiary structure assessment and may facilitate RNA structure predictions. RNAGCN can be downloaded from https://gitee.com/dcw-RNAGCN/rnagcn.
In object detection, non-maximum suppression (NMS) methods are extensively adopted to remove horizontal duplicates of detected dense boxes for generating final object instances. However, due to the degraded quality of dense detection boxes and not explicit exploration of the context information, existing NMS methods via simple intersection-over-union (IoU) metrics tend to underperform on multi-oriented and long-size objects detection. Distinguishing with general NMS methods via duplicate removal, we propose a novel graph fusion network, named GFNet, for multi-oriented object detection. Our GFNet is extensible and adaptively fuse dense detection boxes to detect more accurate and holistic multi-oriented object instances. Specifically, we first adopt a locality-aware clustering algorithm to group dense detection boxes into different clusters. We will construct an instance sub-graph for the detection boxes belonging to one cluster. Then, we propose a graph-based fusion network via Graph Convolutional Network (GCN) to learn to reason and fuse the detection boxes for generating final instance boxes. Extensive experiments both on public available multi-oriented text datasets (including MSRA-TD500, ICDAR2015, ICDAR2017-MLT) and multi-oriented object datasets (DOTA) verify the effectiveness and robustness of our method against general NMS methods in multi-oriented object detection.
Recently, graph-based hashing that learns similarity-preserving binary codes via an affinity graph has been extensively studied for large-scale image retrieval. However, most graph-based hashing methods resort to intractable binary quadratic programs, making them unscalable to massive data. In this paper, we propose a novel graph convolutional network-based hashing framework, dubbed GCNH, which directly carries out spectral convolution operations on both an image set and an affinity graph built over the set, naturally yielding similarity-preserving binary embedding. GCNH fundamentally differs from conventional graph hashing methods which adopt an affinity graph as the only learning guidance in an objective function to pursue the binary embedding. As the core ingredient of GCNH, we introduce an intuitive asymmetric graph convolutional (AGC) layer to simultaneously convolve the anchor graph, input data, and convolutional filters. By virtue of the AGC layer, GCNH well addresses the issues of scalability and out-of-sample extension when leveraging affinity graphs for hashing. As a use case of our GCNH, we particularly study the semisupervised hashing scenario in this paper. Comprehensive image retrieval evaluations on the CIFAR-10, NUS-WIDE, and ImageNet datasets demonstrate the consistent advantages of GCNH over the state-of-the-art methods given limited labeled data.
Extensive studies have been conducted on human action recognition, whereas relatively few methods have been proposed for hand action recognition. Although it is very natural and straightforward to apply a human action recognition method to hand action recognition, this approach cannot always lead to state-of-the-art performance. One of the important reasons is that both the between-class difference and the within-class difference in hand actions are much smaller than those in human actions. In this article, we study first-person hand action recognition from RGB-D sequences. To explore whether pretrained networks substantially influence accuracy, eight classic pretrained networks and one pretrained network designed by us are introduced for extracting RGB-D features. A Lie group is introduced for hand pose representation. Ablation studies are conducted to compare the discriminative power of the RGB modality, depth modality, pose modality, and their combinations. In our method, a fixed number of frames are randomly sampled to represent an action. This temporal modeling strategy is simple but is proven more effective than both the graph convolutional network (GCN) and the recurrent neural network (RNN), which are widely adopted by conventional methods. Evaluation experiments on two public data sets demonstrate that our method markedly outperforms recent baselines.
Spatial-temporal graph modeling plays an important role in the fields of transportation, meteorology, and social networks. Traffic flow prediction is a classic spatial-temporal modeling task. Existing methods usually do not take into account the asynchronous spatial-temporal correlation in traffic data. In addition, due to the complexity and variability of traffic data, long-term traffic forecasting is highly challenging. In order to solve the above problems, this article proposes a new deep learning-based asynchronous dilation graph convolution network (ADGCN) to model the spatial-temporal graphs. We mine the asynchronous spatial-temporal correlation in the traffic network, and propose the asynchronous spatial-temporal graph convolution (ASTGC) operation to extract this special relationship. Furthermore, we extend the dilated 1-D causal convolution to a graph convolution. The receptive field of the model increases exponentially with the increase of the network depth. Experiments are conducted on three public traffic data sets, and the results show that the prediction performance of ADGCN is better than the existing counterpart methods, especially in long-term prediction tasks.
Neural architecture search (NAS) adopts a search strategy to explore the predefined search space to find superior architecture with the minimum searching costs. Bayesian optimization (BO) and evolutionary algorithms (EA) are two commonly used search strategies, but they suffer from being computationally expensive, challenging to implement, and exhibiting inefficient exploration ability. In this article, we propose a neural predictor guided EA to enhance the exploration ability of EA for NAS (NPENAS) and design two kinds of neural predictors. The first predictor is a BO acquisition function for which we design a graph-based uncertainty estimation network as the surrogate model. The second predictor is a graph-based neural network that directly predicts the performance of the input neural architecture. The NPENAS using the two neural predictors are denoted as NPENAS-BO and NPENAS-NP, respectively. In addition, we introduce a new random architecture sampling method to overcome the drawbacks of the existing sampling method. Experimental results on five NAS search spaces indicate that NPENAS-BO and NPENAS-NP outperform most existing NAS algorithms, with NPENAS-NP achieving state-of-the-art performance on four of the five search spaces.
Online ride-hailing order forecasting is a very important part of the intelligent traffic dispatch system. Accurate order forecasting can reduce the flow of invalid vehicles and improve the user experience of online ride-hailing. We propose a multi-view deep long short-term memory (LSTM) network architecture (MultiView deep LSTM framework), which uses convolutional neural network and graph convolutional network to extract the temporal and spatial characteristics of online ride-hailing orders, obtains the correlation information between regional orders through the order view, regional speed view, and weather factor view, and then uses LSTM unit and attention unit to predict the order volume in real time. We use Didi Haikou, China's online ride-hailing dataset for training, compare it with the prediction algorithms of other articles, and experiment with different choices of the contrast framework. The experimental results show that our deep learning framework can effectively capture comprehensive spatio-temporal correlation and obtain better results. The model maintained good performance at 15 min, 30 min, and 1 h. Experiments conducted on the actual demand data onto ride-hailing from Didi Haikou data prove that our method is better than the latest method.
Label Distribution Learning (LDL) can better describe the real-world data by learning a set of label distributions instead of discrete binary labels. Particularly, hashing-based LDL has achieved promising performance due to its desirable advantages of fast similarity computation and extremely low storage cost. However, existing hashing-based LDL methods are still shallow learning methods, which cannot deeply capture the implicit data semantics, and meanwhile fail to fully model the semantic data relations. In this letter, we propose an effective and efficient Deep Discrete Hashing for Label Distribution Learning (DDH-LDL) method, which develops the first deep hashing framework for LDL. Specifically, DDH-LDL captures implicit semantic information by multi-layer non-linear transformation, and simultaneously preserves the modeled semantic relations of instances into hash codes via semantic message aggregation on Graph Convolutional Network (GCN). Furthermore, we elaborately design a discrete optimization module that is seamlessly integrated into our proposed deep hashing framework to reduce the binary quantization errors. Experiments on several widely tested datasets verify the superiority of the proposed method on both learning accuracy and efficiency.
In order to find a suitable designer team for the collaborative design crowdsourcing task of a product, we consider the matching problem between collaborative design crowdsourcing task network graph and the designer network graph. Due to the difference in the nodes and edges of the two types of graphs, we propose a graph matching model based on a similar structure. The model first uses the Graph Convolutional Network to extract features of the graph structure to obtain the node-level embeddings. Secondly, an attention mechanism considering the differences in the importance of different nodes in the graph assigns different weights to different nodes to aggregate node-level embeddings into graph-level embeddings. Finally, the graph-level embeddings of the two graphs to be matched are input into a multi-layer fully connected neural network to obtain the similarity score of the graph pair after they are obtained from the concat operation. We compare our model with the basic model based on four evaluation metrics in two datasets. The experimental results show that our model can more accurately find graph pairs based on a similar structure. The crankshaft linkage mechanism produced by the enterprise is taken as an example to verify the practicality and applicability of our model and method.
Computed tomography and magnetic resonance imaging produce high-resolution images; however, during surgery or radiotherapy, only low-resolution cone-beam CT and low-dimensional X-ray images can be obtained. Furthermore, because the duodenum and stomach are filled with air, even in high-resolution CT images, it is hard to accurately segment their contours. In this paper, we propose a method that is based on a graph convolutional network (GCN) to reconstruct organs that are hard to detect in medical images. The method uses surrounding detectable-organ features to determine the shape and location of the target organ and learns mesh deformation parameters, which are applied to a target organ template. The role of the template is to establish an initial topological structure for the target organ. We conducted experiments with both single and multiple organ meshes to verify the performance of our proposed method.
In recent years, with the rapid development of digital currency, digital currency brings us convenience and wealth, but also breeds some illegal and criminal behaviors. Different from traditional currencies, digital currency provides concealment to criminals while also exposing their behavior. The analysis of their behavior can be used to detect whether the current digital currency transaction is legal. There is a problem that most digital currency transactions are in compliance with laws and regulations, and only a small part of them uses digital currency to conduct illegal activities. It belongs to the problem of sample imbalance. It is quite challenging to accurately distinguish which transactions are legal and which are illegal in the massive digital currency transactions. For this reason, this study combines the mutual information and the traditional cross-entropy loss function and obtains the loss function based on the mutual information prior. The loss function based on the mutual information prior is that the bias of the category prior distribution is added after the output of the model (before the softmax), which makes the model consider category prior information to a certain extent when predicting. The experimental results show that the use of the loss function based on mutual information prior to the detection of digital currency illegal behavior has a good effect in SVM, DNN, GCN, and GAT methods.
With the widespread application of semantic segmentation in remote sensing images with high-resolution, how to improve the accuracy of segmentation becomes a research goal in the remote sensing field. An innovative Fully Convolutional Network (FCN) is proposed based on regional attention for improving the performance of the semantic segmentation framework for remote sensing images. The proposed network follows the encoder-decoder architecture of semantic segmentation and includes the following three strategies to improve segmentation accuracy. The enhanced GCN module is applied to capture the semantic features of remote sensing images. MGFM is proposed to capture different contexts by sampling at different densities. Furthermore, RAM is offered to assign large weights to high-value information in different regions of the feature map. Our method is assessed on two datasets: ISPRS Potsdam dataset and CCF dataset. The results indicate that our model with those strategies outperforms baseline models (DCED50) concerning F1, mean IoU and PA, 10.81%,19.11%, and 11.36% on the Potsdam dataset and 29.26%, 27.64% and 13.57% on the CCF dataset.
Local climate zone (LCZ) has become a new standard classification scheme in urban landscapes and showed great potential in urban climate research. Traditional classifiers and ordinary neural networks only consider the spectral or local spatial features of the pixel, ignoring the effect of nonlocal information on the LCZ classification. The graph convolutional network (GCN) has been used to exploit the relationship between adjacent and global land covers owing to the ability to conduct flexible convolution over graphs. In this work, we integrated a convolutional neural network and two GCNs into an end-to-end hybrid framework and generated LCZs directly from the original images. Local-, regional-, and global-level features were extracted and grouped complementarily to foster better performance. Experiments were conducted in six cities around the world to verify the effectiveness of our method. Results showed that the average classification accuracy of the six cities reached 0.956 and performed better than any other comparable model. Ablation experiments also demonstrated the mutual promotion of the different modules. Finally, the small sample experiment provided a practical reference for the LCZ classification in the absence of samples in future.
Given a question about an image, Visual Commonsense Reasoning (VCR) needs to provide not only a correct answer, but also a rationale to justify the answer. VCR is a challenging task due to the requirement of proper semantic alignment and reasoning between the image and linguistic expression. Recent approaches offer a great promise by exploring holistic attention mechanisms or graph-based networks, but most of them do implicit reasoning and ignore the semantic dependencies among the linguistic expression. In this paper, we propose a novel explicit cross-modal representation learning network for VCR by incorporating syntactic information into the visual reasoning and natural language understanding. The proposed method enjoys several merits. First, based on a two-branch neural module network, we can do explicit cross-modal reasoning guided by the high-level syntactic structure of linguistic expression. Second, the semantic structure of the linguistic expression is incorporated into a syntactic GCN to facilitate language understanding. Third, our explicit cross-modal representation learning network can provide a traceable reasoning-flow, which offers visible fine-grained evidence of the answer and rationale. Quantitative and qualitative evaluations on the public VCR dataset demonstrate that our approach performs favorably against state-of-the-art methods.
Living objects are hard to grasp because they can actively dodge and struggle by writhing or deforming while or even prior to being contacted and modeling or predicting their responses to grasping is extremely difficult. This letter presents an algorithm based on reinforcement learning (RL) to attack this challenging problem. Considering the complexity of living object grasping, we divide the whole task into pre-grasp and in-hand stages and let the algorithm switch between the stages automatically. The pre-grasp stage is aimed at finding a good pose of a robot hand approaching a living object for performing a grasp. Dense reward functions are proposed for facilitating the learning of right hand actions based on the poses of both hand and object. Since an object held in hand may struggle to escape, the robot hand needs to adjust its configuration and respond correctly to the object's movement. Hence, the goal of the in-hand stage is to determine an appropriate adjustment of finger configuration in order for the robot hand to keep holding the object. At this stage, we treat the robot hand as a graph and use the graph convolutional network (GCN) to determine the hand action. We test our algorithm with both simulation and real experiments, which show its good performance in living object grasping. More results are available on our website: https://sites.google.com/view/graph-rl.
This article presents a method for the trajectory prediction of surrounding vehicles and proactive longitudinal control of autonomous vehicles (AVs) in an urban road environment. A long short-term memory (LSTM)-based deep learning model is designed for the surrounding vehicles' trajectory prediction. In our model, the historical evolution of the relation between a target vehicle and lanes is considered to learn the driver's behavior in a lane-aware manner. Interaction among adjacent vehicles is captured based on a graph convolutional network (GCN), which uses a self-attention mechanism. Compared to other approaches, our prediction model utilizes environment information that is acquirable in AVs with local sensors. A model predictive control (MPC) is designed to derive the control inputs of acceleration for AVs. The proposed control method utilizes the prediction results of the target vehicle to give action requests to AV in a proactive manner considering both safety and ride quality. The results of comparative studies indicate that the proposed prediction model achieves improved accuracy compared to baselines. The control results provided by automated driving tests show that the proposed control algorithm applied by the LSTM-based prediction model enables AVs to achieve safety with respect to surrounding vehicles and provide ride comfort to passengers.
Graph convolution networks (GCNs) are useful in remote sensing (RS) image retrieval. It is found to be effective because, in a graph representation, the relative geometrical interactions between different regions (or segments) are appropriately captured, along with their region-wise features in their region adjacency graphs. Also, the attention mechanism has often been applied to the nodes to highlight the essential features in each node. In this regard, a significant amount of high-frequency information is missed since each image segment is effectively summarized within a single node. To account for this and increase the learning capacity, we propose to attend over the edge/adjacency matrix to highlight the interactions among meaningful regions that contribute to supervised learning from images. We exploit this novel edge attention mechanism together with node attention to highlight essential image context by allowing more importance to the meaningful neighboring regions that highlight a relevant node. We implement the proposed context-attended GCN framework for image retrieval on the benchmarked UC-Merced and the PatternNet datasets. We observe a notable improvement in the results compared to the state of the art.
More than 90% of neuroblastoma patients are cured in the low-risk group while only less than 50% for those with high-risk disease can be cured. Since the high-risk patients still have poor outcomes, we need more accurate stratification to establish an individualized precise treatment plan for the patients to improve the long-term survival rate. We focus on extracting features and providing a workflow to improve survival prediction for neuroblastoma patients. With a workflow for gene co-expression network (GCN) mining in microarray and RNA-Seq datasets, we extracted molecular features from each co-expressed module and summarized them into eigengenes. Then we adopted the lasso-regularized Cox proportional hazards model to select the most informative eigengene features regarding association to the risk of metastasis. Nine eigengenes were selected which show strong association with patient survival prognosis. All of the nine corresponding gene modules also have highly enriched biological functions or cytoband locations. Three of them are unique modules to RNA-Seq data, which complement the modules from microarray data in terms of survival prognosis. We then merged all eigengenes from these unique modules and used an integrative method called Similarity Network Fusion to test the prognostic power of these eigengenes for prognosis. The prognostic accuracies are significantly improved as compared to using all eigengenes, and a subgroup of patients with very poor survival rate was identified. We first compared GCNs mined from microarray and RNA-seq data. We discovered that each data modality yields unique GCNs, which are enriched with clear biological functions. Then we do module unique analysis and use lasso-cox model to select survival-associated eigengenes. Integration of unique and survival-associated eigengenes from both data types provides complementary information that leads to more accurate survival prognosis. Reviewed by Susmita Datta, Marco Chierici and Dimitar Vassilev.
The increasing penetration of renewable energy sources (RES) brings volatile stochasticity, which significantly challenge the optimal dispatch of power systems. This paper aims at developing a cost-effective and robust policy for stochastic dynamic optimization of power systems, which improves the economy as well as avoiding the risk of high costs in some critical scenarios with small probability. However, it is hard for existing risk-neutral methods to incorporate risk measure since most samples are normal. For this regard, a novel risk-averse policy learning approach based on deep reinforcement learning with risk-oriented sampling is proposed. Firstly, a generative adversarial network (GAN) with graph convolutional neural network (GCN) is proposed to learn from historical data and achieve risk-oriented sampling. Specifically, system state is modelled as graph data and GCN is employed to capture the underlying correlation of the uncertainty corresponding to the system topology. Risk knowledge is the embedded to encourage more critical scenarios are sampled while aligning with historical data distributions. Secondly, a modified deep reinforcement learning (DRL) with risk-measure under soft actor critic framework is proposed to learn the optimal dispatch policy from sampling data. Compared with the traditional deep reinforcement learning which is risk-neutral, the proposed method is more robust and adaptable to uncertainties. Comparative simulations verify the effectiveness of the proposed method.
Schizophrenia is a mental disorder that will progressively change a person's mental state and cause serious social problems. Symptoms of schizophrenia are highly correlated to emotional status, especially depression. We are thus motivated to design a mental status detection system for schizophrenia patients in order to provide an assessment tool for mental health professionals. Our system consists of two phases, including model learning and status detection. For the learning phase, we propose a multi-task learning framework to infer the patient's mental state, including emotion and depression severity. Unlike previous studies inferring emotional status mainly by facial analysis, in the learning phase, we adopted a Cross-Modality Graph Convolutional Network (CMGCN) to effectively integrate visual features from different modalities, including the face and context. We also designed task-aware objective functions to realize better model convergence for multi-task learning, i.e., emotion recognition and depression estimation. Further, we followed the correlation between depression and emotion to design the Emotion Passer module, to transfer the prior knowledge on emotion to the depression model. For the detection phase, we drew on characteristics of schizophrenia to detect the mental status. In the experiments, we performed a series of experiments on several benchmark datasets, and the results show that the proposed learning framework boosts state-of-the-art (SOTA) methods significantly. In addition, we take a trial on schizophrenia patients, and our system can achieve 69.52 in mAP in a real situation.
Maximal subgraph mining is increasingly important in various domains, including bioinformatics, genomics, and chemistry, as it helps identify common characteristics among a set of graphs and enables their classification into different categories. Existing approaches for identifying maximal subgraphs typically rely on traversing a graph lattice. However, in practice, these approaches are limited to relatively small subgraphs due to the exponential growth of the search space and the NP-completeness of the underlying subgraph isomorphism test. In this work, we propose SCAMA, an approach that addresses these limitations by adopting a divide-and-conquer strategy for efficient mining of maximal subgraphs. Our approach involves initially partitioning a graph database into equivalence classes using bootstrapped backbones, which are tree-shaped frequent subgraphs. We then introduce a learning process based on a novel graph convolutional network (GCN) to extract maximal backbones for each equivalence class. A critical insight of our approach is that by estimating each maximal backbone directly in the embedding space, we can avoid the exponential traversal of the graph lattice. From the extracted maximal backbones, we construct the maximal frequent subgraphs. Furthermore, we outline how SCAMA can be extended to perform top-������ largest frequent subgraph mining and how the discovered patterns facilitate graph classification. Our experimental results demonstrate the effectiveness of SCAMA in identifying almost perfectly maximal frequent subgraphs, while exhibiting approximately 10 times faster performance compared to the best baseline technique.
Abnormal event detection in videos plays an essential role for public security. However, most weakly supervised learning methods ignore the relationship between the complicated spatial correlations and the dynamical trends of temporal pattern in video data. In this paper, we provide a new perspective, i.e., spatial similarity and temporal consistency are adopted to construct Spatio-Temporal Graph-based CNNs (STGCNs). For the feature extraction, we use Inflated 3D (I3D) convolutional networks to extract features which can better capture appearance and motion dynamics in videos. For the spatio graph and temporal graph, each video segment is regarded as a vertex in the graph, and attention mechanism is introduced to allocate attention for each segment. For the spatial-temporal fusion graph, we propose a self-adapting weighting to fuse them. Finally, we build ranking loss and classification loss to improve the robustness of STGCNs. We evaluate the performance of STGCNs on UCF-Crime datasets (total 128 h) and ShanghaiTech datasets (total 317,398 frames) with the AUC score 84.2% and 92.3%, respectively. The experimental results also show the effectiveness and robustness with other evaluation metrics.
In this paper, we study the problem of traffic forecasting, which aims to predict the future traffic state of the road network. One key challenge is that the previous approaches lack discussion of capturing temporal dependencies, as well as spatial dependencies among locations in the traffic network. In addition, the long-term traffic prediction is not satisfied. In this paper, we propose a Traffic dYnamic gRaph modEl - TYRE - which is composed of a Graph Convolutional Network with Gated and Attention mechanisms. TYRE can learn the 'importance' of all adjacent and distant locations, control the aggregation of adjacent and distant neighbourhood information, and learn the temporal dependencies to support long effective historical sizes. We demonstrate the validity and effectiveness of our approach on two different traffic datasets (i.e., PeMSD4 and PeMSD8). The result shows that compared to the related approaches, our model that captures temporal and spatial dependence yields substantially improved performance. When predicting traffic conditions for the next 120 min, on PeMSD8 dataset, our model shows almost 6.6% RMSE improvement, 10.9% MAE improvement, and 2.1% MAPE improvement over the previous state of the art. All source codes of this work will be publicly available at https://github.com/wzhtxy/Traffic-dYnamic-gRaph-modEl
The idea of the paper concentrates on an iterative learning process in Graph Convolution Networks (GCNs) involved in two vital steps: one is a message propagation (message passing) step to aggregate neighboring node features via aggregators performed, and another is an encoding output step to encode node feature representations by using updaters. In our model, we propose a novel affinity-aware encoding as an updater in GCNs, which aggregates the neighboring nodes of a node while updating this node's features. By utilizing affinity values of our encoding, we order the neighboring nodes to determine the correspondence between encoding functions and the neighboring nodes. Furthermore, to explicitly reduce the model size, we propose a lightweight variant of our updater that integrates Depth-wise Separable Convolution (DSC) into it, namely Depth-wise Separable Graph Convolution (DSGC). Comprehensive experiments conducted on graph data demonstrate that our models' accuracy improved significantly for graphs of low-dimensional node features. Also, performed in the low-dimensional node feature space we provide state-of-the-art results on two metrics (Macro-f1 and Matthews correlation coefficient (MCC)). Besides, our models are robust when taking different low-dimensional feature selection strategies. (c) 2020 Elsevier Ltd. All rights reserved.
Graph convolutional network (GCN) has been used to capture spatial correlation between multiple sensors for better performance of short-term water demand forecasting, which is essential for the implementation of smart water such as optimal scheduling and anomaly detection. However, the GCN assumes every sensor's importance to be the same and describes the spatial correlation purely from a data perspective. To resolve the two issues that affect prediction accuracy, this study proposes a weighting strategy and develops a spatial correlation-based GCN (SCGCN) prediction model. Self-attention mechanism is used to comprehensively analyze water demand data of every sensor and flow resistance between sensors (i.e., head loss along pipes), generating spatial correlation coefficients with the consideration of hydraulics. Then the coefficients are used as weights to aggregate neighboring sensors' data, extracting accurate input features for the SCGCN model. The study utilized real monitoring data to develop the SCGCN model and compare it with a traditional artificial neural network (ANN) model. Results show that the SCGCN model can outperform the ANN model, especially for multi-step prediction. The root mean square errors of 30, 45, and 60 min multi-step prediction cases are reduced by 4.4% to 9.2% for different sensors.
Missing data imputation (MDI) is the task of replacing missing values in a dataset with alternative, predicted ones. Because of the widespread presence of missing data, it is a fundamental problem in many scientific disciplines. Popular methods for MDI use global statistics computed from the entire dataset (e.g., the feature-wise medians), or build predictive models operating independently on every instance. In this paper we propose a more general framework for MDI, leveraging recent work in the field of graph neural networks (GNNs). We formulate the MDI task in terms of a graph denoising autoencoder, where each edge of the graph encodes the similarity between two patterns. A GNN encoder learns to build intermediate representations for each example by interleaving classical projection layers and locally combining information between neighbors, while another decoding GNN learns to reconstruct the full imputed dataset from this intermediate embedding. In order to speed-up training and improve the performance, we use a combination of multiple losses, including an adversarial loss implemented with the Wasserstein metric and a gradient penalty. We also explore a few extensions to the basic architecture involving the use of residual connections between layers, and of global statistics computed from the dataset to improve the accuracy. On a large experimental evaluation with varying levels of artificial noise, we show that our method is on par or better than several alternative imputation methods. On three datasets with pre-existing missing values, we show that our method is robust to the choice of a downstream classifier, obtaining similar or slightly higher results compared to other choices. (C) 2020 Elsevier Ltd. All rights reserved.
Real-world knowledge bases such as DBPedia, Yago, and Freebase contain sparse linkage connectivity, which poses a severe challenge to link prediction between entities. To cope with such data scarcity issues, recent models have focused on learning interactions between entity pairs by means of relations that exist between them. However promising, some relations are associated with very few tail entities or head entities, resulting in poor estimation of the relation interaction between entities. In this article, we break the sole dependency of modeling relation interactions between entity pairs by associating a triple with pairwise embeddings, i.e., distributed vector representations for pairs of word-based entities and relation of a triple. We capture the interactions that exist between pairwise embeddings by means of a Pairwise Factorization Model that employs a factorization machine with relation attention. This approach allows parameters for related interactions to be estimated efficiently, ensuring that the pairwise embeddings are discriminative, providing strong supervisory signals for the decoding task of link prediction. The Pairwise Factorization Model we propose exploits a neural bag-of-words model as the encoder, which effectively encodes word-based entities into distributed vector representations for the decoder. The proposed model is simple and enjoys efficiency and capability, showing superior link prediction performance over state-of-the-art complex models on benchmark datasets DBPedia5OK and FB15K-237.
Motivation: Recent advances in spatially resolved transcriptomics (ST) technologies enable the measurement of gene expression profiles while preserving cellular spatial context. Linking gene expression of cells with their spatial distribution is essential for better understanding of tissue microenvironment and biological progress. However, effectively combining gene expression data with spatial information to identify spatial domains remains challenging. Results: To deal with the above issue, in this paper, we propose a novel unsupervised learning framework named STMGCN for identifying spatial domains using multi-view graph convolution networks (MGCNs). Specifically, to fully exploit spatial information, we first construct multiple neighbor graphs (views) with different similarity measures based on the spatial coordinates. Then, STMGCN learns multiple view-specific embeddings by combining gene expressions with each neighbor graph through graph convolution networks. Finally, to capture the importance of different graphs, we further introduce an attention mechanism to adaptively fuse view-specific embeddings and thus derive the final spot embedding. STMGCN allows for the effective utilization of spatial context to enhance the expressive power of the latent embeddings with multiple graph convolutions. We apply STMGCN on two simulation datasets and five real spatial transcriptomics datasets with different resolutions across distinct platforms. The experimental results demonstrate that STMGCN obtains competitive results in spatial domain identification compared with five state-of-the-art methods, including spatial and non-spatial alternatives. Besides, STMGCN can detect spatially variable genes with enriched expression patterns in the identified domains. Overall, STMGCN is a powerful and efficient computational framework for identifying spatial domains in spatial transcriptomics data.
Graph Convolutional Neural Networks (GCNs) are widely used for graph analysis. Specifically, in medical applications, GCNs can be used for disease prediction on a population graph, where graph nodes represent individuals and edges represent individual similarities. However, GCNs rely on a vast amount of data, which is challenging to collect for a single medical institution. In addition, a critical challenge that most medical institutions continue to face is addressing disease prediction in isolation with incomplete data information. To address these issues, Federated Learning (FL) allows isolated local institutions to collaboratively train a global model without data sharing. In this work, we propose a framework, FedNI, to leverage network inpainting and inter-institutional data via FL. Specifically, we first federatively train missing node and edge predictor using a graph generative adversarial network (GAN) to complete the missing information of local networks. Then we train a global GCN node classifier across institutions using a federated graph learning platform. The novel design enables us to build more accurate machine learning models by leveraging federated learning and also graph learning approaches. We demonstrate that our federated model outperforms local and baseline FL methods with significant margins on two public neuroimaging datasets.
A sequential recommendation has become a hot research topic, which seeks to predict the next interesting item for each user based on his action sequence. While previous methods have made many efforts to capture the dynamics of sequential patterns, we contend that they still suffer from two inherent limitations: 1) they fail to model item transition patterns in an efficient and time-sensitive manner and 2) they are unaware of the importance of dynamically capturing social influence, resulting in suboptimal performance. We introduce a new concept dubbed socio-sequential recommendation, where the challenge mainly lies in dynamically modeling social influences and capturing item-to-item transition patterns in a time-sensitive manner. In light of this, we contribute a novel solution named GCARec (short for graph-augmented co-attention model), which takes into account the joint effect of dynamic sequential patterns and dynamic social influences. GCARec decomposes socio-sequential recommendation workflow into two steps. First, we adopt a light graph embedding module to model long-term user preference. Then, we propose a time-sensitive attention mechanism and a social-aware attention mechanism to capture dynamic patterns at sequential-level and social-level, respectively. Extensive experiments have been conducted on eight real-world datasets from different scenarios, demonstrating the superiority of GCARec against several state-of-the-art methods. The codes and datasets have been released at: https://github.com/wubinzzu/GCARec.
With recent advancements, graph neural networks (GNNs) have shown considerable potential for various graph-related tasks, and their applications have gained considerable attention. However, adversarial attacks can significantly degrade the performance of GNNs, hindering their deployment in critical real-world tasks. GNNs must be robust against adversarial attacks, in which imperceptible adversarial perturbations are intro-duced to induce serious security issues. To achieve this goal, we propose a robust graph convolutional network, ERGCN, for node classification via data enhancement. ERGCN simultaneously utilizes properties from the "data domain" and "model space" as guidance. Based on the feature smoothness assumption, a graph structure enhancement (GSE) mech-anism is proposed to improve the structural reliability of input graphs. Moreover, inspired by self-training methods that assign pseudo-labels to unlabeled training samples and use them to optimize the target model iteratively, a reliable node selection metric, model boundary distance (MBD), is defined based on the distance from training samples to model decision boundary. Finally, a self-training-based robust graph convolutional network is proposed for node classification. Extensive experiments on three public datasets demon-strate the superiority of our model over existing state-of-the-art methods. Our study pro-vides a solution for trustworthy graph machine learning systems in adversarial environments. The code is available at https://github.com/star4455/ERGCN.(c) 2022 Elsevier Inc. All rights reserved.
Motivation: Proteins are ubiquitous molecules whose function in biological processes is determined by their 3D structure. Experimental identification of a protein's structure can be time-consuming, prohibitively expensive and not always possible. Alternatively, protein folding can be modeled using computational methods, which however are not guaranteed to always produce optimal results. GraphQA is a graph-based method to estimate the quality of protein models, that possesses favorable properties such as representation learning, explicit modeling of both sequential and 3D structure, geometric invariance and computational efficiency. Results: GraphQA performs similarly to state-of-the-art methods despite using a relatively low number of input features. In addition, the graph network structure provides an improvement over the architecture used in ProQ4 operating on the same input features. Finally, the individual contributions of GraphQA components are carefully evaluated. Availability and implementation: PyTorch implementation, datasets, experiments and link to an evaluation server are available through this GitHub repository: github.com/baldassarreFe/graphqa.
With the aim of constructing a low-dimensional representation space, Hyperbolic Knowledge Embeddings have gradually become a hot spot in various information retrieval and machine learning tasks. However, most of the existing Hyperbolic knowledge embedding methods focus on the shallow embedding, and often ignore the network structure characteristics (e.g., hierarchy) of Knowledge Graphs. Therefore, this paper designs a novel Hyperbolic Skipped Knowledge Graph Convolutional Network, HSKGCN, to improve link prediction accuracy with low embedding dimension requirements. Firstly, the model is designed based on the hyperbolic geometric operations on the Poincare ball, which can effectively utilize the characteristics of the hyperbolic geometry (e.g., Poincare ball) to capture the hierarchy of Knowledge Graphs; Secondly, each single-layer convolutional layer introduces the feature aggregation weight, which ensures the reasonable distribution of node features during the aggregation process; In addition, the skip-connection mechanism is applied to HSKGCN to weaken the information loss caused by the stacked of the graph convolutional layers; Finally, we evaluate HSKGCN on benchmark datasets, WN18RR and FB15k-237. Experiments show that HSKGCN achieves substantial improvements against state-of-the-art models on the 32-dimensional embedding task, and the results of different relations on WN18RR show graphs similar with tree topology can performer better. (c) 2022 Elsevier B.V. All rights reserved.
Statistical relational learning (SRL) and graph neural networks (GNNs) are two powerful approaches for learning and inference over graphs. Typically, they are evaluated in terms of simple metrics such as accuracy over individual node labels. Complex aggregate graph queries (AGQ) involving multiple nodes, edges, and labels are common in the graph mining community and are used to estimate important network properties such as social cohesion and influence. While graph mining algorithms support AGQs, they typically do not take into account uncertainty, or when they do, make simplifying assumptions and do not build full probabilistic models. In this paper, we examine the performance of SRL and GNNs on AGQs over graphs with partially observed node labels. We show that, not surprisingly, inferring the unobserved node labels as a first step and then evaluating the queries on the fully observed graph can lead to sub-optimal estimates, and that a better approach is to compute these queries as an expectation under the joint distribution. We propose a sampling framework to tractably compute the expected values of AGQs. Motivated by the analysis of subgroup cohesion in social networks, we propose a suite of AGQs that estimate the community structure in graphs. In our empirical evaluation, we show that by estimating these queries as an expectation, SRL-based approaches yield up to a 50-fold reduction in average error when compared to existing GNN-based approaches.
MicroRNAs (miRNAs) are human post-transcriptional regulators in humans, which are involved in regulating various physiological processes by regulating the gene expression. The subcellular localization of miRNAs plays a crucial role in the discovery of their biological functions. Although several computational methods based on miRNA functional similarity networks have been presented to identify the subcellular localization of miRNAs, it remains difficult for these approaches to effectively extract well-referenced miRNA functional representations due to insufficient miRNA-disease association representation and disease semantic representation. Currently, there has been a significant amount of research on miRNA-disease associations, making it possible to address the issue of insufficient miRNA functional representation. In this work, a novel model is established, named DAmiRLocGNet, based on graph convolutional network (GCN) and autoencoder (AE) for identifying the subcellular localizations of miRNA. The DAmiRLocGNet constructs the features based on miRNA sequence information, miRNA-disease association information and disease semantic information. GCN is utilized to gather the information of neighboring nodes and capture the implicit information of network structures from miRNA-disease association information and disease semantic information. AE is employed to capture sequence semantics from sequence similarity networks. The evaluation demonstrates that the performance of DAmiRLocGNet is superior to other competing computational approaches, benefiting from implicit features captured by using GCNs. The DAmiRLocGNet has the potential to be applied to the identification of subcellular localization of other non-coding RNAs. Moreover, it can facilitate further investigation into the functional mechanisms underlying miRNA localization. The source code and datasets are accessed at .
The converter steelmaking process smelts hot metal to liquid steel and occupies an important position in industry. The composition of liquid steel at the endpoint is an essential quality index, including the concentrations of multiple elements, such as carbon, silicon, and manganese. Accurately predicting endpoint composition is the basis of production optimization. Hence, a multichannel diffusion graph convolutional network (MCDGCN) is presented in this article. Unlike conventional models, the developed MCDGCN describes the converter steelmaking process as a graph to exploit the correlations among element concentrations for an accurate endpoint composition prediction. We also develop a unique K-hop diffusion method to extract the globally consistent information over the graph for predicting each element. The proposed method addresses the composition prediction task for a realistic converter steelmaking process. To the best of our knowledge, this is the first time that up to 15 elements of liquid steel are covered and predicted to present a comprehensive process model. Compared with six benchmark models, MCDGCN presents state-of-the-art results, i.e., an average R-2 of 0.8475 and an average MAE of 0.0189, which shows that the correlation mining of graph deep learning can indeed improve the prediction performance for endpoint composition.
Predicting the therapeutic effect of anti-cancer drugs on tumors based on the characteristics of tumors and patients is one of the important contents of precision oncology. Existing computational methods regard the drug response prediction problem as a classification or regression task. However, few of them consider leveraging the relationship between the two tasks. In this work, we propose a Multi-task Interaction Graph Convolutional Network (MTIGCN) for anti-cancer drug response prediction. MTIGCN first utilizes an graph convolutional network-based model to produce embeddings for both cell lines and drugs. After that, the model employs multitask learning to predict anti-cancer drug response, which involves training the model on three different tasks simultaneously: the main task of the drug sensitive or resistant classification task and the two auxiliary tasks of regression prediction and similarity network reconstruction. By sharing parameters and optimizing the losses of different tasks simultaneously, MTIGCN enhances the feature representation and reduces overfitting. The results of the experiments on two in vitro datasets demonstrated that MTIGCN outperformed seven state-of-the-art baseline methods. Moreover, the well-trained model on the in vitro dataset GDSC exhibited good performance when applied to predict drug responses in in vivo datasets PDX and TCGA. The case study confirmed the model's ability to discover unknown drug responses in cell lines.
Bearings are commonly used to reduce friction between moving parts. Bearings may fail due to lubrication failure, contamination, corrosion, and fatigue. To prevent bearing failures, it is important to predict the remaining useful life (RUL) of bearings. While many data-driven methods have been introduced, very few studies have considered the correlation of features at different time points, such a correlation could be used to identify and aggregate features at different time points for improving the robustness of predictive models. Moreover, many existing data-driven methods leverage neural networks with recurrent characteristics such as recurrent neural network (RNN) and long short term memory (LSTM). These methods are ineffective in processing long sequences and require longer training time due to the recurrent characteristics. To address these issues, a Siamese LSTM network is firstly introduced to classify degradation stages before predicting the RUL of bearings. Then we introduce a self-adaptive graph convolutional network (SAGCN) along with a self-attention mechanism in order to con-sider the correlation of features at different time points without using recurrent characteristics. Experimental results have demonstrated that the proposed method can accurately predict the RUL with a minimum average root mean squared error of 0.119, and outperforms existing data-driven methods, such as graph convolutional network, convolutional LSTM, convolutional neural network, and generative adversarial network.
The recommender system is of great significance to alleviate information overload. The rise of online social networks leads to a promising direction-social recommendation. By injecting the interaction influence among social users, recommendation performance has been further improved. Successful as they are, we argue that most social recommendation methods are still not sufficient to make full use of social network information. Existing solutions typically either considered only the local neighbors or treat neighbors' information equally, even or both. However, few studies have attempted to solve these social recommendation problems jointly from both the perspective of social depth and social strength. Recently, graph convolutional neural networks have shown great potential in learning graph data by modeling the information propagation and aggregation process. Thus, we propose an attention-based social aggregation neural networks (abbreviated as SAN) model to build a recommendation system. Different from previous work, our proposed SAN model simulates the recursive social aggregation process to spread the global social influence, and simultaneously introduces social attention mechanism to incorporate the heterogeneous influences for better model user embedding. Instead of a shallow linear interaction function, we adopt multi-layer perception to model the complex user-item interaction. Extensive experiments on two real-world datasets show the effectiveness of our proposed model SAN, and further analysis verifies the generalization and flexibility of the model.
Inferring the unseen attribute-object composition is critical to make machines learn to decompose and compose complex concepts like people. Most existing methods are limited to the composition recognition of single-attribute-object, and can hardly learn relations between the attributes and objects. In this paper, we propose an attribute-object semantic association graph model to learn the complex relations and enable knowledge transfer between primitives. With nodes representing attributes and objects, the graph can be constructed flexibly, which realizes both single- and multi-attribute-object composition recognition. In order to reduce mis-classifications of similar compositions (e.g., scratched screen and broken screen), driven by the contrastive loss, the anchor image feature is pulled closer to the corresponding label feature and pushed away from other negative label features. Specifically, a novel balance loss is proposed to alleviate the domain bias, where a model prefers to predict seen compositions. In addition, we build a large-scale Multi-Attribute Dataset (MAD) with 116,099 images and 8,030 label categories for inferring unseen multi-attribute-object compositions. Along with MAD, we propose two novel metrics Hard and Soft to give a comprehensive evaluation in the multi-attribute setting. Experiments on MAD and two other single-attribute-object benchmarks (MIT-States and UT-Zappos50K) demonstrate the effectiveness of our approach.
Recommendation system plays an important role in the rapid development of micro-video sharing platform. Micro-video has rich modal features, such as visual, audio, and text. It is of great significance to carry out personalized recommendation by integrating multi-modal features. However, most of the current multi-modal recommendation systems can only enrich the feature representation on the item side, while it leads to poor learning of user preferences. To solve this problem, we propose a novel module named Learning the User's Deeper Preferences (LUDP), which constructs the item-item modal similarity graph and user preference graph in each modality to explore the learning of item and user representation. Specifically, we construct item-item similar modalities graph using multi-modal features, the item ID embedding is propagated and aggregated on the graph to learn the latent structural information of items; The user preference graph is constructed through the historical interaction between the user and item, on which the multi-modal features are aggregated as the user's preference for the modal. Finally, combining the two parts as auxiliary information enhances the user and item representation learned from the collaborative signals to learn deeper user preferences. Through a large number of experiments on two public datasets (TikTok, Movielens), our model is proved to be superior to the most advanced multi-modal recommendation methods.
Aspect sentiment triplet extraction task detects three elements of fine-grained sentiment analysis from given sentence, including aspect and opinion terms and their sentiment polarity. Existing methods mainly include tagging-based and span-based methods, where the former show defects on handling overlapped triplets, and the latter could theoretically handle all overlapped triplets but lack of tailored inter-word dependency so that suffer from insufficient span semantic. In this paper, we propose a span-based dependency-enhanced graph convolutional network, which leverages contextual semantic and latent dependency to enrich span representations. Specifically, we devise a latent graph convolutional network to emphasize critical inter-word dependencies and cut off redundant connections in a learnable gating manner, improving the information flow during inter-word interaction. In addition, considering the problem of multi-word term sentiment consistency, we detect effective aspect and opinion terms derived from the output of span enumeration, and introduce term-level interactions by coupling, which meanwhile enables our model to deal with various types of triplets including many-to-one and one-to-many overlapped triplets. Extensive experiments over four benchmark datasets verify that the proposed method outperforms all the baselines with an average F1 improvement of up to 6.13%, and meanwhile shows fine interpretability. The experimental results demonstrate that effectively enhancing token-level and term-level interactions can significantly improve the aspect sentiment triplet extraction performance.
Forecasting traffic inflows and outflows is crucial for intelligent transportation applications such as traffic management and risk assessment. Recently, deep learning models, which focus on capturing spatio-temporal correlations between stations (locations) by constructing Spatio-Temporal Feature Learners (STFL), have achieved promising performance in traffic inflows and outflows prediction. However, two unresolved issues limit the performance of these models. i) dynamic and heterogeneous intra-and inter-relationships between flows are ignored, and ii) the STFL in these models cannot capture the global information. To address the above issues, we propose a novel deep Spatio-Temporal Network framework based on Multi-Relational learning (MR-STN) for predicting traffic inflows and outflows. Specifically, a multi-relational learning module is designed to comprehensively model three kinds of relationships between flows while extracting diverse spatio-temporal features. In this module, an enhanced STFL is developed to capture both local and global information. Then, a feature fusion module is introduced to extract fused features for inflows and outflows respectively via a gated fusion mechanism. On this basis, the prediction module uses fusion features to generate future inflows and outflows. Finally, we implement the proposed framework with four state-of-the-art graph-based deep spatio-temporal models to demonstrate its generality and superiority. Extensive experiments on three datasets show that the proposed framework can significantly boost the performance of existing models.
In recent years, reviews and user-item interaction have been recognized as valuable information to improve representation learning abilities in recommendations. However, on the one hand, the existing review-based recommendations normally ignore the importance of sentiment words regarding the corresponding aspect words, which reflect user preference for the item aspect. On the other hand, when modeling interaction, both user-user and user-item interactions should be considered. To solve these issues, in this paper, we propose a novel sentiment-enhanced neural graph recommender by incorporating the information derived from both textual reviews and bipartite graph. Specifically, we first design a hierarchically structured attention mechanism with a sentiment auxiliary task to help the recommendation task learn user preference for different aspects of items from reviews, where the co-attention mechanism is used to select important item/user reviews for the current user/item. Second, we construct a user-item interaction graph to capture preference-based user-item interaction with social-based user-user interaction, where the graph convolutional network is used to simulate the diffusion of information. Finally, we adopt a Factorization Machine model to accomplish the recommendation task. The experimental results demonstrate that our model significantly outperforms the related approaches w.r.t. rating prediction accuracy on Yelp and Amazon datasets. (C) 2022 Elsevier Inc. All rights reserved.
Data-driven fault diagnosis for critical industrial processes has exhibited promising potential with massive operating data from the supervisory control and data acquisition system. However, automatically extracting the complicated interactions between measurements and subtly integrating it with temporal evolutions have not been fully considered. Besides, with the increasing complexity of industrial processes, accurately locating fault roots is of tremendous significance. In this article, we propose an unsupervised spatial-temporal aware graph encoder-decoder (STAGED) model for industrial fault diagnosis. Firstly, the high-dimensional measurements are constructed as a weighted graph to depict the complicated interactions. Then, the graph convolutional network, long short-term memory network and attention mechanism are applied to learn a comprehensive representation for multi-series. To enforce the model to better capture the temporal evolution, the dual decoder that performs reconstruction and prediction tasks simultaneously is adopted with a well-designed comprehensive loss function. By learning the spatial-temporal evolutions of datasets, faults can be diagnosed and located at a fine-grained level based on reconstruction deviations. To verify the performance of STAGED, experiments on Cranfield three-phase flow facility and secure water treatment datasets are implemented and the results indicate that it can provide insight into fault evolution and accurately diagnose faults.
In many brain network studies, brain functional connectivity data is extracted from neuroimaging data and then used for disease prediction. For now, brain disease data not only has a small sample but also has the problem of high dimensional and nonlinear. Therefore, deep clustering on brain functional connectivity data is very challenging. To solve these problems, we propose a Soft-orthogonal Constrained Dual-stream Encoder with Self-supervised clustering network (SSCDE), which consists of a pretext task and downstream task, which can fully mine the effective information in brain disease data. In the pretext task, we use two brain disease data under the same category to do cross-domain learning to obtain effective information from the same dataset. In the downstream task, to reduce redundancy and avoid negative coding, we propose a soft-orthogonal constrained dual-stream encoder to encode features separately. At the same time, we use the pseudo labels given by the pretext task as prior information for self-supervised learning. We conduct validation on different brain disease recognition tasks, and the result have proved that the proposed framework has achieved good performance compared with the unsupervised clustering analysis algorithms. To our knowledge, this is the first cross-domain assisted recognition study on brain functional connectivity data. The code is available at https://github.com/hulu88/SSCDE.
Herein, we highlight the simplistic fabrication of a light-weight, flexible self-charging power pack by the prudent integration of two paper-based high-performance triboelectric nanogenerators (HPTENGs), one commercial semi-flexible photovoltaic/solar cell and a paper-based all-solid-state asymmetric-type supercapacitor (ASSASC) with optimized performance. Each HPTENG unit comprises of a similar to 20 wt% barium titanate nanoparticles loaded surface micropatterned post-polled PDMS composite (PDMS-20BTO) film-strip impregnated with graphite coated Whatman (R) 41 filter paper (GFP) as negative and a polypyrrole electrodeposited GFP as positive tribo-electric friction layers, respectively. Contrariwise, the ASSASC consists of a nickel-cobalt-molybdenum oxide-graphitic C3N4 hybrid composite coated GFP (NCMO-gCN2/GFP) as positive and a graphitic C3N4 modified reduced graphene oxide coated GFP (gCN-m-RGO/GFP) as negative electrodes, separated by a thin PVA-KOH gel-type electrolyte membrane. Finally, under deformations/stress and illumination of solar light individually on top of our photovoltaic and HPTENGs driven self-charging ASSASC (PTSCASC) power pack, it efficaciously generates electrical energy and consequently stores this generated energy as electrochemical energy for sus-tainable power supply. Our self-powered PTSCASC# power pack prototype (with two ASSASCs) has been effectually integrated with a medical smart patch for electric pulsatile mediated controlled drug release. Hence, our as-designed self-charging power pack possesses immense potentials for self-powered multifunctional electronics and smart e-healthcare monitoring systems.
In the recommendation system, collaborative filtering methods based on the graph convolution network can explicitly model the interaction between the nodes of the user-item bipartite graph and effectively use higher-order neighbor information. However, its representations are very susceptible to the noise of interaction. In response to this problem, SGL explored the self-supervised learning on the user-item graph to improve the robustness of GCN. Nevertheless, the contrastive learning framework it applied does not consider the specificity of the recommendation task and the uncertainty of user-item interaction fully.In order to solve the above problems, we propose a learning paradigm called supervised contrastive learning (SCL) based on the graph convolutional neural network. We carefully design SCL guided by the basic idea of the recommendation task that users with similar interaction histories have similar interests and preferences. Specifically, we will calculate the similarity between different nodes on the user side and the item side respectively during data preprocessing firstly. And then when applying contrastive learning, not only will the augmented samples be regarded as the positive samples, but also a certain number of augmented samples of similar nodes will be regarded as the positive samples, which is different with SGL that treats other samples in a batch as negative samples. SCL purposefully makes representations learned by similar nodes close to each other in the feature space. In addition, to address the uncertainty of node interaction, we also propose a new data augment method called node replication. We apply SCL on the most advanced LightGCN. Empirical research and ablation study on Gowalla, Yelp2018, and Amazon-Book datasets prove the effectiveness, accuracy, and robustness of SCL and node replication.(c) 2022 Published by Elsevier B.V.
The g-C3N4 (GCN) adsorbent with two different morphologies, coral (CGCN) and nano fiber (GCNNF), was synthesized and recruited for extraction and preconcentration of lead and copper metal ions by effervescent salt-assisted dispersive micro solid phase extraction procedure. The structures of the two adsorbents were affirmed by Fourier-transform infrared spectroscopy, X-ray diffraction, field emission scanning electron microscopy and Brunauer-Emmett-Teller analyses. The factors affecting the extraction efficiency were carefully studied and the optimum values of the parameters for both adsorbents were pH 6.5, adsorbent dosage 8 mg, desorption time 3 min, and the elution solvent 300 mu L of 2 mol L-1 of HNO3. The detection limits of Pb(II (and Cu(II) ions for CGCN were 0.9 and 0.3 mu gL(-1) and for GCNNF were 1.56 and 0.7 mu gL(-1), respectively. The percent relative standard deviations were obtained to be 1.32% and 2.23% for CGCN (n = 3) and 1.24% and 2.29% for GCNNF (n = 3), respectively for the lead and copper metal ions. In addition, the adsorbents could be used up to 7 times without an imperative reduction in the percentages of analytes recovery. Finally, the performance of CGCN and GCNNF were used for preconcentrate of lead and copper ions in honey, canned fish, and human hair samples.
Gene co-expression networks (GCNs) have been developed as relevant analytical tools for the study of the gene expression patterns behind complex phenotypes. Determining the association between structure and function in GCNs is a current challenge in biomedical research. Several structural differences between GCNs of breast cancer and healthy phenotypes have been reported. In a previous study, using co-expression multilayer networks, we have shown that there are abrupt differences in the connectivity patterns of the GCN of basal-like breast cancer between top co-expressed gene-pairs and the remaining gene-pairs. Here, we compared the top-100,000-interactions networks for the four breast cancer phenotypes (Luminal-A, Luminal-B, Her2+ and Basal), in terms of structural properties. For this purpose, we used the graph-theoretical k-core of a network (maximal sub-network with nodes of degree at least k). We developed a comprehensive analysis of the network k-core (k = 30) structures in cancer, and its relationship with biological functions. We found that in the Top-100,000edges networks, the majority of interactions in breast cancer networks are intra-chromosome, meanwhile inter-chromosome interactions serve as connecting bridges between clusters. Moreover, core genes in the healthy network are strongly associated with processes such as metabolism and cell cycle. In breast cancer, only the core of Luminal A is related to those processes, and genes in its core are over-expressed. The intersection of the core nodes in all subtypes of cancer is composed only by genes in the chr8q24.3 region. This region has been observed to be highly amplified in several cancers before, and its appearance in the intersection of the four breast cancer k-cores, may suggest that local co-expression is a conserved phenomenon in cancer. Considering the many intricacies associated with these phenomena and the vast amount of research in epigenomic regulation which is currently undergoing, there is a need for further research on the epigenomic effects on the structure and function of gene co-expression networks in cancer.
The present work accentuated on preparation of phosphorous doped g-C(3)N(4)modified AgBr/V2O5 (AgBr/VO) nanocomposite and its applicability in photocatalysis of phenol. g-C3N4 (GCN) and phosphorous doped g-C3N4 (PCN) were fabricated via thermal polycondensation method using dicyandiamide and diammonium hydrogen phosphate as precursors. Heterojunctioned Ag/AgBr/V2O5/PCN ternary nanocomposite was fabricated via single-step hydrothermal method. The morphological study of ternary nanocomposite displayed uniform decoration of AgBr/V2O5 nanoparticles on PCN surface. Ag/AgBr/V2O5/PCN nanocomposite displayed advanced photocatalytic efficacy as compared to bare PCN, AgBr and V2O5 (VO). The improved photodegradation ability of Ag/AgBr/VO/PCN nanocomposite was ascribed to appropriate band alignment as well as Z-scheme electron hole pair generation which were facilitated by good storage and transmission of electron through Ag among PCN, AgBr and VO and resulted reduction in photoinduced charge carrier recombination. PL analysis confirmed the proposed mechanism for extended visible-light response of Ag/AgBr/VO/PCN nanocomposites. Lastly, recyclability along with mechanistic description detailing phenol photodegradation via Ag/AgBr/VO/PCN, Ag/AgBr/VO and PCN photocatalysts was also reconnoitered and removal efficiency was observed to be 99%, 65% and 54%, respectively. The proposed photocatalytic mechanism study signposted that h(+), (OH), O-2(-) radicals are foremost reactive species that play vital role in photodegradation process.
A major challenge concerning a mixed traffic flow system, composed of connected autonomous vehicles (CAVs) and human-driven vehicles (HDVs), is how to improve overall efficiency and safety by assigning appropriate control strategies to CAVs. Deep reinforcement learning (DRL) is a promising approach to address this challenge. It enables the joint training of multiple CAVs by fusing CAV sensing information and does not need compliance of HDVs. However, the fusion of CAV sensing information is non-trivial. Traditional DRL models usually fail to take advantage of connectivity among CAVs and time series characteristics of vehicle sensing information, leading to insufficient awareness of the traffic environment. Aimed at tackling these issues, this study proposes a DRL framework named spatiotemporal deep Q network (STDQN), by integrating a double deep Q network (DDQN) and a spatiotemporal information extraction module. A long-short term memory neural network with an attention mechanism (AttenLSTMNN) is leveraged to extract temporal dependencies from vehicle perceptive information. In addition, a graph convolution network (GCN) is employed to model the spatial correlations among vehicles in a local range, as well as the connectivity of multiple CAVs in a global range. Simulation experiments are conducted in an onramp merging scenario, which is one of the most important and commonly seen scenarios in highway or city expressway systems. Experimental results prove that as compared to baseline DRL and rule-based methods, the proposed STDQN can improve the overall traffic efficiency, safety, and driving comfort. The proposed framework is promised to be deployed into real CAVs, to realize cooperative, safe, and efficient autonomous driving.(c) 2022 Elsevier B.V. All rights reserved.
Shared-account cross-domain sequential recommendation (SCSR) task aims to recommend the next item via leveraging the mixed user behaviors in multiple domains. It is gaining immense research attention as more and more users tend to sign up on different platforms and share accounts with others to access domain-specific services. Existing works on SCSR mainly rely on mining sequential patterns via recurrent neural network (RNN)-based models, which suffer from the following limitations: 1) RNN-based methods overwhelmingly target discovering sequential dependencies in single-user behaviors and they are not expressive enough to capture the relationships among multiple entities in SCSR; 2) all existing methods bridge two domains via knowledge transfer in the latent space and ignore the explicit cross-domain graph structure; and 3) none existing studies consider the time interval information among items, which is essential in the sequential recommendation for characterizing different items and learning discriminative representations for them. In this work, we propose a new graph-based solution, namely, time interval-enhanced domain-aware graph convolutional network (TiDA-GCN), to address the above challenges. Specifically, we first link users and items in each domain as a graph. Then, we devise a domain-aware graph convolution network to learn user-specific node representations. To fully account for users' domain-specific preferences on items, two effective attention mechanisms are further developed to selectively guide the message-passing process. Moreover, to further enhance item-and account-level representation learning, we incorporate the time interval into the message passing and design an account-aware self-attention module for learning items' interactive characteristics. Experiments demonstrate the superiority of our proposed method from various aspects.
Nowadays, hybrid photocatalysts are gaining importance due to their improved photo-catalytic activity. In the present work, Ag2CO3 was integrated phosphorous and sulphur co-doped g-C3N4 (PSGCN) photocatalyst (Ag2CO3/PSGCN) to minimize the recombination of photogenerated electron-hole pair. The co-doping resulted in band gap lowering in GCN leading to more visible light activity. Successful formation of well dispersed Ag2CO3/PSGCN suspension in water was established by zeta potential and Tyndall effect experiments. Phosphorous and sulphur co-doping in g-C3N4 resulted lowering of optical band gap that enhanced its photodegradation ability under visible light. The reduction in photogenerated electron-hole pair recombination was confirmed by photoluminescence and electrochemical impedance analysis. The photodegradation of 2, 4, dinitrophenol (DNP) followed pseudo first order kinetics and enhanced photocatalytic activity was due to semiconductor heterojunction for effective separation of electron-hole pair. Holes and hydroxyl radicals were two main oxidative species responsible for photodegradation of DNP into nontoxic products. COD, HPLC and LC-MS investigations were used to investigate the degradation fragment during DNP mineralization. Ag2CO3/PSGCN nanocomposite revealed high stability and recycle efficiency substantial for ten catalytic cycles. (C) 2018 Production and hosting by Elsevier B.V. on behalf of King Saud University.
Accurate and timely traffic flow prediction is crucial for intelligent transportation systems (ITS). Recent advances in graph-based neural networks have achieved promising prediction results. However, some challenges remain, especially regarding graph construction and the time complexity of models. In this paper, we propose a multi-stream feature fusion approach to extract and integrate rich features from traffic data and leverage a data-driven adjacent matrix instead of the distance-based matrix to construct graphs. We calculate the Spearman rank correlation coefficient between monitor stations to obtain the initial adjacent matrix and fine-tune it while training. As to the model, we construct a multi-stream feature fusion block (MFFB) module, which includes a three-channel network and the soft-attention mechanism. The three-channel networks are graph convolutional neural network (GCN), gated recurrent unit (GRU) and fully connected neural network (FNN), which are used to extract spatial, temporal and other features, respectively. The soft-attention mechanism is utilized to integrate the obtained features. The MFFB modules are stacked, and a fully connected layer and a convolutional layer are used to make predictions. We conduct experiments on two real-world traffic prediction tasks and verify that our proposed approach outperforms the state-of-the-art methods within an acceptable time complexity.
The current work emphasized the facile fabrication of PCN/GO nanocomposites via a straight forward sonochemical method. The thermal polycondensation method was used for the preparation of graphitic carbon nitride (GCN) and phosphorous doped graphitic carbon nitride (PCN) photocatalysts using melamine and BmimPF(6)(1-Butyl-3-methylimidazolium hexafluorophosphate) precursors. Phosphorous doped g-C(3)N(4)with different wt % ratio of phosphorous (0.05, 0.1, and 0.3%) was successfully fabricated and coupled with graphitic oxide (GO) for malathion degradation and bacterial disinfection. Phosphorous doping improved the electronic and textual properties of g-C(3)N(4)and augmented solar light-responsive range. On the other hand, simultaneously, the GO support simultaneously facilitated the charge separation and transportation, which was validated by PL and EIS analysis. The extremely organized porous structure of PCN/GO nanosheets expanded active sites, quickened electron transmission rate, and caused strong adsorption of pollutants. Specific surface area (S-BET) of 0.1 wt% PCN/GO and PCN photocatalysts was 13.6840 and 2.8401 m(2) g(-1), respectively. The addition of peroxymonosulfate (PMS) in photodegradation processes augmented the photodegradation ability of nanocomposites due to the triggering of sulfate radical (SO4 center dot(-)) based advanced oxidation process. The influence of different reaction parameters, including a concentration of PMS, catalyst dosage, initial concentration of the pesticide, and pH, was also assessed in the photodegradation process. All the photodegradation processes followed the pseudo-first-order kinetics as the regression coefficient (R-2), and values of linear graphs were from 0.95 to 0.98. The nanocomposite 0.1 wt% PCN/GO/PMS displayed the highest photodegradation efficiency, i.e., 98%, followed by 0.1 wt% PCN/GO (95%) and other photocatalysts. Similarly, 98%Escherichia coli(E.Coli) bacterial disinfection was observed for 0.1 wt% PCN/GO nanocomposite.
The globalization of the integrated circuit (IC) supply chain has moved most of the design, fabrication, and testing process from a single trusted entity to various untrusted third-party entities worldwide. The risk of using untrusted third-Party Intellectual Property (3PIP) is the possibility for adversaries to insert malicious modifications known as Hardware Trojans (HTs). These HTs can compromise the integrity, deteriorate the performance, deny the service, and alter the functionality of the design. While numerous HT detection methods have been proposed in the literature, the crucial task of HT localization is overlooked. Moreover, a few existing HT localization methods have several weaknesses: reliance on a golden reference, inability to generalize for all types of HT, lack of scalability, low localization resolution, and manual feature engineering/property definition. To overcome their shortcomings, we propose a novel, golden reference-free HT localization method at the pre-silicon stage by leveraging graph convolutional network (GCN). In this work, we convert the circuit design into its intrinsic data structure, graph, and extract the node attributes. Afterward, the graph convolution performs automatic feature extraction for nodes to classify the nodes as Trojan or benign. Our approach is automated and does not burden the designer with manual code review. It locates the Trojan signals with 99.6% accuracy, 93.1% F1-score, and a false-positive rate below 0.009%.
The video captioning task aims to describe video content using several natural-language sentences. Although one-step encoder-decoder models have achieved promising progress, the generations always involve many errors, which are mainly caused by the large semantic gap between the visual domain and the language domain and by the difficulty in long-sequence generation. The underlying challenge of video captioning, i.e., sequence-to-sequence mapping across different domains, is still not well handled. Inspired by the proofreading procedure of human beings, the generated caption can be gradually polished to improve its quality. In this paper, we propose a deep reinforcement polishing network (DRPN) to refine the caption candidates, which consists of a word-denoising network (WDN) to revise word errors and a grammar-checking network (GCN) to revise grammar errors. On the one hand, the long-term reward in deep reinforcement learning benefits the long-sequence generation, which takes the global quality of caption sentences into account. On the other hand, the caption candidate can be considered a bridge between visual and language domains, where the semantic gap is gradually reduced with better candidates generated by repeated revisions. In experiments, we present adequate evaluations to show that the proposed DRPN achieves comparable and even better performance than the state-of-the-art methods. Furthermore, the DRPN is model-irrelevant and can be integrated into any video captioning models to refine their generated caption sentences.
Grapevine (Vitis vinifera L.) is a widely cultivated fruit crop whose growth and productivity are greatly affected by low temperatures. On the other hand, wild Vitis species represent valuable genetic resources of natural stress tolerance. We have isolated and characterized a MYB-like gene encoding a putative GARP-type transcription factor from Amur grape (V. amurensis) designated as VaAQUILO. AQUILO (AQ) is induced by cold in both V. amurensis and V. vinifera, and its overexpression results in significantly improved tolerance to cold both in transgenic Arabidopsis and in Amur grape calli. In Arabidopsis, the ectopic expression of VaAQ increased antioxidant enzyme activities and up-regulated reactive oxygen species-(ROS) scavenging-related genes. Comparative mRNA sequencing profiling of 35S: VaAQ Arabidopsis plants suggests that this transcription factor is related to phosphate homeostasis like their Arabidopsis closest homologues: AtHRS1 and AtHHO2. However, when a cold stress is imposed, AQ is tightly associated with the cold-responsive pathway and with the raffinose family oligosaccharides (RFOs), as observed by the up-regulation of galactinol synthase (GoLS) and raffinose synthase genes. Gene co-expression network (GCN) and cis-regulatory element (CRE) analyses in grapevine indicated AQ as potentially regulating VvGoLS genes. Increased RFO content was confirmed in both transgenic Arabidopsis and Amur grape calli overexpressing VaAQ. Taken together, our results imply that AQ improves cold tolerance through promoting the accumulation of osmoprotectants.
Pixels of clouds and cloud shadows in a remote sensing image impact image quality, image interpretation, and subsequent applications. In this paper, we propose a novel cloud removal method based on deep learning that automatically reconstructs the invalid pixels with the auxiliary information from multi-temporal images. Our method's innovation lies in its feature extraction and loss functions, which reside in a novel gated convolutional network (GCN) instead of a series of common convolutions. It takes the current cloudy image, a recent cloudless image, and the mask of clouds as input, without any requirements of external training samples, to realize a self-training process with clean pixels in the bi-temporal images as natural training samples. In our feature extraction, gated convolutional layers, for the first time, are introduced to discriminate cloudy pixels from clean pixels, which make up for a common convolution layer's lack of the ability to discriminate. Our multi-level constrained joint loss function, which consists of an image-level loss, a feature-level loss, and a total variation loss, can achieve local and global consistency both in shallow and deep levels of features. The total variation loss is introduced into the deep-learning-based cloud removal task for the first time to eliminate the color and texture discontinuity around cloud outlines needing repair. On the WHU cloud dataset with diverse land cover scenes and different imaging conditions, our experimental results demonstrated that our method consistently reconstructed the cloud and cloud shadow pixels in various remote sensing images and outperformed several mainstream deep-learning-based methods and a conventional method for every indicator by a large margin.
With the rapid development of high-tech multimedia technologies, many musical resource assets are available online and it has always triggered an interest in the classification of different music genres. Detecting a set of music belonging to a similar genre is the main intention of the music recommendation playlist. With the help of machine learning, transfer learning and deep learning concepts, a robust music classifier is necessary so that the unlabelled music can be easily tagged and thereby the users experience of using media players with music files can be improved. The existing approaches in the past decade has various shortcomings due to the manual extraction of features followed by traditional machine learning classification techniques affecting the classification accuracy to a great extent along with its drawback to not perform well on multiclass classification problems and its inability to deal with huge data size. In this work, five interesting and novel approaches are proposed for music genre classification such as the proposed Weighted Visibility Graph based Elastic Net Sparse Classifier (WVG-ELNSC), the proposed classification using sequential machine learning analysis with Stacked Denoising Autoencoder (SDA) classifier, the proposed Riemannian Alliance based Tangent Space Mapping (RA-TSM) transfer learning techniques, classification using Transfer Support Vector Machine (TSVM) algorithm, and finally the proposed deep learning classifier with Bidirectional Long Short-Term Memory (BiLSTM) cum Attention model with Graphical Convolution Network (GCN) termed as BAG deep learning model is used here. The experiments are done for three music datasets such as GTZAN, ISMIR 2004 and MagnaTagATune datasets and a relatively higher classification accuracy of 93.51% is obtained when the proposed deep learning BAG model is utilized.
This paper addresses video highlight detection which aims to select a small subset of frames according to user's major or special interest. The performances of conventional methods highly depend on large-scale manually labeled training data which are time-consuming and labor-intensive to collect. To deal with this problem, we trace back to the original problem definition and find that whether a user is interested in a specific video segment heavily depends on human's subjective emotions. Leveraging this insight, we introduce an emotion knowledge driven video detection framework for modeling human's general emotion and inferencing highlight strength. Firstly, we obtain the concept-level representation of the video clip with a front-end network. The concepts are used as nodes to build an emotion-related knowledge graph, and their relationships in the graph are modeled via external public knowledge graphs. Then we adopt Siamese GCNs to model the dependencies between nodes in the graph and propagate messages along the edges. Finally, we compute the emotion-aware representation of the video clip based on the GCN layers and further use it to predict the highlight score. Our framework, including the front-end network, graph convolution layers and the highlight mapping network, can be trained in an end-to-end manner with the constraint of a ranking loss. Experiments on two benchmark datasets show that our proposed method performs favorably against the state-of-the-art methods.
Typhoons are some of the most serious natural disasters, and the key to disaster prevention and mitigation is typhoon level classification. How to better use data of satellite cloud pictures to achieve accurate classification of typhoon levels has become one of classification the hot issues in current studies. A new framework of deep learning neural network, Graph Convolutional-Long Short-Term Memory Network (GC-LSTM), is proposed, which is based on the data of satellite cloud pictures of the Himawari-8 satellite in 2010-2019. The Graph Convolutional Network (GCN) is used to process the irregular spatial structure of satellite cloud pictures effectively, and the Long Short-Term Memory (LSTM) network is utilized to learn the characteristics of satellite cloud pictures over time. Moreover, to verify the effectiveness and accuracy of the model, the prediction effect and model stability are compared with other models. The results show that: the algorithm performance of this model is better than other prediction models; the prediction accuracy rate of typhoon level classification reaches 92.35%, and the prediction accuracy of typhoons and super typhoons reaches 95.12%. The model can accurately identify typhoon eye and spiral cloud belt, and the prediction results are always kept in the minimum range compared with the actual results, which proves that the GC-LSTM model has stronger stability. The model can accurately identify the levels of different typhoons according to the satellite cloud pictures. In summary, the results can provide a theoretical basis for the related research of typhoon level classification.
With the development of data plane programmable Software-Defined Networking (SDN), Distributed Denial of Service (DDoS) attacks on the data plane increasingly become fatal. Currently, traditional attack detection methods are mainly used to detect whether a DDoS attack occurs and it is difficult to find the path that the attack flow traverses the network, which makes it difficult to accurately mitigate DDoS attacks. In this article, we propose a detection method based on Spatial-Temporal Graph Convolutional Network (ST-GCN) over the data plane programmable SDN, which maps the network into a graph. It senses the state of switches through In-band Network Telemetry (INT) with sampling, inputs the network state into the spatial-temporal graph convolutional network detection model, and finally finds out the switches through which DDoS attack flows pass. Based on this, we propose a defense method combined with an enhanced whitelist and a precise dropping strategy, which can effectively mitigate DDoS attacks and minimize the impact on legitimate network traffic. The evaluation results show that our detection method can accurately detect the path that the DDoS attack flows pass through, and can effectively mitigate the DDoS attack. Compared to classic methods, our method improves the detection accuracy by nearly 10%. At the same time, the southbound interface load and CPU overhead brought by our detection and defense process are much lower than the classic methods.
Most publicly available datasets for image classification are with single labels, while images are inherently multilabeled in our daily life. Such an annotation gap makes many pretrained single-label classification models fail in practical scenarios. For aerial images, this annotation issue is more concerned: Aerial data naturally cover a relatively large land area with multiple labels, while annotated aerial datasets currently publicly available (e.g., UCM and AID) are single-labeled. As manually annotating multilabel aerial images (MAIs) would be time-/ labor-consuming, we propose a novel self-correction integrated domain adaptation (SCIDA) method for automatic multilabel learning. SCIDA is weakly supervised, i.e., automatically learning the multilabel image classification model from using massive, publicly available single-label images. To achieve this goal, we propose a novel labelwise self-correction (LWC) module to better explore underlying label correlations. This module also makes the unsupervised domain adaptation (UDA) from single-label to multilabel data possible. For model training, the proposed method uses single-label information yet requires no prior knowledge of multilabeled data and predicts labels for MAIs. Through extensive evaluations, the proposed model, which is trained with single-labeled MAI-AID-s and MAI-UCM-s datasets, achieves much better performances than comparative methods on our collected multiscene aerial image dataset. The code and data are available on GitHub (https://github.com/Ryan315/Single2multi-DA).
A deep understanding of our visual world is more than an isolated perception on a series of objects, and the relationships between them also contain rich semantic information. Especially for those satellite remote sensing images, the span is so large that the various objects are always of different sizes and complex spatial compositions. Therefore, the recognition of semantic relations is conducive to strengthen the understanding of remote sensing scenes. In this paper, we propose a novel multi-scale semantic fusion network (MSFN). In this framework, dilated convolution is introduced into a graph convolutional network (GCN) based on an attentional mechanism to fuse and refine multi-scale semantic context, which is crucial to strengthen the cognitive ability of our model Besides, based on the mapping between visual features and semantic embeddings, we design a sparse relationship extraction module to remove meaningless connections among entities and improve the efficiency of scene graph generation. Meanwhile, to further promote the research of scene understanding in remote sensing field, this paper also proposes a remote sensing scene graph dataset (RSSGD). We carry out extensive experiments and the results show that our model significantly outperforms previous methods on scene graph generation. In addition, RSSGD effectively bridges the huge semantic gap between low-level perception and high-level cognition of remote sensing images.
Spleen volume estimation using automated image segmentation technique may be used to detect splenomegaly (abnormally enlarged spleen) on Magnetic Resonance Imaging (MRI) scans. In recent years, Deep Convolutional Neural Networks (DCNN) segmentation methods have demonstrated advantages for abdominal organ segmentation. However, variations in both size and shape of the spleen on MRI images may result in large false positive and false negative labeling when deploying DCNN based methods. In this paper, we propose the Splenomegaly Segmentation Network (SSNet) to address spatial variations when segmenting extraordinarily large spleens. SSNet was designed based on the framework of image-to-image conditional generative adversarial networks (cGAN). Specifically, the Global Convolutional Network (GCN) was used as the generator to reduce false negatives, while the Markovian discriminator (PatchGAN) was used to alleviate false positives. A cohort of clinically acquired 3D MRI scans (both T1 weighted and T2 weighted) from patients with splenomegaly were used to train and test the networks. The experimental results demonstrated that a mean Dice coefficient of 0.9260 and a median Dice coefficient of 0.9262 using SSNet on independently tested MRI volumes of patients with splenomegaly.
Events are happening in real world and real time, which can be planned and organized for occasions, such as social gatherings, festival celebrations, influential meetings, or sports activities. Social media platforms generate a lot of real-time text information regarding public events with different topics. However, mining social events is challenging because events typically exhibit heterogeneous texture and metadata are often ambiguous. In this article, we first design a novel event-based meta-schema to characterize the semantic relatedness of social events and then build an event-based heterogeneous information network (HIN) integrating information from external knowledge base. Second, we propose a novel Pairwise Popularity Graph Convolutional Network, named as PP-GCN, based on weighted meta-path instance similarity and textual semantic representation as inputs, to perform fine-grained social event categorization and learn the optimal weights of meta-paths in different tasks. Third, we propose a streaming social event detection and evolution discovery framework for HINs based on meta-path similarity search, historical information about meta-paths, and heterogeneous DBSCAN clustering method. Comprehensive experiments on real-world streaming social text data are conducted to compare various social event detection and evolution discovery algorithms. Experimental results demonstrate that our proposed framework outperforms other alternative social event detection and evolution discovery techniques.
Origin-Destination (OD) prediction which aims to predict the number of passenger's travel demands from one region to another, is critically important to many real applications including intelligent transportation systems and public safety. The challenges of this problem lie in both the dynamic patterns of the human mobility data and data sparsity in issue in some regions. Thus it is difficult to model the complex spatio-temporal correlations of the human mobility data to predict the OD of their trips. Meanwhile, the crowd flows in different regions of a city and the context features (e.g. holiday, weather and POIs) are potentially useful to alleviate the data sparsity issue and improve the OD prediction, but are largely ignored by existing works. In this paper, we propose a deep spatio-temporal framework which named Auxiliary-tasks Enhanced Spatio-Temporal Network (AEST) to more effectively address the OD prediction problem. AEST trains a model to conduct OD inference via learning crowd flow and external data as auxiliary task. The novel Hierarchical Convolutional LSTM (HC-LSTM) Network is proposed which combines CNN, GCN and LSTM to effectively capture spatiao-temporal correlations. In addition, we design a Contextual Network (ContextNet) which learns representations of contextual information to assist OD prediction. We conduct extensive experiments over bike and taxicab trip datasets in New York. The results show that our method is superior to the state-of-art approaches.
A simple and effective photoelectrochemical sensor was fabricated by Cu/graphitic carbon nitride (Cu/gCN) composites for detecting bisphenol A. The Cu/g-CN composites were obtained via a solvothermal process in the presence of the copper-based ionic liquid. In view of localized surface plasmon resonance of Cu nanoparticles, Cu nanoparticles can promote light absorbance and rapid electron transport of g-CN. As a result, the Cu/g-CN composites obtained greatly enhancement of photocurrent, when compared to the pure g-CN. In addition, the introduction of bisphenol A can hinder electron-hole recombination, resulting in sensitive photoelectrochemical monitoring of bisphenol A. The detection limit of the bisphenol A photoelectrochemical sensor was below 0.012 mu mol/L. The bisphenol A photoelectrochemical sensor exhibited an excellent stability and acceptable anti-interference. The photoelectrochemical sensor provided the promising platform to monitor bisphenol A at low concentration in water environment. (C) 2018 Chinese Chemical Society and Institute of Materia Medica, Chinese Academy of Medical Sciences. Published by Elsevier B.V. All rights reserved.
With accumulating dysregulated circular RNAs (circRNAs) in pathological processes, the regulatory functions of circRNAs, especially circRNAs as microRNA (miRNA) sponges and their interactions with RNA-binding proteins (RBPs), have been widely validated. However, the collected information on experimentally validated circRNA-disease associations is only preliminary. Therefore, an updated CircR2Disease database providing a comprehensive resource and web tool to clarify the relationships between circRNAs and diseases in diverse species is necessary. Here, we present an updated CircR2Disease v2.0 with the increased number of circRNA-disease associations and novel characteristics. CircR2Disease v2.0 provides more than 5-fold experimentally validated circRNA-disease associations compared to its previous version. This version includes 4201 entries between 3077 circRNAs and 312 disease subtypes. Secondly, the information of circRNA-miRNA, circRNA-miRNA-target, and circRNA-RBP interactions has been manually collected for various diseases. Thirdly, the gene symbols of circRNAs and disease name IDs can be linked with various nomenclature databases. Detailed descriptions such as samples and journals have also been integrated into the updated version. Thus, CircR2Disease v2.0 can serve as a platform for users to systematically investigate the roles of dysregulated circRNAs in various diseases and further explore the posttranscriptional regulatory function in diseases. Finally, we propose a computational method named circDis based on the graph convolutional network (GCN) and gradient boosting decision tree (GBDT) to illustrate the applications of the CircR2Disease v2.0 database. CircR2Disease v2.0 is available at http://bioinfo.snnu.edu.cn/CircR2Disease_v2.0 and https://github.com/bioinforlab/CircR2Disease-v2.0.
The histone acetyl transferase (HAT) are involved in acetylation of histones that lead to transcription activation in numerous gene regulatory mechanisms. There are very few GCN5 HAT inhibitors reported despite of their role in cancer progression. In this study, we have utilized in-silico virtual screening approaches based on various machine learning algorithm to identify potent inhibitors of GCN5 HAT from commercially available Maybridge library. We have generated predictive chemoinformatics models based on k-Nearest neighbour, naive Bayesian, Random Forest and Support Vector Machine. Based on statistical parameters, the RF and SVM models have shown comparative performance. Therefore, we performed the virtual screening with these two models and the consensus hits were selected for further evaluation using molecular docking into the active site of GCN-5 HAT. Finally, a set of 10 molecules were selected and subjected to biological evaluation. Subsequently, inhibition of acetylation shown by three out of the ten molecules in the in-vitro experiments validated their utility as potential HAT inhibitors. Furthermore, the selected hits have also shown weak cell growth decrease in MCF-7 cancer cell lines, which suggests that after subsequent structural optimization the identified molecules may further be explored for the development of anti-cancer agents.
It is always a hot issue in the intelligence analysis field to predict the trend of news description by pre-trained language models and graph neural networks. However, there are several problems in the existing research: (1) there are few Chinese data sets on this subject in academia and industry; and (2) using the existing pre-trained language models and graph classification algorithms cannot achieve satisfactory results. The method described in this paper can better solve these problems. (1) We built a Chinese news database predicted by more than 9000 annotated news time trends, filling the gaps in this database. (2) We designed an improved method based on the pre-trained language model and graph neural networks pooling algorithm. In the graph pooling algorithm, the Graph U-Nets Pooling method and self-attention are combined, which can better solve the analysis of the problem of forecasting the development trend of news events. The experimental results show that the effect of this method compared with the baseline graph classification algorithm is improved, and it also solves the shortcomings of the pre-trained language model that cannot handle very long texts. Therefore, it can be concluded that our research has strong processing capabilities for analyzing and predicting the development trend of Chinese news events.
As a vital research subject in the field of intelligent transportation systems (ITSs), traffic flow prediction using deep learning methods has attracted much attention in recent years. However, numerous existing studies mainly focus on short-term traffic flow predictions and fail to consider the influence of external factors. Effective long-term traffic flow prediction has become a challenging issue. As a solution to these challenges, this paper proposes a deep learning approach based on a spatiotemporal graph convolutional network for long-term traffic flow prediction with multiple factors. In the proposed method, our innovative idea is to introduce an attribute feature unit (AF-unit) to fuse external factors into a spatiotemporal graph convolutional network. The proposed method consists of (1) constructing a weighted adjacency matrix using Gaussian similarity functions; (2) assembling a feature matrix to store time-series traffic flow; (3) building an external attribute matrix composed of external factors, including temperature, visibility, and weather conditions; and (4) building a spatiotemporal graph convolutional network based on a deep learning architecture (i.e., T-GCN). The experimental results indicate that (1) the performance of our method considering spatiotemporal dependence has better prediction capability than baseline models; (2) the fusion of meteorological factors can reduce the inaccuracy of traffic prediction; and (3) our method has high accuracy and stability in long-term traffic flow prediction.
Traffic flow prediction is the key problem of intelligent transportation system. Accurate prediction results are indispensable for traffic management and road planning. However, due to the complex spatial-temporal correlation of traffic flow data, including the spatial correlation and temporal correlation of adjacency, periodicity, and trend that exist between different roads. The existing forecasting methods consider the spatial-temporal correlation but lack the dynamic modeling of spatial-temporal correlation. To deal with this dynamic feature, this paper proposes a multi-dimensional attention-based spatial-temporal network (MA-STN). It mainly contains three parts, the spatial-temporal attention unit, the spatial-temporal feature extraction unit based on Graph Convolutional Network (GCN) and the fusion prediction unit, and the residual connection is also added to the model to avoid the gradient disappearance problem. Meanwhile, this paper divides the dataset into three subsets to deal with the three features in the temporal dimension separately. To verify the effectiveness of the proposed model, two real-world road traffic flow data collected by PeMS system are used for validation. By comparing six different models, the proposed network in this paper has a 7% accuracy improvement compared to the baseline model. To verify the effectiveness of the attention mechanism, ablation experiments are used in this paper for validation, and the results show that the attention mechanism can achieve a 5% accuracy improvement.
General-purpose embeddings do not guarantee to produce the best representation for the target tasks. In the graph domain, random walk-based graph embedding methods like DeepWalk and Node2Vec are widely used methods that generate general-purpose embedding. These methods, however, can not achieve high accuracy in different tasks, including node classification. In contrast, semi-supervised methods such as Graph Convolutional Network (GCN), Graph Attention Network (GAT), and their extensions achieve state-of-the-art performance in this task as they use few labels for learning the most appropriate embedding. These methods, however, depend on node features and cannot achieve high performance in the absence of node features or low dimension features. In this paper, we propose GuidedWalk, a semi-supervised random walk-based graph embedding method that can outperform other random walk-based competitors as well as GNNs in the semi-supervised setting on graphs without node features. The proposed model works based on exploring graph paths with more emphasis on the paths that connect nodes of the same class. We show that the neural processing core of DeepWalk and Node2Vec propagates latent features across sampled paths. Therefore, our selected paths increase the chances of propagating the right latent features, which is appropriate for the node classification task. Our experiments on Cora, Pubmed, Twitch DE, and Facebook datasets, show 0.53%, 0.78%, 5.07%, and 7.13% improvement in node classification accuracy compared to the state-of-the-art techniques in the field.
Remaining useful life (RUL) prediction of bearing is essential to guarantee its safe operation. In recent years, deep learning (DL)-based methods attract a lot of research attention for accurate RUL prediction. However, the weak interpretability of the DL models prevents their wide use in practical systems. In this article, the graph is used to represent the degradation state of bearings, and a graph neural network (GNN) is applied for their RUL prediction. Specifically, regression shapelet is proposed to transform the bearings time series data into graph structure first. Then, with the proposed distance matrix/adjacency matrix as the input and smoothed nonlinear health index (SNHI) as the output, a deep GNN model combining graph convolutional neural network (GCN) and gate recurrent unit (GRU) is set up in both spatial and temporal perspectives to predict the bearing RUL. Meanwhile, graph evolution is adopted to monitor the graph changes with time and offer an explanation for the bearing degradation procedure. The experiment study on the PRONOSTIA platform is used to evaluate the proposed method. The results show that the proposed method can well explain the bearing degradation process from the graph perspective and will achieve superior performance to the existing methods.
As an important field of computer vision, object detection has been studied extensively in recent years. However, existing object detection methods merely utilize the visual information of the image and fail to mine the high-level semantic information of the object, which leads to great limitations. To take full advantage of multi-source information, a knowledge update-based multimodal object recognition model is proposed in this paper. Specifically, our method initially uses Faster R-CNN to regionalize the image, then applies a transformer-based multimodal encoder to encode visual region features (region-based image features) and textual features (semantic relationships between words) corresponding to pictures. After that, a graph convolutional network (GCN) inference module is introduced to establish a relational network in which the points denote visual and textual region features, and the edges represent their relationships. In addition, based on an external knowledge base, our method further enhances the region-based relationship expression capability through a knowledge update module. In summary, the proposed algorithm not only learns the accurate relationship between objects in different regions of the image, but also benefits from the knowledge update through an external relational database. Experimental results verify the effectiveness of the proposed knowledge update module and the independent reasoning ability of our model.
Hyperspectral image (HSI) classification has attracted much attention in the field of remote sensing. However, the lack of sufficient labeled training samples is a huge challenge for HSI classification. To face this challenge, we propose a semisupervised HSI classification method based on graph convolutional broad network (GCBN). First, to avoid the underfitting problem caused by the insufficient linear sparse feature representation ability of broad learning system (BLS), graph convolution operation is applied to extract nonlinear and discriminative spectral-spatial features from the original HSI to replace the linear mapping features in the traditional BLS. Second, to solve the problem of insufficient model classification ability caused by limited labeled samples, the combinatorial average method (CAM) is proposed to use valuable paired samples to generate sample expansion set for GCBN model training. Third, BLS is used to perform broad expansion on spectral-spatial features extracted by GCN and extended by CAM, which further enhances the feature representation ability. Finally, the output weights can be easily calculated by the ridge regression theory. Experimental results on three real HSI datasets demonstrate the effectiveness of our proposed GCBN.
In the skeleton-based human action recognition domain, the spatial-temporal graph convolution networks (ST-GCNs) have made great progress recently. However, they use only one fixed temporal convolution kernel, which is not enough to extract the temporal cues comprehensively. Moreover, simply connecting the spatial graph convolution layer (GCL) and the temporal GCL in series is not the optimal solution. To this end, we propose a novel enhanced spatial and extended temporal graph convolutional network (EE-GCN) in this paper. Three convolution kernels with different sizes are chosen to extract the discriminative temporal features from shorter to longer terms. The corresponding GCLs are then concatenated by a powerful yet efficient one-shot aggregation (OSA) + effective squeeze-excitation (eSE) structure. The OSA module aggregates the features from each layer once to the output, and the eSE module explores the interdependency between the channels of the output. Besides, we propose a new connection paradigm to enhance the spatial features, which expand the serial connection to a combination of serial and parallel connections by adding a spatial GCL in parallel with the temporal GCLs. The proposed method is evaluated on three large scale datasets, and the experimental results show that the performance of our method exceeds previous state-of-the-art methods.
The increasing use of distributed generation (DG) in power systems can result in frequent online voltage problems. In scenarios in which substantial DG prediction errors occur because of high DG accommodation levels, traditional technical solutions cannot meet the online voltage regulation requirements. Hence, new resources for online voltage regulation are needed. Here, flexible network reconfiguration is proposed to coordinate with the existing resources for severe online voltage deviations. For online topology-based voltage regulation (OTVR), the authors develop a deep reinforcement learning (DRL) algorithm based on the following specially designed modelling to enhance the computational performance. The mechanism of action incorporates the concepts of local research, branch exchange, and action separation, and it effectively simplifies the action dimension and action space. In addition, for the graph data in OTVR, a graph convolution network (GCN) is applied to obtain better feature extraction. Case studies performed on IEEE 14-bus, 33-bus, 141-bus systems and a practical system verify that our proposed algorithm can obtain close to optimal solutions in 2 s which can meet the needs of online voltage regulation. Moreover, we verify that the developed OTVR effectively increases DG penetration and decreases the need for investment in additional regulating devices.
Texture characterization from the metrological point of view is addressed in order to establish a physically relevant and directly interpretable feature. In this regard, a generic formulation is proposed to simultaneously capture the spectral and spatial complexity in hyperspectral images. The feature, named relative spectral difference occurrence matrix (RSDOM) is thus constructed in a multireference, multidirectional, and multiscale context. As validation, its performance is assessed in three versatile tasks. In texture classification on HyTexiLa, content-based image retrieval (CBIR) on ICONES-HSI, and land cover classification on Salinas, RSDOM registers 98.5% accuracy, 80.3% precision (for the top 10 retrieved images), and 96.0% accuracy (after post-processing) respectively, outcompeting GLCM, Gabor filter, LBP, SVM, CCF, CNN, and GCN. Analysis shows the advantage of RSDOM in terms of feature size (a mere 126, 30, and 20 scalars using GMM in order of the three tasks) as well as metrological validity in texture representation regardless of the spectral range, resolution, and number of bands.
Graph deep learning (DL)-based prognostic methods have been successfully applied in bearing remaining useful life (RUL) prediction, as graph represents spatial and temporal dependencies of signals. However, graph data-driven prediction methods using single-sensor data are still insufficiently studied, and the graph construction is not interpretable, where the physical meaning of edges is unclear. To overcome these limitations, a node-level PathGraph-based bearing RUL prediction method is proposed, where a Chebyshev graph convolutional network (ChebCGN) with bidirectional long short-term memory network (BiLSTM) is designed. The node-level PathGraph is constructed to represent the relationships among the time-discrete signals, where edges denote the chronological order and nodes represent the signals. After that, graph feature learning ability of ChebGCN-LSTM is enhanced by inputting different chronological PathGraphs related to bearings' states. In ChebGCN-LSTM, the BiLSTM captures the temporal information, overcoming the limitation of ChebGCN that ignored global temporal dependencies of signals. The constructed PathGraphs are input to ChebGCN-LSTM simultaneously to realize RUL prediction. Experimental results on case studies verify the effectiveness of the proposed bearing RUL prediction method.
Traffic accident prediction on road levels and minute levels plays an important role in optimizing public safety and improving traffic infrastructure. However, there are still some challenges in this work. Firstly, the dynamic factors (e.g. traffic flow) affecting traffic accidents make the road network have dynamic spatio-temporal dependency, which leads to biased prediction results. Secondly, the occurrence of traffic accidents is a small probability event, which brings about zero-inflation problem. To address aforementioned problems, the authors propose a Multi-Attention Dynamic Graph Convolution Network with Cost Sensitive Learning approach (MADGCN). Specifically, in the spatial dimension, MADGCN calculates the attention scores of different types of dynamic factors through attention mechanism to simulate the different influence degrees of different factors, and models dynamic inter-road spatial correlation through Graph Convolution Network (GCN). In the temporal aspect, MADGCN adaptively models the dynamic temporal correlations through self-attention blocks. In addition, MADGCN improves the loss function based on cost-sensitive learning strategy to increase the cost of false classification of positive samples, so as to accurately mine sparse positive samples. Experimental results on two real-world traffic accident datasets demonstrate the superiority of MADGCN. Compared with the existing state-of-the-art methods, F1-score of MADGCN on two real-world traffic accident datasets is improved by 11.61% and 9.15%, respectively.
In skeleton-based human action recognition domain, the methods based on graph convolution networks have great success recently. However, most graphical neural networks consider the skeleton as a spatiotemporally uncorrelated graph and rely on a predetermined adjacency matrix, ignoring the spatiotemporal relevance of human actions and taking up significant computational costs. Meanwhile, the methods use graph convolution to focus too much on the neighboring nodes of the joints and ignore the totality of the action. In this work, we propose a lightweight but efficient neural network called NLB-ACSE based on the Graph Convolutional Network (GCN). Our model consists of two large branches: non-local block branch that focuses on the long distance features and adaptive cross-spacetime edge branch that focuses on the short distance features. Both branches extract information across time and space, and focus on long and short information. Some simple but effective strategies also are applied to our model, such as semantics, maxpooling, and fusion inputs, which have small parameter burden but obtain a higher accuracy on ablation study. The proposed method with an order of magnitude smaller size than most previous papers is evaluated on three large datasets, NTU60, NTU120, and Northwesten-UCLA. The experimental results show that our method achieves the state-of-the-art performance.
Solar irradiance forecasting is fundamental and essential for commercializing solar energy generation by overcoming output variability. Accurate forecasting depends on historical solar irradiance data, correlations between various meteorological variables (e.g., wind speed, humidity, and cloudiness), and influences between the weather contexts of spatially adjacent regions. However, existing studies have been limited to spatiotemporal analysis of a few variables, which have clear correlations with solar irradiance (e.g., sunshine duration), and do not attempt to establish atmospheric contextual information from a variety of meteorological variables. Therefore, this study proposes a novel solar irradiance forecasting model that represents atmospheric parameters observed from multiple stations as an attributed dynamic network and analyzes temporal changes in the network by extending existing spatio-temporal graph convolutional network (ST-GCN) models. By comparing the proposed model with existing models, we also investigated the contributions of (i) the spatial adjacency of the stations, (ii) temporal changes in the meteorological variables, and (iii) the variety of variables to the forecasting performance. We evaluated the performance of the proposed and existing models by predicting the hourly solar irradiance at observation stations in the Korean Peninsula. The experimental results showed that the three features are synergistic and have correlations that are difficult to establish using single-aspect analysis.
Most stock price predictive models merely rely on the target stock's historical informa-tion to forecast future prices, where the linkage effects between stocks are neglected. However, a group of prior studies has shown that the leverage of correlations between stocks could significantly improve the predictions. This article proposes a unified time-series relational multi-factor model (TRMF), which composes a self-generating relations (SGR) algorithm that can extract relational features automatically. In addition, the TRMF model integrates stock relations with other multiple dimensional features for the price prediction compared to extant works. Experimental validations are performed on the NYSE and NASDAQ data, where the model is compared with the popular methods such as attention Long Short-Term Memory network (Attn-LSTM), Support Vector Regression (SVR), and multi-factor framework (MF). Results show that compared with these extant methods, our model has a higher expected cumulative return rate and a lower risk of return volatility.
Multi-label semantic decoding is a challenging task with great scientific significance and application value. The existing methods mainly focus on label learning and ignore the amount of information contained in the sample itself, especially non-image sample, which may limit their performance. To address these issues, we propose a novel semi-supervised modality assistance co-training network, which utilizes image modality to assist non-image modality for multi-label learning. In real application, there are two thorny issues: (i) non-image modality tends to be missing owing to the difficulty in obtaining them; (ii) although the image modality is easy to obtain from the Internet, image label annotation is still time-consuming and expensive. Therefore, the proposed method utilizes a small number of paired & labeled images and non-image modalities, and a large number of unpaired & unlabeled images from web sources to improve results. It consists of the modality-specific feature generators, the feature translators and the label relationship network. Specifically, the modality-specific feature generators are used to generate different features (views) for each modality. Semantic translators are employed to capture the relationship between the paired modalities and impute the missing modality feature by using unpaired & unlabeled images. Label relation network is a graph convolution network (GCN) aiming to capture the correlation between labels. To mine the information in unlabeled features, the co-training mechanism is considered. With this mechanism, we introduce a multi-view orthogonality constraint and a multi-label co-regularization constraint. Extensive experiments on three computer vision and neuroscience datasets demonstrate the effectiveness of the proposed method.
A novel smart metering technique capable of anomaly detection was proposed for real-time home power management system. Smart meter data generated in real-time were obtained from 900 households of single apartments. To detect outliers and missing values in smart meter data, a deep learning model, the autoencoder, consisting of a graph convolutional network and bidirectional long short-term memory network, was applied to the smart metering technique. Power management based on the smart metering technique was executed by multi-objective optimization in the presence of a battery storage system and an electric vehicle. The results of the power management employing the proposed smart metering technique indicate a reduction in electricity cost and amount of power supplied by the grid compared to the results of power management without anomaly detection.
STUDY QUESTION Is there an association between low-to-moderate levels of prenatal alcohol exposure (PAE) and children's facial shape? SUMMARY ANSWER PAE before and during pregnancy, even at low level (<12 g of alcohol per week), was found associated with the facial shape of children, and these associations were found attenuated as children grow older. WHAT IS KNOWN ALREADY High levels of PAE during pregnancy can have significant adverse associations with a child's health development resulting in recognizably abnormal facial development. STUDY DESIGN, SIZE, DURATION This study was based on the Generation R Study, a prospective cohort from fetal life onwards with maternal and offspring data. We analyzed children 3-dimensional (3D) facial images taken at ages 9 (n = 3149) and 13 years (n = 2477) together with the data of maternal alcohol consumption. PARTICIPANTS/MATERIALS, SETTING, METHODS We defined six levels of PAE based on the frequency and dose of alcohol consumption and defined three tiers based on the timing of alcohol exposure of the unborn child. For the image analysis, we used 3D graph convolutional networks for non-linear dimensionality reduction, which compressed the high-dimensional images into 200 traits representing facial morphology. These 200 traits were used for statistical analysis to search for associations with PAE. Finally, we generated heatmaps to display the facial phenotypes associated with PAE. MAIN RESULTS AND THE ROLE OF CHANCE The results of the linear regression in the 9-year-old children survived correction for multiple testing with false discovery rate (FDR). In Tier 1 where we examined PAE only before pregnancy (exposed N = 278, unexposed N = 760), we found three traits survived FDR correction. The lowest FDR-P is 1.7e-05 (beta = 0.021, SE = 0.0040) in Trait #29; In Tier 2b where we examine any PAE during first trimester (exposed N = 756; unexposed N = 760), we found eight traits survived FDR correction. The lowest FDR-P is 9.0e-03 (beta = -0.013, SE = 0.0033) in Trait #139. Moreover, more statistically significant facial traits were found in higher levels of PAE. No FDR-significant results were found in the 13-year-old children. We map these significant traits back to the face, and found the most common detected facial phenotypes included turned-up nose tip, shortened nose, turned-out chin, and turned-in lower-eyelid-related regions. LIMITATIONS, REASONS FOR CAUTION We had no data for alcohol consumption more than three months prior to pregnancy and thus do not know if maternal drinking had chronic effects. The self-reported questionnaire might not reflect accurate alcohol measurements because mothers may have denied their alcohol consumption. WIDER IMPLICATIONS OF THE FINDINGS Our results imply that facial morphology, such as quantified by the approach we proposed here, can be used as a biomarker in further investigations. Furthermore, our study suggests that for women who are pregnant or want to become pregnant soon, should quit alcohol consumption several months before conception and completely during pregnancy to avoid adverse health outcomes in the offspring. STUDY FUNDING/COMPETING INTEREST(S) This work was supported by Erasmus Medical Centre, Rotterdam, the Erasmus University Rotterdam, and the Netherlands Organization for Health Research. V.W.V.J. reports receipt of funding from the Netherlands Organization for Health Research (ZonMw 90700303). W.J.N. is a founder, a scientific lead, and a shareholder of Quantib BV.
Background Artificial intelligences (AIs) are emerging in the field of medical informatics in many areas. They are mostly used for diagnosis support in medical imaging but have potential uses in many other fields of medicine where large datasets are available. Aim To develop an artificial intelligence (AI) "ToxNet", a machine-learning based computer-aided diagnosis (CADx) system, which aims to predict poisons based on patient's symptoms and metadata from our Poison Control Center (PCC) data. To prove its accuracy and compare it against medical doctors (MDs). Methods The CADx system was developed and trained using data from 781,278 calls recorded in our PCC database from 2001 to 2019. All cases were mono-intoxications. Patient symptoms and meta-information (e.g., age group, sex, etiology, toxin point of entry, weekday, etc.) were provided. In the pilot phase, the AI was trained on 10 substances, the AI's prediction was compared to naive matching, literature matching, a multi-layer perceptron (MLP), and the graph attention network (GAT). The trained AI's accuracy was then compared to 10 medical doctors in an individual and in an identical dataset. The dataset was then expanded to 28 substances and the predictions and comparisons repeated. Results In the pilot, the prediction performance in a set of 8995 patients with 10 substances was 0.66 +/- 0.01 (F1 micro score). Our CADx system was significantly superior to naive matching, literature matching, MLP, and GAT (p < 0.005). It outperformed our physicians experienced in clinical toxicology in the individual and identical dataset. In the extended dataset, our CADx system was able to predict the correct toxin in a set of 36,033 patients with 28 substances with an overall performance of 0.27 +/- 0.01 (F1 micro score), also significantly superior to naive matching, literature matching, MLP, and GAT. It also outperformed our MDs. Conclusion Our AI trained on a large PCC database works well for poison prediction in these experiments. With further research, it might become a valuable aid for physicians in predicting unknown substances and might be the first step into AI use in PCCs.
Background: The workflow of prostate cancer diagnosis and grading is cumbersome and the results suffer from substantial inter-observer variability. Recent trials have shown potential in using machine learning to develop automated systems to address this challenge. Most automated deep learning systems for prostate cancer Gleason grading focused on supervised learning requiring demanding fine-grained pixel-level annotations. Methods: A weakly-supervised deep learning model with slide-level labels is presented in this study for the diagnosis and grading of prostate cancer with whole slide image (WSI). WSIs are first cropped into small patches and then processed with a deep learning model to extract patch-level features. A graph convolution network (GCN) is used to aggregate the features for classifications. Throughout the training process, the noisy labels are progressively filtered out to reduce inter-observer variations in clinical reports. Finally, multi-center independent test cohorts with 6,174 slides are collected to evaluate the prostate cancer diagnosis and grading performance of our model. Results: The cancer diagnosis (2-level classification) results on two external test sets (n = 4,675, n = 844) show an area under the receiver operating characteristic curve (AUC) of 0.985 and 0.986. The Gleason grading (6-level classification) results reach 0.931 quadratic weighted kappa on the internal test set (n = 531). It generalizes well on the external test dataset (n = 844) with 0.801 quadratic weighted kappa with the reference standard set independently. The model enables pathological meaningful interpretability by visualizing the most attended lesions which are highly consistent with expert annotations. Conclusion: The proposed model incorporates a graph network in weakly supervised learning with only slide -level reports. A robust learning strategy is also employed to correct the label noise. It is highly accurate (> 0.985 AUC for diagnosis) and also interpretable with intuitive heatmap visualization. It can be unified with a digital pathology pipeline to deliver prostate cancer metrics for a pathology report.
Taxi demand prediction in a city is a highly demanded smart city research application for better traffic strategies formulation. It is essential for the interest of the commuters and the taxi companies both to have an accurate measure of taxi demands at different regions of a city and at varying time intervals. This reduces the cost of resources, efforts and meets the customers' satisfaction at its best. Modern predictive models have shown the potency of Deep Neural Networks (DNN) in this domain over any traditional, statistical, or Tensor-Based predictive models in terms of accuracy. The recent DNN models using leading technologies like Convolution Neural Networks (CNN), Graph Convolution Networks (GCN), ConvLSTM, etc. are not able to efficiently capture the existing spatio-temporal characteristics in taxi demand time-series. The feature aggregation techniques in these models lack channeling and uniqueness causing less distinctive but overlapping feature space which results in a compromised prediction performance having high error propagation possibility. The present work introduces Spatio-Temporal Aggregator Predictor (ST-A(G)P), a DNN model which aggregates spatio-temporal features into (1) non-redundant and (2) highly distinctive feature space and in turn helps (3) reduce noise propagation for a high performing multi-step predictive model. The proposed model integrates the effective feature engineering techniques of machine learning approach with the non-linear capability of a DNN model. Consequently, the proposed model is able to use only the informative features responsible for the objective task with reduce noise propagation. Unlike, existing DNN models, ST-A(G)P is able to induce these qualities of feature aggregation without the use of Multi-Task Learning (MTL) approach or any additional supervised attention that existing models need for their notable performance. A considerable high-performance gain of 25 - 37% on two real-world city taxi datasets by ST-A(G)P over the state-of-art models on standard benchmark metrics establishes the efficacy of the proposed model over the existing ones.
Edge computing places cloudlets with high computational capabilities near mobile devices to reduce the latency and network congestion encountered in cloud server-based task offloading. However, many cloudlets are required in such an edge computing network, leading to a tremendous increase in carbon emissions of computing networks globally. This increase in carbon emission envisages the need to employ green energy resources to power these cloudlets. This need has led to the concept of Green Cloudlet Networks (GCNs). But GCNs must deal with the problem of the unpredictability of green energy available to them while optimizing the performance (in terms of latency) delivered to the mobile user. This paper proposes a novel task-assignment called Green Energy and Latency Aware Task Assignment (Ge-LATA) for GCNs to address this issue. The primary aim of Ge-LATA is to optimize the latency and the green energy consumed in processing the offloaded tasks from the mobile devices. In this GCN, the cloudlets are connected in a network to process the incoming tasks cooperatively to ensure load-balancing at the cloudlets. Ge-LATA considers various factors like the current load, available green energy, service rate offered by cloudlets, and the distance from the mobile user, leading to optimal decisions in terms of latency and green energy consumed. Simulations are performed using the actual solar insolation data taken from the NREL database. Ge-LATA is tested with other offloading schemes for latency in processing the offloaded tasks and green energy consumed under different solar insolation scenarios in these simulations. Simulation results show that Ge-LATA achieves up to 31.87% of reduction in the latency while ensuring up to 50.15% of reduction in the energy consumption than other comparable task-assignment schemes.Thus, Ge-LATA suggests that it leads to an optimal task assignment by considering the various factors mentioned above during the task assignment process. Thus, Ge-LATA considers the above-mentioned extensive set of parameters during the task allotment process. It also proposes an efficient green energy allotment scheme that adapts itself to actual weather and network conditions, leading to optimal task assignment decisions in GCNs.
Metastasis on lymph nodes (LNs), the most common way of spread for primary tumor cells, is a sign of increased mortality. However, metastatic LNs are time-consuming and challenging to detect even for professional radiologists due to their small sizes, high sparsity, and ambiguity in appearance. It is desired to leverage recent development in deep learning to automatically detect metastatic LNs. Besides a two-stage detection network, we here introduce an additional branch to leverage information about LN stations, an important reference for radiologists during metastatic LN diagnosis, as supplementary information for metastatic LN detection. The branch targets to solve a closely related task on the LN station level, i.e., classifying whether an LN station contains metastatic LN or not, so as to learn representations for LN stations. Considering that a metastatic LN station is expected to significantly affect the nearby ones, a GCN-based structure is adopted by the branch to model the relationship among different LN stations. At the classification stage of metastatic LN detection, the above learned LN station features, as well as the features reflecting the distance between the LN candidate and the LN stations, are integrated with the LN features. We validate our method on a dataset containing 114 intravenous contrast-enhanced Computed Tomography (CT) images of oral squamous cell carcinoma (OSCC) patients and show that it outperforms several state-of-the-art methods on the mFROC, maxF1, and AUC scores, respectively.
Insulin plays important role in testicular functions such as germ cell proliferation and steroidogenesis, despite its conventional role as a hypoglycaemic agent. It is also well known that testicular activity is severely get affected by heat stress and heat stress induces testicular pathogenesis. The effect of insulin on heat-induced testicular impairment has not been investigated. Thus, it is hypothesized that insulin might modulate testicular activity in a heat-stressed model. Experimental mice were separated into 4 groups; the first group was the normal control (CN), and the second group was subjected to heat stress (HS) by submerging the lower body part in a thermostatically controlled water bath maintained at 43 degrees C for 15 min. The third and fourth groups were treated with a single dose of intra-testicular insulin (0.6 IU/mice) before and after heat stress. Animal tissue samples were collected after 14 days of heat treatment. Insulin treatment did not improve the sperm parameters; however, both insulin pre and post-treatment improved the markers of spermatogenesis such as Johnsen score, germinal epithelium height and the number of stages VII/VIII. The histoarchitecture of testis also showed amelioration from heat-induced pathogenesis in the insulin-treated groups. Insulin treatment has also increased the proliferation of germ cells (increased PCNA and GCN), survival (Bcl2), and decreased apoptosis (active caspase-3). Furthermore, insulin treatment decreased MDA levels, without pronounced effects on the activities of antioxidant enzymes. Heat stress also decreased the circulating testosterone and oestrogen levels, and insulin treatment significantly increased oestrogen levels only. Although testosterone showed an increasing trend, it was insignificant. The expression of aromatase, AR, ER-alpha, and ER-beta was down regulated by heat-stress and insulin treatment up regulated these markers. In conclusion, our results showed the amelioration of heat-induced testicular impairment by pre and post-intra-testicular insulin treatments. Insulin-associated improvements in the pre-and post-treatment groups suggested a preventive mechanism of insulin against heat stress in the testis.
Software knowledge community contains a large scale of software knowledge entity information, complex structure and rich semantic correlations. It is significant to recognize and extract software knowledge entity from software knowledge community, as it has great impact on entity-centric tasks such as software knowledge graph construction, software document generation and expert recommendation. Since the texts of the software knowledge community are unstructured by user-generated texts, it is difficult to apply the traditional entity extraction method in the domain of the software knowledge community due to the problems of entity variation, entity sparsity, entity ambiguity, out-of-vocabulary (OOV) words and the lack of annotated data sets. This paper proposes a novel software knowledge entity extraction model, named AttenSy-SNER, which integrates syntactic features and semantic augmentation information, to extract fine-grained software knowledge entities from unstructured user-generated content. The input representation layer utilizes Bidirectional Encoder Representations from Transformers (BERT) model to extract the feature representation of the input sequence. The contextual coding layer leverages the Bidirectional Long Short-Term Memory (BiLSTM) network and Graph Convolutional Network (GCN) for contextual information and syntactic dependency information, and a semantic augmentation strategy based on attention mechanism is introduced to enrich the semantic feature representation of sequences as well. The tag decoding layer leverages Conditional Random Fields (CRF) to solve the dependency between the output tags and obtain the global optimal label sequence. The results of model comparison experiments show that the proposed model has better performance than the benchmark model in software engineering domain.
3D skeleton data has been widely used in action recognition as the skeleton-based method has achieved good performance in complex dynamic environments. The rise of spatio-temporal graph convolutions has attracted much attention to use graph convolution to extract spatial and temporal features together in the field of skeleton-based action recognition. However, due to the huge difference in the focus of spatial and temporal features, it is difficult to improve the efficiency of extracting the spatiotemporal features. In this paper, we propose a channel attention and multi-scale neural network (CA-MSN) for skeleton-based action recognition with a series of spatio-temporal extraction modules. We exploit the relationship of body joints hierarchically through two modules, i.e., a spatial module which uses the residual GCN network with the channel attention block to extract the high-level spatial features, and a temporal module which uses the multi-scale TCN network to extract the temporal features at different scales. We perform extensive experiments on both the NTU-RGBD60 and NTU-RGBD120 datasets to verify the effectiveness of our network. The comparison results show that our method achieves the state-of-the-art performance with the competitive computing speed. In order to test the application effect of our CA-MSN model, we design a multi-task tandem network consisting of 2D pose estimation, 2D to 3D pose regression and skeleton action recognition model. The end-to-end (RGB video-to-action type) recognition effect is demonstrated. The code is available at https://github.com/Rh-Dang/CA-MSN-action-recognition.git.
In some stock markets, stock prices are not allowed to rise above a daily limit to restrain the surge of price (called price limit). When the price limit occurs, investors tend to chase the continuing upward momentum for profit-making. However, For the stocks that hit daily price limit, we observe whether they close at daily price limit will lead to the opposite price trends of the next trading day. Therefore, this work aims to predict whether a stock that hits its daily price limit will also close at the same price level (i.e., Type I or Type II). The occurrence of price limit is driven by different levels of market state. For example, it can result from macro-economic changes of the whole market, or it can be traced to some industry-specific factors. A challenging task is to learn a better stock representation with less uncertainty by comprehensively considering the hierarchical property of market state. Accordingly, we design a novel hierarchical architecture, called Hierarchical Graph Neural Network (HGNN), to investigate the market state at hierarchical view for stock type prediction. In HGNN, we construct the stock relation graph and merge stock information hierarchically extracted from multiple views of market state, including node view, relation view and graph view, which takes both historical sequence pattern and stock relation into consideration. Our key innovation is the introduction of hierarchical structure makes the predictive model able to more comprehensively infer the hierarchical property of market state. Further, it also provides the deeper insight for the actual investment practice. To validate the effectiveness of our method, we conduct back-testing on the two-year historical data of more than 2500 main-board stocks in two China stock markets, SSE and SZSE. To support further study of the stock type prediction task, we have published two longrange stock datasets (Datasets are available at https://drive.google.com/file/d/ 1TXiAyqt3rHveuzdGT6YtswU1e-tBSFUe/view?usp=sharing). Extensive experiments show that our method outperforms the state-of-the-art solutions including ALSTM, GCN and GAT with the improvements of at least 3.54% on average in accuracy. In addition, the average return ratio of SSE and SZSE has improved by 18.57% and 8.75%, respectively.(c) 2022 Elsevier Inc. All rights reserved.
Extracellular amino acid (AA) withdrawal/restriction invokes an integrated stress response (ISR) that induce: global suppression of protein synthesis whilst allowing transcription and translation of a select group of genes, whose protein products facilitate cellular adaptation to AA insufficiency. Transcriptional induction of the Systetr A/SNAT2 AA transporter represents a classic adaptation response and crucially depends upon activation of the General Control Nonderepressible-2 kinase/Activating transcription factor 4 (GCN2/ATF4) pathway. However, the ISR may also include additional signalling inputs operating in conjunction or independently of GCN2/ATF4 to upregulate SNAT2. Herein, we show that whilst pharmacological inhibition of MEK-ERK, mTORC1 and p38 MAP kinase signalling has no detectable effect on System A upregulation, inhibitors targeting GSK3 (e.g. SB415286) caused significant repression of the SNAT2 adaptation response. Strikingly, the effects of SB415286 persist in cells in which GSK3 alpha/beta have been stably silenced indicating an off-target effect. We show that SB415286 can also inhibit cyclin-dependent kinases (CDK) and that roscovitine and flavopiridol (two pan CDR inhibitors) are effective repressors of the SNAT2 adaptive response. In particular, our work reveals that CDK7 activity is upregulated in AA-deprived cells in a GCN-2-dependent manner and that a potent and selective CDK7 inhibitor, THZ-1, not only attenuates the increase in ATF4 expression but blocks System A adaptation. Importantly, the inhibitory effects of THZ-1 on System A adaptation are mitigated in cells expressing a doxycycline-inducible drug-resistant form of CDK7. Our data identify CDK7 as a novel component of the ISR regulating System A adaptation in response to AA insufficiency.
The development of Internet-of-Things (IoT) technology promotes the advances of grain condition detection and analysis systems. Temperature monitoring is a main element to maintain grain quality, and effective control of grain temperature is crucial to safe storage of grain. In this article, an encoder-decoder model with attention mechanism is proposed to accurately forecast the temperature of stored grain. Considering that the points on the gradient direction of the temperature surface have a great influence on the temperature of the target point, the Sobel operator is used to extract the local characteristics of the target point. In addition, considering the correlation structure in the sensory data, the attention mechanism is used to extract the global features of the target point. The extracted spatial features are fed into long short-term memory (LSTM) networks to obtain the long-term state information of spatial factors. LSTM unit and convolutional neural network are used to encode the spatial features of the target points. Taking meteorological factors as the external input of the decoder, temporal attention mechanism and LSTM unit are used to complete the decoding process and realize the prediction of grain temperature in the future. The results with real grain storage data show that the proposed model outperforms several schemes, including Kalman-modified the least absolute shrinkage and selection operator (Kalman-modified LASSO), temporal graph convolutional network (T-GCN), LSTM, CNN-LSTM, and convolutional LSTM (Conv-LSTM), with considerable gains.
To cope with nutrient scarcity, plants generally follow two main complementary strategies. On the one hand, they can slow down growing, mainly shoot growth, to diminish the demand of nutrients. We can call this strategy as "stop growing." On the other hand, plants can develop different physiological and morphological responses, mainly in their roots, aimed to facilitate the acquisition of nutrients. We can call this second strategy as "searching for nutrients." Both strategies are compatible and can function simultaneously but the interconnection between them is not yet well-known. In relation to the "stop growing" strategy, it is known that the TOR (Target Of Rapamycin) system is a central regulator of growth in response to nutrients in eukaryotic cells. TOR is a protein complex with kinase activity that promotes protein synthesis and growth while some SnRK (Sucrose non-fermenting 1-Related protein Kinases) and GCN (General Control Non-derepressible) kinases act antagonistically. It is also known that some SnRKs and GCNs are activated by nutrient deficiencies while TOR is active under nutrient sufficiency. In relation to the "searching for nutrients" strategy, it is known that the plant hormone ethylene participates in the activation of many nutrient deficiency responses. In this Mini Review, we discuss the possible role of ethylene as the hub connecting the "stop growing" strategy and the "searching for nutrients" strategy since very recent results also suggest a clear relationship of ethylene with the TOR system.
Drug-target interaction (DTI) prediction plays an important role in drug repositioning, drug discovery and drug design. However, due to the large size of the chemical and genomic spaces and the complex interactions between drugs and targets, experimental identification of DTIs is costly and time-consuming. In recent years, the emerging graph neural network (GNN) has been applied to DTI prediction because DTIs can be represented effectively using graphs. However, some of these methods are only based on homogeneous graphs, and some consist of two decoupled steps that cannot be trained jointly. To further explore GNN-based DTI prediction by integrating heterogeneous graph information, this study regards DTI prediction as a link prediction problem and proposes an end-to-end model based on HETerogeneous graph with Attention mechanism (DTI-HETA). In this model, a heterogeneous graph is first constructed based on the drug-drug and target-target similarity matrices and the DTI matrix. Then, the graph convolutional neural network is utilized to obtain the embedded representation of the drugs and targets. To highlight the contribution of different neighborhood nodes to the central node in aggregating the graph convolution information, a graph attention mechanism is introduced into the node embedding process. Afterward, an inner product decoder is applied to predict DTIs. To evaluate the performance of DTI-HETA, experiments are conducted on two datasets. The experimental results show that our model is superior to the state-of-the-art methods. Also, the identification of novel DTIs indicates that DTI-HETA can serve as a powerful tool for integrating heterogeneous graph information to predict DTIs.
Unsupervised domain adaptation (UDA)-based methods have made great progress in mechanical fault diagnosis under variable working conditions. In UDA, three types of information, including class label, domain label, and data structure, are essential to bridging the labeled source domain and unlabeled target domain. However, most existing UDA-based methods use only the former two information and ignore the modeling of data structure, which make the information contained in the features extracted by the deep network incomplete. To tackle this issue, a domain adversarial graph convolutional network (DAGCN) is proposed to model the three types of information in a unified deep network and achieving UDA. The first two types of information are modeled by the classifier and the domain discriminator, respectively. In data structure modeling, a convolutional neural network (CNN) is first employed to exact features from input signals. After that, the CNN features are input to the proposed graph generation layer to construct instance graphs by mining the relationship of structural characteristics of samples. Then, the instance graphs are modeled by a graph convolutional network, and the maximum mean discrepancy metric is leveraged to estimate the structure discrepancy of instance graphs from different domains. Experimental results conducted on two case studies demonstrate that the proposed DAGCN can not only obtain the best performance among the comparison methods, but also can extract transferable features for domain adaptation. The code library is available at: https://github.com/HazeDT/DAGCN.
Diabetic Retinopathy (DR) causes quite a few blindness worldwide, which can be refrained by the timely diagnosis on retinal images. Recently, researches on deep learning-based retinal image classification have accelerated outstanding improvements in DR grading task. However, existing DR grading works are mostly limited to a supervised manner. They require accurately annotated data labeled by professional experts, and the annotating work is very laborious and time-consuming. We propose a Semi-supervised Auto-encoder Graph Network (SAGN) for the challenging DR diagnosis to relax this constraint. Precisely, SAGN consists of three major modules: auto-encoder feature learning, neighbor correlation mining, and graph representation. Firstly, our model learns to extract representations from retinal images and reconstruct them as close to original inputs as possible. Then neighbor correlations among labeled and unlabeled samples are established by their similarities, calculated by the radial basis function. Finally, we operate Graph Convolutional Neural Network (GCN) to grade retinal samples from extracted features and their correlations. To evaluate the performance of SAGN, we conduct sufficient comparative experiments on APTOS 2019 dataset, trained from EyePACS. Results demonstrate that our SAGN model can achieve comparable performance with limited labeled retinal images with the help of large amounts of unlabeled data.
Road link speed is often employed as an essential measure of traffic state in the operation of an urban traffic network. Not only real-time traffic demand but also signal timings and other local planning factors are major influential factors. This paper proposes a short-term traffic speed prediction approach, called PL-WGAN, for urban road networks, which is considered an important part of a novel parallel learning framework for traffic control and operation. The proposed method applies Wasserstein Generative Adversarial Nets (WGAN) for robust data-driven traffic modeling using a combination of generative neural network and discriminative neural network. The generative neural network models the road link features of the adjacent intersections and the control parameters of intersections using a hybrid graph block. In addition, the spatial-temporal relations are captured by stacking a graph convolutional network (GCN), a recurrent neural network (RNN), and an attention mechanism. A comprehensive computational experiment was carried out including comparing model prediction and computational performances with several state-of-the-art deep learning models. The proposed approach has been implemented and applied for predicting short-term link traffic speed in a large-scale urban road network in Hangzhou, China. The results suggest that it provides a scalable and effective traffic prediction solution for urban road networks.
In view of most current studies on text sentiment classification focus on the deep learning model to obtain the sentimental characteristics of English text. Chinese text sentiment analysis is rarely involved, and only the context information of the statement is considered, but the syntax information of the statement is rarely considered. In this paper, a novel sentiment classification model is proposed (Dependency Tree Graph Convolutional Network, DTGCN) combined Chinese syntactically dependent tree with graph convolution. Firstly, the Bi-GRU (Bi-directional Gated Recurrent Unit) model is used to learn the contextual feature representation of a given text. Secondly, the syntax-dependent tree structure of a given text is constructed, then obtain its adjacency matrix according to the syntax-dependent tree, with the initial features extracted from the bidirectional gate control network, input into the graph convolutional neural network (GCN) to extract the sentimental features of the text; the obtained sentimental characteristics are then input into the classifier SoftMax for text sentimental polarity classification. Finally, the data set is compared with the mainstream neural network model. The experimental results show that the accuracy of the proposed DTGCN model proposed on the data set is 90.51% and the recall rate is 90.34%. Compared with the benchmark models (LSTM, CNN, TextCNN and Bi-GRU), the proposed DTGCN model shows a 4.45% advantage in accuracy. It shows that the proposed DTGCN model can effectively use the grammatical information of Chinese text to mine the hidden relationship in statements, it can improve the accuracy of Chinese text sentiment classification. In addition, the proposed DTGCN model not only improves the performance of sentiment classification in the essay, it also provides a new research method for social network public opinion identification. (c) 2022 THE AUTHORS. Published by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
The present work aims to find a suitable morphology of graphitic carbon nitride (g-CN) for electrocatalytic applications which includes bulk g-CN (g-CNB), g-CN nanosheets (g-CNNS) and g-CN quantum dots (gCND). The different morphologies of g-CN were synthesized by solid-phase thermal method using urea, citric acid and trisodium citrate as precursors. The X-ray diffraction (XRD) pattern of g-CNs showed characteristic 2 theta values due to (002) interlayer diffraction and (100) in-plane structural packing. The g-CN with the morphology of bulk, sheets and dots were then attached directly on GC electrode by immersing it into the respective gCN solution. The scanning electron microscopy (SEM) images showed that the g-CNB coated on GC plate displays layer like structure whereas g-CNNS exhibits crumpled and enfolded thin sheets like graphene. The SEM image of g-CND coated GC plate shows that they were uniformly covered the whole area as dots with the size of 30 nm. Under optimized conditions, the electrochemical impedance studies showed that the order of the charge transfer resistance was as follows: g-CNNS <g-CND < g-CNB < GC. The impact of g-CN morphology on the oxidation of ascorbic acid (AA) and dopamine (DA) and the reduction of hydrogen peroxide (HP) was studied at pH 7.2 phosphate buffer (PB) solution. The g-CNs modified electrodes irrespective of the morphology enhanced the electrocatalytic activity in contrast to bare GC electrode. Among the three g-CNs, GC/g-CNNS electrode exhibited higher electrocatalytic activity towards all the three analytes. The cause for the higher electrocatalytic activity was attributed to its higher electroactive surface area and faster electron transfer rate in contrast to GC/g-CNB and GC/g-CND electrodes. Further, GC/g-CNNS electrode was effectively used for the sensitive determination of HP. While increasing its concentration from 100 nM to 1 mM, HP reduction current increases linearly with R2 value of 0.9905 and LOD was 11 nM (S/N = 3). Finally, GC/g-CNNS electrode was successfully used to quantify HP in blood serum samples.
Cumulative research studies have verified that multiple circRNAs are closely associated with the pathogenic mechanism and cellular level. Exploring human circRNA-disease relationships is significant to decipher pathogenic mechanisms and provide treatment plans. At present, several computational models are designed to infer potential relationships between diseases and circRNAs. However, the majority of existing approaches could not effectively utilize the multisource data and achieve poor performance in sparse networks. In this study, we develop an advanced method, GATGCN, using graph attention network (GAT) and graph convolutional network (GCN) to detect potential circRNA-disease relationships. First, several sources of biomedical information are fused via the centered kernel alignment model (CKA), which calculates the corresponding weight of different kernels. Second, we adopt the graph attention network to learn latent representation of diseases and circRNAs. Third, the graph convolutional network is deployed to effectively extract features of associations by aggregating feature vectors of neighbors. Meanwhile, GATGCN achieves the prominent AUC of 0.951 under leave-one-out cross-validation and AUC of 0.932 under 5-fold cross-validation. Furthermore, case studies on lung cancer, diabetes retinopathy, and prostate cancer verify the reliability of GATGCN for detecting latent circRNA-disease pairs.
Since graph learning could preserve the structure information of the samples to improve the learning ability, it has been widely applied in both shallow learning and deep learning. However, the current graph learning methods still suffer from the issues such as outlier influence and model robustness. In this paper, we propose a new dynamic graph neural network (DGCN) method to conduct semi-supervised classification on multi-view data by jointly conducting the graph learning and the classification task in a unified framework. Specifically, our method investigates three strategies to improve the quality of the graph before feeding it into the GCN model: (i) employing robust statistics to consider the sample importance for reducing the outlier influence, i.e. assigning every sample with soft weights so that the important samples are with large weights and outliers are with small or even zero weights; (ii) learning the common representation across all views to improve the quality of the graph for every view; and (iii) learning the complementary information from all initial graphs on multi-view data to further improve the learning of the graph for every view. As a result, each of the strategies could improve the robustness of the DGCN model. Moreover, they are complementary for reducing outlier influence from different aspects, i.e. the sample importance reduces the weights of the outliers, both the common representation and the complementary information improve the quality of the graph for every view. Experimental result on real data sets demonstrates the effectiveness of our method, compared to the comparison methods, in terms of multi-class classification performance.
Address matching is a crucial task in various location-based businesses like take-out services and express delivery, which aims at identifying addresses referring to the same location in address databases. It is a challenging one due to various possible ways to express the address of a location, especially in Chinese. Traditional address matching approaches relying on string similarities and learning matching rules to identify addresses referring to the same location, could hardly solve the cases with redundant, incomplete or unusual expression of addresses. In this paper, to learn the geographical semantic representations for address strings, we novelly propose to get rich contexts for addresses from the Web through Web search engines, which could strongly enrich the semantic meaning of addresses that could be learned. Apart from that, we propose a two-stage geographical address representation learning model for address matching. In the first stage, we propose to use an encode-decoder architecture to learn the semantic vector representation for each address string where an up-sampling and sub-sampling strategy is applied to solve the problem of address redundancy and incompleteness. The attention mechanism is also applied to the model to highlight important features of addresses in their semantic representations. And in the second stage, we construct a single large graph from the corpus, which contains address elements and addresses as nodes, and the edges between nodes are built by word co-occurrence information to learn embedding representations for all the nodes on the graph. Our empirical study conducted on two real-world address datasets demonstrates that our approach greatly improves both precision (up to 8%) and recall (up to 12%) of the state-of-the-art existing methods.
The ATP-binding cassette (ABC) F/GCN (general control non-derepressible) subfamily is a group of soluble ABC proteins that has two nucleotide binding domains (NBDs) but no transmembrane domains (TMDs). Previous study has indicated that ABCF3, also called GCN20/SCORD5, is involved in stress-associated protein translation control and defense responses to bacterial infection. Here, we show that ABCF3 regulates H2O2 uptake and endoplasmic reticulum (ER) stress responses in Arabidopsis. ABCF3 expressed mainly in leaves, stems, root tips, seeds, and anther. Analysis of abcf3 mutants and transgenic overexpressors (OX) of ABCF3 indicates that ABCF3 regulates H2O2 uptake. qRT-PCR analysis indicated that ABCF3 affects the expression of several aquaporin genes that were involved in H2O2 uptake in plants. In addition, abcf3 mutants exhibited enhanced sensitivity to ER stress and amino acid deprivation when challenged with ER stress inducers tunicamycin and amino acid synthesis inhibitor chlorsulfuron compared to wild type. Overexpression of AtABCF3 increases, whereas, abcf3 mutants depress the expression of ER stress-related genes. Taken together, these results indicated that ABCF3 regulates stress response by modulating aquaporin gene expression and ER stress responses.
Background and objective: Cancer, as the most challenging part in the human disease history, has always been one of the main threats to human life and health. The high mortality of cancer is largely due to the complexity of cancer and the significant differences in clinical outcomes. Therefore, it will be significant to improve accuracy of cancer survival prediction, which has become one of the main fields of cancer research. Many calculation models for cancer survival prediction have been proposed at present, but most of them generate prediction models only by using single genomic data or clinical data. Multiple genomic data and clinical data have not been integrated yet to take a comprehensive consideration of cancers and predict their survival. Method: In order to effectively integrate multiple genomic data (including genetic expression, copy number alteration, DNA methylation and exon expression) and clinical data and apply them to predictive studies on cancer survival, similar network fusion algorithm (SNF) was proposed in this paper to integrate multiple genomic data and clinical data so as to generate sample similarity matrix, min-redundancy and max-relevance algorithm (mRMR) was used to conduct feature selection of multiple genomic data and clinical data of cancer samples and generate sample feature matrix, and finally two matrixes were used for semi-supervised training through graph convolutional network (GCN) so as to obtain a cancer survival prediction method integrating multiple genomic data and clinical data based on graph convolutional network (GCGCN). Result: Performance indexes of GCGCN model indicate that both multiple genomic data and clinical data play significant roles in the accurate survival time prediction of cancer patients. It is compared with existing survival prediction methods, and results show that cancer survival prediction method GCGCN which integrates multiple genomic data and clinical data has obviously superior prediction effect than existing survival prediction methods. Conclusion: All study results in this paper have verified effectiveness and superiority of GCGCN in the aspect of cancer survival prediction.
The 16S ribosomal RNA gene is the most widely used marker gene in microbial ecology. Counts of 16S sequence variants, often in PCR amplicons, are used to estimate proportions of bacterial and archaeal taxa in microbial communities. Because different organisms contain different 16S gene copy numbers (GCNs), sequence variant counts are biased towards clades with greater GCNs. Several tools have recently been developed for predicting GCNs using phylogenetic methods and based on sequenced genomes, in order to correct for these biases. However, the accuracy of those predictions has not been independently assessed. Here, we systematically evaluate the predictability of 16S GCNs across bacterial and archaeal clades, based on similar to 6,800 public sequenced genomes and using several phylogenetic methods. Further, we assess the accuracy of GCNs predicted by three recently published tools (PICRUSt, CopyRighter, and PAPRICA) over a wide range of taxa and for 635 microbial communities from varied environments. We find that regardless of the phylogenetic method tested, 16S GCNs could only be accurately predicted for a limited fraction of taxa, namely taxa with closely to moderately related representatives (less than or similar to 15% divergence in the 16S rRNA gene). Consistent with this observation, we find that all considered tools exhibit low predictive accuracy when evaluated against completely sequenced genomes, in some cases explaining less than 10% of the variance. Substantial disagreement was also observed between tools (R-2 < 0.5) for the majority of tested microbial communities. The nearest sequenced taxon index (NSTI) of microbial communities, i.e., the average distance to a sequenced genome, was a strong predictor for the agreement between GCN prediction tools on non-animal-associated samples, but only a moderate predictor for animal-associated samples. We recommend against correcting for 16S GCNs in microbiome surveys by default, unless OTUs are sufficiently closely related to sequenced genomes or unless a need for true OTU proportions warrants the additional noise introduced, so that community profiles remain interpretable and comparable between studies.
Driver attention prediction is becoming an essential research problem in human-like driving systems. This work makes an attempt to predict the driver attention in driving accident scenarios (DADA). However, challenges tread on the heels of that because of the dynamic traffic scene, intricate and imbalanced accident categories. In this work, we design a semantic context induced attentive fusion network (SCAFNet). We first segment the RGB video frames into the images with different semantic regions (i.e., semantic images), where each region denotes one semantic category of the scene (e.g., road, trees, etc.), and learn the spatio-temporal features of RGB frames and semantic images in two parallel paths simultaneously. Then, the learned features are fused by an attentive fusion network to find the semantic-induced scene variation in driver attention prediction. The contributions are three folds. 1) With the semantic images, we introduce their semantic context features and verify the manifest promotion effect for helping the driver attention prediction, where the semantic context features are modeled by a graph convolution network (GCN) on semantic images; 2) We fuse the semantic context features of semantic images and the features of RGB frames in an attentive strategy, and the fused details are transferred over frames by a convolutional LSTM module to obtain the attention map of each video frame with the consideration of historical scene variation in driving situations; 3) The superiority of the proposed method is evaluated on our previously collected dataset (named as DADA-2000) and two other challenging datasets with state-of-the-art methods.
Skeleton-based action recognition has attracted considerable attention since the skeleton data is more robust to the dynamic circumstances and complicated backgrounds than other modalities. Recently, many researchers have used the Graph Convolutional Network (GCN) to model spatial-temporal features of skeleton sequences by an end-to-end optimization. However, conventional GCNs are feedforward networks for which it is impossible for the shallower layers to access semantic information in the high-level layers. In this paper, we propose a novel network, named Feedback Graph Convolutional Network (FGCN). This is the first work that introduces a feedback mechanism into GCNs for action recognition. Compared with conventional GCNs, FGCN has the following advantages: (1) A multi-stage temporal sampling strategy is designed to extract spatial-temporal features for action recognition in a coarse to fine process; (2) A Feedback Graph Convolutional Block (FGCB) is proposed to introduce dense feedback connections into the GCNs. It transmits the high-level semantic features to the shallower layers and conveys temporal information stage by stage to model video level spatial-temporal features for action recognition; (3) The FGCN model provides predictions on-the-fly. In the early stages, its predictions are relatively coarse. These coarse predictions are treated as priors to guide the feature learning in later stages, to obtain more accurate predictions. Extensive experiments on three datasets, NTU-RGB+D, NTU-RGB+D120 and Northwestern-UCLA, demonstrate that the proposed FGCN is effective for action recognition. It achieves the state-of-the-art performance on all three datasets.
For semantic segmentation of remote sensing images (RSI), trade-off between representation power and location accuracy is quite important. How to get the trade-off effectively is an open question, where current approaches of utilizing very deep models result in complex models with large memory consumption. In contrast to previous work that utilizes dilated convolutions or deep models, we propose a novel two-stream deep neural network for semantic segmentation of RSI (RSI-Net) to obtain improved performance through modeling and propagating spatial contextual structure effectively and a decoding scheme with image-level and graph-level combination. The first component explicitly models correlations between adjacent land covers and conduct flexible convolution on arbitrarily irregular image regions by using graph convolutional network, while densely connected atrous convolution network (DenseAtrousCNet) with multi-scale atrous convolution can expand the receptive fields and obtain image global information. Extensive experiments are implemented on the Vaihingen, Potsdam and Gaofen RSI datasets, where the comparison results demonstrate the superior performance of RSI-Net in terms of overall accuracy (91.83%, 93.31% and 93.67% on three datasets, respectively), F1 score (90.3%, 91.49% and 89.35% on three datasets, respectively) and kappa coefficient (89.46%, 90.46% and 90.37% on three datasets, respectively) when compared with six state-of-the-art RSI semantic segmentation methods.
Traffic patterns of urban road intersections are important in traffic monitoring and accident prediction, thus play crucial roles in urban traffic management. Although real-time traffic information is consistently provided by surveillance cameras equipped at road intersections, the sparsity of surveillance distribution poses great challenges in performing a complete real-time traffic pattern analysis. To tackle that, existing works either assume that the traffic patterns are static, or assume a multi-variant distribution model for intersection traffic volumes. The former assumption neglects the temporal features of traffic patterns, and the latter is limited in capturing fine-grained spatiotemporal dependencies. To tackle the problem, we propose a novel framework, SpatioTemporal-Generative Adversarial Network (ST-GAN), that exploits deep spatiotemporal features of urban networks and offers accurate traffic pattern inferences with incomplete surveillance information. The ST-GAN framework incorporates a modified GCN network wired with the encoder-decoder mechanism and an LSTM network, which are further boosted by an iterative adversarial training process. Comprehensive experiments on real datasets show that ST-GAN achieves better inference accuracies than state-of-the-art solutions.
Because traffic flow data has complex spatial dependence and temporal correlation, it is a challenging problem for researchers in the field of Intelligent Transportation to accurately predict traffic flow by analyzing spatio-temporal traffic data. Based on the idea of spatio-temporal data fusion, fully considering the correlation of traffic flow data in the time dimension and the dependence of spatial structure, this paper proposes a new spatio-temporal traffic flow prediction model based on Graph Neural Network (GNN), which is called Bidirectional-Graph Recurrent Convolutional Network (Bi-GRCN). First, aiming at the spatial dependence between traffic flow data and traffic roads, Graph Convolution Network (GCN) which can directly analyze complex non-Euclidean space data is selected for spatial dependence modeling, to extract the spatial dependence characteristics. Second, considering the temporal dependence of traffic flow data on historical data and future data in its time-series period, Bidirectional-Gate Recurrent Unit (Bi-GRU) is used to process historical data and future data at the same time, to learn the temporal correlation characteristics of data in the bidirectional time dimension from the input data. Finally, the full connection layer is used to fuse the extracted spatial features and the learned temporal features to optimize the prediction results so that the Bi-GRCN model can better extract the spatial dependence and temporal correlation of traffic flow data. The experimental results show that the model can not only effectively predict the short-term traffic flow but also get a good prediction effect in the medium- and long-term traffic flow prediction.
The task of point cloud upsampling aims to acquire dense and uniform point sets from sparse and irregular point sets. Although significant progress has been made with deep learning models, state-of-the-art methods require ground-truth dense point sets as the supervision, which makes them limited to be trained under synthetic paired training data and not suitable to be under real-scanned sparse data. However, it is expensive and tedious to obtain large numbers of paired sparse-dense point sets as supervision from real-scanned sparse data. To address this problem, we propose a self-supervised point cloud upsampling network, named SPU-Net, to capture the inherent upsampling patterns of points lying on the underlying object surface. Specifically, we propose a coarse-to-fine reconstruction framework, which contains two main components: point feature extraction and point feature expansion, respectively. In the point feature extraction, we integrate the self-attention module with the graph convolution network (GCN) to capture context information inside and among local regions simultaneously. In the point feature expansion, we introduce a hierarchically learnable folding strategy to generate upsampled point sets with learnable 2D grids. Moreover, to further optimize the noisy points in the generated point sets, we propose a novel self-projection optimization associated with uniform and reconstruction terms as a joint loss to facilitate the self-supervised point cloud upsampling. We conduct various experiments on both synthetic and real-scanned datasets, and the results demonstrate that we achieve comparable performances to state-of-the-art supervised methods.
With the more and more in-depth research on intelligent transportation, many scholars have proposed their models for accurate prediction of traffic. In this paper, we analyze the advantages and disadvantages of the existing models and propose our own model. In our model, the temporal and spatial factors are taken into account. Gate Recurrent Unit (GRU) and Gated Linear Units (GLU) are used to learn the short-term temporal features of traffic data, and Graph Convolutional Network (GCN) is used to learn the spatial features of traffic data. In order to fully learn short-term feature changes, a multi time step perception layer is proposed. A new network GCGRU is proposed to learn the long-term features of traffic data. As the sensor will be affected by urban canyon, weather, and other factors, there will be missing value and noise in the collected data. We created a short-term trend based missing value filling up algorithm to fill in missing values and use Singular Spectrum Analysis (SSA) algorithm to eliminate noise of training data set. In order to reduce the process of adjusting parameters manually in the model training process, we propose k-block search method based on fuzzy extreme points. Finally, the model is compared with the existing traffic forecasting models, and the analysis results show that our model has advantages in many indicators.
Recent advances in neuroscience indicate that analysis of bio-signals such as rest state electroencephalogram (EEG) and eye-tracking data can provide more reliable evaluation of children autism spectrum disorder (ASD) than traditional methods of behavior measurement relying on scales do. However, the effectiveness of the new approaches still lags behind the increasing requirement in clinical or educational practices as the "bio-marker" information carried by the bio-signal of a single-modality is likely insufficient or distorted. This study proposes an approach to joint analysis of EEG and eye-tracking for children ASD evaluation. The approach focuses on deep fusion of the features in two modalities as no explicit correlations between the original bio-signals are available, which also limits the performance of existing methods along this direction. First, the synchronization measures, information entropy, and time-frequency features of the multi-channel EEG are derived. Then a random forest applies to the eye-tracking recordings of the same subjects to single out the most significant features. A graph convolutional network (GCN) model then naturally fuses the two group of features to differentiate the children with ASD from the typically developed (TD) subjects. Experiments have been carried out on the two types of the bio-signals collected from 42 children (21 ASD and 21 TD subjects, 3-6 years old). The results indicate that (1) the proposed approach can achieve an accuracy of 95% in ASD detection, and (2) strong correlations exist between the two bio-signals collected even asynchronously, in particular the EEG synchronization against the face related/joint attentions in terms of covariance.
In recent years, neurological disorders have globally become a leading cause of disability and death. Neurological disorders are very common in both high- and low-income countries, and the number of patients is predicted to increase in the coming decades. Disorders caused by the expanded trinucleotide repeats (CAG, CGG, CCG, CTG, CUG, GAA, and GCN) in the genome, also described as trinucleotide repeat expansion disorders (TREDs), comprise of the major class of neurological diseases. Various TREDs have different modes of pathogenesis, but the severity and time of onset of disease depends on the trinucleotide repeat numbers. Numerous therapeutic strategies, including symptomatic treatment, blockage of mutant protein synthesis, targeting the toxic protein aggregates and degradation of RNA transcripts have been developed for the treatment of these diseases. However, various limitations to these therapeutic strategies have been reported, and therefore, researchers are exploring different avenues of therapeutics development. One of the recent developments include targeting the expanded repeats with small molecules. Small molecule binds with the secondary/tertiary structure of RNA (like bulges, loops, and hairpins) irrespective of its sequences. Altogether, small molecule-based therapeutics may have the advantage over others to be able to overcome the hurdles of the blood-brain barrier, poor absorption, and allergic reactions. In this review, we have summarized various TREDs and envisage the potential of small molecule-based therapeutics for targeting these hitherto incurable neurological disorders.
Commuting flow prediction is a crucial issue for transport optimization and urban planning. However, the two existing types of solutions have inherent flaws. One is traditional models, such as the gravity model and radiation model. These models rely on fixed and simple mathematical formulas derived from physics, and ignore rich geographic semantics, which makes them difficult to model complex human mobility patterns. The other is the machine learning models, most of which simply leverage the features of Origin-Destination (OD), ignoring the topological nature of the interaction network and the spatial correlation brought by the nearby areas. In this paper, we propose a 'preprocessing-encoder-decoder' hybrid learning model, which can make full use of geographic semantic information and spatial neighborhood effects, thereby significantly improving the prediction performance. Specifically, in the preprocessing part, we divide the study area into grids, and then incorporates features such as location, population, and land use types. The second step of the encoder designs a convolutional neural network (CNN) to achieve the fusion of neighborhood features, constructs a spatial interaction network with the grids as nodes and the flows as edges, and then uses the graph convolutional network (GCN) to extract the embeddings of the nodes. In the last step of the decoder, a random forest regressor is trained to predict the commuting flow based on the learned embedding vectors. An empirical study on a commuter dataset in Beijing shows that our proposed model is approximately 20% better than XGBoost (state-of-the-art), thus proving its effectiveness.
As one of the most important operation and maintenance approaches, health state diagnosis technology plays a crucial role in ensuring the safety and reliability of mechanical equipment. The planar parallel manipulator, as a typical actuator, is widely employed in the field of precision manufacturing due to its advantages of high stiffness, large load support capability, and high precision. However, compared with common key functional components (such as bearings and gearboxes), planar parallel manipulators have more complicated operating mechanisms and failure behaviors. To satisfy the health state diagnosis demands of planar parallel manipulators in the scenario of insufficient label information, a novel intelligent health state diagnosis approach, termed semi-supervised graph-guided network with perception attention (SGN-PA), is developed for a 3-PRR (P and R represent prismatic and revolute pairs, respectively) planar parallel manipulator. Specifically, an improved multiorder graph perception module is constructed to extract multiscale feature information, and achieve feature fusion by combining perceptual attention mechanism, which enables the proposed SGN-PA model to have adaptation adjustment capabilities. Following that, local and nonlocal feature constraint strategies are employed with pseudo-label technology to reduce intraclass differences and maximize interclass differences, and then to fit the demands of health state diagnosis tasks. Eventually, based on the simulation and experimental scenarios of a 3-PRR planar parallel manipulator, the effectiveness and feasibility of the proposed SGN-PA model is extensively confirmed, and the diagnosis results show that it can significantly relax the constraints of label information while maintaining superior performances.
Cross-modal image-text matching has attracted considerable interest in both computer vision and natural language processing communities. The main issue of image-text matching is to learn the compact cross-modal representations and the correlation between image and text representations. However, the image-text matching task has two major challenges. First, the current image representation methods focus on the semantic information and disregard the spatial position relations between image regions. Second, most existing methods pay little attention to improving textual representation which plays a significant role in image-text matching. To address these issues, we designed a decipherable cross-modal multi-relationship aware reasoning network (CMRN) for image-text matching. In particular, a new method is proposed to extract multi-relationship and to learn the correlations between image regions, including two kinds of visual relations: the geometric position relation and semantic interaction. In addition, images are processed as graphs, and a novel spatial relation encoder is introduced to perform reasoning on the graphs by employing a graph convolutional network (GCN) with attention mechanism. Thereafter, a contextual text encoder based on Bidirectional Encoder Representations from Transformers is adopted to learn distinctive textual representations. To verify the effectiveness of the proposed model, extensive experiments were conducted on two public datasets, namely MSCOCO and Flickr30K. The experimental results show that CMRN achieved superior performance when compared with state-of-the-art methods. On Flickr30K, the proposed method outperforms state-of-the-art methods more than 7.4% in text retrieval from image query, and 5.0% relatively in image retrieval with text query (based on Recall@1). On MSCOCO, the performance reaches 73.9% for text retrieval and 60.4% for image retrieval (based on Recall@1).
Malicious social robots are the disseminators of malicious information on social networks, which seriously affect information security and network environments. Efficient and reliable classification of social robots is crucial for detecting information manipulation in social networks. Supervised classification based on manual feature extraction has been widely used in social robot detection. However, these methods not only involve the privacy of users but also ignore hidden feature information, especially the graph feature, and the label utilization rate of semi-supervised algorithms is low. Aiming at the problems of shallow feature extraction and low label utilization rate in existing social network robot detection methods, in this paper a robot detection scheme based on weighted network topology is proposed, which introduces an improved network representation learning algorithm to extract the local structure features of the network, and combined with the graph convolution network (GCN) algorithm based on the graph filter, to obtain the global structure features of the network. An end-to-end semi-supervised combination model (Semi-GSGCN) is established to detect malicious social robots. Experiments on a social network dataset (cresci-rtbust-2019) show that the proposed method has high versatility and effectiveness in detecting social robots. In addition, this method has a stronger insight into robots in social networks than other methods.
Knowledge graphs (KGs) have become popular structures for unifying real-world entities by modelling the relationships between them and their attributes. To support multilingual applications, a significant number of language-specific KGs have been built by different parties using various data sources. As a result, these monolingual KGs are often disconnected, causing semantic heterogeneity and detracting from the original purpose of KGs. Entity alignment - the task of identifying corresponding entities across different KGs - has attracted a great deal of attention in both academia and industry. However, existing alignment techniques often require large amounts of labelled data, are unable to encode multi-modal data simultaneously, and enforce only a few consistency constraints. In this paper, we propose an end-to-end, unsupervised entity alignment framework for cross-lingual KGs that fuses different types of information in order to fully exploit the richness of KG data. The model captures the relation-based correlation between entities by using a multi-order graph convolutional neural (GCN) model that is designed to satisfy the consistency constraints, while incorporating the attribute-based correlation via a translation machine. We adopt a late-fusion mechanism to combine all the information together, which allows these approaches to complement each other and thus enhances the final alignment result, and makes the model more robust to consistency violations. Empirical results for various scenarios on real-world and synthetic KGs show that our model is up to 22.71 percent more accurate and orders of magnitude faster than existing baselines. We also demonstrate its sensitivity to hyper-parameters, effort saving in terms of labelling, and the robustness against adversarial conditions.
The advancement of Internet of Things (IoT) technologies leads to a wide penetration and large-scale deployment of IoT systems across an entire city or even country. While IoT systems are capable of providing intelligent services, the large amount of data collected and processed in IoT systems also raises serious security concerns. Many research efforts have been devoted to design intelligent network intrusion detection system (NIDS) to prevent misuse of IoT data across smart applications. However, existing approaches may suffer from the issue of limited and imbalanced attack data when training the detection model, which make the system vulnerable especially for those unknown type attacks. In this study, a novel hierarchical adversarial attack (HAA) generation method is introduced to realize the level-aware black-box adversarial attack strategy, targeting the graph neural network (GNN)-based intrusion detection in IoT systems with a limited budget. By constructing a shadow GNN model, an intelligent mechanism based on a saliency map technique is designed to generate adversarial examples by effectively identifying and modifying the critical feature elements with minimal perturbations. A hierarchical node selection algorithm based on random walk with restart (RWR) is developed to select a set of more vulnerable nodes with high attack priority, considering their structural features, and overall loss changes within the targeted IoT network. The proposed HAA generation method is evaluated using the open-source data set UNSW-SOSR2019 with three baseline methods. Comparison results demonstrate its ability in degrading the classification precision by more than 30% in the two state-of-the-art GNN models, GCN and JK-Net, respectively, for NIDS in IoT environments.
A new aquatic associated genus of Trichopezinae, Gondwanodromia gcn. nov., with one new species from southern South America (G. mikae sp. nov.), six new species from eastern Australia (G. bulbosa sp. nov., G. colomatta sp. nov., G. lutea sp. nov., G. tasmanica sp. nov., G. thredbo sp. nov., G. tonnoiri sp. nov.) and four new species from New Zealand (G. elongata sp. nov.. G. femorata sp. nov., G. tongariro sp. nov., G. wardi sp. nov.) are described. The following new combination is proposed for the New Zealand species Gondwanodromia mutabilis (Collin) comb. nov. and the male of this species is described for the first time. All species are illustrated, distributions mapped and the phylogenetic affinities of the new genus are discussed. A key to genera of Trichopezinae of the Southern Hemisphere and key to species of Gondwanodromia are presented.
Graph convolutional network (GCN) nowadays become new state-of-the-art for networks representation learning. Most of the existing methods are single-granular methods that failed to analyze the graph at multi-granular views so as to lose abundant information. Advanced graph pooling techniques can be successfully benefiting from semi-supervised networks representation learning. How to capture multi-granular information through the graph pooling techniques on graphs without additional input features is a great challenge. Technically speaking, we propose our graph node embeddings framework, MGPOOL. First, inspired by the triadic influence learning, we use the 3-clique algorithm to coarsen the graph repeatedly. Three nodes of a triangle form a supernode. We treat the supernodes as key nodes for our graph pooling operations. That keeps the local relationship. These graphs capture consecutive 3-cliques from the finest to the coarsest to preserve global structural relationships. Second, we use the unsupervised single-granular algorithms on the coarsest graph to acquire its node embeddings. Based on that, our graph pooling operations combining with that node embeddings to generate another same size of the coarsest graph. This makes up for the uniqueness of the coarsening result at a time and expands the receptive field for each node to avoid high-proximity information lost. Third, we take the embeddings, the coarsest graph and new coarsest graph as uniform input of MGPOOL. We restore the coarsest graph to the original graph to get the original graph node embeddings. The experimental results on four public datasets, Wiki, Cora, CiteSeer, and DBLP, demonstrate that our method has a better Macro F1 value for node classification tasks and AUC and Ap value for link prediction than the baseline methods.
Bike-sharing systems have been prevalent since their appearance. As a way to solve the difficulty of the last mile, it can reduce greenhouse gas production. In a bike-sharing system, users can pick up bikes at nearby stations and return them to the stations near their destinations, that provides convenience for users. However, the number of bikes rented from or returned to stations changes over time, causing an imbalance in the number of bikes, and leading to both users? and operators? problems. Bikes flow inequality will lead to inefficient use of bike, and waste users? time when the target station has no dock, or the departure station has no bikes. Bike check-out/in flow prediction is a crucial research and practical issue in bikesharing systems, which plays a vital role in bike rebalancing There are three main research ideas in current studies, and the first is clustering-level flow prediction. i.e., all stations are Nowadays, bike-sharing is available in many cities, solving the problem of the last mile, and it is an environmental-friendly way to commute. However, there is a tidal phenomenon in the bike-sharing system, and the rents/returns of bikes at different stations are unbalanced. Thus, bikes at different stations need to be rebalanced regularly and station-level demand prediction plays an essential role in bike-sharing rebalancing. In this paper, a novel deep graph convolutional network (GCN) model with temporal attention (TAGCN) is proposed for bike check-out/in number prediction of each station. TAGCN can not only model the spatial and temporal dependency between varying stations, but also reflect the influence of different time granularity, which are hour-level, day-level and week-level time periodicity. With the help of well-designed temporal attention mechanism, our model can capture the dynamical temporal correlations and comprehensive spatial patterns in bike check-out/in flow effectively. The proposed model consistently outperforms state-of-the-art methods on four real-world bike-sharing datasets that are four seasons data of Divvy Bike System in Chicago. (c) 2021 Elsevier Inc. All rights reserved.
Traffic data missing issues due to unpredictable equipment failure, extreme weather, and other reasons have brought great challenges to traffic flow prediction modeling. In this paper, a novel reinforced dynamic graph convolutional network model is proposed to simultaneously conduct data imputation and network-wide traffic flow prediction. First, a multi-graph convolutional fusion network is proposed for data imputation by using the graph convolutional network to analyze the propagation law of traffic states between traffic flow detection stations in both time and space dimensions. Second, to enhance the robustness of network-wide traffic flow prediction, a dynamic graph learning method based on deep reinforcement learning is proposed to adaptively generate the graph adjacency matrix to represent the dynamic spatiotemporal dependencies be-tween the stations. Finally, experimental results on two real-world traffic datasets show that the proposed method outperforms other baseline methods and can effectively extract the data missing features and spatiotemporal dependence features between the stations. The visualization results of the graph adjacency matrix indicate that the proposed method can effectively identify the influential traffic stations in the process of traffic flow prediction, and the extracted dependencies between the stations are interpretable. The proposed model has strong generalization in tackling network-wide traffic flow prediction tasks with different data missing rates and missing patterns, and can be extended to assist decision-makers in enhancing traffic management and mitigating traffic congestion.
In this paper, we seek to solve the problem of video anomaly detection under the weakly-supervised setting. Different from previous works that usually deal with the problem in a multiple-instance learning manner, we formulate it as a fully-supervised learning task with label noises. Under this new perspective, we can fully leverage the advantages of well-designed action classifiers for anomaly detection as long as the label noises are cleaned. For this purpose, we devise a graph convolutional network for label noise cleaning, which integrates two crucial characteristics for anomaly analysis: feature similarity and temporal consistency. Supervised by both direct and indirect signals, the net propagates supervision information from high-confidence snippets to low-confidence ones and provides cleaned labels for action classifier training. In this way, we design an alternate learning strategy to progressively promote the discrimination of the action classifier. During the test phase, we directly utilize the learned action classifier for anomaly detection in an end-to-end fashion without any intermediate processing. We have conducted extensive experiments on various anomaly datasets of three scales with two main types of action classifiers, and achieved superior or comparable performances compared with state-of-the-art methods. Furthermore, we manually annotate the temporal duration of anomalies in the training data of UCFCrime, and give out the upper-limit performance of our cleaner net. The annotation can also be used as the ground truth for studying anomaly detection models under multi-level supervisory signals, which will mitigate the present shortage of large-scale anomaly datasets. (c) 2022 Elsevier B.V. All rights reserved.
An image is the abstraction of a thousand words. The meaning and essence of complex topics, ideas, and concepts can be easily and effectively conveyed visually by a single image rather than a lengthy verbal description. It is not only essential to teach computers how to recognize and classify images but also how to generate them. Controlled image generation depicting complex and multiple objects is a challenging task in computer vision despite the significant advancements in generative modeling. Among the core challenges, scene graph-based and scene layout-based image generation is a significant problem in computer vision and requires generative models to reason about object relationships and compositionality. Due to its ease of use, less time cost, and labor needs, image generation/synthesizing models from scene graphs and layouts are proliferating. In the case of a more significant number of scene graphs and layout to image generation models, a unique experimental evaluation methodology is required to evaluate the controlled image generation. To this extent, we, in this work, present a standard methodology to evaluate the performance of scene graph and scene layout-based image generation models. We perform a comparative analysis of image generation models to evaluate image generation models' complexity from scene graphs and scene layouts. We analyze the different components of these models on Visual Genome and COCO-Stuff datasets. The experimental results show that the scene layout-based image generation outperforms its graph-based counterpart in most quantitative and qualitative evaluations. & COPY; 2023 The Author(s). Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
Knowledge services are becoming a rising star in the family of XaaS (Everything as a Service). In recent years, people are more willing to search for answers and share their knowledge directly over the Internet, which drives the knowledge service ecosystem prosperous and quickly evolve. In this article, we aim to predict the popularity of knowledge services, which will benefit the downstream industries that provide Knowledge as a Service (KaaS). Toward such a task, the spatial interactions (e.g., hyperlinks in Wikipedia) and temporal observations (e.g., page views) provide crucial information. However, it is difficult to utilize this information due to: (i) complicated and different usage observations, (ii) intricate and evolutionary spatial interactions, and (iii) small world trait of the network. To tackle such issues, we propose Evolutionary Graph Convolutional Recurrent Neural Networks (E-GCRNNs) to simultaneously model both temporal and spatial dependencies of knowledge services from their evolving networks. Specifically, an elementary unit (called E-GCGRU) is designed to dynamically perceive the evolutionary spatial dependencies, aggregate spatial information of knowledge services, and model the temporal patterns by considering the records of one sequence and its neighbors simultaneously. Additionally, a localized mini-batch training scheme is developed, which allows the E-GCRNNs to work on large-scale knowledge services networks and reduce the prediction bias caused by the small world trait. Extensive experiments on real-world datasets have demonstrated that the proposed E-GCRNNs outperform baselines in terms of prediction accuracy, especially with the prediction range being longer, while remaining computationally efficient.
Point cloud upsampling can improve the resolutions of point clouds and maintain the forms of point clouds, which has attracted more and more attention in recent years. However, upsampling networks sometimes generate point clouds with unclear contours and deficient topological structures, i.e., the problem of insufficient form fidelity of upsampled point clouds. This paper focuses on the above problem. Firstly, we manage to find the points located at contours or sparse positions of point clouds, i.e., the form describers, and make them multiply correctly. To this end, 3 statistics of points, i.e., local coordinate difference, local normal difference and describing index, are designed to estimate the form describers of the point clouds and rectify the feature aggregation of them with reliable neighboring features. Secondly, we divide points into disjoint levels according to the above statistics and apply K nearest neighbors algorithm to the points of different levels respectively to build an accurate graph. Finally, cascaded networks and graph information are fused and added to the feature aggregation so that the network can learn the topology of objects deeply, enhancing the perception of model toward graph information. Our upsampling model PU-FPG is obtained by combining these 3 parts with upsampling networks. We conduct abundant experiments on PU1K dataset and Semantic3D dataset, comparing the upsampling effects of PU-FPG and previous works in multiple metrics. Compared with the baseline model, the Chamfer distance, the Hausdorff distance and the point-to-surface distance of PU-FPG are reduced by 0.159 x 10(-3), 2.892 x 10(-3) and 0.852 x 10(-3), respectively. This shows that PU-FPG can improve the form fidelity and raise the quality of upsampled point clouds effectively. Our code is publicly available at https://github.com/SATURN2021/PU-FPG.
Aspect-level sentiment analysis aims to determine the sentiment polarity towards a specific target in a sentence. The main challenge of this task is to effectively model the relation between targets and senti-ments so as to filter out noisy opinion words from irrelevant targets. Most recent efforts capture relations through target-sentiment pairs or opinion spans from a word-level or phrase-level perspective. Based on the observation that targets and sentiments essentially establish relations following the grammatical hierarchy of phrase-clause-sentence structure, it is hopeful to exploit comprehensive syntactic informa-tion for better guiding the learning process. Therefore, we introduce the concept of Scope, which outlines a structural text region related to a specific target. To jointly learn structural Scope and predict the sen-timent polarity, we propose a hybrid graph convolutional network (HGCN) to synthesize information from constituency tree and dependency tree, exploring the potential of linking two syntax parsing meth-ods to enrich the representation. Experimental results on five public datasets illustrate that our HGCN model outperforms current state-of-the-art baselines. More specifically, the average accuracy/ F1 score improvements of our HGCN compared to baseline models on Restaurant 14, 15 and 16 are 2.46%/5.36%, 2.25%/5.70% and 1.73%/5.50%, while the performance improvements are 3.32%/4.30% and 2.50%/3.08% on the Laptop and Twitter datasets, respectively. Furthermore, when cascaded to five mod-els, our method has significantly improved their performances by simplifying the sentence from multiple targets to a single one. (c) 2022 Elsevier B.V. All rights reserved.
Graph deep learning has recently emerged as a powerful ML concept allowing to generalize successful deep neural architectures to non-euclidean structured data. Such methods have shown promising results on a broad spectrum of applications ranging from social science, biomedicine, and particle physics to computer vision, graphics, and chemistry. One of the limitations of the majority of current graph neural network architectures is that they are often restricted to the transductive setting and rely on the assumption that the underlying graph is known and fixed. Often, this assumption is not true since the graph may be noisy, or partially and even completely unknown. In such cases, it would be helpful to infer the graph directly from the data, especially in inductive settings where some nodes were not present in the graph at training time. Furthermore, learning a graph may become an end in itself, as the inferred structure may provide complementary insights next to the downstream task. In this paper, we introduce Differentiable Graph Module (DGM), a learnable function that predicts edge probabilities in the graph which are optimal for the downstream task. DGM can be combined with convolutional graph neural network layers and trained in an end-to-end fashion. We provide an extensive evaluation of applications from the domains of healthcare (disease prediction), brain imaging (age prediction), computer graphics (3D point cloud segmentation), and computer vision (zero-shot learning). We show that our model provides a significant improvement over baselines both in transductive and inductive settings and achieves state-of-the-art results.
Pedestrian trajectory prediction is an important area in computer vision, with wide applications in au-tonomous driving, robot path planning, and surveillance systems. The core underlying technique of these applications is pattern recognition. A key challenge in this area is modeling social interactions between pedestrians, such as pedestrian view area and group behaviors. However, although many methods have been proposed to model social interactions, pedestrian view area and group behaviors have not been ex-plored together to account for complex situations. Additionally, most existing studies require additional detectors and manual annotations to handle view area and group interactions, respectively. In this paper, we propose a dual-branch spatio-temporal graph neural network to automatically model view area and grouping together. Specifically, a spatio-temporal graph attention network (STGAT) branch is designed to handle pedestrian view area, and a spatio-temporal graph convolutional network (STGCN) branch is de-signed to model group interactions. The features of these branches are then fused to provide better fea-ture representations, on which a temporal convolution operation (TCN) is performed for trajectory pre-diction. Experiments on public standard datasets demonstrate that the proposed method achieves very competitive performance and predicts socially acceptable trajectories in different challenging scenarios. & COPY; 2023 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ )
The hyperspectral image (HSI) classification aims to assign each pixel to a land-cover category. It is receiving increasing attention from both industry and academia. The main challenge lies in capturing reliable and informative spatial and spectral dependencies concealed in the HSI for each class. To address the challenge, we propose a spatial-spectral 1DSwin (SS1DSwin) Transformer with groupwise feature tokenization for HSI classification. Specifically, we reveal local and hierarchical spatial-spectral relationships from two different perspectives. It mainly consists of a groupwise feature tokenization module (GFTM) and a 1DSwin Transformer with cross-block normalized connection module (TCNCM). For GFTM, we reorganize an image patch into overlapping cubes and further generate groupwise token embeddings with multihead self-attention (MSA) to learn the local spatial-spectral relationship along the spatial dimension. For TCNCM, we adopt the shifted windowing strategy when acquiring the hierarchical spatial-spectral relationship along the spectral dimension with 1-D window-based MSA (1DW-MSA) and 1-D shifted window-based MSA (1DSW-MSA) and leverage cross-block normalized connection (CNC) to adaptively fuse the feature maps from different blocks. In SS1DSwin, we apply these two modules in order and predict the class label for each pixel. To test the effectiveness of the proposed method, extensive experiments are conducted on four HSI datasets, and the results indicate that SS1DSwin outperforms several current state-of-the-art methods. The source code of the proposed method is available at https://github.com/Minato252/SS1DSwin.
Recently, visible and infrared thermal (RGB-T) images have drawn wide publicity for vehicle fusion detection in traffic monitoring because of their strong complementarities. How to fully use RGB-T images for vehicle fusion detection has generated enormous publicity. However, the infrared thermal dataset is relatively insufficient. Moreover, the most important requirements of vehicle fusion detection are accuracy, fast speed, and flexibility. Therefore, to address these difficulties, we propose a concise and flexible vehicle fusion detection method in RGB-T images via spare network and dynamic weight coefficient-based Dempster-Shafer (D-S) evidence theory. It combines the detection results of RGB-T images based on a decision-level vehicle fusion strategy. In this work, we focus on vehicle detection using infrared thermal images and the vehicle fusion detection strategy. For the former, we construct an applicable network for vehicle detection in infrared thermal images with sparse parameters (weights) and high generalization ability. For the latter, a fusion strategy via dynamic weight coefficient-based D-S evidence theory is proposed to fuse the two detection results of the RGB-T images. In the vehicle fusion detection strategy, we do not directly fuse the two detection results but judge the detection accuracy in advance. Finally, we introduce the VIVID, VOT2019, and RGBT234 datasets to verify the proposed vehicle fusion detection method. The vehicle fusion detection results show that the proposed method presents superior results compared with several mainstream approaches. (C) 2022 Society of Photo-Optical Instrumentation Engineers (SPIE)
Accurate traffic prediction is a critical yet challenging task in Intelligent Transportation Systems, benefiting a variety of smart services, e.g., route planning and traffic management. Although extensive efforts have been devoted to this problem, it is still not well solved due to the flexible dependency within traffic data along both spatial and temporal dimensions. In this paper, we explore the flexibility from three aspects, namely the time-varying local spatial dependency, the dynamic temporal dependency, and the global spatial dependency. Then we propose a novel Dual Graph Gated Recurrent Neural Network (DG(2)RNN) to effectively model all these dependencies and offer flexible (multi-step) predictions for future traffic flow. Specifically, we design a Dual Graph Convolution Module to capture the local spatial dependency from two perspectives, namely road distance and adaptive correlation. To model the dynamic temporal dependency, we firstly develop a Bidirectional Gated Recurrent Layer to capture the forward and backward sequential contexts of historical traffic flow, then combine the derived hidden states with their various contributions learned by a temporal attention mechanism. Besides, we further design a spatial attention mechanism to learn the latent global spatial dependency among all locations to facilitate the prediction. Extensive experiments on three types of real-world traffic datasets demonstrate that our model outperforms state-of-the-arts. Results also show our model has more stable performance for the flexible prediction with varying prediction horizons.
Aspect Level Sentiment Classification (ALSC) deals with classifying the sentiment polarity towards a particular aspect or target. The performance of any method in ALSC is primarily driven by its capability to map the aspect or target term to the correct sentiment context words. The dependency tree's syntactical information is crucial for correctly mapping the appropriate context terms to the aspect term. Thus, recent top-performing methods use the graph neural network (GNN) to incorporate the syntactical knowledge of the dependency tree. However, the architecture of such methods is quite complex with the computationally expensive GNNs. In this work, we propose a method syntactic neighbour-based attention network (SNBAN), that is architecturally simple, takes less computational time and is efficient. SNBAN has a novel and simple architecture that is based on Bi-GRU (Bi-directional Gated Recurrent unit). Specifically, SNBAN can exploit both semantic and syntactic knowledge of the input sentence using two muti-head attentions (MHATT) where the first and second MHATT handle the semantic and syntactic knowledge of the input sentence respectively. The experiments show that the proposed SNBAN significantly outperforms the non-syntactic knowledge-based baselines. The experiments also show that the proposed SNBAN takes a significantly reduced average training time in comparison to GNNs and at the same time performs with comparable accuracy and F1 score against the GNN based methods. & COPY; 2023 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
The use of face masks has become a widespread non-pharmaceutical practice to mitigate the transmission of COVID-19. However, achieving accurate facial detection while people wear masks or similar face occlusions is a major challenge. This paper introduces a model to detect occluded or masked faces based on fused convolutional graphs. This model includes a deep neural architecture with two spatial-based graphs that rely on a set of key facial features. First, a distance graph is used to identify geographical similarity between the facial nodes that represent certain key face parts. Second, a correlation graph is formulated to compute the correlations between every two nodes that represent two different augmented facial modalities. Transfer learning is then performed using a pretrained deep architecture as a baseline to map the abstract semantic information into multiple feature filters. Then, discriminant graph convolutions are constructed based on the fusion of distance and correlation graphs. This model evaluates two tasks of facial detection, which are the binary detection of masked or unmasked faces, and multi-category detection of masked, unmasked, or occluded face with no mask. The experimental results on two benchmarking real-world datasets show that the proposed deep learning model is highly effective with an accuracy of 98% achieved in binary detection. Even with high variance in image occlusions, our proposed model has great promise in detecting and distinguishing between types of facial occlusion with an accuracy of 86% reported in multi-category detection.
APS is the association of antiphospholipid antibodies (aPL) with thromboses and/or recurrent pregnancy loss (RPL). Among patients with SLE, one-third have aPL and 10-15% have a manifestation of secondary APS. Animal studies suggested that complement activation plays an important role in the pathogenesis of thrombosis and pregnancy loss in APS. We performed a cross-sectional study on complement proteins and genes in 525 patients with aPL. Among them, 237 experienced thromboses and 293 had SLE; 111 had both SLE and thromboses, and 106 had neither SLE nor thrombosis. Complement protein levels were determined by radial immunodiffusion for C4, C3 and factor H; and by functional ELISA for mannan binding lectin (MBL). Total C4, C4A and C4B gene copy numbers (GCN) were measured by TaqMan-based realtime PCR. Two to six copies of C4 genes are frequently present in a diploid genome, and each copy may code for an acidic C4A or a basic C4B protein. We observed significantly (a) higher protein levels of total C4, C4A, C4B, C3, and anticardiolipin (ACLA) IgG, (b) increased frequencies of lupus anticoagulant and males, and (c) decreased levels of complement factor H, MBL and ACLA-IgM among patients with thrombosis than those without thrombosis (N = 288). We also observed significantly lower GCNs of total C4 and C4A among aPL-positive patients with both SLE and thrombosis than others. By contrast, aPL-positive subjects with SLE had significantly reduced protein levels of C3, total C4, C4A, C4B and ACLA-IgG, and higher frequency of females than those without SLE. Patients with thrombosis but without SLE (N = 126), and patients with SLE but without thrombosis (N = 182) had the greatest differences in mean protein levels of C3 (p = 2.6 x 10(-6)), C4 (p = 2.2 x 10(-9)) and ACLA-IgG (p = 1.2 x 10(-5)). RPL occurred in 23.7% of female patients and thrombotic SLE patients had the highest frequency of RPL (41.0%; p = 3.8 x 10(-1)0). Compared with non-RPL females, RPL had significantly higher frequency of thrombosis and elevated C4 protein levels. Female patients with homozygous C4A deficiency all experienced RPL (p = 0.0001) but the opposite was true for patients with homozygous C4B deficiency (p = 0.017). These results provide new insights and biomarkers for diagnosis and management of APS and SLE.
Hetero-structured nanocomposite consisting of graphitic carbon nitride host, decorated by gamma-phase iron oxide, maghemite (gamma-Fe2O3@G-CN) was synthesized in different mass contents of gamma-Fe2O3 & nbsp;(5%, 10% and 20%) in the composite, by the method of nanosecond pulsed laser fragmentation, and defect engineering in liquid for the removal of hazardous organic pollutants from aqueous solutions. The elemental, structural, and morphological characterizations of the synthesized nanocomposites by XPS, XRD, TEM, and HR-TEM exhibited the proper anchoring of gamma-Fe2O3 on the graphitic carbon nitride polymeric network. Also, the diffuse reflectance spectra, and the room temperature photoluminescence spectra respectively revealed that the presence of gamma-Fe2O3 & nbsp;in graphitic carbon nitride brought about the enhanced and extended visible light absorption, and reduced recombination of photo induced electron hole pairs, the characteristics desired in a good photo-catalyst. Moreover, this composite material exhibited the z-scheme photo catalytic mechanism, where the more energetic electrons and holes in the composite band structure mediate the redox reaction in the photo-catalysis. The photo-catalytic efficiency of gamma-Fe2O3@G-CN nanocomposite was evaluated in the photo-catalytic degradation of methyl blue (MB), and rhodamine-B (Rh-B) cationic dyes under visible light irradiations. For both the degradation processes, all the variants of gamma-Fe2O3@G-CN nanocomposite consistently showed the enhanced photocatalytic efficiency with respect to pure GCN, with the maximum efficiency recorded for 10% gamma-Fe2O3 in gamma-Fe2O3@G-CN nanocomposite.
Photocatalysis has fascinated wide consideration due to its promising advantage in wastewater treatment. And the metal-oxides and g-C3N4 that possess Z-scheme heterojunctions have become the energetic photocatalysts (PCs) in degrading the organic impurities. In this work, a novel magnetic separable g-C3N4/-Fe2O3 (GFE) nanocomposites (NCs) were fabricated by a facile hydrothermal strategy. Structural, morphological, optical, surface area and magnetic belongings of GFE composites were effectively explored using XRD, FT-IR, XPS, FESEM, HRTEM with EDX mapping, BET, UV-DRS and PL spectra. The (g-C3N4/20 wt % alpha-Fe2O3) GFE2 com-posite PCs were verified robust with significantly upgraded the photocatalytic efficiency for (anionic) RhB (97.2%) and (cationic) MB (90.6%) mixed aqueous organic pollutants degradation in 150 min under visible-light exposure, which was favourably higher than to GCN (65.2%) and alpha-Fe2O3 (16.6%) PCs. Moreover, the as-obtained GFE composite PCs also exposed great stability after five successive recyclabilities. The enhanced photo-degradation activity was largely ascribed to the extended visible-light fascination ability, high surface area, augmented active sites and strong redox ability relatively. Also, the energetic formation of alpha-Fe2O3 coupled g-C3N4 heterojunction that skilled the probable recombination rate and beneficial for the separation of photo-excited electron and hole (e(-)/h(+)) pairs based on active "Z-scheme " mechanism was liable for eliminating organic mixed pollutants.
An energy management strategy is a key technology used to exploit the energy-saving potential of a plug-in hybrid electric vehicle. This paper proposes the environmental perceiver-based equivalent consumption minimization strategy (EP-ECMS) for parallel plug-in hybrid vehicles. In this method, the traffic characteristic information obtained from the intelligent traffic system is used to guide the adjustment of the equivalence factor, improving the environmental adaptiveness of the equivalent consumption minimization strategy (ECMS). Two main works have been completed. First, a high-accuracy environmental perceiver was developed based on a graph convolutional network (GCN) and attention mechanism to complete the traffic state recognition of all graph regions based on historical information. Moreover, it provides the grade of the corresponding region where the vehicle is located (for the ECMS). Secondly, in the offline process, the search for the optimal equivalent factor is completed by using the Harris hawk optimization algorithm based on the representative working conditions under various grades. Based on the identified traffic grades in the online process, the optimized equivalence factor tables are checked for energy management control. The simulation results show that the improved EP-ECMS can achieve 7.25% energy consumption optimization compared with the traditional ECMS.
Accurate traffic status prediction is of great importance to improve the security and reliability of the intelligent transportation system. However, urban traffic status prediction is a very challenging task due to the tight symmetry among the Human-Vehicle-Environment (HVE). The recently proposed spatial-temporal 3D convolutional neural network (ST-3DNet) effectively extracts both spatial and temporal characteristics in HVE, but ignores the essential long-term temporal characteristics and the symmetry of historical data. Therefore, a novel spatial-temporal 3D residual correlation network (ST-3DRCN) is proposed for urban traffic status prediction in this paper. The ST-3DRCN firstly introduces the Pearson correlation coefficient method to extract a high correlation between traffic data. Then, a dynamic spatial feature extraction component is constructed by using 3D convolution combined with residual units to capture dynamic spatial features. After that, based on the idea of long short-term memory (LSTM), a novel architectural unit is proposed to extract dynamic temporal features. Finally, the spatial and temporal features are fused to obtain the final prediction results. Experiments have been performed using two datasets from Chengdu, China (TaxiCD) and California, USA (PEMS-BAY). Taking the root mean square error (RMSE) as the evaluation index, the prediction accuracy of ST-3DRCN on TaxiCD dataset is 21.4%, 21.3%, 11.7%, 10.8%, 4.7%, 3.6% and 2.3% higher than LSTM, convolutional neural network (CNN), 3D-CNN, spatial-temporal residual network (ST-ResNet), spatial-temporal graph convolutional network (ST-GCN), dynamic global-local spatial-temporal network (DGLSTNet), and ST-3DNet, respectively.
Recently, the deep learning models have achieved great success in the recognition of inverse synthetic aperture radar (ISAR) images. However, most of the deep learning models fail to obtain satisfactory results under the condition of small samples due to the contradiction between the large parameter space of the deep learning models and the insufficient labeled samples of space target imaging by ISAR. In this article, a method of meta-learner-based stacking network (MSN) is proposed, which can realize the high-precision classification of space target by ISAR images under the condition of small sample. Innovatively, a rotation-invariant attention mechanism (RAM) module is added into Resnet50 network to magnify the difference of embedded features of target and background. Complementarily, the deep relationship between the features of fine-grained ISAR image is extracted by using graph convolutional network and relation network. Finally, an innovative adaptive weighted XGBoost algorithm is used to integrate the prediction results of the base learners. The main contributions of this article include proposing a RAM module and using an innovative adaptive weighted XGBoost algorithm to realize ensemble learning. The experiment results show that the RAM module effectively concentrates the network's attention on the recognized target, and the recognition rate of MSN is about 5% higher than that of a single base learner under different data volume conditions, which proves that MSN achieves competitive accuracy against other state-of-the-art approaches.
Hematopoietic stem cells (HSCs) undergo functional deterioration with increasing age that causes loss of their self-renewal and regenerative potential. Despite various efforts, significant success in identifying molecular regulators of HSC aging has not been achieved, one prime reason being the non-availability of appropriate human HSC samples. To demonstrate the scope of integrating and re-analyzing the HSC transcriptomics data available, we used existing tools and databases to structure a sequential data analysis pipeline to predict potential candidate genes, transcription factors, and microRNAs simultaneously. This sequential approach comprises (i) collecting matched young and aged mice HSC sample datasets, (ii) identifying differentially expressed genes, (iii) identifying human homologs of differentially expressed genes, (iv) inferring gene co-expression network modules, and (v) inferring the microRNA-transcription factor-gene regulatory network. Systems-level analyses of HSC interaction networks provided various insights based on which several candidates were predicted. For example, 16 HSC aging-related candidate genes were predicted (e.g., CD38, BRCA1, AGTR1, GSTM1, etc.) from GCN analysis. Following this, the shortest path distance-based analyses of the regulatory network predicted several novel candidate miRNAs and TFs. Among these, miR-124-3p was a common regulator in candidate gene modules, while TFs MYC and SP1 were identified to regulate various candidate genes. Based on the regulatory interactions among candidate genes, TFs, and miRNAs, a potential regulation model of biological processes in each of the candidate modules was predicted, which provided systems-level insights into the molecular complexity of each module to regulate HSC aging.
IoT sensor networks have an inherent graph structure that can be used to extract graphical features for improving performance in a variety of prediction tasks. We propose a framework that represents IoT sensor network data as a graph, extracts graphical features, and applies feature selection methods to identify the most useful features that are to be used by a classifier for prediction tasks. We show that a set of generic graph-based features can improve performance of sensor network predictions without the need for application-specific and task-specific feature engineering. We apply this approach to three different prediction tasks: activity recognition from motion sensors in a smart home, demographic prediction from GPS sensor data in a smart phone, and activity recognition from GPS sensor data in a smart phone. Our approach produced comparable results with most of the state-of-the-art methods, while maintaining the additional advantage of general applicability to IoT sensor networks without using sophisticated and application-specific feature generation techniques or background knowledge. We further investigate the impact of using edge-transition times, categorical features, different sensor window sizes, and normalization in the smart home domain. We also consider deep learning approaches, including the Graph Convolutional Network (GCN), for the elimination of feature engineering in the smart home domain, but our approach provided better performance in most cases. We conclude that the graphical feature-based framework that is based on IoT sensor categorization, nodes and edges as features, and feature selection techniques provides superior results when compared to the non-graph-based features.
Background and Objective: For early identification of Alzheimer's disease (AD) based on multi-modal mag-netic resonance imaging (MRI) data, it is important to make comprehensive use of image features and non-image information to analyze the gray matter atrophy and the structural/functional connectivity ab-normalities for different courses of AD.Methods: In this study, we propose an extensible hierarchical graph convolutional network (EH-GCN) for early AD identification. Based on the extracted image features from multi-modal MRI data using the pre-sented multi-branch residual network (ResNet), the brain regions-of-interests (ROIs) based GCN is built to extract structural and functional connectivity features between different ROIs of the brain. In order to further improve the performance of AD identification, an optimized spatial GCN is proposed as convolu-tion operator in the population-based GCN to avoid rebuilding the graph network and take advantage of relationships between subjects. Finally, the proposed EH-GCN is built by embedding the image features and internal brain connectivity features into the spatial population-based GCN, which provides an ex-tensible way to improve early AD identification performance by adding imaging features and non-image information from multi-modal data.Results: Experiments are performed on two datasets, which illustrate the effectiveness of the extracted structural/functional connectivity features and the high computational efficiency of the proposed method. The classification accuracy of AD vs NC, AD vs MCI and MCI vs NC classification tasks reaches 88 . 71% , 82 . 71% and 79 . 68% respectively. The extracted connectivity features between ROIs indicate that functional abnormalities are earlier than gray matter atrophy and abnormalities of structural connections, which is consistent with the clinical manifestations. The proposed method allows for the addition of other modal image features and non-image information from multi-modal data to continuously improve the perfor-mance of clinical data analysis.Conclusions: The proposed method can help us comprehensively analyze the role of gray matter atrophy, the damage of white matter nerve fiber tracts and the degradation of functional connectivity for different courses of AD, which could be useful for further extraction of clinical biomarkers for early AD identifica-tion. (c) 2023 Elsevier B.V. All rights reserved.
With the wide application of graph data in many fields, the research of graph representation learning technology has become the focus of scholars' attention. Especially, dynamic graph representation learning is an important part of solving the problem of change graph in reality. On the one hand, most dynamic graph representation methods focus either on graph structure changes or node embedding changes, ignoring the internal relationship. On the other hand, most dynamic graph neural networks require learn node embeddings from specific tasks, resulting in poor universality of node embeddings and cannot be used in unsupervised tasks. Hence, Dual Evolving Dynamic Graph Convolutional Network (DEDGCN) was proposed to solve the above problems. DEDGCN uses the recurrent neural network to push the evolvement of GCN and nodes, from which it can extract the structural features of dynamic graph and learns the stability features of nodes, respectively, forming an adaptive dynamic graph convolution network. DEDGCN can be classified as unsupervised graph convolutional network. Thus, it is capable of training the unlabeled dynamic graph, it has more extensive application scenarios, and the calculated node embedding has strong generality. We evaluate our proposed method on experimental data in three tasks which are node classification, edge classification, and link prediction. In the classification task, facing the graph with large scale, complex connection relationship, and uncertain change rule, the F1 value of node classification task obtained by DEDGCN reaches 77%, and the F1 value of edge classification task reaches more than 90%. The results show that DEDGCN is effective in capturing graph features, and the effect of DEDGCN is much higher than other baseline methods, which proves the importance of capturing node stability features in dynamic graph representation learning. At the same time, the ability of DEDGCN in unsupervised tasks is further verified by using clustering and anomaly detection tasks, which proves that DEDGCN learning network embedding is widely used.
Background and Objective: Sleep staging is an essential step for sleep disorder diagnosis, which is time-intensive and laborious for experts to perform this work manually. Automatic sleep stage classification methods not only alleviate experts from these demanding tasks but also enhance the accuracy and efficiency of the classification process. Methods: A novel multi-channel biosignal-based model constructed by the combination of a 3D convolutional operation and a graph convolutional operation is proposed for the automated sleep stages using various physiological signals. Both the 3D convolution and graph convolution can aggregate information from neighboring brain areas, which helps to learn intrinsic connections from the biosignals. Electroencephalogram (EEG), electromyogram (EMG), electrooculogram (EOG) and electrocardiogram (ECG) signals are employed to extract time domain and frequency domain features. Subsequently, these signals are input to the 3D convolutional and graph convolutional branches, respectively. The 3D convolution branch can explore the correlations between multichannel signals and multi-band waves in each channel in the time series, while the graph convolution branch can explore the connections between each channel and each frequency band. In this work, we have developed the proposed multi-channel convolution combined sleep stage classification model (MixSleepNet) using ISRUC datasets (Subgroup 3 and 50 random samples from Subgroup 1). Results: Based on the first expert's label, our generated MixSleepNet yielded an accuracy, F1 -score and Cohen kappa scores of 0.830, 0.821 and 0.782, respectively for ISRUC-S3. It obtained accuracy, F1 -score and Cohen kappa scores of 0.812, 0.786, and 0.756, respectively for the ISRUC-S1 dataset. In accordance with the evaluations conducted by the second expert, the comprehensive accuracies, F1 -scores, and Cohen kappa coefficients for the ISRUC-S3 and ISRUC-S1 datasets are determined to be 0.837, 0.820, 0.789, and 0.829, 0.791, 0.775, respectively. Conclusion: The results of the performance metrics by the proposed method are much better than those from all the compared models. Additional experiments were carried out on the ISRUC-S3 sub-dataset to evaluate the contributions of each module towards the classification performance.
We recently identified FAM134B2, which is an N-terminal truncated reticulophagy receptor highly induced by starvation such as fasting of mice and treatment of mammalian cells with a starvation medium that does not contain amino acids, glucose and growth factors. However, which starvation signal mediates the induction of FAM134B2 is still obscure. In this study, we found that amino acid deficiency (AAD) could mimic the starvation condition to induce FAM134B2 expression. Unexpectedly, EIF2AK4/GCN2-mediated integrated signal response (ISR) and MTOR (mechanistic target of rapamycin kinase) signals, which constitute two major signaling pathways that respond to AAD, did not contribute to AAD-induced FAM134B2 induction. mRNA-seq and siRNA screenings identified two ISR-independent transcription factors, MEF2D (myocyte enhancer factor 2D) and NR4A1 (nuclear receptor subfamily 4 group A member 1), involved in AAD-induced FAM134B2 expression. AAD induces MEF2D, resulting in the induction of NR4A1, which in turn induces FAM134B2-mediated reticulophagy to maintain intracellular amino acid levels. In conclusion, the MEF2D-NR4A1-FAM134B2 cascade is a critical signal in amino acid homeostasis.
Rapid economic development and industrialization may include environmentally harmful human activities that cause heavy-metal accumulation in soils, ultimately threatening the quality of the soil environment and human health. Therefore, accurate identification of pollution sources is an important weapon in efforts to control and prevent pollution. The self-organizing map (SOM) method is widely used in pollution source identification because of its capacity for visualization of high-dimensional data. The SOM ignores the graph structure relationship among chemical elements in soils; the SOM analysis of pollution sources has high uncertainty. Here, we propose a new analysis method, i.e., the graph convolutional self-organizing map (GCSOM), which uses a graph convolutional network (GCN) to extract the graph structure relationship among the chemical elements in soils, then performs data visualization using an SOM. We compared the performances of GCSOM and SOM, then assessed the pollution source characteristics of trace metal(loid)s (TMs, mostly heavy metals) in Jiangmen City using the GCSOM. Our experimental results showed that the GCSOM is superior to the SOM for identification of TM sources, while the TMs in the soil of Jiangmen originate from three main sources: agricultural activities (mainly in Taishan City, Jiangmen), traffic emissions (mainly in Xinhui and Pengjiang Districts), and industrial activities (mainly in Xinhui District). The risk assessment indicated that the risk of all TMs was within threshold.
In recent years, various deep learning architectures have been proposed to solve complex challenges (e.g. spatial dependency, temporal dependency) in traffic domain, which have achieved satisfactory performance. These architectures are composed of multiple deep learning techniques in order to tackle various challenges in traffic tasks. Traditionally, convolution neural networks (CNNs) are utilized to model spatial dependency by decomposing the traffic network as grids. However, many traffic networks are graph-structured in nature. In order to utilize such spatial information fully, it's more appropriate to formulate traffic networks as graphs mathematically. Recently, various novel deep learning techniques have been developed to process graph data, called graph neural networks (GNNs). More and more works combine GNNs with other deep learning techniques to construct an architecture dealing with various challenges in a complex traffic task, where GNNs are responsible for extracting spatial correlations in traffic network. These graph-based architectures have achieved state-of-the-art performance. To provide a comprehensive and clear picture of such emerging trend, this survey carefully examines various graph-based deep learning architectures in many traffic applications. We first give guidelines to formulate a traffic problem based on graph and construct graphs from various kinds of traffic datasets. Then we decompose these graph-based architectures to discuss their shared deep learning techniques, clarifying the utilization of each technique in traffic tasks. What's more, we summarize some common traffic challenges and the corresponding graph-based deep learning solutions to each challenge. Finally, we provide benchmark datasets, open source codes and future research directions in this rapidly growing field.
The development of an efficient and photostable heterostructured photocatalyst has attracted a great deal of attention for the degradation of organic pollutants under visible light. Herein, we have developed a highly efficient graphitic carbon nitride/zinc oxide/iron oxide (g-C3N4/ZnO/Fe2O3) ternary composite photocatalysts that were prepared by a simple and cost-effective calcination method. The crystalline structure, functional groups, morphological and optical properties of the as-prepared g-C3N4/ZnO/Fe2O3 (GZF) ternary composite were characterized by X-ray diffraction, Fourier transform infrared spectroscopy, scanning electron microscopy and UV-Vis diffuse-reflectance spectroscopic techniques. The GZF composite reveals enhanced methylene blue (MB) degradation with good photostability of 100% retention rate even after 5 cycles under visible light irradiation. Moreover, GZF composite was degraded 94% of MB after 120 min under visible light irradiation which was almost 6.6- and 3.1-fold higher than individual g-C3N4 (GCN) and g-C3N4/ZnO (GZ). The results suggest that the composites of g-C3N4 with metal oxide under visible light significantly enhance the electron transfer process.
To improve the efficiency of safety management, it is important to classify massive and complex construction site safety hazard texts in large-scale projects. High-precision safety hazard text classification is a lengthy and challenging process. Most existing safety hazard text classification methods capture semantic information using machine learning or deep learning, ignoring the syntactic dependency between words. However, syntactic dependency contains rich structural information that is useful to alleviate information loss and enrich text features. To address these issues, this study proposes a graph structure-based hybrid deep learning method to achieve the automatic classification of large-scale project safety hazard texts. The method uses syntactic dependency and Bidirectional Encoder Representation from Transformers to express the syntactic structure and semantic information of text, and a graph structure fusing the syntactic structure and semantic information is constructed to quantify text information. Further, an encoding-decoding mechanism is built using a graph convolutional neural network and bidirectional long short-term memory to address graph structure data and classify safety hazard texts. Our proposed method is used to classify hydraulic engineering construction safety hazard texts, and the classification accuracy reaches 86.56%. Meanwhile, the experimental results demonstrate that our model achieves superior performance compared to existing methods. This proves the ability of our model to capture and analyze text information and verifies the reliability and effectiveness of this method in large-scale project safety hazard management.
Visual Emotion Analysis (VEA) aims at finding out how people feel emotionally towards different visual stimuli, which has attracted great attention recently with the prevalence of sharing images on social networks. Since human emotion involves a highly complex and abstract cognitive process, it is difficult to infer visual emotions directly from holistic or regional features in affective images. It has been demonstrated in psychology that visual emotions are evoked by the interactions between objects as well as the interactions between objects and scenes within an image. Inspired by this, we propose a novel Scene-Object interreLated Visual Emotion Reasoning network (SOLVER) to predict emotions from images. To mine the emotional relationships between distinct objects, we first build up an Emotion Graph based on semantic concepts and visual features. Then, we conduct reasoning on the Emotion Graph using Graph Convolutional Network (GCN), yielding emotion-enhanced object features. We also design a Scene-Object Fusion Module to integrate scenes and objects, which exploits scene features to guide the fusion process of object features with the proposed scene-based attention mechanism. Extensive experiments and comparisons are conducted on eight public visual emotion datasets, and the results demonstrate that the proposed SOLVER consistently outperforms the state-of-the-art methods by a large margin. Ablation studies verify the effectiveness of our method and visualizations prove its interpretability, which also bring new insight to explore the mysteries in VEA. Notably, we further discuss SOLVER on three other potential datasets with extended experiments, where we validate the robustness of our method and notice some limitations of it.
Intelligent Transportation Systems (ITS) have attracted an increasing amount of attention in recent years. Thanks to the fast development of vehicular computing hardware, vehicular sensors and citywide infrastructures, many impressive applications have been proposed under the topic of ITS, such as Vehicular Cloud (VC), intelligent traffic controls, etc. These applications can bring us a safer, more efficient, and also more enjoyable transportation environment. However, an accurate and efficient traffic flow prediction system is needed to achieve these applications, which creates an opportunity for applications under ITS to deal with the possible road situation in advance. To achieve better traffic flow prediction performance, many prediction methods have been proposed, such as mathematical modeling methods, parametric methods, and non-parametric methods. Among the non-parametric methods, the one of the most famous methods today is the Machine Learningbased (ML) method. It needs less prior knowledge about the relationship among different traffic patterns, less restriction on prediction tasks, and can better fit non-linear features in traffic data. There are several sub-classes under the ML method, such as regression model, kernel-based model, etc. For all these models, it is of vital importance that we choose an appropriate type of ML model before building up a prediction system. To do this, we should have a clear view of different ML methods; we investigate not only the accuracy of different models, but the applicable scenario and sometimes the specific type of problem the model was designed for. Therefore, in this paper, we are trying to build up a clear and thorough review of different ML models, and analyze the advantages and disadvantages of these ML models. In order to do this, different ML models will be categorized based on the ML theory they use. In each category, we will first give a short introduction of the ML theory they use, and we will focus on the specific changes made to the model when applied to different prediction problems. Meanwhile, we will also compare among different categories, which will help us to have a macro overview of what types of ML methods are good at what types of prediction tasks according to their unique model features. Furthermore, we review the useful add-ons used in traffic prediction, and last but not least, we discuss the open challenges in the traffic prediction field.
In the remote sensing domain, it is crucial to complete semantic segmentation on the raster images, e.g., river, building, forest, etc., on raster images. A deep convolutional encoder-decoder (DCED) network is the state-of-the-art semantic segmentation method for remotely sensed images. However, the accuracy is still limited, since the network is not designed for remotely sensed images and the training data in this domain is deficient. In this paper, we aim to propose a novel CNN for semantic segmentation particularly for remote sensing corpora with three main contributions. First, we propose applying a recent CNN called a global convolutional network (GCN), since it can capture different resolutions by extracting multi-scale features from different stages of the network. Additionally, we further enhance the network by improving its backbone using larger numbers of layers, which is suitable for medium resolution remotely sensed images. Second, channel attention is presented in our network in order to select the most discriminative filters (features). Third, domain-specific transfer learning is introduced to alleviate the scarcity issue by utilizing other remotely sensed corpora with different resolutions as pre-trained data. The experiment was then conducted on two given datasets: (i) medium resolution data collected from Landsat-8 satellite and (ii) very high resolution data called the ISPRS Vaihingen Challenge Dataset. The results show that our networks outperformed DCED in terms of F1 for 17.48% and 2.49% on medium and very high resolution corpora, respectively.
Accurate and real-time trajectory data publishing plays an important role in providing users with the latest traffic and road condition information to help in rationally planning travel time and routes. However, the improper publishing of location information and reverse analysis and reasoning can easily leak users' personal information, which may threaten users' privacy and lives. Owing to the inclusion of differential privacy model noise, privacy protection introduces inaccuracies in data publishing and validity. To improve the accuracy and usability of published data, we propose a data publishing method based on deep learning and differential privacy models for securing spatiotemporal trajectory data publishing. The method divides the trajectory data into two-dimensional grid regions, counts the density of trajectories at grids, performs a top-down recursive division of regions, and formulates rules for privacy budget allocation from multiple perspectives as recurrence depth increases. Furthermore, the method integrates spatiotemporal sequence data according to temporal order. Subsequently, it extracts temporal and spatial features of the data by the temporal graph convolutional network model for budget matrix prediction, adds Laplace noise to the regions, and evaluates the effect of differential privacy protection with the original data to protect trajectory data privacy. Experiments demonstrate that under the premise of satisfying epsilon-difference privacy, the query error and Jensen-Shannon divergence are smaller, the Kendall coefficient is more consistent, and the upper and lower limit values are more stable. Hence, the top-down division method achieves better results than those of the two traditional region division methods of the uniform grid and adaptive grid. The proposed method can be used to allocate the privacy budget more reasonably and achieve privacy protection of trajectories, which can be applied to a large amount of spatiotemporal trajectory data.
Scene classification is an active research area in the remote sensing (RS) domain. Some categories of RS scenes, such as medium residential and dense residential scenes, would contain the same type of geographical objects but have various spatial distributions among these objects. The adjacency and disjointness relationships among geographical objects are normally neglected by existing RS scene classification methods using convolutional neural networks (CNNs). In this study, a multi-output network (MopNet) combining a graph neural network (GNN) and a CNN is proposed for RS scene classification with a joint loss. In a candidate RS image for scene classification, superpixel regions are constructed through image segmentation and are represented as graph nodes, while graph edges between nodes are created according to the spatial adjacency among corresponding superpixel regions. A training strategy of a jointly learning CNN and GNN is adopted in the MopNet. Through the message propagation mechanism of MopNet, spatial and topological relationships imbedded in the edges of graphs are employed. The parameters of the CNN and GNN in MopNet are updated simultaneously with the guidance of a joint loss via the backpropagation mechanism. Experimental results on the OPTIMAL-31 and aerial image dataset (AID) datasets show that the proposed MopNet combining a graph convolutional network (GCN) or graph attention network (GAT) and ResNet50 achieves state-of-the-art accuracy. The overall accuracy obtained on OPTIMAL-31 is 96.06% and those on AID are 95.53% and 97.11% under training ratios of 20% and 50%, respectively. Spatial and topological relationships imbedded in RS images are helpful for improving the performance of scene classification.
While traffic modeling and prediction are at the heart of providing high-quality telecommunication services in cellular networks and attract much attention, they have been approved as an extremely challenging task. Due to the diverse network demand of Internet-based apps, the cellular traffic from an individual user can have a wide dynamic range. Most existing methods, on the other hand, model traffic patterns as probabilistic distributions or stochastic processes and impose stringent assumptions over these models. Such assumptions may be beneficial at providing closed-form formula in evaluating prediction performances, but fall short for practice use. In this paper we propose STEP, a spatio-temporal fine-granular user traffic prediction mechanism for cellular networks. A deep graph convolution network, called GCGRN, is constructed. It is a novel combination of the graph convolution network (GCN) and gated recurrent units (GRU), which exploits graph neural network to learn an efficient spatio-temporal model from a user's massive dataset for traffic prediction. The prototype of STEP has been implemented. Extensive experimental results demonstrate that our model outperforms the state-of-the-art time-series based approaches. Besides, STEP merely incurs mild energy consumption, communication overhead and system resource occupancy to mobile devices. Moreover, NS-3 based simulations validate the efficacy of STEP in reducing session dropping ratio in cellular networks.
Citation recommendation can help researchers quickly find supplementary or alternative references in massive academic resources. Current research on citation recommendation mainly focuses on the citing papers, resulting in the enormous cited papers are ignored, including the relations among cited papers and their citation context cited in citing papers. Moreover, cited paper's content is often denoted with its original title and abstract, which is hard to acquire and rarely considers different citation motivations. Furthermore, the most appropriate method for semantic representation of cited papers' relations and content is uncertain. Therefore, this paper studies citation recommendation from the perspective of semantic representation of cited papers' relations and content. Firstly, four forms of citation context are designed and extracted as cited papers' content considering citation motivations, as well as co-citation relationships are extracted as cited papers' relations. Secondly, 132 methods are designed for generating semantic vector of cited paper, including four network embedding methods, 16 methods by combining four text representation algorithms with four forms of citation content, and 112 fusion methods. Finally, similarity among cited papers is calculated for citation recommendation and a quantitative evaluation method based on link prediction is designed, to find the most appropriate form of citation content and the optimal method. The result shows that doc2vecC (Document to Vector through Corruption) with the form of CS&SS (Current Sentences and Surrounding Sentences) performs best, in which the AUC (Area Under Curve) and MAP (Macro Average Precision) reach 0.877 and 0.889 and have increased by 0.462 and 0.370 compared with the worst-performing method. This performance is slightly improved by parameters adjustment, and a case study is performed whose results have further proved the effectiveness of this method. In addition, among four forms of cited papers' content, CS&SS performs best in almost all methods. Furthermore, the fusion methods not always perform better than the single methods, where doc2vecC (CS&SS) performs better than the best fusion method GCN (Graph Convolutional Network). These results not only prove the effectiveness of citation recommendation from the perspective of cited paper, but also provide helpful and useful suggestions for method selection and citation content selection. The data and conclusions can be extended to other text mining-related tasks. Simultaneously, it is a preliminary research which needs to be further studied in other domains using emerging semantic representation methods.
Although many graph convolutional neural networks (GCNNs) have achieved superior performances in semisupervised node classification, they are designed from either the spatial or spectral perspective, yet without a general theoretical basis. Besides, most of the existing GCNNs methods tend to ignore the ubiquitous noises in the network topology and node content and are thus unable to model these uncertainties. These drawbacks certainly reduce their effectiveness in integrating network topology and node content. To provide a probabilistic perspective to the GCNNs, we model the semisupervised node classification problem as a topology-constrained probabilistic latent space model, probabilistic graph convolutional network (PGCN). By representing the nodes in a more efficient distribution form, the proposed framework can seamlessly integrate the node content and network topology. When specifying the distribution in PGCN to be a Gaussian distribution, the transductive node classification problems can be solved by the general framework and a specific method, called PGCN with the Gaussian distribution representation (PGCN-G), is proposed. To overcome the overfitting problem in covariance estimation and reduce the computational complexity, PGCN-G is further improved to PGCN-G+ by imposing the covariance matrices of all vertices to possess the identical singular vectors. The optimization algorithm based on expectation-maximization indicates that the proposed method can iteratively denoise the network topology and node content with respect to each other. Besides the effectiveness of this top-down framework demonstrated via extensive experiments, it can also be deduced to cover the existing methods, graph convolutional network, graph attention network, and Gaussian mixture model and elaborate their characteristics and relationships by specific derivations.
Existing malicious device detection preprocessing ignores the topological similarity of node neighborhood structures in the network. According to the structural equivalence hypothesis, devices with approximately local symmetry in the device-account graph have similar topological embeddings after preprocessing. In order to improve the performance of malicious device detection, we propose the Graph Structural-topic Similar Subgraph Merging, abbreviated GraphSTSGM, to extract topological similarity between nodes. GraphSTSGM extracts approximate local symmetry features by adding local neighborhood structural patterns merge to Graph Structural-topic Neural Network (GraphSTONE). In this algorithm, we build a device-account relationship graph G with devices and accounts as nodes, build an edge between associated devices and accounts, and then calculate the approximate local symmetry of each device via the merge-similar-substructures-based anonymous walk in G. Then, the approximate local symmetry features and device features of the nodes are aggregated through Graph Convolutional Network (GCN). We use the above algorithm as a preprocessing method to enhance the ability of malicious device detection by accurately characterizing the approximate local symmetry features of nodes. Finally, the obtained aggregated features are used as the input of the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) model for malicious device detection. Experiments based on Alibaba Cloud Security data show that the proposal outperforms the state-of-the-art algorithms by 3.6% with respect to the AUC of malicious device detection. In addition, experiments based on the graph dataset Cora show that the proposal outperforms the state-of-the-art algorithms by 2.6% with respect to the AUC of node classification.
The graduation development such as employment and graduate school admission of college students are important tasks. However, mining the factors that can affect the development of graduation remains challenging, because the most important factor "course" is not independent and inequality, which are always ignored by previous researchers. Furthermore, traditional structured methods cannot handle the complex relationships between courses, and attention networks cannot distinguish the weights of compulsory and elective courses with different distributions. Therefore, we present a Graph-based Hierarchical Attention Neural Network Model with Elective Course (GHANN-EC) for the prediction of graduation development in this study. Specifically, we use graph embedding that captures the unstructured relationships between courses and hierarchical attention that assigns the importance of the courses to excavating course information that represent students' independent interests, and can more accurately understand the relationship between graduation development and academic performance. Experimental results on the real-world datasets show that GHANN-EC outperforms the existing popular approach.
In skeleton-based human action recognition, Transformer, which models the correlations between joint pairs in global topology, has achieved remarkable results. However, compared to many researches on changing graph topology learning in graph convolution network (GCN), Transformer self-attention ignores the topology of the skeleton graph when capturing the dependencies between joints. To address these problems, we propose a novel two-stream spatial Graphormer network (2s-SGR), which uses self-attention incorporating structural encodings to model joint and bone information, and which consists of two networks, the joint stream spatial Graphormer network (Js-SGR) and the bone stream spatial Graphormer network (Bs-SGR). First, in the Js-SGR, while Transformer models joint correlations in the global topology of the space, the topology of the joints and the edge information of the bones are introduced into the self-attention through custom structural encodings. At the same time, joint motion information is modeled in spatial-temporal blocks. The added information on structure and motion can effectively capture the dependencies of nodes between frames and enhance feature representation. Second, for the second-order information of the skeleton, the Bs-SGR adapts to the structure of the bone by adjusting the custom structural encodings. Finally, the global spatial-temporal features of joints and bones in the skeleton are fused and input into the classification network to obtain action recognition results. Extensive experiments on three large-scale datasets, NTU-RGB+D 60, NTU-RGB+D 120, and Kinetics, demonstrate that the performance of the 2s-SGR proposed in this paper is at the state-of-the-art level and is effectively validated by ablation experiments.
Motivation: Protein function prediction is a difficult bioinformatics problem. Many recent methods use deep neural networks to learn complex sequence representations and predict function from these. Deep supervised models require a lot of labeled training data which are not available for this task. However, a very large amount of protein sequences without functional labels is available. Results: We applied an existing deep sequence model that had been pretrained in an unsupervised setting on the supervised task of protein molecular function prediction. We found that this complex feature representation is effective for this task, outperforming hand-crafted features such as one-hot encoding of amino acids, k-mer counts, secondary structure and backbone angles. Also, it partly negates the need for complex prediction models, as a two-layer perceptron was enough to achieve competitive performance in the third Critical Assessment of Functional Annotation benchmark. We also show that combining this sequence representation with protein 3D structure information does not lead to performance improvement, hinting that 3D structure is also potentially learned during the unsupervised pretraining.
Human activity recognition is one of the most studied topics in the field of computer vision. In recent years, with the availability of RGB-D sensors and powerful deep learning techniques, research on human activity recognition has gained momentum. From simple human atomic actions, the research has advanced towards recognizing more complex human activities using RGB-D data. This paper presents a comprehensive survey of the advanced deep learning based recognition methods and categorizes them in human atomic action, human-human interaction, human-object interaction. The reviewed methods are further classified based on the individual modality used for recognition i.e. RGB based, depth based, skeleton based, and hybrid. We also review and categorize recent challenging RGB-D datasets for the same. In addition, the paper also briefly reviews RGB-D datasets and methods for online activity recognition. The paper concludes with a discussion on limitations, challenges, and recent trends for promising future directions.
Graph representations are often used to model structured data at an individual or population level and have numerous applications in pattern recognition problems. In the field of neuroscience, where such representations are commonly used to model structural or functional connectivity between a set of brain regions, graphs have proven to be of great importance. This is mainly due to the capability of revealing patterns related to brain development and disease, which were previously unknown. Evaluating similarity between these brain connectivity networks in a manner that accounts for the graph structure and is tailored for a particular application is, however, non-trivial. Most existing methods fail to accommodate the graph structure, discarding information that could be beneficial for further classification or regression analyses based on these similarities. We propose to learn a graph similarity metric using a siamese graph convolutional neural network (s-GCN) in a supervised setting. The proposed framework takes into consideration the graph structure for the evaluation of similarity between a pair of graphs, by employing spectral graph convolutions that allow the generalisation of traditional convolutions to irregular graphs and operates in the graph spectral domain. We apply the proposed model on two datasets: the challenging ABIDE database, which comprises functional MRI data of 403 patients with autism spectrum disorder (ASD) and 468 healthy controls aggregated from multiple acquisition sites, and a set of 2500 subjects from UK Biobank. We demonstrate the performance of the method for the tasks of classification between matching and non-matching graphs, as well as individual subject classification and manifold learning, showing that it leads to significantly improved results compared to traditional methods.
The mushroom growth of cellular users requires novel advancements in the existing cellular infrastructure. One way to handle such a tremendous increase is to densely deploy terrestrial small-cell base stations (TSBSs) with careful management of smart backhaul/fronthaul networks. Nevertheless, terrestrial backhaul hubs significantly suffer from the dense fading environment and are difficult to install in a typical urban environment. Therefore, this paper considers the idea of replacing terrestrial backhaul network with an aerial network consisting of unmanned aerial vehicles (UAVs) to provide the fronthaul connectivity between the TSBSs and the ground core-network (GCN). To this end, we focus on the joint positioning of UAVs and the association of TSBSs such that the sum-rate of the overall system is maximized. In particular, the association problem of TSBSs with UAVs is formulated under communication-related constraints, i.e., bandwidth, number of connections to a UAV, power limit, interference threshold, UAV heights, and backhaul data rate. To meet this joint objective, we take advantage of the genetic algorithm (GA) due to the offline nature of our optimization problem. The performance of the proposed approach is evaluated using the unsupervised learning-based k-means clustering algorithm. We observe that the proposed approach is highly effective to satisfy the requirements of smart fronthaul networks.
The rational design of ultralong carbon nitride nanostructures is highly attractive due to their high aspect ratio alongside their high surface-to-bulk ratio, which make them suitable candidates for various applications such as photocatalysts, water treatment, and sensors. However, the synthesis of ultralong, continuous carbon nitride wires is highly challenging. Here we report the synthesis of 4 cm long and large lateral size carbon nitride wires by utilizing unique supramolecular spheres composed of graphitic carbon nitride (g-CN) monomers as the reactants. In situ scanning electron microscopy studies reveal that upon calcination the gCN wires spontaneously start to grow from the spheres, while the remaining assembly which acts as a substrate creates self-standing carbon rich g-CN porous films. The different morphology, chemical composition, and electronic properties of the wires and carbon-rich g-CN allow their utilization as both photocatalyst and water cleaning materials. The g-CN wires exhibit excellent photoactivity for hydrogen production whereas the porous carbon-rich g-CN porous film can be efficiently used for water cleaning applications. The reported work opens opportunities for tailored design of g-CN nanostructures and their use as multifunctional materials for photocatalysis, sensing, and other energy-related applications.
ATP binding cassette transporters (ABCTs) is one of the largest gene superfamily comprising of integral membrane proteins that are ubiquitously found in all domains of life and implicated in ATP dependent active transport of ligands across the concentration gradient. We present here the identification and distribution of ABC proteins from seven plant species into four groups (Full, Half, Quarter and ABC2 molecules), eight families (ABCA to ABCG and ABCI) and twelve sub families (MDR, PDR, MRP, PMP, AOH, ATH, ATM, TAP, WBC, RLI, GCN and NAP) based on topology, orientation, size, and phylogenetic relationships with main focus on four cotton species especially tetraploid Gossypium hirsutum (Gh) encoding 320 ORFs. Dynamics of complex formation of structurally characterized ABCTs from each subfamily shows their kinetic and molecular mechanisms to combine the ATP hydrolysis and binding for substrate translocation, portraying a "structure to function relationship". Analysis of protein motif and genomic organizations displayed structural and functional conservation within same subfamily but diverged among the different subfamilies. Abundance of small sized single ABCs signifies the higher gene death/birth rate and ongoing evolution for functional advancements and environmental adaptability. Gene duplication relationship analysis illustrates the major role of tandem and segmental duplication in large scale expansion of ABC gene family in mentioned species. The overall Ka/Ks ratio indicated the intense purifying selection of ABC genes in four cotton species during evolution. In addition, tissue specific expression profiling, abiotic stress resistance and Co-expression networking of GhABCs infers their role in diverse range of molecular, cellular and biological processes. Cis-elements and gene enrichments also supported their predicted roles in substrates translocation, xenobiotic detoxification, lipid metabolism, hormonal and abiotic stresses responses. Forward and reverse genetics along with evolutionary trajectories, structural dynamics and validated expression profiling will provide much-needed clarity and a qualitative molecular framework for future research. This study will further broaden our insights into the evolution and functional elucidation of ABC gene family in cotton.
In recent years, the motion capture system has received a lot of attention because of its wide application, such as movie animation, sport and medical applications. In the field of rehabilitation, motion capture systems are often used to collect the motion information of the patient when he/she is performing rehabilitation tasks. It can be used to quantify the patient's rehabilitation effectiveness and provide the physician with more objective data as a reference. Using inertial sensors is one of motion capture methods. However, the major challenge to reconstruct accurate human posture with sensor measurements are signal noise, bias and inaccurate gyroscope estimation during long-term wearing. Based on the reason mentioned above, this paper proposes a graph convolutional network (GCN)-based deep learning architecture that uses effective information collected by inertial sensors to predict a sequence of position of each joint of a human's lower limbs in the 3D space throughout the entire motion. Such motion prediction result based on the deep learning model is to reduce the joint's tracking error relying only on direct calculations based on measurements of inertial sensors. In the final experiment, the lower limb motion trajectory during walking is used to verify that the method proposed in this work can actually outperform the traditional ones as just mentioned by achieving 2.9 mm drop in mean per joint position error (MPJPE) in 3.6M dataset, resulting in 12.2 mm in MPJPE, and mitigate the drift in real scenario. In our future work, we plan to verify the effectiveness of the proposed model and system for rehabilitation through clinical studies.
Point clouds are the most general data representations of real and abstract objects, and have a wide variety of applications in many science and engineering fields. Point clouds also provide the most scalable multi-resolution composition for geometric structures. Although point cloud learning has shown remarkable results in shape estimation and semantic segmentation, the unsupervised generation of 3D object parts still pose significant challenges in the 3D shape understanding problem. We address this problem by proposing a novel Generative Adversarial Network (GAN), named HSGAN, or Hierarchical Self-Attention GAN, with remarkable properties for 3D shape generation. Our generative model takes a random code and hierarchically transforms it into a representation graph by incorporating both Graph Convolution Network (GCN) and self-attention. With embedding the global graph topology in shape generation, the proposed model takes advantage of the latent topological information to fully construct the geometry of 3D object shapes. Different from the existing generative pipelines, our deep learning architecture articulates three significant properties HSGAN effectively deploys the compact latent topology information as a graph representation in the generative learning process and generates realistic point clouds, HSGAN avoids multiple discriminator updates per generator update, and HSGAN preserves the most dominant geometric structures of 3D shapes in the same hierarchical sampling process. We demonstrate the performance of our new approach with both quantitative and qualitative evaluations. We further present a new adversarial loss to maintain the training stability and overcome the potential mode collapse of traditional GANs. Finally, we explore the use of HSGAN as a plug-and-play decoder in the auto-encoding architecture.
IMPORTANCE Repeat expansion of CGG in LRP12 has been identified as the causative variation of oculopharyngodistal myopathy (OPDM). However, to our knowledge, the clinicopathologic features of OPDM with CGG repeat expansion in LRP12 (hereafter referred to as OPDM_LRP12) remain unknown. OBJECTIVE To identify and characterize the clinicopathologic features of patients with OPQM_LRP12. DESIGN, SETTING, AND PARTICIPANTS This case series included 208 patients with a clinical or clinicopathologic diagnosis of oculopharyngeal muscular dystrophy (OPDM) from January 1, 1978, to December 31, 2020. Patients with GCN repeat expansions in PABPNI were excluded from the study. Repeat expansions of CGG in LRP12 were screened by repeat primed polymerase chain reaction and/or Southern blot. MAIN OUTCOMES AND MEASURES Clinical information, muscle imaging data obtained by either computed tomography or magnetic resonance imaging, and muscle pathologic characteristics. RESULTS Sixty-five Japanese patients with OPDM (40 men [62%]; mean [SD] age at onset, 41.0 [10.1] years) from 59 families with CGG repeat expansions in LRP12 were identified. This represents the most common OPDM subtype among all patients in Japan with genetically diagnosed OPDM. The expansions ranged from 85 to 289 repeats. A negative correlation was observed between the repeat size and the age at onset (r(2) = 0.188, P = .001). The most common initial symptoms were ptosis and muscle weakness, present in 24 patients (37%). Limb muscle weakness was predominantly distal in 53 of 64 patients (83%), but 2 of 64 patients (3%) had predominantly proximal muscle weakness. Ptosis was observed in 62 of 64 patients (97%), and dysphagia or dysarthria was observed in 63 of 64 patients (98%). A total of 21 of 64 patients (33%) had asymmetric muscle weakness. Aspiration pneumonia was seen in 11 of 64 patients (17%), and 5 of 64 patients (8%) required mechanical ventilation. Seven of 64 patients (11%) developed cardiac abnormalities, and 5 of 64 patients (8%) developed neurologic abnormalities. Asymmetric muscle involvement was detected on computed tomography scans in 6 of 27 patients (22%) and on magnetic resonance imaging scans in 4 of 15 patients (27%), with the soleus and the medial head of the gastrocnemius being the worst affected. All 42 muscle biopsy samples showed rimmed vacuoles. lntranuclear tubulofilamentous inclusions were observed in only 1 of 5 patients. CONCLUSIONS AND RELEVANCE This study suggests that OPDM_LRP12 is the most frequent OPDM subtype in Japan and is characterized by oculopharyngeal weakness, distal myopathy that especially affects the soleus and gastrocnemius muscles, and rimmed vacuoles in muscle biopsy.
Accurately predicting the fluids holds immense significance in exploration work, assisting in the identification of exploration targets, estimation of reserve potential, and evaluation of reservoirs. In our research, we employed an innovative approach by using the gram angle field (GAF) to transform logging parameters. By adeptly capturing time series information and converting one-dimensional data into two-dimensional matrix representations, GAF takes into account not only the values at each time point but also their relative position and order. This method effectively preserves the temporal evolution characteristics of the original data. The resulting Gram Angle Field matrix can be viewed as a two-dimensional image, facilitating visualization and analysis through image processing techniques. Additionally, we introduced the dynamic graph convolutional network (DGCN) to segment the transformed images. The DGCN structure, employed for feature learning, can extract more comprehensive and representative feature representations from the logging data. Since logging data demonstrate a time series relationship, indicating a temporal correlation between logging curves at different depths, DGCN utilizes dynamic graph structures to capture and comprehend this time series information. This capability enables DGCN to model the evolution process of well log data effectively. DGCN assigns varying weights to nodes and edges at each time step, updating the current node representation with information from neighboring nodes. This localized approach enables DGCN to meticulously focus on significant features at each time step, facilitating the identification of potential patterns and trends in the logging data. Our research not only paves the way for advancements in the field but also provides valuable insights for geologists and professionals engaged in oil and gas exploration.
Recommender systems are designed to help users find matching items from plenty of candidates in online platforms. In many online platforms, such as Yelp and Epinions, users' behaviors are constantly recorded over time, and the users also can build connections with others and share their interests. Previous recommendation methods have either modeled the dynamic interests or the dynamic social influences. A few studies have focused on the modeling of both factors, but they still have several limi-tations: 1) they fail to consider the complex items transitions among all session sequences, which can be used as a local factor to boost the performance of recommendation methods, and 2) they ignore that a user and their friends only share the same preferences in certain sessions, by keeping the friend vector unchanged for all target users at time t, and 3) they do not consider that a user's long-term preference may change with the evolution of interests. To overcome the above issues, in this paper, we propose an approach to incorporate item graph embedding and contextual friendship modeling into the recommendation task. Specifically, 1) we construct a directed item graph based on all historical session sequences and utilize a graph neural network to capture the rich local dependency between items, and 2) take a session-level attention mechanism to get each friend's representation according to the target user's current interests, and 3) apply max-pooling on the target user's historical session interests to learn the dynamics of his/her long-term interests. Extensive experiments on two real-world datasets show that our proposed model outperforms stateof-the-art methods consistently on various evaluation metrics. (c) 2020 Elsevier B.V. All rights reserved.
Introduction: Recent studies in human brain connectomics with multimodal magnetic resonance imaging (MRI) data have widely reported abnormalities in brain structure, function and connectivity associated with schizophrenia (SZ). However, most previous discriminative studies of SZ patients were based on MRI features of brain regions, ignoring the complex relationships within brain networks. Methods: We applied a graph convolutional network (GCN) to discriminating SZ patients using the features of brain region and connectivity derived from a combined multimodal MRI and connectomics analysis. Structural magnetic resonance imaging (sMRI) and resting-state functional magnetic resonance imaging (rs-fMRI) data were acquired from 140 SZ patients and 205 normal controls. Eighteen types of brain graphs were constructed for each subject using 3 types of node features, 3 types of edge features, and 2 brain atlases. We investigated the performance of 18 brain graphs and used the TopK pooling layers to highlight salient brain regions (nodes in the graph). Results: The GCN model, which used functional connectivity as edge features and multimodal features (sMRI + fMRI) of brain regions as node features, obtained the highest average accuracy of 95.8%, and outperformed other existing classification studies in SZ patients. In the explainability analysis, we reported that the top 10 salient brain regions, predominantly distributed in the prefrontal and occipital cortices, were mainly involved in the systems of emotion and visual processing. Discussion: Our findings demonstrated that GCN with a combined multimodal MRI and connectomics analysis can effectively improve the classification of SZ at an individual level, indicating a promising direction for the diagnosis of SZ patients. The code is available at https://github.com/CXY-scut/GCN-SZ.git.
Research in semi-supervised learning on graphs has attracted more and more attention in recent years, as learning on graphs is applied in more and more domains and labeling data is expensive and time-consuming. Some scenarios have inherent graph structures in their data, such as the relationships between people in social scenarios or the relationships between objects that are mutually referenced. However, there are also many data types without inherent graph structures, such as image data, and each image can be described with different features, which is a typical type of multi-view data. For image data and other non-graph data, there are significantly fewer deep learning approaches that target multi-view graph-based semi-supervised learning. This paper attempts to fill this gap. Based on the Graph Convolutional Network (GCN) architecture, we propose a Sample-weighted Fused Graph-based Semi-supervised Classification (WFGSC) method for multi view data in this paper. It (i) constructs a semi-supervised graph in each view using a flexible model for joint graph and label estimation, (ii) obtains an additional graph based on the representation of nodes provided by the joint estimator, and then obtains a fused graph between all views, (iii) gives higher weights to hard-to-classify samples, (iv) proposes a loss function to train the GCN on the fused features and the consensus graph that integrates graph auto-encoder loss and label smoothing over the consensus graph. The results of our experiments on six multi-view datasets show that our WFGSC performs well on both fused graph construction and semi-supervised classification, and generally outperforms traditional GCNs and other multi-view semi-supervised multi-view classification methods.1
Stereopsis is the ability of human beings to get the 3D perception on real scenarios. The conventional stereopsis measurement is based on subjective judgment for stereograms, leading to be easily affected by personal consciousness. To alleviate the issue, in this paper, the EEG signals evoked by dynamic random dot stereograms (DRDS) are collected for stereogram recognition, which can help the ophthalmologists diagnose strabismus patients even without real-time communication. To classify the collected Electroencephalography (EEG) signals, a novel multi-scale temporal self-attention and dynamical graph convolution hybrid network (MTS-DGCHN) is proposed, including multi-scale temporal self-attention module, dynamical graph convolution module and classification module. Firstly, the multi-scale temporal self-attention module is employed to learn time continuity information, where the temporal self-attention block is designed to highlight the global importance of each time segments in one EEG trial, and the multi-scale convolution block is developed to further extract advanced temporal features in multiple receptive fields. Meanwhile, the dynamical graph convolution module is utilized to capture spatial functional relationships between different EEG electrodes, in which the adjacency matrix of each GCN layer is adaptively tuned to explore the optimal intrinsic relationship. Finally, the temporal and spatial features are fed into the classification module to obtain prediction results. Extensive experiments are conducted on collected datasets i.e., SRDA and SRDB, and the results demonstrate the proposed MTS-DGCHN achieves outstanding classification performance compared with the other methods. The datasets are available at https://github.com/YANGeeg/TJU-SRD-datasets and the code is at https://github.com/YANGeeg/MTS-DGCHN.
Convolutional neural networks (CNNs) have promoted the development of insulation defect diagnosis for gas-insulated switchgear (GIS) because of their excellent feature extraction and classification capabilities. However, CNN ignores the correlation between the local areas of the feature space, resulting in insufficient feature utilization. Moreover, deploying and applying the methods explored in massive laboratory data to complex and few-shot conditions on-site is a difficult problem currently. Therefore, this study proposes a novel domain adaptation graph convolutional network (DAGCN) for GIS insulation defect diagnosis. First, the graph signal and graph convolution network are used to take advantage of the correlation between the local areas of the feature space while employing the numerical characteristics of the insulation defect signal. Then, the learned diagnostic method is deployed to the on-site GIS insulation defect diagnosis with domain adaptive transfer learning (TL). The difference between the two tasks is reduced by minimizing the difference between the marginal and conditional distributions of the source and target domains, thus, realizing the feature migration. The experimental verification shows that DAGCN has higher diagnostic accuracy and robustness than traditional methods, especially in diagnosing few-shot on-site. It provides a reliable reference for high-precision and robust diagnosis of few-shot GIS insulation defect diagnosis.
Simple Summary Identifying cancer driver genes plays a significant role in cancer diagnosis and treatment. With the advancement of next-generation sequencing technologies, a wealth of multi-omics cancer data, including genomic, epigenomic, and transcriptomic data, are now available for cancer research. Integrating these data to effectively identify cancer driver genes causally associated with cancer is a computational challenge. Methods for identifying cancer driver genes are mainly based on population levels. Considering the trend of precision medicine and the heterogeneity of patients, it is challenging but crucial to identify cancer driver genes at the individual level. We developed a method called PDGCN (Personalized Drivers of GCN), which constructs sample-gene interaction networks by integrating multiple types of data features and using network structural features extracted from Node2vec. Then, a graphical convolutional neural network model with a conditional random field layer is used to prioritize candidate driver genes in the network. The results show that PDGCN can identify driver genes at the individual level, providing a new perspective for predicting driver genes in individual samples.Abstract Cancer is a complex and evolutionary disease mainly driven by the accumulation of genetic variations in genes. Identifying cancer driver genes is important. However, most related studies have focused on the population level. Cancer is a disease with high heterogeneity. Thus, the discovery of driver genes at the individual level is becoming more valuable but is a great challenge. Although there have been some computational methods proposed to tackle this challenge, few can cover all patient samples well, and there is still room for performance improvement. In this study, to identify individual-level driver genes more efficiently, we propose the PDGCN method. PDGCN integrates multiple types of data features, including mutation, expression, methylation, copy number data, and system-level gene features, along with network structural features extracted using Node2vec in order to construct a sample-gene interaction network. Prediction is performed using a graphical convolutional neural network model with a conditional random field layer, which is able to better combine the network structural features with biological attribute features. Experiments on the ACC (Adrenocortical Cancer) and KICH (Kidney Chromophobe) datasets from TCGA (The Cancer Genome Atlas) demonstrated that the method performs better compared to other similar methods. It can identify not only frequently mutated driver genes, but also rare candidate driver genes and novel biomarker genes. The results of the survival and enrichment analyses of these detected genes demonstrate that the method can identify important driver genes at the individual level.
Social recommendation leverages social information to alleviate data sparsity and cold-start issues of collaborative filtering (CF) methods. Most existing works model user interests following the assumption of social homophily based on social-relation data. The explicit modeling of social influence, which also largely affects user behaviors, has not been well explored. Considering user behaviors may be driven by social factors in today's information services (e.g., purchasing products shared by close friends on social e-commerce applications), these methods will be suboptimal. In this work, we propose a method modeling both social homophily-aware user interests and social influence as two essential effects on user behaviors for social recommendation, named as DISGCN (short for DISentangled modeling of Social homophily and influence with Graph Convolutional Network). Specifically, we devise a disentangled embedding layer to encode these two effects. Furthermore, two tailored graph convolutional layers are developed to disentangle them refinedly, leveraging the high-order embedding propagation in social-network graph from two aspects. Technically, first, the operation of attentive embedding propagation is adopted for capturing personalized social homophily-aware interests, and second, the item-gate-based embedding propagation is proposed for capturing item-specific social influence. In addition, to ensure the disentanglement of social influence, we propose a contrastive learning framework that endows corresponding embeddings with explicit semantics. Extensive experiments on two real-world datasets demonstrate the effectiveness of our proposed model. Further studies also verify the rationality and necessity of our designs. We have released the datasets and codes at this link: https://github.com/tsinghua-fib-lab/DISGCN.
Benefiting from the intuitiveness and naturalness of sketch interaction, sketch-based video retrieval (SBVR) has received considerable attention in the video retrieval research area. However, most existing SBVR research still lacks the capability of accurate video retrieval with fine-grained scene content. To address this problem, in this paper we investigate a new task, which focuses on retrieving the target video by utilizing a fine-grained storyboard sketch depicting the scene layout and major foreground instances' visual characteristics (e.g., appearance, size, pose, etc.) of video; we call such a task "fine-grained scene-level SBVR". The most challenging issue in this task is how to perform scene-level cross-modal alignment between sketch and video. Our solution consists of two parts. First, we construct a scene-level sketch-video dataset called SketchVideo, in which sketch-video pairs are provided and each pair contains a clip-level storyboard sketch and several keyframe sketches (corresponding to video frames). Second, we propose a novel deep learning architecture called Sketch Query Graph Convolutional Network (SQ-GCN). In SQ-GCN, we first adaptively sample the video frames to improve video encoding efficiency, and then construct appearance and category graphs to jointly model visual and semantic alignment between sketch and video. Experiments show that our fine-grained scene-level SBVR framework with SQ-GCN architecture outperforms the state-of-the-art fine-grained retrieval methods. The SketchVideo dataset and SQ-GCN code are available in the project webpage https://iscas-mmsketch.github.io/FG-SL-SBVR/.
Graph theory analysis using electroencephalogram (EEG) signals is currently an advanced technique for seizure prediction. Recent deep learning approaches, which fail to fully explore both the characterizations in EEGs themselves and correlations among different electrodes simultaneously, generally neglect the spatial or temporal dependencies in an epileptic brain and, thus, produce suboptimal seizure prediction performance consequently. To tackle this issue, in this article, a patient-specific EEG seizure predictor is proposed by using a novel spatio-temporal-spectral hierarchical graph convolutional network with an active preictal interval learning scheme (STS-HGCN-AL). Specifically, since the epileptic activities in different brain regions may be of different frequencies, the proposed STS-HGCN-AL framework first infers a hierarchical graph to concurrently characterize an epileptic cortex under different rhythms, whose temporal dependencies and spatial couplings are extracted by a spectral-temporal convolutional neural network and a variant self-gating mechanism, respectively. Critical intrarhythm spatiotemporal properties are then captured and integrated jointly and further mapped to the final recognition results by using a hierarchical graph convolutional network. Particularly, since the preictal transition may be diverse from seconds to hours prior to a seizure onset among different patients, our STS-HGCN-AL scheme estimates an optimal preictal interval patient dependently via a semisupervised active learning strategy, which further enhances the robustness of the proposed patient-specific EEG seizure predictor. Competitive experimental results validate the efficacy of the proposed method in extracting critical preictal biomarkers, indicating its promising abilities in automatic seizure prediction.
The continuous improvement of the cyber threat intelligence sharing mechanism provides new ideas to deal with Advanced Persistent dures (TTP) from Cyber Threat Intelligence (CTI) can facilitate APT actors??? profiling for an immediate response. However, it is difficult for traditional manual methods to analyze attack behaviors from cyber threat intelligence due to its heterogeneous nature. Based on the Adversarial Tactics, Techniques and Common Knowledge (ATT&CK) of threat behavior description, this paper proposes a threat behavioral knowledge extraction framework that integrates Heterogeneous Text Network (HTN) and Graph Convolutional Network (GCN) to solve this issue. It leverages the hierarchical correlation relationships of attack techniques and tactics in the ATT&CK to construct a text network of heterogeneous cyber threat intelligence. With the help of the Bidirectional Encoder Representation from Transformers (BERT) pretraining model to analyze the contextual semantics of cyber threat intelligence, the task of threat behavior identification is transformed into a text classification task, which automatically extracts attack behavior in CTI, then identifies the malware and advanced threat actors. The experimental results show that F1 achieve 94.86% and 92.15% for the multi-label classification tasks of tactics and techniques. Extend the experiment to verify the method???s effectiveness in identifying the malware and threat actors in APT attacks. The F1 for malware and advanced threat actors identification task reached 98.45% and 99.48%, which are better than the benchmark model in the experiment and achieve state of the art. The model can effectively model threat intelligence text features with a priori knowledge to compensate for insufficient sample data and improve the classification performance and recognition ability of threat behavior in text.
Predicting the development trend of future scientific research not only provides a reference for researchers to understand the development of the discipline, but also provides support for decision-making and fund allocation for decision-makers. The continuous growth of scientific publications has brought challenges to track the development trends of scientific research topics. The existing topic trend prediction methods have proved that the research topic trend of a publication is influenced by other peer publications. However, they ignore the fact that the research topics of different publications belong to different research topic space. Moreover, the existing topic prediction methods do not fully consider the interactive influence among publications that the research topic of one publication affects the topics of other publications, it is also influenced by the research topics of other publications. In line with this, this paper proposes a scientific research topic trend prediction model based on multi-long short-term memory (multi-LSTM) and Graph Convolutional Network. Specifically, multiple LSTMs are employed to map research topics of different publications into their respective topic space. Then, the graph convolutional neural network is applied to learn the scientific influence context of each publication, so that the research topic of each publication not only integrates the influence of neighbor nodes, but also considers the influence of the neighbors of the neighbor node on the research topic of the publication, so as to more accurately fuse scientific influence context of research topic of peer publications. Experiments results on the data set of scientific research papers in the field of artificial intelligence and data mining demonstrate that the model improves the prediction precision and achieves the state-of-the-art research topic trend prediction effect compared with the other baseline models.
Deep neural network (DNN) methods play an essential role in hyperspectral classification. However, the massive parameters and vast computing overhead of DNN needs to be reduced when facing the deployment with limited storage and computing resources for real-time response applications, especially considering the high dimensionality of hyperspectral image. So, applying dimension reduction (DR) methods is a crucial pre-processing method in various studies. Still, most of them ignore the feature restoration after the data transformation by DR. In neural networks, many works still involve sophisticated skip connections and dense feature reuse, which can lead to feature redundancy and increase computational complexity, especially when DR methods have been applied first. Motivated by these issues, an efficient joint framework assisted by embedded feature smoother (FS) and sparse skip connection (SSC) is proposed in this article. Instead of directly feeding DR data into the subsequent network, we embedded a computing-cheap FS based on isotropic total variation to restore and enhance the spatial features. Furthermore, we proposed a SSC 3D convolution neural network to complete spatial-spectral feature representation and classification. The SSC is embodied in the design of log2n-skip connection to concatenate feature maps instead of dense connection, pruning the number of channels and reducing the model parameters. Experimental results show that the embedded FS significantly improves classification accuracy and is superior to other processing methods. Our framework offers much superior to other state-of-the-art deep learning-based methods considering classification performance and lightweight aspects, especially when using few training samples. Moreover, considering detailed processing steps, our framework has a competitively cheaper time consumption.
In order to address the problem of air pollution along with the fast development of the economy and an increase of urban population, this paper aims to capture the spatial-temporal correlation in air quality data and improve the prediction accuracy of -PM2.5 concentration. Existing models usually neglect the correlation in temporal and spatial dimensions, and the prediction results do not correspond to those in practical applications. We propose a multi-period spatial-temporal graph convolutional network (MST-GCN), in which the time division module fully explores the temporal correlation within the data and builds separate models for different time periods; the spatial-temporal convolution module captures the characteristics of historical data in the time dimension and spatial dimension, in which GCN is used to learn spatial dependencies between stations, and CNN is applied to learn the temporal dependencies of adjacent time points; meanwhile, a spatial-temporal attention mechanism module is introduced to enhance the key information in different dimensions, thereby capturing the spatialtemporal dynamic correlation. Finally, the experiments with real air quality data from Beijing monitoring stations show that the time division method is effective to extract the features in time dimensions; therefore, the model is able to capture the characteristics and dynamic correlation of air quality data in spatial- temporal dimensions. The superiority of the proposed method has been validated over state-of-the-art methods, and the average mean absolute error and root-mean-square error of MST-GCN are 34.37 and 35.55, respectively, which achieves the best performance in the experiments.
Graph convolution networks (GCNs) have achieved remarkable success in processing non-Euclidean data. GCNs update the feature representations of each sample by aggregating the structure information from K-order (layer) neighborhood samples. Existing GCNs variants rely heavily on the K-th layer semantic information with K-order neighborhood informa-tion aggregating. However, semantic features from different convolution layers have dis-tinct sample attributes. The single-layer semantic feature is only a one-sided feature representation. Besides, the semantic features of traditional GCNs will be oversmoothing with multi-layer structure information aggregates. In this paper, to solve the above -mentioned problem, we propose adaptive graph convolutional collaboration networks (AGCCNs) for the semi-supervised classification task. AGCCNs can fully use the different scales of discrimination information contained in the different convolutional layers. Specifically, AGCCNs utilize the attention mechanism to learn the relevance (contribution) coefficient of the deep semantic features from different convolution layers for the task, which aims to effectively discriminant their importance. After multiple optimizations, AGCCNs can adaptively learn the robust deep semantic features via the effective semantic fusion process between multi-layer semantic information. Compared with GCNs that only utilize the K-th layer semantic features, AGCCNs make the learned deep semantic features contain richer and more robust semantic information. What is more, our proposed AGCCNs can aggregate the appropriate K-order neighborhood information for each sample, which can relieve the oversmoothing issue of traditional GCNs and better generalize shallow GCNs to more deep layers. Abundant experimental results on several popular datasets demonstrate the superiority of our proposed AGCCNs compared with traditional GCNs. (c) 2022 Elsevier Inc. All rights reserved.
Human immunodeficiency virus (HIV) infection causes acquired immunodeficiency syndrome (AIDS), one of the most devastating diseases affecting humankind. Here, we have proposed a framework to examine the differences among microarray gene expression data of uninfected and three different HIV-1 infection stages using module preservation statistics. We leverage the advantage of gene co-expression networks (GCN) constructed for each infection stages to detect the topological and structural changes of a group of differentially expressed genes. We examine the relationship among a set of co-expression modules by constructing a module eigengene network considering the overall similarity/dissimilarity among the genes within the modules. We have utilized different module preservation statistics with two composite statistics: "Zsummary" and "MedianRank" to examine the changes in co-expression patterns between modules. We have found several interesting results on the preservation characteristics of gene modules across different stages. Some genes are identified to be preserved in a pair of stages while altering their characteristics across other stages. We further validated the obtained results using permutation test and classification techniques. The biological significances of the obtained modules have also been examined using gene ontology and pathway-based analysis. Additionally, we have identified a set of key immune regulatory hub genes in the associated protein-protein interaction networks (PPINs) of the differentially expressed (DE) genes, which interacts with HIV-1 proteins and are likely to act as potential biomarkers in HIV-1 progression.
Middle Ordovician (Darriwilian) species representing early Laurentian occurrences of the Subfamily Calymeninae Milne Edwards, 1840 (=Flexicalymeninae Siveter, 1977) are assigned to Atlanticalymene n. gcn. (type species: A. bardensis n. sp. from the Table Cove Formation, western Newfoundland, Canada). They have routinely been confused with the older (Dapingian) calymenoidean taxon Protocalymene Ross, 1967. Revision of the type species of Protocalymene, P. mcallisteri Ross, 1967, from the Antelope Valley Formation, Funeral Mountains, California, indicates that it is not a calymenine, and that while it is clearly a calymenoidean its close affinity is otherwise difficult to determine. A single genuine calymenine species is known from the Laurentian Dapingian, and revised here as "Calymeninae n. gen.? n. sp. A" from the Antelope Valley Formation, Nevada, USA. A species from the Dapingian of Tarim, known from a single partial cranidium. appears to represent an older, extra-Laurentian species of Atlanticalymene.
Type II toxin-antitoxins systems are widespread in prokaryotic genomes. Typically, they comprise two proteins, a toxin, and an antitoxin, encoded by adjacent genes and forming a complex in which the enzymatic activity of the toxin is inhibited. Under stress conditions, the antitoxin is degraded liberating the active toxin. Though thousands of various toxin-antitoxins pairs have been predicted bioinformatically, only a handful has been thoroughly characterized. Here, we describe the AtaT2 toxin from a toxin-antitoxin system from Escherichia coli O157:H7. We show that AtaT2 is the first GNAT (Gcn5-related N-acetyltransferase) toxin that specifically targets charged glycyl tRNA. In vivo, the AtaT2 activity induces ribosome stalling at all four glycyl codons but does not evoke a stringent response. In vitro, AtaT2 acetylates the aminoacyl moiety of isoaccepting glycyl tRNAs, thus precluding their participation in translation. Our study broadens the known target specificity of GNAT toxins beyond the earlier described isoleucine and formylmethionine tRNAs, and suggest that various GNAT toxins may have evolved to specificaly target other if not all individual aminoacyl tRNAs.
The truss structural optimization is a major research topic in the field of structural, civil, aerospace engineering, etc. Conventionally, the truss structural optimization methods are often inefficient because they run in iterations and are computationally intensive during each iteration. In this paper, we propose a generative design framework based on deep learning networks to predict three dimensional structural topologies without iterative computations while achieving acceptable accuracy. Different from most commonly used deep learning driven structural optimization approaches that transform structural geometries into images, our innovation lies in solving optimization problems based on geometric analysis from the perspective of graphs, and efficiently predict the near optimal truss structure with a negligible computational time. Therefore, it shows potential significance in design scenarios when the structure is described by connections and massive number of optimization computations are required. The proposed generative design framework is called TSO-GCN (Truss Structural Optimization -Graph Convolutional Network), which is an encoder-decoder based graph convolution network designed to map the problem definition and the desired truss layout. Once trained, it is expected to directly predict truss layouts by feeding into the encoded optimization problem definitions. To train the TSO-GCN, a dataset consisting of different number of problem definitions and their corresponding minimum volume results generated by conventional methods is constructed and fed into the network. The experiments show that TSO-GCN can predict results with the near optimal accuracy compared with conventional approaches while costing an average time of only 1 s. Besides, extra experiments with totally unseen dataset are performed to demonstrate the generalizability of the proposed method.(c) 2023 Elsevier B.V. All rights reserved.
More recently, vision transformer (ViT) has shown competitive performance with convolutional neural network (CNN) on computer vision tasks, which provided more possibilities for accurate classification of hyperspectral image (HSI). However, whether CNN or ViT, they generally only focus on single type of feature, resulting in insufficient information utilization. For instance, CNN has powerful local feature extraction ability, while ViT pays more attention to long-range dependencies and global features. To consider multiple types of feature information, we propose a multiple vision architectures-based hybrid network (MVAHN) for HSI classification, which consists of joint CNN and transformer (JCT) structure and graph convolutional module (GCM). Firstly, JCT successfully embeds convolution operations into ViT to capture local and global features, which mainly include: 1) A spectral spatial convolution block (SSCB) is proposed to unearth local spectral spatial features. 2) A convolution embedding is aggregated into self-attention to design a local-global attention (LGA) mechanism, which can realize the seamless integration of CNN and ViT, thereby capturing local-global combined features. Secondly, a plug-and-play GCM is developed in parallel with transformer encoders to further improve the model classification ability by mining the similarity relationship between pixels in HSI. Overall, an elegant integration of these seemingly distinct paradigms is realized by MVAHN to capture multiple types of feature information. The overall accuracies (OAs) of MVAHN on Pavia University, Houston 2013, Salinas Valley, Kennedy Space Center, Indian Pines and Botswana datasets are 96.37%, 88.33%, 97.57%, 98.96%, 96.25% and 99.26%, respectively. Compared with the state-of-the-art hybrid models, MVAHN achieves competitive classification results. The source code will be available at https://github.com/ZJier/MVAHN.
Deep learning (DL) methods are promising for the multilabel aerial image classification (MAIC) task. However, current DL methods face a common problem: the need for large multilabeled datasets. Collecting and annotating raw aerial image datasets can be extremely time- and labor-consuming. To address this concern in MAIC, domain adaptation (DA) provides a novel solution by transferring the knowledge learned from a label-rich dataset (i.e., the source domain) to a label-scarce dataset (i.e., the target domain), while current DA models are mainly designed for single-labeled tasks. In this article, we propose a novel end-to-end MAIC model based on DA techniques, named DA-MAIC. To the best of our knowledge, this article for the first time integrates DA to tackle the label scarcity problem in the MAIC task. Specifically, the proposed DA-MAIC is composed of two main parts: the image classifier and the domain classifier. The image classifier captures task-discriminative features based on the graph convolutional network (GCN) to predict multiple image labels; and the domain classifier extracts domain-invariant representations, which mitigates the domain shift between two underlying distributions. We extensively evaluate the proposed DA-MAIC from different perspectives on three benchmark datasets, including the commonly used UCM dataset, the high-resolution AID dataset, and the recently proposed DFC15 dataset. Both quantitative and qualitative results support that the proposed DA-MAIC can generalize the source domain knowledge to new scenarios and substantially improve the classification performance on the target domain task.
In this paper, we propose a GraphBit method to learn unsupervised deep binary descriptors for efficient image representation. Conventional binary representation learning methods directly quantize each element according to the threshold without considering the quantization ambiguousness. The elements near the boundary dubbed as "ambiguous bits " fail to collect effective information for reliable binarization and are sensitive to noise that causes reversed bits. We argue that there are implicit inner relationships among bits in binary descriptors called bitwise interaction, where the related bits can provide extra instruction as prior knowledge for ambiguousness reduction. Specifically, we design a deep reinforcement learning model to learn the structure of the graph for bitwise interaction mining, and the uncertainty of binary codes is reduced by maximizing the mutual information with input and related bits. Consequently, the ambiguous bits receive additional instruction from the graph for reliable binarization. Moreover, we further present a differentiable search method (GraphBit+) that mines the bitwise interaction in continuous space, so that the heavy search cost caused by the training difficulties in reinforcement learning is significantly reduced. Since the GraphBit and GraphBit+ methods learn fixed bitwise interaction which is suboptimal for various input, the inaccurate instruction from the fixed bitwise interaction cannot effectively decrease the ambiguousness of binary descriptors. To address this, we further propose the unsupervised binary descriptor learning method via dynamic bitwise interaction mining (D-GraphBit), where a graph convolutional network called GraphMiner reasons the optimal bitwise interaction for each input sample. Extensive experimental results on the CIFAR-10, NUS-WIDE, ImageNet-100, Brown and HPatches datasets demonstrate the efficiency and effectiveness of the proposed GraphBit, GraphBit+ and D-GraphBit.
Motivation: Mining drug-disease association and related interactions are essential for developing in silico drug repurposing (DR) methods and understanding underlying biological mechanisms. Recently, large-scale biological databases are increasingly available for pharmaceutical research, allowing for deep characterization for molecular informatics and drug discovery. However, DR is challenging due to the molecular heterogeneity of disease and diverse drug-disease associations. Importantly, the complexity of molecular target interactions, such as protein-protein interaction (PPI), remains to be elucidated. DR thus requires deep exploration of a multimodal biological network in an integrative context. Results: In this study, we propose BiFusion, a bipartite graph convolution network model for DR through heterogeneous information fusion. Our approach combines insights of multiscale pharmaceutical information by constructing a multirelational graph of drug-protein, disease-protein and PPIs. Especially, our model introduces protein nodes as a bridge for message passing among diverse biological domains, which provides insights into utilizing PPI for improved DR assessment. Unlike conventional graph convolution networks always assuming the same node attributes in a global graph, our approach models interdomain information fusion with bipartite graph convolution operation. We offered an exploratory analysis for finding novel drug-disease associations. Extensive experiments showed that our approach achieved improved performance than multiple baselines for DR analysis.
Background Non-germinal center B-cell-like diffuse large B-cell lymphoma (non-GCB-DLBCL) has worse clinical outcome than GCB-DLBCL, and some relapsed/refractory non-GCB-DLBCL (R/R non-GCB-DLBCL) are even resistant to CD20 monoclonal antibody (rituximab). Bruton's tyrosine kinase inhibitors (BTKis) are new drugs for B-cell lymphoma. BTKis can promote apoptosis of DLBCL by inactivating nuclear transcription factor kappa B (NF kappa B) signaling pathway. Cylindromatosis (CYLD) is a tumor suppressor and ubiquitinase. CYLD can inactivate NF kappa B signaling pathway through ubiquitination and regulate the apoptosis of hematological tumors. The ubiquitination of CYLD can be regulated by phosphorylation, suggesting that the regulation of CYLD phosphorylation can be a potential mechanism to promote the apoptosis of hematological tumors. Therefore, we hypothesized that BTKis could promote the apoptosis of non-GCB-DLBCL by regulating the phosphorylation of CYLD, especially in rituximab resistant cases, and we proved this hypothesis through both in vivo and in vitro experiments. Methods The baseline expression levels of CYLD phosphorylation in non-GCB-DLBCL patients and cell lines were detected by Western Blotting. The non-GCB-DLBCL cell lines were treated with BTKis, and apoptosis induced by BTKis treatment was detected by Western blotting, cell viability assay and Annexin V assay. To verify whether the effect of BTKis on apoptosis in non-GCN-DLBCL cells is CYLD dependent, the expression of CYLD was knocked down by lentiviral shRNAs. To verify the effect of BTKis on the phosphorylation of CYLD and the apoptosis in vivo and in rituximab resistant non-GCB-DLBCL, the xeograft model and rituximab resistant non-GCB-DLBCL cells were generated by tumor cell inoculation and escalation of drug concentrations, respectively. Results BTKis induced apoptosis by down-regulating CYLD phosphorylationin in non GCB-DLBCL, xenograft mouse model, and rituximab-resistant cells, and this effect could be enhanced by rituximab. Knocking-down CYLD reversed apoptosis which was induced by BTKis. BTKis induced CYLD-dependent apoptosis in non-GCB-DLBCL including in rituximab-resistant cells. Conclusions The present results indicated that CYLD phosphorylation is a potential clinical therapeutic target for non-GCB-DLBCL, especially for rituximab-resistant relapsed/refractory cases.
As an emerging concept, Knowledge as a Service (KaaS) aims to provide on-demand content-based (data, information, knowledge) delivery to meet the needs of users. With the prosperity of knowledge services, the prediction of the usage tendency of knowledge services has become an important and timely research topic. This study focuses on speculating the possible popularity of knowledge services in the next period of time, which can assist other downstream service tasks such as service recommendations. The interactions among knowledge services and their rich information (such as historical usage observation and text information) provide grounding for predicting the usage trend of services. However, recent spatial-temporal prediction based on graph neural networks usually depends heavily on the quality of manually created graphs, which may be expensive for knowledge services. To tackle such a limitation, this article proposes a novel Multi-modal Reciprocal SpatioTemporal (MRST) framework, which can jointly mine spatial dependencies and model time patterns for spatiotemporal coupling prediction. Two types of Edge Inference Networks (called EIN-o and EIN-t) are designed to sufficiently discover the spatial dependencies among knowledge services based on the data of usage observation sequences and service descriptions, respectively, and generate multi-modal directed weighted knowledge service graphs. Based on these graphs, MRST integrates GCN-based spatiotemporal prediction models as backbones to make predictions. Particularly, MRST features a unique reciprocal framework. On the one hand, EINs infer and generate multi-modal graphs to serve GCNs; on the other hand, GCNs utilize such spatial dependencies to make predictions and then introduce feedback to optimize EINs. In the meantime, to facilitate reproducible research, we collect a new knowledge service dataset from Wikipedia called Wiki-EN dataset. Experiments on this real data set show that the proposed MRST framework significantly surpasses the baselines and can learn meaningful spatial dependencies outside the predefined graphic structure.
Dynamic vision sensors (event cameras) have recently been introduced to solve a number of different vision tasks such as object recognition, activities recognition, tracking, etc. Compared with the traditional RGB sensors, the event cameras have many unique advantages such as ultra low resources consumption, high temporal resolution and much larger dynamic range. However, these cameras only produce noisy and asynchronous events of intensity changes, i.e., event-streams rather than frames, where conventional computer vision algorithms can't be directly applied. In our opinion the key challenge for improving the performance of event cameras in vision tasks is finding the appropriate representations of the event-streams so that cutting-edge learning approaches can be applied to fully uncover the spatio-temporal information contained in the event-streams. In this paper, we focus on the event-based human gait identification task and investigate the possible representations of the event-streams when deep neural networks are applied as the classifier. We propose new event-based gait recognition approaches basing on two different representations of the event-stream, i.e., graph and image-like representations, and use graph-based convolutional network (GCN) and convolutional neural networks (CNN) respectively to recognize gait from the event-streams. The two approaches are termed as EV-Gait-3DGraph and EV-Gait-IMG. To evaluate the performance of the proposed approaches, we collect two event-based gait datasets, one from real-world experiments and the other by converting the publicly available RGB gait recognition benchmark CASIA-B. Extensive experiments show that EV-Gait-3DGraph achieves significantly higher recognition accuracy than other competing methods when sufficient training samples are available. However, EV-Gait-IMG converges more quickly than graph-based approaches while training and shows good accuracy with only few number of training samples (less than ten). So image-like presentation is preferable when the amount of training data is limited.
Malaria is a serious and fatal infectious disease and early detection of the patient's infection severity can effectively curb the outbreak of this infectious disease. Deep learning has been verified to have excellent capability in image classification and disease diagnosis in many challenging tasks, such as cell detection and histological image classification. There exist many deep learning researches on malaria parasite recognition with successful applications, but they mainly focus on binary classification of single Ring stage and red blood cells. The most important disadvantage of them are ignoring other stages of malaria parasites, including Trophozoite, Gametocytes, and Schizont. In this paper, we are the first to study the multi-stage malaria parasite recognition problem, and propose a novel Neighbor Correlated Graph Convolutional Network (NCGCN) for this challenging task. Specifically, NCGCN consists of CNN (Convolutional Neural Network) feature learning, neighbor correlation mining, and graph representation modules. The method firstly extracts CNN representations from each parasite image and then establishes the neighbor correlations among CNN features by combining K-Nearest Neighbor (KNN) and epsilon-radius graph building algorithms, with operating Graph Convolutional Network (GCN) on CNN features and their correlations. To evaluate the performance of our NCGCN model, we compare it with several advanced existing methods, and our model can reach a high Accuracy of 94.17%, Precision of 94.84%, Recall of 94.17% and F1-score of 94.20%. The comparison with these outstanding methods verifies the NCGCN model has an excellent capability for recognizing multi-stage malaria parasites, which is higher than the compared methods at least 8.67% in Accuracy.
Human segmentation and tracking (HS-T) in the video often utilize person detection results. In addition, 3D human pose estimation (3D-HPE) and human activity recognition (HAR) often use human segmentation results to reduce data storage and computational time. With recent advantages of deep learning, especially using Convolutional Neural Networks (CNNs), there are excellent results in these relevant tasks. Consequently, they can be applied to building many practical applications such as sports analysis, sports scoring, health protection, teaching, and preserving traditional martial arts. In this paper, we performed a survey of relevant studies, methods, datasets, and results for HS-T, 3D-HPE, and HAR. We also deeply analyze the results of detecting persons as it affects the results of human segmentation and human tracking. The survey is performed in great detail up to source code paths. The MADS (Martial Arts, Dancing, and Sports) dataset comprises fast and complex activities. It has been published for the task of estimating human pose. However, before determining the human pose, the person needs to be detected as a segment in the video, especially the 3D human pose annotation data is different from the point cloud data generated from RGB-D images. Therefore, we have also prepared 2D human pose annotation data on the 28k images for creating 3D human pose annotation and action labeling data. Moreover, we also evaluated the MADS dataset with many recently published deep learning methods for human segmentation (Mask R-CNN, PointRend, TridentNet, TensorMask, and CenterMask) and tracking, 3D-HPE (RepNet, MediaPipe Pose, and Lifting from the Deep, V2V-PoseNet), and HAR (ST-GCN, DD-net, and PA-GesGCN) in the video. All data and published results are available.
Oculopharyngeal muscular dystrophy (OPMD) is a late-onset, primarily autosomal dominant disease caused by a short GCN expansion in the PABPN1 (polyadenylate-binding protein nuclear 1) gene that results in an alanine expansion at the N terminus of the PABPN1 protein. Expression of alanine-expanded PABPN1 is linked to the formation of nuclear aggregates in tissues from individuals with OPMD. However, as with other nuclear aggregate-associated diseases, controversy exists over whether these aggregates are the direct cause of pathology. An emerging hypothesis is that a loss of PABPN1 function and/or aberrant protein interactions contribute to pathology in OPMD. Here, we present the first global proteomic analysis of the protein interactions of WT and alanine-expanded PABPN1 in skeletal muscle tissue. These data provide both insight into the function of PABPN1 in muscle and evidence that the alanine expansion alters the protein-protein interactions of PABPN1. We extended this analysis to demonstrate altered complex formation with and loss of function of TDP-43 (TAR DNA-binding protein 43), which we show interacts with alanine-expanded but not WT PABPN1. The results from our study support a model where altered protein interactions with alanine-expanded PABPN1 that lead to loss or gain of function could contribute to pathology in OPMD.
Graph convolution networks (GCNs) have drawn attention for skeleton-based action recognition. They have achieved remarkable performance by adaptively learning spatial features of human action dynamics. However, the existing methods are limited in temporal sequence modelling of human actions. To give adequate consideration to temporal factors in action modelling, a novel temporal-enhanced graph convolution network is presented. First, a Causal Convolution layer is introduced to ensure no future information leakage at each time step for keeping ordering information of inputs. Second, a novel cross-spatial-temporal graph convolution layer that extends an adaptive graph from the spatial to the temporal domain to capture local cross-spatial-temporal dependencies among joints is presented. Third, a temporal attention layer is designed to enhance the modelling capability of long-range temporal dependencies, helping the network to directly focus on important time steps. Experimental results on three large-scale datasets, NTU-RGB + D, Kinetics-Skeleton, and UAV-Human, indicate that the authors' network achieves accuracy improvement with better generalisation capability over previous methods. The authors' code and data are available at .
This letter proposes a new travel time estimation model based on graph neural network (GraphTTE) to improve the accuracy of travel time estimation. We design a Multi-layer Spatiotemporal Graph frame (MSG), which consists of static network and dynamic networks, to fully consider the influence of traffic temporal characteristics and road network topological characteristics on travel time. Moreover, we design an Attention Graph Nodes Impact Index algorithm (AGNII) to score the impact of each node on travel time. In particular, the dynamic networks utilize the graph convolution network and gate recurrent unit to obtain the traffic characteristics, the static network utilizes graph convolution network to obtain the road basic attributes. We combine the real paths sequence with the impact score of nodes to extract the subgraph with a great impact on the trajectory. After the graph representation learning and deep residual network, the estimated time is obtained. A simulator was designed to train and test our model in Chengdu and Xi'an datasets, the results show that the mean absolute percent error (MAPE) is 12.58% and 14.01%, which is 1.54% and 1.78% lower than the baselines.
For a class F of complex-valued functions on a set D, we denote by gn(F) its sampling numbers, i.e., the minimal worst-case error on F, measured in L2, that can be achieved with a recovery algorithm based on n function evaluations. We prove that there is a universal constant c is an element of N such that, if F is the unit ball of a separable reproducing kernel Hilbert space, then gcn(F)2 <= 1 E n k >= n dk(F )2, where dk(F) are the Kolmogorov widths (or approximation numbers) of F in L2. We also obtain similar upper bounds for more general classes F, including all compact subsets of the space of continuous functions on a bounded domain D subset of Rd, and show that these bounds are sharp by providing examples where the converse inequality holds up to a constant. The results rely on the solution to the Kadison-Singer problem, which we extend to the subsampling of a sum of infinite rank-one matrices. (c) 2022 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
Landmark localization is an important step in quantifying craniomaxillofacial (CMF) deformities and designing treatment plans of reconstructive surgery. However, due to the severity of deformities and defects (partially missing anatomy), it is difficult to automatically and accurately localize a large set of landmarks simultaneously. In this work, we propose two cascaded networks for digitizing 60 anatomical CMF landmarks in cone-beam computed tomography (CBCT) images. The first network is a U-Net that outputs heatmaps for landmark locations and landmark features extracted with a local attention mechanism. The second network is a graph convolution network that takes the features extracted by the first network as input and determines whether each landmark exists via binary classification. We evaluated our approach on 50 sets of CBCT scans of patients with CMF deformities and compared them with state-of-the-art methods. The results indicate that our approach can achieve an average detection error of 1.47mm with a false positive rate of 19%, outperforming related methods.
With the growing demands on green short life-cycle products, advanced energy-aware process planning (AEPP) becomes critical. A major limitation of the existing methods is the poor resistance to the perturbations encountered in advanced machining systems. Therefore, a graph convolutional reinforcement learning (GCRL) method is proposed to overcome such limitations. In this method, a graph convolutional policy network is trained to rapidly adapt the learned commonalities to specific tasks. Unlike algorithms that fix decision variables before optimization, this method employs graph generation to represent AEPP while taking into consideration the flexibilities of operations, machines, and cutting tools. The problem is reformulated as a novel Markov decision process (MDP) to describe the dynamic generation procedure of process plans. A graph convolutional network (GCN) is concurrently used to perform graph embedding to compress the topology of input graphs. Additionally, reinforcement learning (RL) is used to achieve robust and intuitive learning for process planning. To improve the adaption performance of the proposed GCRL, a two-phase multitask training strategy is adopted. Learning efficiency is improved because agents can incorporate both intertask similarities and task-specific rules. A comprehensive case study, including energy characteristics and algorithm performance analyses, is also performed to validate the developed method.
Air pollution is a lethal global threat. To mitigate the effects of air pollution, we must first understand it, find its patterns and correlations, and predict it in advance. Air pollution is highly dependent on spatial and temporal correlations of prior meteorological, wildfire, and pollution structures. We use the advanced deep predictive Convolutional LSTM (ConvLSTM) model paired with the cutting-edge Graph Convolutional Network (GCN) architecture to predict spatiotemporal hourly PM2.5 across the Los Angeles area over time. Our deep-learning model does not use atmospheric physics or chemical mechanism data, but rather multisource imagery and sensor data. We use high-resolution remote-sensing satellite imagery from the Moderate Resolution Imaging Spectroradiometer (MODIS) instrument onboard the NASA Terra+Aqua satellites and remote-sensing data from the Tropospheric Monitoring Instrument (TROPOMI), a multispectral imaging spectrometer onboard the Sentinel-5P satellite. We use the highly correlated Fire Radiative Power data product from the MODIS instrument which provides valuable information about the radiant heat output and effects of wildfires on atmospheric air pollutants. The input data we use in our deep-learning model is representative of the major sources of ground-level PM2.5 and thus we can predict hourly PM2.5 at unparalleled accuracies. Our RMSE and NRMSE scores over various site locations and predictive time frames show significant improvement over existing research in predicting PM2.5 using spatiotemporal deep predictive algorithms.
Breast cancer is one of the most prevalent cancers in females, with more than 450,000 deaths each year worldwide. Among the subtypes of breast cancer, basal-like breast cancer, also known as triple-negative breast cancer, shows the lowest survival rate and does not have effective treatments yet. Somatic mutations in the TP53 gene frequently occur across all breast cancer subtypes, but comparative analysis of gene correlations with respect to mutations in TP53 has not been done so far. The primary goal of this study is to identify gene correlations in two groups of breast cancer patients and to derive potential prognostic gene pairs for breast cancer. We partitioned breast cancer patients into two groups: one group with a mutated TP53 gene (mTP53) and the other with a wild-type TP53 gene (wtTP53). For every gene pair, we computed the hazard ratio using the Cox proportional hazard model and constructed gene correlation networks (GCNs) enriched with prognostic information. Our GCN is more informative than typical GCNs in the sense that it indicates the type of correlation between genes, the concordance index, and the prognostic type of a gene. Comparative analysis of correlation patterns and survival time of the two groups revealed several interesting findings. First, we found several new gene pairs with opposite correlations in the two GCNs and the difference in their correlation patterns was the most prominent in the basal-like subtype of breast cancer. Second, we obtained potential prognostic genes for breast cancer patients with a wild-type TP53 gene. From a comparative analysis of GCNs of mTP53 and wtTP53, we found several gene pairs that show significantly different correlation patterns in the basal-like breast cancer subtype and obtained prognostic genes for patients with a wild-type TP53 gene. The GCNs and prognostic genes identified in this study will be informative for the prognosis of survival and for selecting a drug target for breast cancer, in particular for basal-like breast cancer. To the best of our knowledge, this is the first attempt to construct GCNs for breast cancer patients with or without mutations in the TP53 gene and to find prognostic genes accordingly.
Lung cancer causes the highest mortality in cancer-related deaths. As these cancers often become resistant to existing therapies, definition of novel molecular targets is needed. Epigenetic modifiers may provide such targets. Recent reports suggest that the histone acetyltransferase (HAT) module within the transcriptional coactivator SAGA complex plays a role in cancer, creating a new link between epigenetic regulators and this disease. GCN5 serves as a coactivator for MYC target genes, and here we investigate links between GCN5 and c-MYC in non-small cell lung cancer (NSCLC). Our data indicate that both GCN5 and c-MYC proteins are upregulated in mouse and human NSCLC cells compared to normal lung epithelial cells. This trend is observable only at the protein level, indicating that this upregulation occurs post-transcriptionally. Human NSCLC tissue data provided by The Cancer Genome Atlas (TCGA) indicates that GCN5 and c-MYC expression are positively associated with one another and with the expression of c-MYC target genes. Depletion of GCN5 in NSCLC cells reduces c-MYC expression, cell proliferation, and increases the population of necrotic cells. Similarly, inhibition of the GCN5 catalytic site using a commercially available probe reduces c-MYC expression, cell proliferation, and increases the percentage of cells undergoing apoptosis. Our findings suggest that GCN5 might provide a novel target for inhibition of NSCLC growth and progression.
Objectives We examined the efficacy and safety of rituximab (RTX) maintenance therapy for patients with antineutrophil cytoplasmic antibody (ANCA)-associated vasculitis (AAV) in Japan. Methods We conducted a retrospective study using a multi-center cohort database of vasculitis patients. All maintenance treatment courses were divided into three groups: a RTX group, a group treated with other immunosuppressant drugs (IS) and a group receiving glucocorticoid monotherapy (GC). The primary endpoint was the comparison of relapse-free survival after 1 year. We also analyzed the occurrence of severe adverse events (SAEs) to assess safety. Results We included 123 courses of 107 patients (RTXn = 14, ISn = 64, GCn = 45). Twelve of 14 in the RTX group patients were diagnosed with granulomatosis with polyangiitis (GPA). The relapse-free survival of RTX maintenance therapy was comparable to that in the other groups (p = .122). After 1 year of treatment, the RTX group was administered lower steroid doses and one-third of them could withdraw corticosteroid. The overall incidence of SAE was 0.54/patient-year in the RTX group, 0.39/patient-year in the IS group and 0.34/patient-year in the GC group. Conclusion RTX maintenance therapy could be effective and safe in Japanese GPA patients.
Water and energy are key sustainability issues that need to be addressed. Photocatalysis represents an attractive means to not only remediate polluted waters, but also harness solar energy. Unfortunately, the employment of photocatalysts remains a practical challenge in terms of high cost, low efficiency, secondary pollution and unexploited water matrices influence. This study investigated the feasibility of photocatalysis to both treat water and produce hydrogen with practical water systems. Polymeric carbon nitride foam (CNF) with large surface area and mesoporous structure was successfully prepared via the bubble-template effect of ammonium chloride decomposition during thermal condensation. The reaction kinetics, mechanisms, and effect of natural water matrices and wastewater on CNF-based photocatalytic removal of tetracycline hydrochloride (TC-HCl) were systematically investigated. Furthermore, the efficiency of clean hydrogen energy from natural water matrices and wastewater was also evaluated. It was found that the photocatalytic performance of CNF for TC-HCl removal was principally affected by calcination temperature in the presence of NH4Cl. The degradation rates of CNF-4 (calcined at 550 degrees C) were approximately 1.84, 2.49 and 7.47 times than that of the CNF-2 (calcined at 600 degrees C), CNF-1 (calcined at 500 degrees C) and GCN (without NH4Cl), respectively. Results indicate that the improved photocatalytic performance was predominantly ascribed to the large specific surface area, increased availability of exposed active sites, and enhanced transport and separation efficiency of the photogenerated carrier. Based on electron spin resonance, chemical trapping experiment and density functional theory calculation, photoinduced oxidizing species (center dot O-2(-) and holes) initially attacked the C-N-C fragment of TC molecules, which were finally mineralized to CO2, water and inorganic matters. Under the synergistic influence of water constituents (including acidity and alkalinity, ion species and dissolved organic substances), various water matrices greatly affected the degradation rate of TC-HCI, with the highest removal efficiency of 78.9% in natural seawater, followed by reservoir water (75.0%), tap water (62.3%), deionized water (49.8%), reverse osmosis concentrate (32.7%) and pharmaceutical wastewater (18.9%). Interestingly, low amounts of the emerging microplastics slightly improved TC-HCl removal, whereas high amounts (1.428 x 10(7) P/cm(3)) restricted removal due to light absorption and the intrinsic adsorption interaction. Moreover, the photocatalysts were able over repeated usage. Notably, the hydrogen yields rates of polymeric carbon nitride foam were 352.2, 299.8, 184.9 and 94.3 mu mol/g/h in natural seawater, pharmaceutical wastewater, water from reservoir and tap water, respectively. This study proves the potential of novel nonmetal porous photocatalyst to simultaneously treat wastewater while converting solar energy into clean hydrogen energy. (C) 2018 Elsevier Ltd. All rights reserved.
The design of integrated circuits (ICs) in the analog spectrum is intricate due to the signals' continuous nature. Additionally, it is strongly affected by the physical implementation of their devices on the circuits' layout, a task that has stubbornly defied all automation attempts. In this paper, disruptive research using modern embedding techniques and a fully unsupervised attention-based encoder-decoder model is conducted to automate the placement task of analog IC layout design. The attention-based graph-to-sequence model, AGraph2Seq for short, differs from other heterogeneous graph embedding approaches by introducing structure in both the input and output data in an encoder-decoder architecture. The structure allows for a smaller and more effective placement regression model, drastically reducing the number of trainable parameters and turning the model inherently independent of the circuit topology in terms of the way devices are connected and the number of devices in a circuit, turning it easily scalable to circuits with higher complexity. Additionally, the attention mechanism makes the model's decoder invariant to the input devices' order. The deep model is ultimately trained in an end-to-end fashion to minimize a fully unsupervised loss function that efficiently evaluates the fulfillment of fundamental placement's topological constraints. As a proof of concept, the final model, but also its intermediate stages, i.e., encoder-only, decoder-only, and encoder-decoder without attention, are extensively used to propose different placement solutions for several modern analog IC blocks in multiple deep nanometer technology nodes at pushbutton speed, including topologies not present in the training set. These present a level of generalization beyond traditional analog IC placement methodologies and most recent machine learning-based approaches and compete with or outperform highly optimized analog layouts and human-made designs.
Motivation: Predictive models of DNA chromatin profile (i.e. epigenetic state), such as transcription factor binding, are essential for understanding regulatory processes and developing gene therapies. It is known that the 3D genome, or spatial structure of DNA, is highly influential in the chromatin profile. Deep neural networks have achieved state of the art performance on chromatin profile prediction by using short windows of DNA sequences independently. These methods, however, ignore the long-range dependencies when predicting the chromatin profiles because modeling the 3D genome is challenging. Results: In this work, we introduce ChromeGCN, a graph convolutional network for chromatin profile prediction by fusing both local sequence and long-range 3D genome information. By incorporating the 3D genome, we relax the independent and identically distributed assumption of local windows for a better representation of DNA. ChromeGCN explicitly incorporates known long-range interactions into the modeling, allowing us to identify and interpret those important long-range dependencies in influencing chromatin profiles. We show experimentally that by fusing sequential and 3D genome data using ChromeGCN, we get a significant improvement over the state-of-the-art deep learning methods as indicated by three metrics. Importantly, we show that ChromeGCN is particularly useful for identifying epigenetic effects in those DNA windows that have a high degree of interactions with other DNA windows.
Cancer diagnosis, prognosis, mymargin and therapeutic response predictions are based on morphological information from histology slides and molecular profiles from genomic data. However, most deep learning-based objective outcome prediction and grading paradigms are based on histology or genomics alone and do not make use of the complementary information in an intuitive manner. In this work, we propose Pathomic Fusion, an interpretable strategy for end-to-end multimodal fusion of histology image and genomic (mutations, CNV, RNA-Seq) features for survival outcome prediction. Our approach models pairwise feature interactions across modalities by taking the Kronecker product of unimodal feature representations, and controls the expressiveness of each representation via a gating-based attention mechanism. Following supervised learning, we are able to interpret and saliently localize features across each modality, and understand how feature importance shifts when conditioning on multimodal input. We validate our approach using glioma and clear cell renal cell carcinoma datasets from the Cancer Genome Atlas (TCGA), which contains paired whole-slide image, genotype, and transcriptome data with ground truth survival and histologic grade labels. In a 15-fold cross-validation, our results demonstrate that the proposed multimodal fusion paradigm improves prognostic determinations from ground truth grading and molecular subtyping, as well as unimodal deep networks trained on histology and genomic data alone. The proposed method establishes insight and theory on how to train deep networks on multimodal biomedical data in an intuitive manner, which will be useful for other problems in medicine that seek to combine heterogeneous data streams for understanding diseases and predicting response and resistance to treatment. Code and trained models are made available at: https://github.com/mahmoodlab/PathomicFusion.
The rapid increase in the number of proteins in sequence databases and the diversity of their functions challenge computational approaches for automated function prediction. Here, we introduce DeepFRI, a Graph Convolutional Network for predicting protein functions by leveraging sequence features extracted from a protein language model and protein structures. It outperforms current leading methods and sequence-based Convolutional Neural Networks and scales to the size of current sequence repositories. Augmenting the training set of experimental structures with homology models allows us to significantly expand the number of predictable functions. DeepFRI has significant de-noising capability, with only a minor drop in performance when experimental structures are replaced by protein models. Class activation mapping allows function predictions at an unprecedented resolution, allowing site-specific annotations at the residue-level in an automated manner. We show the utility and high performance of our method by annotating structures from the PDB and SWISS-MODEL, making several new confident function predictions. DeepFRI is available as a webserver at https://beta.deepfri.flatironinstitute.org/. The rapid increase in the number of proteins in sequence databases and the diversity of their functions challenge computational approaches for automated function prediction. Here, the authors introduce DeepFRI, a Graph Convolutional Network for predicting protein functions by leveraging sequence features extracted from a protein language model and protein structures.
Multispectral points, as a new data source containing both spectrum and spatial geometry, opens the door to three-dimensional (3D) land cover classification at a finer scale. In this paper, we model the multispectral points as a graph and propose a multi-attribute smooth graph convolutional network (MaSGCN) for multispectral points classification. We construct the spatial graph, spectral graph, and geometric-spectral graph respectively to mine patterns in spectral, spatial, and geometric-spectral domains. Then, the multispectral points graph is generated by combining the spatial, spectral, and geometric-spectral graphs. Moreover, dimensionality features and spectrums are introduced to screen the appropriate connection points for constructing the spatial graph. For remote sensing scene classification tasks, it is usually desirable to make the classification map relatively smooth and avoid salt and pepper noise. A heat operator is then introduced to enhance the low-frequency filters and enforce the smoothness in the graph signal. Considering that different land covers have different scale characteristics, we use multiple scales instead of the single scale when leveraging heat operator on graph convolution. The experimental results on two real multispectral points data sets demonstrate the superiority of the proposed MaSGCN to several state-of-the-art methods.
The revolutionary advances in machine learning and data mining techniques have contributed greatly to the rapid developments of maritime Internet of Things (IoT). In maritime IoT, the spatio-temporal vessel trajectories, collected from the hybrid satellite-terrestrial automatic identification system (AIS) base stations, are of considerable importance for promoting traffic situation awareness and vessel traffic services, etc. To guarantee traffic safety and efficiency, it is essential to robustly and accurately predict the AIS-based vessel trajectories (i.e., the future positions of vessels) in maritime IoT. In this work, we propose a spatio-temporal multigraph convolutional network (STMGCN)-based trajectory prediction framework using the mobile edge computing (MEC) paradigm. Our STMGCN is mainly composed of three different graphs, which are, respectively, reconstructed according to the social force, the time to closest point of approach, and the size of surrounding vessels. These three graphs are then jointly embedded into the prediction framework by introducing the spatio-temporal multigraph convolutional layer. To further enhance the prediction performance, the self-attention temporal convolutional layer is proposed to further optimize STMGCN with fewer parameters. Owing to the high interpretability and powerful learning ability, STMGCN is able to achieve superior prediction performance in terms of both accuracy and robustness. The reliable prediction results are potentially beneficial for traffic safety management and intelligent vehicle navigation in MEC-enabled maritime IoT.
Esophagogastroduodenoscopy (EGD) is a critical step in the diagnosis of upper gastrointestinal disorders. However, due to inexperience or high workload, there is a wide variation in EGD performance by endoscopists. Variations in performance may result in exams that do not completely cover all anatomical locations of the stomach, leading to a potential risk of missed diagnosis of gastric diseases. Numerous guidelines or expert consensus have been proposed to assess and optimize the quality of endoscopy. However, there is a lack of mature and robust methods to accurately apply to real clinical real-time video environments. In this paper, we innovatively define the problem of recognizing anatomical locations in videos as a multi-label recognition task. This can be more consistent with the model learning of image-to-label mapping relationships. We propose a combined structure of a deep learning model (GL-Net) that combines a graph convolutional network (GCN) with long short-term memory (LSTM) networks to both extract label features and correlate temporal dependencies for accurate real-time anatomical locations identification in gastroscopy videos. Our methodological evaluation dataset is based on complete videos of real clinical examinations. A total of 29,269 images from 49 videos were collected as a dataset for model training and validation. Another 1736 clinical videos were retrospectively analyzed and evaluated for the application of the proposed model. Our method achieves 97.1% mean accuracy (mAP), 95.5% mean per-class accuracy and 93.7% average overall accuracy in a multi-label classification task, and is able to process these videos in real-time at 29.9 FPS. In addition, based on our approach, we designed a system to monitor routine EGD videos in detail and perform statistical analysis of the operating habits of endoscopists, which can be a useful tool to improve the quality of clinical endoscopy.
Background: At present, using computer methods to predict drug-target interactions (DTIs) is a very important step in the discovery of new drugs and drug relocation processes. The potential DTIs identified by machine learning methods can provide guidance in biochemical or clinical experiments. Objective: The goal of this article is to combine the latest network representation learning methods for drug-target prediction research, improve model prediction capabilities, and promote new drug development. Methods: We use large-scale information network embedding (LINE) method to extract network topology features of drugs, targets, diseases, etc., integrate features obtained from heterogeneous networks, construct binary classification samples, and use random forest (RF) method to predict DTIs. Results: The experiments in this paper compare the common classifiers of RF, LR, and SVM, as well as the typical network representation learning methods of LINE, Node2Vec, and DeepWalk. It can be seen that the combined method LINE-RF achieves the best results, reaching an AUC of 0.9349 and an AUPR of 0.9016. Conclusion: The learning method based on LINE network can effectively learn drugs, targets, diseases and other hidden features from the network topology. The combination of features learned through multiple networks can enhance the expression ability. RF is an effective method of supervised learning. Therefore, the Line-RF combination method is a widely applicable method.
The process of designing biomolecules, in particular proteins, is witnessing a rapid change in available tooling and approaches, moving from design through physicochemical force fields, to producing plausible, complex sequences fast via end-to-end differentiable statistical models. To achieve conditional and controllable protein design, researchers at the interface of artificial intelligence and biology leverage advances in natural language processing (NLP) and computer vision techniques, coupled with advances in computing hardware to learn patterns from growing biological databases, curated annotations thereof, or both. Once learned, these patterns can be used to provide novel insights into mechanistic biology and the design of biomolecules. However, navigating and understanding the practical applications for the many recent protein design tools is complex. To facilitate this, we 1) document recent advances in deep learning (DL) assisted protein design from the last three years, 2) present a practical pipeline that allows to go from de novo-generated sequences to their predicted properties and web-powered visualization within minutes, and 3) leverage it to suggest a generated protein sequence which might be used to engineer a biosynthetic gene cluster to produce a molecular glue-like compound. Lastly, we discuss challenges and highlight opportunities for the protein design field.(c) 2022 The Authors. Published by Elsevier B.V.
Accurate precipitation prediction can help decision makers judge the trend of climate change and formulate more effective measures, and prevent flood and drought disasters. In this paper, we propose a short-term regional precipitation prediction model based on wind-improved spatiotemporal convolutional network. Among them, the improved graph convolution network integrates the effects of wind direction and geographic location at past moments to capture the spatial dependence, whilst the gated recurrent unit captures the temporal dependence by learning the dynamic changes of data. The spatio-temporal memory flow module and attention module are added to capture spatial deformation and temporal variation more accurately, thereby better matching the physical properties of precipitation. The proposed model achieves better prediction results on real data sets. Experiments show that our method is better at extracting the spatio-temporal information of precipitation data and capturing its time dependence and spatial correlation. Plain Language Summary Deep-learning technology has not been fully explored in regional short-term precipitation prediction. The traditional graph convolution neural network does not consider the practical significance of wind direction in precipitation. Therefore, we introduce a novel short-term regional precipitation prediction model based on wind improved spatiotemporal convolution network (ASS-TGCN). Measured data of automatic meteorological station in Jiangsu Province, China have been utilized. Compared with the comparison model, our proposed model has achieved better performance in various indicators.
A material of graphitic carbon nitride-supported cobalt oxides (Co3O4/g-CN) was synthesized via a facile and cost-effective impregnation route as a high-performance catalyst for decomposition of N2O. For comparison, bare Co3O4 and other Co3O4 catalysts supported on activated carbon (AC) and gamma-Al2O3 (Co3O4-A, Co3O4/AC, and Co3O4/gamma-Al2O3, respectively) were also prepared. While g-CN was found to be active in the decomposition of N2O, AC and gamma-Al2O3 were inert to this reaction. Co3O4/g-CN showed superior catalytic activity than the other catalysts, and concurrently exhibited much higher specific activity compared to Co3O4-A. The experimental results revealed that all examined catalysts had the spinel structure. The Co species could incorporate into the gCN matrix/layers and bond to the g-CN matrix through Co-N coordination bonds. The excellent performance of Co3O4/gamma-CN was attributed to the high surface Co2+ content, massive surface oxygen species, facile electrons transfer from the catalyst to N2O domains, and the synergistic coupling effects among active species such as Co3+/Co2+ redox couple, Co-N, and nitrogen sites. The active Co3O4/g-CN catalyst additional activity tests were conducted with N2O gas contaminated with H2O, O-2, or NO.
3D hand pose estimation from a monocular RGB image is a highly challenging task due to self-occlusion, diverse appearances, and inherent depth ambiguities within monocular images. Most of the previous methods first employ deep neural networks to fit 2D joint location maps, then combines them with implicit or explicit pose-aware features to directly regress 3D hand joints positions using their designed network structure. However, the skeleton positions and corresponding skeleton-aware content information located in the latent space are invariably ignored. These skeleton-aware contents effectively bridge the gap between hand joint and hand skeleton information by associating the relationship between different hand joints features and the hand skeleton positions distribution in 2D space. To address this issue, we propose a simple yet efficient deep neural network to directly recover reliable 3D hand pose from monocular RGB images with faster estimation process. Our purpose is the reduction of the model computational complexity while maintaining high precision performance. Therefore, we design a novel Feature Chat Block (FCB) to complete feature boosting, which enables the intuitively enhanced interaction between joint and skeleton features. First, this FCB module updates joint features effectively based on semantic graph convolutional neural network and multi-head self-attention mechanism. The GCN-based structure focuses on the physical hand joints included in a binary adjacency matrix and the self-attention part pays attention to hand joints located in a complementary matrix. Then, the FCB module employs query and key mechanisms respectively representing joint and skeleton features to further implement feature interaction. After a set of FCB modules, our model updates the fused features in a coarse-to-fine manner and finally outputs a predicted 3D hand pose. We conducted a comprehensive set of ablation experiments on the InterHand2.6M dataset to validate the effectiveness and significance of the proposed method. Additionally, experimental results on Rendered Hand Dataset, Stereo Hand Datasets, First-Person Hand Action Dataset and FreiHAND Dataset show our model surpasses the state-of-the-art methods with faster inference speed.
Oculopharyngeal muscular dystrophy (OPMD) is a late-onset muscle disease caused by an abnormal (GCN) triplet expansion within the polyadenylate-binding protein nuclear 1 gene and consequent mRNA processing impairment and myogenic defects. Because a reduced cell proliferation potential and the consequent regeneration failure of aging muscle have been shown to be governed by lethal-7 (let-7) microRNA-mediated mechanisms, in the present study, we evaluated the role of let-7 in the pathogenesis of OPMD. By a multidisciplinary approach, including confocal microscopy, Western blot, and quantitative PCR analyses on muscle biopsies from patients and unaffected individuals, we found a significant increase in let-7 expression in OPMD muscles associated with an unusual high percentage of paired box 7-positive satellite cells. Furthermore, IL-6, a cytokine involved in the regulation of satellite cell proliferation and differentiation and a potential target of let-7, was found strongly down-regulated in OPMD compared with control muscles. The decrease in IL-6 transcript levels and protein content was also confirmed in vitro during differentiation of patients' and controls' muscle cells. Overall, our data suggest a key role of let-7 in the regeneration and degeneration process in OPMD muscle and pointed to IL-6 as a potential target molecule for new therapeutic approaches for this disorder.-Cappelletti, C., Galbardi, B., Bruttini, M., Salerno, F., Canioni, E., Pasanisi, M. B., Rodolico, C., Brizzi, T., Mora, M., Renieri, A., Maggi, L., Bernasconi, P., Mantegazza, R. Aging-associated genes and let-7 microRNAs: a contribution to myogenic program dysregulation in oculopharyngeal muscular dystrophy.
Crime issues have been attracting widespread attention from citizens and managers of cities due to their unexpected and massive consequences. As an effective technique to prevent and control urban crimes, the data-driven spatial-temporal crime prediction can provide reasonable estimations associated with the crime hotspot. It thus contributes to the decision making of relevant departments under limited resources, as well as promotes civilized urban development. However, the deficient performance in the aspect of the daily spatial-temporal crime prediction at the urban-district-scale needs to be further resolved, which serves as a critical role in police resource allocation. In order to establish a practical and effective daily crime prediction framework at an urban police-district-scale, an "online" integrated graph model is proposed. A residual neural network (ResNet), graph convolutional network (GCN), and long short-term memory (LSTM) are integrated with an attention mechanism in the proposed model to extract and fuse the spatial-temporal features, topological graphs, and external features. Then, the "online" integrated graph model is validated by daily theft and assault data within 22 police districts in the city of Chicago, US from 1 January 2015 to 7 January 2020. Additionally, several widely used baseline models, including autoregressive integrated moving average (ARIMA), ridge regression, support vector regression (SVR), random forest, extreme gradient boosting (XGBoost), LSTM, convolutional neural network (CNN), and Conv-LSTM models, are compared with the proposed model from a quantitative point of view by using the same dataset. The results show that the predicted spatial-temporal patterns by the proposed model are close to the observations. Moreover, the integrated graph model performs more accurately since it has lower average values of the mean absolute error (MAE) and root mean square error (RMSE) than the other eight models. Therefore, the proposed model has great potential in supporting the decision making for the police in the fields of patrolling and investigation, as well as resource allocation.
Motivation: Due to cancer heterogeneity, the therapeutic effect may not be the same when a cohort of patients of the same cancer type receive the same treatment. The anticancer drug response prediction may help develop personalized therapy regimens to increase survival and reduce patients' expenses. Recently, graph neural network-based methods have aroused widespread interest and achieved impressive results on the drug response prediction task. However, most of them apply graph convolution to process cell line-drug bipartite graphs while ignoring the intrinsic differences between cell lines and drug nodes. Moreover, most of these methods aggregate node-wise neighbor features but fail to consider the element-wise interaction between cell lines and drugs. Results: This work proposes a neighborhood interaction (NI)-based heterogeneous graph convolution network method, namely NIHGCN, for anticancer drug response prediction in an end-to-end way. Firstly, it constructs a heterogeneous network consisting of drugs, cell lines and the known drug response information. Cell line gene expression and drug molecular fingerprints are linearly transformed and input as node attributes into an interaction model. The interaction module consists of a parallel graph convolution network layer and a NI layer, which aggregates node-level features from their neighbors through graph convolution operation and considers the element-level of interactions with their neighbors in the NI layer. Finally, the drug response predictions are made by calculating the linear correlation coefficients of feature representations of cell lines and drugs. We have conducted extensive experiments to assess the effectiveness of our model on Cancer Drug Sensitivity Data (GDSC) and Cancer Cell Line Encyclopedia (CCLE) datasets. It has achieved the best performance compared with the state-of-the-art algorithms, especially in predicting drug responses for new cell lines, new drugs and targeted drugs. Furthermore, our model that was well trained on the GDSC dataset can be successfully applied to predict samples of PDX and TCGA, which verified the transferability of our model from cell line in vitro to the datasets in vivo. Availability and implementation: The source code can be obtained from. Supplementary information: Supplementary data are available at Bioinformatics online.
Mutant KRAS is a key driver in colorectal cancer (CRC) and promotes Myc translation and Myc-dependent stress adaptation and proliferation. Here, we report that the combination of two FDA-approved drugs Bortezomib and Everolimus (RAD001) (BR) is highly efficacious against mutant KRAS CRC cells. Mechanistically, the combination, not single agent, rapidly depletes Myc protein, not mRNA, and leads to GCN2- and p-eIF2alpha-dependent cell death through the activation of extrinsic and intrinsic apoptotic pathways. Cell death is selectively induced in mutant KRAS CRC cells with elevated basal Myc and p-eIF2alpha and is characterized by CHOP induction and transcriptional signatures in proteotoxicity, oxidative stress, metabolic inhibition, and immune activation. BR-induced p-GCN2/p-eIF2alpha elevation and cell death are strongly attenuated by MYC knockdown and enhanced by MYC overexpression. The BR combination is efficacious against mutant KRAS patient derived organoids (PDO) and xenografts (PDX) by inducing p-eIF2alpha/CHOP and cell death. Interestingly, an elevated four-gene (DDIT3, GADD45B, CRYBA4 and HSPA1L) stress signature is linked to shortened overall survival in CRC patients. These data support that Myc-dependent stress adaptation drives the progression of mutant KRAS CRC and serves as a therapeutic vulnerability, which can be targeted using dual translational inhibitors.
Network alignment, or identifying the same entities (anchors) across multiple networks, has significant applications across diverse fields. Unsupervised approaches for network alignment, though popular, strictly assume that the anchor nodes' structure and attributes remain consistent across different networks. However, in practice, strictly adhering to these constraints makes it difficult to deal with networks with high variance in the structural characteristics and inherent structural noises like missing nodes and edges, resulting in poor generalization. In order to handle these shortcomings, we propose HCNA: Hyperbolic Contrastive Learning Framework for Self -Supervised Network Alignment , a novel self-supervised contrastive learning model which learns from the multiple augmented views of each network, thereby making HCNA robust to the inherent multi-network characteristics. Furthermore, we propose multi-order hyperbolic graph convolution networks to generate node embedding for each network which can handle the hierarchical structure of networks. The main objective of HCNA is to obtain structure-preserving embeddings that are also robust to noises and variations for better alignment results. The major novelty lies in generating augmented multiple graph views for contrastive learning that are driven by real world network dynamics. Rigorous investigations on 4 real datasets show that HCNA consistently outperforms the baselines by at least 1-84% in terms of accuracy score. Furthermore, HCNA is also more resilient to structural and attributes noises, as evidenced by its adaptivity analysis on adversarial conditions.
Motivation: Biological pathway is an important curated knowledge of biological processes. Thus, cancer subtype classification based on pathways will be very useful to understand differences in biological mechanisms among cancer subtypes. However, pathways include only a fraction of the entire gene set, only one-third of human genes in KEGG, and pathways are fragmented. For this reason, there are few computational methods to use pathways for cancer subtype classification. Results: We present an explainable deep-learning model with attention mechanism and network propagation for cancer subtype classification. Each pathway is modeled by a graph convolutional network. Then, a multi-attention based ensemble model combines several hundreds of pathways in an explainable manner. Lastly, network propagation on pathway gene network explains why gene expression profiles in subtypes are different. In experiments with five TCGA cancer datasets, our method achieved very good classification accuracies and, additionally, identified subtype-specific pathways and biological functions.
In translation initiation, AUG recognition triggers rearrangement of the 48S preinitiation complex (PIC) from an open conformation to a closed state with more tightly-bound Met-tRNAi. Cryo-EM structures have revealed interactions unique to the closed complex between arginines R55/R57 of eIF2 alpha with mRNA, including the -3 nucleotide of the 'Kozak' context. We found that R55/R57 substitutions reduced recognition of a UUG start codon at HIS4 in Sui(-) cells (Ssu(-) phenotype); and in vitro, R55G-R57E accelerated dissociation of the eIF2.GTP.Met-tRNAi ternary complex (TC) from reconstituted PICs with a UUG start codon, indicating destabilization of the closed complex. R55/R57 substitutions also decreased usage of poor-context AUGs in SUI1 and GCN4 mRNAs in vivo. In contrast, eIF2 alpha-R53 interacts with the rRNA backbone only in the open complex, and the R53E substitution enhanced initiation at a UUG codon (Sui(-) phenotype) and poor-context AUGs, while reducing the rate of TC loading (Gcd(-) phenotype) in vivo. Consistently, R53E slowed TC binding to the PIC while decreasing TC dissociation at UUG codons in vitro, indicating destabilization of the open complex. Thus, distinct interactions of eIF2 alpha with rRNA or mRNA stabilize first the open, and then closed, conformation of the PIC to influence the accuracy of initiation in vivo.
Binary code traceability aims to use the relevant characteristics of anonymous binary codes to identify concealed authors or teams and replace error-prone and time-consuming manual reverse engineering tasks with automated systems. Although significant progress has been made in source code traceability technology, research on tracking binary files is still limited. Hence, we propose a feature extraction method and deep learning model that exploit the sequence and structure information of binary codes to identify the authors of anonymous and malicious binary codes and their relations with other known binary code families. We further propose a new multigranularity information fusion feature based on biological genes oriented to the traceability of binary codes. The evaluations conducted on the Google Code Jam (GCJ) dataset indicate that our method can accurately trace the binary code from 10 00 people to the target author with an accuracy rate of 71%. Further, experimental results verify the robustness of the proposed model. For malicious code datasets, in particular, the proposed method achieved a stable traceability accuracy rate for malicious samples using only a small number of training samples. For the problem of malicious code tracking, in 300 team organizations, the proposed method achieved a code-tracing accuracy rate of 82%. (C) 2022 Elsevier Ltd. All rights reserved.
Hard carbons (HCs) possess high lithium/sodium storage capacities, which however suffer from low electric conductivity and poor ion diffusion kinetics. An efficient structure design with appropriate heteroatoms doping and optimized graphitic/defective degree is highly desired to tackle these problems. This work reports a new design of N-doped HC nanoshells (N-GCNs) with homogeneous defective nanographite domains, fabricated through the prechelation between Ni2+ and chitosan and subsequent catalyst confined graphitization. The as-prepared N-GCNs deliver a high reversible lithium storage capacity of 1253 mA h g(-1), with outstanding rate performance (175 mA h g(-1) at a high rate of 20 A g(-1)) and good cycling stability, which outperforms most state-of-the-art HCs. Meanwhile, a high reversible sodium storage capacity of 325 mA h g(-1) is also obtained, which stabilizes at 174 mA h g(-1) after 200 cycles. Density functional theory calculations are performed to uncover the coupling effect between heteroatom-doping and the defective nanographitic domains down to the atomic scale. The in situ Raman analysis reveals the adsorption mechanism for sodium storage and the adsorption-intercalation mechanism for lithium storage of N-GCNs.
Code summarization aims to generate high-quality functional summaries of code snippets to improve the efficiency of program development and maintenance. It is a pressing challenge for code summariza-tion models to capture more comprehensive code knowledge by integrating the feature correlations between the semantics and syntax of the code. In this paper, we propose a multi-modal similarity network based code summarization method: GT-SimNet. It proposes a novel code semantic modelling method based on a local application programming interface (API) dependency graph (Local-ADG), which exhibits an excellent ability to mask irrelevant semantics outside the current code snippet. For code feature fusion, GT-SimNet uses the SimNet network to calculate the correlation coefficients between Local-ADG and abstract syntax tree (AST) nodes and performs fusion under the influence of the correlation coefficients. Finally, it completes the prediction of the target summary by the generator. We conduct extensive experiments to evaluate the performance of GT-SimNet on two language datasets (Java and Solidity). The results show that GT-SimNet achieved BLEU scores of 38.73% and 41.36% on the two datasets, 1.47%similar to 2.68% higher than the best existing baseline. Importantly, GT-SimNet reduces the BLEU scores by 7.28% after removing Local-ADG. This indicates that Local-ADG is effective for the semantic representation of the code.(c) 2022 Elsevier Inc. All rights reserved.
Either traditional learning methods or deep learning methods have been widely applied for the early Alzheimer's disease (AD) diagnosis, but these methods often suffer from the issue of training set bias and have no interpretability. To address these issues, this paper proposes a two-phase framework to iteratively assign weights to samples and features. Specifically, the first phase automatically distinguishes clean samples from training samples. Training samples are regarded as noisy data and thus should be assigned different weights for penalty, while clean samples are of high quality and thus are used to learn the feature weights. In the second phase, our method iteratively assigns sample weights to the training samples and feature weights to the clean samples. Moreover, their updates are iterative so that the proposed framework deals with the training set bias issue as well as contains interpretability on both samples and features. Experimental results on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset show that our method achieves the best classification performance in terms of binary classification tasks and has better interpretability, compared to the state-of-the-art methods.
Eukaryotes harbour a conserved signalling pathway, called General Amino Acid Control (GAAC) in Saccharomyces cerevisiae, for overcoming amino acid starvation. Upon starvation, the protein kinase Gcn2, which phosphorylates the eukaryotic translation initiation factor eIF2 alpha, becomes stimulated to trigger the GAAC response. Genetic studies suggest that Yih1, which is the yeast homolog of mammalian IMPACT and which binds monomeric actin, inhibits Gcn2 when released from actin. Here, we found that D56A substitution in actin (the act1-9 allele) leads to reduced eIF2 alpha phosphorylation, suggesting that the Asp56 residue is required for full Gcn2 activation. In the act1-9 mutant, Yih1 overexpression further enhanced the sensitivity to amino acid starvation-inducing drugs and further impaired eIF2 alpha phosphorylation, suggesting that Gcn2 inhibition was mediated via Yih1. The D56A substitution may impair the actin-Yih1 interaction, directly or indirectly, thereby increasing the amount of Yih1 available to inhibit Gcn2.
Pose estimation is an essential technology for product grasping and assembly in intelligent manufacturing. Finding local correspondences between the 2-D image and the 3-D model is the key step to estimate the 6-D pose of an object. However, when the objects are textureless, it is difficult to identify distinguishable point features. In this article, we propose a novel deep learning framework called the pseudo-Siamese graph matching network to tackle the problem of feature matching of textureless objects and estimate accurate object poses with a single RGB-only image. We utilize a pseudo-Siamese network structure to learn the similarity between the 2-D image features and the 3-D mesh model of the object. A fully convolutional network and a graph convolutional network are used to extract high-dimensional deep features of the 2-D image and the 3-D model, respectively. Dense 2-D-3-D correspondences are inferred using the pseudo-Siamese matching network. Then, the pose of the object is calculated by the Perspective-n-Point and random sample consensus (RANSAC) methods. Experiments on the LINEMOD dataset and a grasping task for metal part show the accuracy and robustness of our proposed method.(1)
Bot detection is a fundamental and crucial task for tracing and mitigating cyber threats in the Internet. This paper aims to address two major limitations of current bot detection systems. First, existing flow-based bot detection approaches ignore structural information of botnets, which lead to false detection. Second, they cannot identify the interactive behavioral patterns among heterogeneous botnet objects. In this paper, we propose a novel bot detection framework, namely Bot-AHGCN, which models fine-grained network flow objects (e.g., IP, response) as a multi-attributed heterogeneous graph and transforms bot detection problem into a semi-supervised node classification task on the graph. Particularly, we first build a multi-attributed heterogeneous information network (AHIN) to model the interdependent relationships among botnet objects. Second, we present a weight-learning based node embedding method, which learns the interactive behavioral patterns among hots and integrates them into weighted similarity graphs. Finally, we perform graph convolution on the learned similarity graphs to characterize more comprehensive and discriminative features of hots, and feed them into a forward neural network to identify hots. The overall experimental results on two real-world datasets confirm that Bot-AHGCN outperforms the existing state-of-the-art approaches, and presents better interpretability by introducing meaningful meta-paths and meta-graphs. (C) 2020 Elsevier Inc. All rights reserved.
Lung cancer is one of the deadliest, most aggressive cancers. Abrupt changes in gene expression represent an important challenge to understand and fight the disease. Gene co-expression networks (GCNs) have been widely used to study the genomic regulatory landscape of human cancer. Here, based on 1,143 RNA-Seq experiments from the TCGA collaboration, we constructed GCN for the most common types of lung tumors: adenocarcinoma (TAD) and squamous cells (TSCs) as well as their respective control networks (NAD and NSC). We compared the number of intra-chromosome (cis-) and inter-chromosome (trans-) co-expression interactions in normal and cancer GCNs. We compared the number of shared interactions between TAD and TSC, as well as in NAD and NSC, to observe which phenotypes were more alike. By means of an over-representation analysis, we associated network topology features with biological functions. We found that TAD and TSC present mostly cis- small disconnected components, whereas in control GCNs, both types have a giant trans- component. In both cancer networks, we observed cis- components in which genes not only belong to the same chromosome but to the same cytoband or to neighboring cytobands. This supports the hypothesis that in lung cancer, gene co-expression is constrained to small neighboring regions. Despite this loss of distant co-expression observed in TAD and TSC, there are some remaining trans- clusters. These clusters seem to play relevant roles in the carcinogenic processes. For instance, some clusters in TAD and TSC are associated with the immune system, response to virus, or control of gene expression. Additionally, other non-enriched trans- clusters are composed of one gene and several associated pseudo-genes, as in the case of the FTH1 gene. The appearance of those common trans- clusters reflects that the gene co-expression program in lung cancer conserves some aspects for cell maintenance. Unexpectedly, 0.48% of the edges are shared between control networks; conversely, 35% is shared between lung cancer GCNs, a 73-fold larger intersection. This suggests that in lung cancer a process of de-differentiation may be occurring. To further investigate the implications of the loss of distant co-expression, it will become necessary to broaden the investigation with other omic-based approaches. However, the present approach provides a basis for future work toward an integrative perspective of abnormal transcriptional regulatory programs in lung cancer.
In this study, Mittal et al. report that sequence-specific transcription factors and their tethered cofactors (e.g., SAGA, Mediator, TUP, NuA4, SWI/SNF, and RPD3-L) are generally bound to promoters prior to induction ("poised"), rather than recruited upon induction, whereas induction recruits the preinitiation complex (PIC) to DNA. Their findings suggest that inducible systems, where present, evolved on top of constitutive systems. Genome-wide, little is understood about how proteins organize at inducible promoters before and after induction and to what extent inducible and constitutive architectures depend on cofactors. We report that sequence-specific transcription factors and their tethered cofactors (e.g., SAGA [Spt-Ada-Gcn5-acetyltransferase], Mediator, TUP, NuA4, SWI/SNF, and RPD3-L) are generally bound to promoters prior to induction ("poised"), rather than recruited upon induction, whereas induction recruits the preinitiation complex (PIC) to DNA. Through depletion and/or deletion experiments, we show that SAGA does not function at constitutive promoters, although a SAGA-independent Gcn5 acetylates +1 nucleosomes there. When inducible promoters are poised, SAGA catalyzes +1 nucleosome acetylation but not PIC assembly. When induced, SAGA catalyzes acetylation, deubiquitylation, and PIC assembly. Surprisingly, SAGA mediates induction by creating a PIC that allows TFIID (transcription factor II-D) to stably associate, rather than creating a completely TFIID-independent PIC, as generally thought. These findings suggest that inducible systems, where present, are integrated with constitutive systems.
Interpretation of guided wave signals is a central challenge for ultrasonic guided wave-based damage detection and localization technology. Because of the complexity of the guided waves that are scattered from structural damage, existing guided wave-based damage detection methods cannot be used to extract the relationship information hidden in the guided waves for use in damage detection and localization. A graph-in-graph convolutional network is thus proposed for guided wave-based damage detection and localization that constructs spatial & x2013;temporal feature representations of the guided wave signals and interconnects them into a global graph to indicate the inherent differences among these signals. By converting the guided wave characteristics into structural and topological information in non-Euclidean space, the proposed method correlates the global graph with the damage location directly and achieves greater damage detection accuracy with fewer training data. Validations are performed using two different experimental datasets, which were collected from aluminum plates and a composite laminate. The results indicate that the proposed method achieves superior performance with high accuracy and stability for even limited and imbalanced datasets acquired with only three transducers.
Purpose: Adenocarcinoma is the most common histopathological type of lung cancer, and histopathological images are important for assessing the stage and subtype of tumors. Patients with lung adenocarcinoma may have genetic alterations in oncogenic drivers, including EGFR, ALK, ROS1, BRAF, among others. Among them, the EGFR mutation-positivity in Asians is as high as 40%-60%. However, no research has explored the relationship between the morphological information of pathological cells and the oncogenic driver gene EGFR.Methods: In this paper, we propose a novel automatic analysis framework and joint semantic, spatial, and clinical information for exploring the relationship between tumor microenvironment features and EGFR gene mutations, namely, JSSC-Net. Our approach consists of the following modules: the semantic feature encoding module, spatial feature encoding module, clinical information feature encoding module, and feature fusion module.Results: We collected 248 digital WSIs images acquired from 248 patients with lung adenocarcinoma, and verified the effectiveness of our proposed model on this dataset. Our proposed method achieved the accuracy of predicting EGFR mutation state was 0.7778, performing significantly better than the baseline methods. In addition, we attempted to learn the associations between histopathological images and the types of EGFR gene mutation, achieving an accuracy was 0.6428.Conclusions: In this study, we proposed a novel deep learning-based method to predict the mutation state of EGFR gene in lung adenocarcinoma. The experiments proved that the conformation of tumor pathology is associated with EGFR mutation-positivity, that is, the tumor microenvironment of different types is predictive of genetic alterations in oncogenic drivers.Significance: We have demonstrated that the proposed deep learning-based analysis framework can auto-matically and efficiently predict the relationship between tumor microenvironment features and EGFR gene mutations. This information is critical for applying appropriate and targeted therapies to lung cancer patients, thereby increasing the scope and performance of precision medicine.
Interactive fusion methods have been successfully applied to multimodal sentiment analysis, due to their ability to achieve data complementarity via interaction of different modalities. However, previous methods treat the information of each modality as a whole and usually treat them equally, failing to distinguish the contribution of different semantic regions in non-textual features towards textual features. It caused that the public regions fail to be captured and private regions are hard to be predicted only with textual. Meanwhile, these methods use sentiment-independent encoder to encode textual features, which may mistakenly identify syntactically irrelevant contextual words as clues for predicting sentiment. In this paper, we propose a coordinated-joint translation fusion framework with sentiment-interactive graph to solve these problems. Specifically, we generate a novel sentiment-interactive graph to incorporate sentiment associations between different words into the syntactic adjacency matrix. The relationships between nodes are no longer limited to the sole existence of syntactic associations but fully consider the interaction of sentiment between different words. Then, we design a coordinated-joint translation fusion module. This module utilizes a cross-modal masked attention mechanism to determine whether there is a correlation between the text and non-text inputs, thereby identifying the most relevant public semantic features in the visual and acoustic modalities corresponding to the text modality. Subsequently, a cross-modal translation-aware mechanism is used to calculate the differences between the visual and acoustic modalities features transformed into the text modality and the text modality itself, which allows us to reconstruct the visual and acoustic modalities towards text modality to obtain private semantic features. In addition, we construct a multimodal fusion layer to fuse textual features and non-textual public and private features to improve multimodal interaction effects. Experimental results on publicly available datasets CMU-MOSI and CMU-MOSEI illustrate that our proposed model achieve a best accuracy of 86.5% and 86.1%, and best F1 of 86.4% and 86.1%. A series of further analyses also indicate the proposed framework effectively improve the sentiment identification capability.
Users from different cultures and backgrounds often feel comfortable expressing their thoughts on trending topics by generating content in their regional languages. Recently, there has been an explosion in multilingual information, and a massive amount of multilingual textual data is added daily on the Internet. Using hashtags for multilingual low-resource content can be an effective way to overcome language barriers because it allows content to be discovered by a wider audience and makes it easier for people interested in the topic to find relevant content, regardless of the language in which it was written. To account for linguistic diversity and universal access to information, hashtag recommendation for multilingual low-resource content is essential. Several approaches have been put forth to recommend content-based and personalized hashtags for multimodal content in high-resource languages. Data availability and linguistic differences often limit the development of hashtag recommendation methods for low-resource Indic languages. Hashtag recommendation for tweets disseminated in low-resource Indic languages has seldom been addressed. Moreover, personalization and language usage aspects to recommend hashtags for tweets posted in low-resource Indic languages have yet to be explored. In view of the foregoing, we propose an automated hashtag recommendation system for tweets posted in low-resource Indic languages dubbed as TAGALOG, capable of recommending personalized and language-specific hashtags. We employ user-guided and language-guided attention mechanisms to distill indicative features from low-resource tweets according to the user's topical and linguistic preferences. We propose a graph-based neural network to mine users' posting behavior by connecting historical tweets of a particular user and language relatedness by linking tweets according to language families, i.e., Indo-Aryan and Dravidian. Experimental results on the curated dataset from Twitter demonstrate that the proposed model outperformed recognized pre-trained language models and extant research, showing an average improvement of 12.3% and 12.8% in the F1-score, respectively. TAGALOG recommends hashtags that align with the user's interests and linguistic predilections, leading to a heightened level of tailored and engaging user experience. Personalized and multilingual hashtag recommendation systems for low-resource Indic languages can help to improve the discoverability and relevance of content in these languages.
Background Recent efforts in the field of nutritional science have allowed the discovery of disease-beating molecules within foods based on the commonality of bioactive food molecules to FDA-approved drugs. The pioneering work in this field used an unsupervised network propagation algorithm to learn the systemic-wide effect on the human interactome of 1962 FDA-approved drugs and a supervised algorithm to predict anticancer therapeutics using the learned representations. Then, a set of bioactive molecules within foods was fed into the model, which predicted molecules with cancer-beating potential.The employed methodology consisted of disjoint unsupervised feature generation and classification tasks, which can result in sub-optimal learned drug representations with respect to the classification task. Additionally, due to the disjoint nature of the tasks, the employed approach proved cumbersome to optimize, requiring testing of thousands of hyperparameter combinations and significant computational resources.To overcome the technical limitations highlighted above, we represent each drug as a graph (human interactome) with its targets as binary node features on the graph and formulate the problem as a graph classification task. To solve this task, inspired by the success of graph neural networks in graph classification problems, we use an end-to-end graph neural network model operating directly on the graphs, which learns drug representations to optimize model performance in the prediction of anticancer therapeutics. Results The proposed model outperforms the baseline approach in the anticancer therapeutic prediction task, achieving an F1 score of 67.99%+/- 2.52% and an AUPR of 73.91%+/- 3.49%. It is also shown that the model is able to capture knowledge of biological pathways to predict anticancer molecules based on the molecules' effects on cancer-related pathways. Conclusions We introduce an end-to-end graph convolutional model to predict cancer-beating molecules within food. The introduced model outperforms the existing baseline approach, and shows interpretability, paving the way to the future of a personalized nutritional science approach allowing the development of nutrition strategies for cancer prevention and/or therapeutics.
Some filamentous fungi of the Trichoderma genus are used as biocontrol agents against airborne and soilborne phytopathogens. The proposed mechanism by which Trichoderma spp. antagonizes phytopathogens is through the release of lytic enzymes, antimicrobial compounds, mycoparasitism, and the induction of systemic disease-resistance in plants. Here we analyzed the role of TGF-1 (Trichoderma Gen Five-1), a histone acetyltransferase of Trichoderma atroviride, in mycoparasitism and antibiosis against the phytopathogen Rhizoctonia solani. Trichostatin A (TSA), a histone deacetylase inhibitor that promotes histone acetylation, slightly affected T. atroviride and R. solani growth, but not the growth of the mycoparasite over R. solani. Application of TSA to the liquid medium induced synthesis of antimicrobial compounds. Expression analysis of the mycoparasitism-related genes ech-42 and prb-1, which encode an endochitinase and a proteinase, as well as the secondary metabolism-related genes pbs-1 and tps-1, which encode a peptaibol synthetase and a terpene synthase, respectively, showed that they were regulated by TSA. A T. atroviride strain harboring a deletion of tgf-1 gene showed slow growth, thinner and less branched hyphae than the wild-type strain, whereas its ability to coil around the R. solani hyphae was not affected. Delta tgf-1 presented a diminished capacity to grow over R. solani, but the ability of its mycelium -free culture filtrates (MFCF) to inhibit the phytopathogen growth was enhanced. Intriguingly, addition of TSA to the culture medium reverted the enhanced inhibition growth of Delta tgf-1 MFCF on R. solani at levels compared to the wild-type MFCF grown in medium amended with TSA. The presence of R. solani mycelium in the culture medium induced similar proteinase activity in a Delta tgf-1 compared to the wild-type, whereas the chitinolytic activity was higher in a Delta tgf-1 mutant in the absence of R. solani, compared to the parental strain. Expression of mycoparasitism- and secondary metabolism-related genes in Delta tgf-1 was differentially regulated in the presence or absence of R. solani. These results indicate that histone acetylation may play important roles in the biocontrol mechanisms of T. atroviride.
General control nonderepressible 2 (GCN2) is a serine/threonine protein kinase, detecting a variety of stresses including amino acid starvation, reactive oxygen species, etc. in eukaryotic cells. Activation of GCN2 requires the interaction of the N-terminal RWD domain with the upstream GCN1 protein and the dimerization by the kinase domain. In this study, we determined two crystal structures of the RWD domain of human GCN2 in two different crystal packing modes. These two different crystal structures reveal a same dimer of the RWD domain, which has not been reported in previous studies. We further confirmed this novel dimer interaction in solution using gel filtration experiments, and in human embryonic kidney (HEK) 293 cells using bimolecular fluorescence complementation (BiFC) and coimmunoprecipitation (co-IP) assays. Together, this study discovers a potential protein-protein interface on the RWD domain of human GCN2, and suggests a possible regulation between the interaction of GCN1 and the formation of GCN2 dimer. (c) 2021 Elsevier Inc. All rights reserved.
The SAGA-like complex SLIK is a modified version of the Spt-Ada-Gcn5-Acetyltransferase (SAGA) complex. SLIK is formed through C-terminal truncation of the Spt7 SAGAsubunit, causing loss of Spt8, one of the subunits that interacts with the TATA-binding protein (TBP). SLIK and SAGA are both coactivators of RNA polymerase II transcription in yeast, and both SAGA and SLIK perform chromatin modifications. The two complexes have been speculated to uniquely contribute to transcriptional regulation, but their respective contributions are not clear. To investigate, we assayed the chromatinmodifying functions of SAGA and SLIK, revealing identical kinetics on minimal substrates in vitro. We also examined the binding of SAGA and SLIK to TBP and concluded that interestingly, both protein complexes have similar affinity for TBP. Additionally, despite the loss of Spt8 and C-terminus of Spt7 in SLIK, TBPprebound to SLIKis not released in the presence of TATA-box DNA, just like TBP prebound to SAGA. Furthermore, we determined a low-resolution cryo-EM structure of SLIK, revealing a modular architecture identical to SAGA. Finally, we performed a comprehensive study of DNA-binding properties of both coactivators. Purified SAGA and SLIK both associate with ssDNA and dsDNA with high affinity (K-D = 10-17 nM), and the binding is sequence-independent. In conclusion, our study shows that the cleavage of Spt7 and the absence of the Spt8 subunit in SLIK neither drive any major conformational differences in its structure comparedwith SAGA, nor significantly affect HAT, DUB, or DNA-binding activities in vitro.
The dark matter content of the ultra-diffuse galaxy NGC 1052-DF2, as inferred from globular cluster (GC) and stellar kinematics, carries a considerable amount of uncertainty, with current constraints also allowing for the complete absence of dark matter. We test the viability of such a scenario by examining whether in a "baryon-only" mass model the observed GC population experiences rapid orbital decay due to dynamical friction. Using a suite of 50 multi-GC N-body simulations that match observational constraints on both the stellar component of NGC 1052-DF2 and its GC population but differ in the initial line-of-sight positions and the tangential velocities of the GCs, we show that there is a substantial amount of realization-to-realization variance in the evolution of the GCs. Nevertheless, over similar to 10 Gyr, some of the GCs experience significant orbital evolution. Others evolve less. A combination of reduced dynamical friction in the galaxy core and GC-GC scattering keeps the GCs afloat, preventing them from sinking all the way to the galaxy center. While the current phase-space coordinates of the GCs are not unlikely for a baryon-only mass model, the GC system does evolve over time. Therefore, if NGC 1052-DF2 has no dark matter, some of its GCs must have formed farther out, and the GC system must have been somewhat more extended in the past. The presence of a low-mass cuspy halo, while allowed by the kinematics, seems improbable, as significantly shorter inspiral timescales in the central region would quickly lead to the formation of a nuclear star cluster.
Polymeric graphitic carbon nitride (g-CN) has emerged as a promising metal-free photocatalyst; however, the polymerization process is still poorly understood, and the synthesized g-CN shows a structural complexity, with photocatalytic activities far from being optimized. Herein we present new insight into its polymerization reaction kinetics and develop a quasi-sealed condensation route to properly regulate the distribution of the degree of polymerization (DP) in the synthesized g-CN. The correlation throughout the condensation process, the structure-property relationship, and the photocatalytic performance of g-CN have been discussed in detail. The synthesized g-CN shows a narrower and uniform DP distribution, possesses improved crystallinity, and features a nanoporous texture with fruitful amine groups and better water dispersibility, which promotes the fast charge-carrier transport under aqueous conditions and give rise to substantially enhanced photocatalytic activity. Compared with the conventional counterpart, its visible-light activity is 4.88 times higher for hydrogen production, 7.81 times higher for the degradation of rhodamine B, and 2.47 times higher for the degradation of 4-chlorophenol. We further report that its solar-driven photocatalytic activity is superior to that of the representative Degussa TiO2 P25 catalyst for scale-up RhB degradation, thus highlighting the great prospects of g-CN-based photocatalysts toward practical applications.
Instance segmentation in biological images is an important task in the field of biological images and biomedical analysis. Different from the instance segmentation of natural image scenes, this task is still challenging because there are a large number of overlapping objects with similar appearance as well as great variability in shape, size and texture in the foreground and background. In this paper, we propose a novel method for segmentation of graph-guided instances of biological images, which successfully addresses these peculiarities. Our method predicts the embedding at each pixel and uses clustering to recover instances during testing. Specifically, we design the Graph-guided Feature Fusion Module in response to overlapping instances. Our Graph-guided Feature Fusion Module combines fine deep features and coarse shallow features to learn the affinity matrix, and then uses graph convolutional network to guide the network to learn object-level local features. Next, we devise the Gated Spatial Attention Module to effectively learn key spatial information by introducing a gating mechanism. Furthermore, we give the Cluster Distance Loss that can effectively distinguish foreground objects from similar backgrounds. The effectiveness of our proposed method has been verified on various biological and biomedical datasets. The experimental results show that our method is superior to previous embedding-based instance segmentation methods. The SBD metric for our method reached 90.8% on the plant phenotype dataset (CVPPP), 72.5% on the cell nucleus dataset (DSB2018), and 81.8% on the C.elegans dataset, all achieving state-of-the-art performance.
The importance of considering related stocks data for the prediction of stock price movement has been shown in many studies; however, advanced graphical techniques for modeling, embedding and analyzing the behavior of inter-related stocks have not been widely exploited for the prediction of stocks price movements yet. The main challenges in this domain are to find a way for modeling the existing relations among an arbitrary set of stocks and to exploit such a model for improving the prediction performance for those stocks. The most of existing methods in this domain rely on basic graph-analysis techniques, with limited prediction power, and suffer from a lack of generality and flexibility. In this paper, we introduce a novel framework, called GCNET that models the relations among an arbitrary set of stocks as a graph structure called influence network and uses a set of history-based prediction models to infer plausible initial labels for a subset of the stock nodes in the graph. Finally, GCNET uses the Graph Convolutional Network algorithm to analyze this partially labeled graph and predicts the next price direction of movement for each stock in the graph.GCNET is a general prediction framework that can be applied for the prediction of the price fluctuations of interacting stocks based on their historical data. Our experiments and evaluations on a set of stocks from the NASDAQ index demonstrate that GCNET improves the performance of the state-of-the-art algorithms in terms of Accuracy and Matthew's Correlation Coefficient by at least 1.5% and 2%, respectively.
The improvement of catalytic efficiency of catalyst is a challenging topic especially for solid catalyst that has restrained surface to contact reactants. Herein, we reported an effective way to improve the catalytic efficiency by designing composites catalyst (to induce synergistic effect) and performing the reaction under united technologies (to make cooperative contribution). As a model case, La-Fe-O mixture (abbreviated as LFO) and graphitic carbon nitride (abbreviated as g-CN) composites (LFO@CN-n, where n means the molar ratio of the precursors of LFO to g-CN) were synthesized and used as photo-Fenton catalysts for oxidation removal of dyes in wastewater. Results showed that LFO@CN-16, with g-CN loading of 69%, has the properties of both LFO and gCN, and exhibits high efficiency for dyes oxidation in the presence of H2O2 and light irradiation, with 98% rhodamine B conversion within 25 min, for example. Mechanistic studies suggested that center dot OH radicals produced from H2O2 are the reaction intermediates, which participate both in the Fenton- and the photo-catalytic processes. Moreover, the catalyst can be reused for at least 5 cycles with no appreciable loss of activity, and can be applied to various organic dyes containing benzene-like cyclic structures with high efficiency.
As a crucial part of the Intelligent Transportation System, traffic forecasting is of great help for traffic management and guidance. However, predicting short-term traffic conditions on a large-scale road network is challenging due to the complex spatio-temporal dependencies found in traffic data. Previous studies used Euclidean proximity or topological adjacency to explore the spatial correlation of traffic flows, but did not consider the higher-order connectivity patterns exhibited in a road network, which have a significant influence on traffic propagation. Meanwhile, traffic sequences display distinct multiple time-frequency properties, yet few researchers have made full use of this resource. To fill this gap, we propose a novel hybrid framework - Wavelet-based Higher-order Spatial-Temporal method (Wavelet-HST) to accurately predict network-scale traffic speeds. Wavelet-HST first uses discrete wavelet transform (DWT) to decompose raw traffic data into several components with different frequency sub-bands. Then a motif-based graph convolutional recurrent neural network (Motif-GCRNN) is proposed to learn the higher-order spatio-temporal dependencies of traffic speeds from low-frequency components, and auto-regressive moving average (ARMA) models are employed to simulate random fluctuations from the high-frequency components. We evaluate the framework on a traffic dataset collected in Chengdu, China, and experimental results demonstrate that Wavelet-HST outperforms six state-of-art prediction methods by an improvement of 7.8% -10.5% in the root mean square error.
Pathological cardiac hypertrophy is a process of abnormal remodeling of cardiomyocytes in response to pressure overload or other stress stimuli, resulting in myocardial injury, which is a major risk factor for heart failure, leading to increased morbidity and mortality. General control nonrepressed protein 5 (GCN5)/lysine acetyltransferase 2 A, a member of the histone acetyltransferase and lysine acetyltransferase families, regulates a variety of physiological and pathological events. However, the function of GCN5 in pathological cardiac hypertrophy remains unclear. This study aimed to explore the role of GCN5 in the development of pathological cardiac hypertrophy. GCN5 expression was increased in isolated neonatal rat cardiomyocytes (NRCMs) and mouse hearts of a hypertrophic mouse model. GCN5 overexpression aggravated the cardiac hypertrophy triggered by transverse aortic constriction surgery. In contrast, inhibition of GCN5 impairs the development of pathological cardiac hypertrophy. Similar results were obtained upon stimulation of NRCMs (having GCN5 overexpressed or knocked down) with phenylephrine. Mechanistically, our results indicate that GCN5 exacerbates cardiac hypertrophy via excessive activation of the transforming growth factor beta-activated kinase 1 (TAK1)-c-Jun N-terminal kinase (JNK)/p38 signaling pathway. Using a TAK1-specific inhibitor in rescue experiments confirmed that the activation of TAK1 is essential for GCN5-mediated cardiac hypertrophy. In summary, the current study elucidated the role of GCN5 in promotion of cardiac hypertrophy, thereby implying it to be a potential target for treatment.
We construct the Hilbert space costratification of G = SU(2)-quantum gauge theory on a finite spatial lattice in the Hamiltonian approach. We build on previous work [F. Furstenberg, G. Rudolph, and M. Schmidt, J. Geom. Phys. 119, 66-81 (2017)], where we have implemented the classical gauge orbit strata on the quantum level within a suitable holomorphic picture. In this picture, each element tau of the classical stratification corresponds to the zero locus of a finite subset {p(i)} of the algebra R of G-invariant representative functions on G(C)(N). Viewing the invariants as multiplication operators (p) over cap (i) on the Hilbert space H, the union of their images defines a subspace of H whose orthogonal complement H-tau is the element of the costratification corresponding to tau. To construct H-tau, one has to determine the images of the (p) over cap (i) explicitly. To accomplish this goal, we construct an orthonormal basis in H and determine the multiplication law for the basis elements; that is, we determine the structure constants of R in this basis. This part of our analysis applies to any compact Lie group G. For G = SU(2), the above procedure boils down to a problem in combinatorics of angular momentum theory. Using this theory, we obtain the union of the images of the operators (p) over cap (i) as a subspace generated by vectors whose coefficients with respect to our basis are given in terms of Wigner's 3nj symbols. The latter are further expressed in terms of 9j symbols. Using these techniques, we are also able to reduce the eigenvalue problem for the Hamiltonian of this theory to a problem in linear algebra. Published by AIP Publishing.
Following spinal cord injury (SCI), multiple signaling cascades are activated instantaneously in the injured segments of the spinal cord to create a complex and pathogenic microenvironment, making it difficult to treat SCI. Nevertheless, the significance of the integrated stress response (ISR) to the series of physiological and pathological changes that occur after SCI remains unclear. Through western blotting (WB), we determined that the autophosphorylation of stress receptors (GCN2, PERK, PKR, and HRI) was enhanced after SCI, leading to increased phosphorylation of eIF2 alpha at Ser51. Strikingly, we found that eIF2 alpha was highly phosphorylated at 1 day post injury (dpi) and that this hypophosphorylation was maintained thereafter in the spinal cord, especially in neurons, which suggests that intervening with eIF2 alpha phosphorylation may be a treatment strategy for SCI. Therefore, we employed the small molecule ISRIB, which inhibits eIF2 alpha phosphorylation when the ISR is activated at moderate or low levels but not when the ISR is highly activated. Daily intraperitoneal injection of ISRIB significantly inhibited ISR signaling after SCI, reduced the cytosolic localization of RNA-binding proteins, and decreased neuronal apoptosis. Histological and functional experiments further demonstrated that treatment with ISRIB after SCI effectively curbed morphological deterioration and promoted the recovery of locomotor function. In summary, the ISR plays an important role in SCI, and ISRIB is a promising drug for the treatment of SCI.
Objectives: A deep learning-based early warning system is proposed to predict sepsis prior to its onset. Design: A novel algorithm was devised to detect sepsis 6 hours prior to its onset based on electronic medical records. Setting: Retrospective cohorts from three separate hospitals are used in this study. Sepsis onset was defined based on Sepsis-3. Algorithms are evaluated based on the score function used in the Physionet Challenge 2019.Patients: Over 60,000 ICU patients with 40 clinical variables (vital signs, laboratory results) for each hour of a patient's ICU stay were used. Interventions: None. Measurements and Main Results: The proposed algorithm predicted the onset of sepsis in the precedingnhours (wheren= 4, 6, 8, or 12). Furthermore, the proposed method compared how many sepsis patients can be predicted in a short time with other methods. To interpret a given result in a clinical perspective, the relationship between input variables and the probability of the proposed method were presented. The proposed method achieved superior results (area under the receiver operating characteristic curve, area under the precision-recall curve, and score) and predicted more sepsis patients in advance. In official phase, the proposed method showed the utility score of -0.101, area under the receiver operating characteristic curve 0.782, area under the precision-recall curve 0.041, accuracy 0.786, and F-measure 0.046. Conclusions: Using Physionet Challenge 2019, the proposed method can accurately and early predict the onset of sepsis. The proposed method can be a practical early warning system in the environment of real hospitals.
Intracellular accumulation of amyloid-beta protein (A beta) is an early event in Alzheimer's disease (AD). The autophagy-lysosomal pathway is an important pathway for maintaining cellular proteostasis and for the removal of damaged organelles and protein aggregates in all eukaryotes. Despite mounting evidence showing that modulating autophagy promotes clearance of A beta aggregates, the regulatory mechanisms and signalling pathways underlying this process remain poorly understood. In order to gain better insight we used our previously characterised yeast model expressing GFP-A beta 42 to identify genes that regulate the removal of A beta 42 aggregates by autophagy. We report that GFP-A beta 42 is sequestered and is selectively transported to vacuole for degradation and that autophagy is the prominent pathway for clearance of aggregates. Next, to identify genes that selectively promote the removal of A beta 42 aggregates, we screened levels of GFP-A beta 42 and non-aggregating GFP-A beta 42 (19:34) proteins in a panel of 192 autophagy mutants lacking genes involved in regulation and initiation of the pathway, cargo selection and degradation processes. The nutrient and stress signalling genes RRD1, SNF4, GCN4 and SSE1 were identified. Deletion of these genes impaired GFP-A beta 42 clearance and their overexpression reduced GFP-A beta 42 levels in yeast. Overall, our findings identify a novel role for these nutrient and stress signalling genes in the targeted elimination of A beta 42 aggregates, which offer a promising avenue for developing autophagy based therapies to suppress amyloid deposition in AD.
The development of whole slide imaging techniques and online digital pathology platforms have accelerated the popularization of telepathology for remote tumor diagnoses. During a diagnosis, the behavior information of the pathologist can be recorded by the platform and then archived with the digital case. The browsing path of the pathologist on the WSI is one of the valuable information in the digital database because the image content within the path is expected to be highly correlated with the diagnosis report of the pathologist. In this article, we proposed a novel approach for computer-assisted cancer diagnosis named session-based histopathology image recommendation (SHIR) based on the browsing paths on WSIs. To achieve the SHIR, we developed a novel diagnostic regions attention network (DRA-Net) to learn the pathology knowledge from the image content associated with the browsing paths. The DRA-Net does not rely on the pixel-level or region-level annotations of pathologists. All the data for training can be automatically collected by the digital pathology platform without interrupting the pathologists' diagnoses. The proposed approaches were evaluated on a gastric dataset containing 983 cases within 5 categories of gastric lesions. The quantitative and qualitative assessments on the dataset have demonstrated the proposed SHIR framework with the novel DRA-Net is effective in recommending diagnostically relevant cases for auxiliary diagnosis. The MRR and MAP for the recommendation are respectively 0.816 and 0.836 on the gastric dataset. The source code of the DRA-Net is available at https://github.com/zhengyushan/dpathnet.
Aspect-based sentiment analysis (ABSA) aims to predict the sentiment expressed in a review with respect to a given aspect. The core of ABSA is to model the interaction between the context and given aspect to extract aspect-related information. In prior work, attention mechanisms and dependency graph networks are commonly adopted to capture the relations between the context and given aspect. And the weighted sum of context hidden states is used as the final representation fed to the classifier. However, the information related to the given aspect may be already discarded and adverse information may be retained in the context modeling processes of existing models. Such a problem cannot be solved by subsequent modules due to two reasons. First, their operations are conducted on the encoder-generated context hidden states, whose value cannot be changed after the encoder. Second, existing encoders only consider the context while not the given aspect. To address this problem, we argue the given aspect should be considered as a new clue out of context in the context modeling process. As for solutions, we design three streams of aspect-aware context encoders: an aspect-aware LSTM, an aspect-aware GCN, and three aspect-aware BERTs. They are dedicated to generating aspect-aware hidden states which are tailored for the ABSA task. In these aspect-aware context encoders, the semantics of the given aspect is used to regulate the information flow. Consequently, the aspect-related information can be retained and aspect-irrelevant information can be excluded in the generated hidden states. We conduct extensive experiments on several benchmark datasets with empirical analysis, demonstrating the efficacies and advantages of our proposed aspect-aware context encoders.
In steerable filters, a filter of arbitrary orientation can be generated by a linear combination of a set of "basis filters." Steerable properties dominate the design of the traditional filters, e.g., Gabor filters and endow features the capability of handling spatial transformations. However, such properties have not yet been well explored in the deep convolutional neural networks (DCNNs). In this paper, we develop a new deep model, namely, Gabor convolutional networks (GCNs or Gabor CNNs), with Gabor filters incorporated into DCNNs such that the robustness of learned features against the orientation and scale changes can be reinforced. By manipulating the basic element of DCNNs, i.e., the convolution operator, based on Gabor filters, GCNs can be easily implemented and are readily compatible with any popular deep learning architecture. We carry out extensive experiments to demonstrate the promising performance of our GCNs framework, and the results show its superiority in recognizing objects, especially when the scale and rotation changes take place frequently. Moreover, the proposed GCNs have much fewer network parameters to be learned and can effectively reduce the training complexity of the network, leading to a more compact deep learning model while still maintaining a high feature representation capacity.
The TabZIP15 gene encoding a 396 amino acid (aa) polypeptide in the fungus Trichoderma asperellum ACCC30536 was cloned and characterised. The protein includes a basic region motif (NR-x2-QR-x2-R) and has a pillar-like structure. The 25 basic region/leucine zipper transcription factors (TFs) identified in the T. asperellum genome were divided into YAP (14 TFs), ATF2 (5), GCN4 (2), Zip1 (2), BRLZ (1) and u1 (1) subfamilies based on conserved domains. T. asperellum was cultured in minimal media (MM) control, C-Hungry and N-Hungry medium (to simulate nutrient competition and interaction with pathogens, respectively), and differential expression analysis showed that 14 TabZIP genes (including TabZIP15) were significantly altered under both conditions; TabZIP23 responded strongly to N-Hungry media and TabZIP24 responded strongly to C-Hungry media. However, only YAP genes TabZIP15, TabZIP12 and TabZIP2 were significantly upregulated under both conditions, and expression levels of TabZIP15 were highest. T. asperellum was also cultured in the presence of five fungal pathogenic toxins, and RT-qPCR results showed that TabZIP15 was significantly upregulated in four of the five toxin stress conditions (MM+Rhizoctonia solani, MM+Fusarium oxysporum, MM+Alternaria alternata and MM+Cytospora chrysosperma).
PurposeMoney laundering is the process of concealing unlawfully obtained funds by presenting them as coming from a legitimate source. Criminals use crypto money laundering to hide the illicit origin of funds using a variety of methods. The most simplified form of bitcoin money laundering leans hard on the fact that transactions made in cryptocurrencies are pseudonymous, but open data gives more power to investigators and enables the crowdsourcing of forensic analysis. With the motive to curb these illegal activities, there exist various rules, policies and technologies collectively known as anti-money laundering (AML) tools. When properly implemented, AML restrictions reduce the negative effects of illegal economic activity while also promoting financial market integrity and stability, but these bear high costs for institutions. The purpose of this work is to motivate the opportunity to reconcile the cause of safety with that of financial inclusion, bearing in mind the limitations of the available data. The authors use the Elliptic dataset; to the best of the authors' knowledge, this is the largest labelled transaction dataset publicly available in any cryptocurrency.Design/methodology/approachAML in bitcoin can be modelled as a node classification task in dynamic networks. In this work, graph convolutional decision forest will be introduced, which combines the potentialities of evolving graph convolutional network and deep neural decision forest (DNDF). This model will be used to classify the unknown transactions in the Elliptic dataset. Additionally, the application of knowledge distillation (KD) over the proposed approach gives finest results compared to all the other experimented techniques.FindingsThe importance of utilising a concatenation between dynamic graph learning and ensemble feature learning is demonstrated in this work. The results show the superiority of the proposed model to classify the illicit transactions in the Elliptic dataset. Experiments also show that the results can be further improved when the system is fine-tuned using a KD framework.Originality/valueExisting works used either ensemble learning or dynamic graph learning to tackle the problem of AML in bitcoin. The proposed model provides a novel view to combine the power of random forest with dynamic graph learning methods. Furthermore, the work also demonstrates the advantage of KD in improving the performance of the whole system.
Two copolymers are synthesized: one (P1) has pendant azo and 5-(1H-1, 2, 3-triazol-1-yl) pentanenitrile (TAPN) groups, and the other (P2) has pendant azo and pillar[5]arene groups. When the two copolymers are mixed in chloroform, an organogel with excellent self-healing capability and dual-stimulus responsiveness is formed. Reversible double noncovalent cross-linked networks including host-guest complexation and pi-pi interactions are responsible for this property. A xerogel prepared from the organogel can capture iodine in aqueous media. The presence of many effective sorption sites including electron-rich phenolic units and azo groups provides the xerogel with iodine uptake ability. The pillar[5]arene-based gel can adsorb iodine and self-heal rapidly, and therefore has potential as a long-life adsorbent.
Tailoring various micro-nano structured materials by employing different techniques to enhance their porosity and conductivity has captivated significant consideration, making their remarkable electrochemical properties accessible within the area of energy storage devices. Herein we report the impact of graphitic carbon nitride concentration (0.03 similar to 0.1 g) on nickel-cobalt sulfide morphologies and performance in hydrogen production. Employing the facile hydrothermal method, a cubic crystalline nickel-cobalt sulfide was stabilized on defective layered graphitic carbon nitride nanosheets for overall water splitting. A performance peak was observed in a sample with a graphitic carbon nitride concentration of 50 mg, which not only prevented the agglomeration but also provided a porous structure for enhanced gas diffusivity and charge transfer rates owing to the synergistic Carbon and Nitrogen bonding with Cobalt and Nickel Sulfide. Optimized concentration of graphitic carbon nitride also increased the electrocatalytic active surface area threefold when compared with nickel-cobalt sulfide. The fabricated well-aligned flower-like pattern CoNi2S4/graphitic carbon nitride (50 mg) delivered a low overpotential of 310 mV and 160 mV for oxygen evolution reactions and hydrogen evolution reactions to reach a current density of 30 mA/cm(2) and 10 mA/cm(2) in alkaline media. The electrolyzer displayed an electrolysis potential of 1.58 V to reach 10 mA/cm(2) current density with the long-term durability of 24 h. This strategy depicts a novel approach for utilizing this renowned nickel-cobalt sulfide with graphitic carbon nitride catalyst for the application of alkaline electrocatalytic water splitting.
Increasing water pollution has imposed great threats to public health, and made efficient monitoring and remediation technologies critical to a clean environment. In this study, a versatile heterojunction of Au nanoparticles modified phosphorus doped carbon nitride (Au/P-CN) is designed and fabricated. The Au/P-CN heterostructure demonstrates improved light absorption, rapid separation of charge carriers, and improved electrical conductivity. Taking the toxic 4-chlorophenol (4-CP) as an example, an ultrasen-sitive photoelectrochemical (PEC) sensor is successfully demonstrated, exhibiting a wide linear range (0.1-52.1 lM), low detection limit (-0.02 lM), significant stability and selectivity, as well as reliable analysis in real samples. Moreover, efficient photocatalytic degradation with a high removing efficiency (-87%) toward 4-CP is also achieved, outperforming its counterpart of Au nanoparticles (NPs) modified graphitic carbon nitride (Au/g-CN,-59%). This work paves a new way for efficient and simultaneous detection and remediation of organic pollutants over versatile photoactive catalysts.(c) 2022 Elsevier Inc. All rights reserved.
The directed evolution of antibodies has yielded important research tools and human therapeutics. The dependence of many antibodies on disulfide bonds for stability has limited the application of continuous evolution technologies to antibodies and other disulfide-containing proteins. Here we describe periplasmic phage-assisted continuous evolution (pPACE), a system for continuous evolution of protein-protein interactions in the disulfide-compatible environment of the E. coli periplasm. We first apply pPACE to rapidly evolve novel noncovalent and covalent interactions between subunits of homodimeric YibK protein and to correct a binding-defective mutant of the anti-GCN4 omega-graft antibody. We develop an intein-mediated system to select for soluble periplasmic expression in pPACE, leading to an eight-fold increase in soluble expression of the omega-graft antibody. Finally, we evolve disulfide-containing trastuzumab antibody variants with improved binding to a Her2-like peptide and improved soluble expression. Together, these results demonstrate that pPACE can rapidly optimize proteins containing disulfide bonds, broadening the applicability of continuous evolution. The directed evolution of antibodies yields important tools for research and therapy. Here the authors develop a periplasmic phage-assisted continuous evolution platform for improvement of protein-protein interactions in the disulfidecompatible E. coli periplasm.
Age and Alzheimer's disease (AD) share some common features such as cognitive impairments, memory loss, metabolic disturbances, bioenergetic deficits, and inflammation. Yet little is known on how systematic shifts in metabolic networks depend on age and AD. In this work, we investigated the global metabolomic alterations in non-transgenic (NTg) and triple-transgenic (3xTg-AD) mouse brain hippocampus as a function of age by using untargeted Ultrahigh Performance Liquid Chromatography-tandem Mass Spectroscopy (UPLC-MS/MS). We observed common metabolic patterns with aging in both NTg and 3xTg-AD brains involved in energy-generating pathways, fatty acids oxidation, glutamate, and sphingolipid metabolism. We found age-related downregulation of metabolites from reactions in glycolysis that consumed ATP and in the TCA cycle, especially at NAD(+)/NADH-dependent redox sites, where age-and AD-associated limitations in the free NADH may alter reactions. Conversely, metabolites increased in glycolytic reactions in which ATP is produced. With age, inputs to the TCA cycle were increased including fatty acid beta-oxidation and glutamine. Overall age- and AD-related changes were > 2-fold when comparing the declines of upstream metabolites of NAD(+)/NADH-dependent reactions to the increases of downstream metabolites (p = 10(-5), n = 8 redox reactions). Inflammatory metabolites such as ceramides and sphingosine-1-phosphate also increased with age. Age-related decreases in glutamate, GABA, and sphingolipid were seen which worsened with AD genetic load in 3xTg-AD brains, possibly contributing to synaptic, learning- and memory-related deficits. The data support the novel hypothesis that age-and AD-associated metabolic shifts respond to NAD(P)(+)/NAD(P)H redox-dependent reactions, which may contribute to decreased energetic capacity.
Resistance spot welding (RSW) is widely used in manufacturing processes of automobiles, aircraft, high-speed trains and other equipment, its appearance quality not only affects the product appearance, but also reflects the internal defects of welding spots and the health statuses of welding equipment to a great extent. Nowadays, a few researchers have tried to use deep learning algorithms to detect the appearance qualities of welding spots, however, the relationships between defect types and welding spot positions are ignored and the subtle visual differences among different welding spots are not fully utilized. To this end, a fine-grained flexible graph convolution network (FFGCN) is proposed for vision inspection of resistance spot welds in this paper, which combines natural language processing with computer vision. Specifically, the prior knowledge of relationships between weld appearance qualities and their positions is mapped to point-wise space by knowledge graph, so the features in point-wise space can be mined by a flexible graph convolution network (FGCN). In the FGCN, multihead attention mechanism is adopted to adaptively update the probabilistic matrix to generate multiple subgraphs, expand the spatial dimensions and increase feature information. Meanwhile, the optical features of weld images are excavated by a fine-grained network, in which the receptive field of model is enlarged and the number of pixels is ensured by dense atrous convolution. Besides, subtle visual differences between welding spots are captured by the bilinear attention convolution. Finally, the features in point-wise space and the visual features are combined by dot product to classify the appearances of welds. A six classification experiment for the vision inspection of resistance spot welds from engineering practice is implemented, results show that the proposed FFGCN has outstanding effect on the inspection of weld appearance qualities, it possesses faster convergence, more robustness, and its accuracy reaches 97.5%, which is higher than the commonly used visual classification algorithms.
Video question answering (VideoQA) is a challenging video understanding task that requires a comprehensive understanding of multimodal information and accurate answers to related questions. Most existing VideoQA models use Graph Neural Networks (GNN) to capture temporal-spatial interactions between objects. Despite achieving certain success, we argue that current schemes have two limitations: (i) existing graph-based methods require stacking multi-layers of GNN to capture high-order relations between objects, which inevitably introduces irrelevant noise; (ii) neglecting the unique self-supervised signals in the high-order relational structures among multiple objects that can facilitate more accurate QA. To this end, we propose a novel Multi-scale Self-supervised Hypergraph Contrastive Learning (MSHCL) framework for VideoQA. Specifically, we first segment the video from multiple temporal dimensions to obtain multiple frame groups. For different frame groups, we design appearance and motion hyperedges based on node semantics to connect object nodes. In this way, we construct a multi-scale temporal-spatial hypergraph to directly capture high-order relations among multiple objects. Furthermore, the node features after hypergraph convolution are injected into a Transformer to capture the global information of the input sequence. Second, we design a self-supervised hypergraph contrastive learning task based on the node- and hyperedge-dropping data augmentation and an improved question-guided multimodal interaction module to enhance the accuracy and robustness of the VideoQA model. Finally, extensive experiments on three benchmark datasets demonstrate the superiority of our proposed MSHCL compared with stat-of-the-art methods. (c) 2023 Elsevier Ltd. All rights reserved.
The mechanisms by which Candida glabrata resists host defense peptides and caspofungin are incompletely understood. To identify transcriptional regulators that enable C. glabrata to withstand these classes of stressors, a library of 215 C. glabrata transcriptional regulatory deletion mutants was screened for susceptibility to both protamine and caspofungin. We identified eight mutants that had increased susceptibility to both host defense peptides and caspofungin. Of these mutants, six were deleted for genes that were predicted to specify proteins involved in histone modification. These genes were ADA2, GCN5, SPT8, HOS2, RPD3, and SPP1. Deletion of ADA2, GCN5, and RPD3 also increased susceptibility to mammalian host defense peptides. The Delta ada2 and Delta gcn5 mutants had increased susceptibility to other stressors, such as H2O2 and SDS. In the Galleria mellonella model of disseminated infection, the Delta ada2 and Delta gcn5 mutants had attenuated virulence, whereas in neutropenic mice, the virulence of the Delta ada2 and Delta rpd3 mutants was decreased. Thus, histone modification plays a central role in enabling C. glabrata to survive host defense peptides and caspofungin, and Ada2 and Rpd3 are essential for the maximal virulence of this organism during disseminated infection.
The integration of advanced oxidation processes (AOPs) and catalytic membrane for filtration and peroxymonosulfate (PMS) activation was appealing for persistent organic pollutants removal. However, constructing a robust catalytic membrane with high reactivity and stability is highly desirable and still challenging. Herein, a kind of novel lawn-like Co3O4@nitrogen-doped carbon nanotube composites (Co3O4@NCNTs) by the pyrolysis of ZIF-67 in-situ grown on g-C3N4 was unprecedentedly designed, and then immobilized into protonated g-C3N4 (gCN) membrane to construct Co3O4@NCNTs/g-CN membrane by vacuum-assisted filtration, where active sites were completely exposed for oxidants and target pollutants. As expected, the degradation rate of sulfamethoxazole (SMX, 20 mg/L) in Co3O4@NCNTs-0.5 (0.01 g/L)/peroxymonosulfate (PMS, 0.2 g/L) system was 0.2224 min- 1, which was 35.9 times higher than that of Co3O4@NCs (0.0062 min- 1) derived from ZIF-67. Besides, it was found that the introduction of lawn-like Co3O4@NCNTs significantly improved the surface hydrophilicity of g-CN membrane, consequently, the permeation flux of the Co3O4@NCNTs/g-CN membrane showed a 16.7 folds increase. Ultimately, the synergistic degradation and filtration process of catalytic membrane not only exhibited superior catalytic and self-cleaning property in humic acid (HA)/SMX coexistence system, but also significantly reduced the leaching concentration of Co2+ (0.016 mg/L) after 5 runs compared to that of Co3O4@NCs/PMS system (0.041 mg/L), demonstrating improved stability and reusability. Furthermore. scavenger experiments and electron paramagnetic resonance (EPR) tests verified that the SMX degradation was dominated for the coexistence of multiple reactive active species (ROS, SO4 center dot-, center dot OH and 1O2) while 1O2 was a major contributor. Overall, this work offered new prospects in developing novel catalytic self-cleaning membrane.
Since COVID-19 emerged in 2019, significant levels of suffering and disruption have been caused on a glo-bal scale. Although vaccines have become widely used, the virus has shown its potential for evading immunities or acquiring other novel characteristics. Whether current drug treatments are still effective for people infected with Omicron remains unclear. Due to the long development cycles and high expense requirements of de novo drug development, many researchers have turned to consider drug repositioning in the search to find effective treatments for COVID-19. Here, we review such drug repositioning and combination efforts towards providing better handling. For potential drugs under consideration, aspects of both structure and function require attention, with specific categories of sequence, expression, struc-ture, and interaction, the key parameters for investigation. For different data types, we show the corre-sponding differing drug repositioning methods that have been exploited. As incorporating drug combinations can increase therapeutic efficacy and reduce toxicity, we also review computational strate-gies to reveal drug combination potential. Taken together, we found that graph theory and neural net-work were the most used strategy with high potential towards drug repositioning for COVID-19. Integrating different levels of data may further improve the success rate of drug repositioning. (c) 2022 The Author(s). Published by Elsevier B.V. on behalf of Research Network of Computational and Structural Biotechnology. This is an open access article under the CC BY-NC-ND license (http://creative-commons.org/licenses/by-nc-nd/4.0/).
Recently, deep learning (DL) has enabled rapid advancements in electrocardiogram (ECG)-based automatic cardiovascular disease (CVD) diagnosis. Multi-lead ECG signals have lead systems based on the potential differences between electrodes placed on the limbs and the chest. When applying DL models, ECG signals are usually treated as synchronized signals arranged in Euclidean space, which is the abstraction and generalization of real space. However, conventional DL models typically merely focus on temporal features when analyzing Euclidean data. These approaches ignore the spatial relationships of different leads, which are physiologically significant and useful for CVD diagnosis because different leads represent activities of specific heart regions. These relationships derived from spatial distributions of electrodes can be conveniently created in non-Euclidean data, making multi-lead ECGs better conform to their nature. Considering graph convolutional network (GCN) adept at analyzing non-Euclidean data, a novel spatial-temporal residual GCN for CVD diagnosis is proposed in this work. ECG signals are firstly divided into single-channel patches and transferred into nodes, which will be connected by spatial-temporal connections. The proposed model employs residual GCN blocks and feed-forward networks to alleviate over-smoothing and over-fitting. Moreover, residual connections and patch dividing enable the capture of global and detailed spatial-temporal features. Experimental results reveal that the proposed model achieves at least a 5.85% and 6.80% increase in F-1 over other state-of-the-art algorithms with similar parameters and computations in both PTB-XL and Chapman databases. It indicates that the proposed model provides a promising avenue for intelligent diagnosis with limited computing resources.
Mesh is a type of data structure commonly used for 3-D shapes. Representation learning for 3-D meshes is essential in many computer vision and graphics applications. The recent success of convolutional neural networks (CNNs) for structured data (e.g., images) suggests the value of adapting insights from CNN for 3-D shapes. However, 3-D shape data are irregular since each node's neighbors are unordered. Various graph neural networks for 3-D shapes have been developed with isotropic filters or predefined local coordinate systems to overcome the node inconsistency on graphs. However, isotropic filters or predefined local coordinate systems limit the representation power. In this article, we propose a local structure-aware anisotropic convolutional operation (LSA-Conv) that learns adaptive weighting matrices for each template's node according to its neighboring structure and performs shared anisotropic filters. In fact, the learnable weighting matrix is similar to the attention matrix in the random synthesizer--a new Transformer model for natural language processing (NLP). Since the learnable weighting matrices require large amounts of parameters for high-resolution 3-D shapes, we introduce a matrix factorization technique to notably reduce the parameter size, denoted as LSA-small. Furthermore, a residual connection with a linear transformation is introduced to improve the performance of our LSA-Conv. Comprehensive experiments demonstrate that our model produces significant improvement in 3-D shape reconstruction compared to state-of-the-art methods.
The stilbenoid pathway is responsible for the production of resveratrol in grapevine (Vitis vinifera L.). A few transcription factors (TFs) have been identified as regulators of this pathway but the extent of this control has not been deeply studied. Here we show how DNA affinity purification sequencing (DAP-Seq) allows for the genome-wide TF-binding site interrogation in grape. We obtained 5190 and 4443 binding events assigned to 4041 and 3626 genes for MYB14 and MYB15, respectively (approximately 40% of peaks located within -10 kb of transcription start sites). DAP-Seq of MYB14/MYB15 was combined with aggregate gene co-expression networks (GCNs) built from more than 1400 transcriptomic datasets from leaves, fruits, and flowers to narrow down bound genes to a set of high confidence targets. The analysis of MYB14, MYB15, and MYB13, a third uncharacterized member of Subgroup 2 (S2), showed that in addition to the few previously known stilbene synthase (STS) targets, these regulators bind to 30 of 47 STS family genes. Moreover, all three MYBs bind to several PAL, C4H, and 4CL genes, in addition to shikimate pathway genes, the WRKY03 stilbenoid co-regulator and resveratrol-modifying gene candidates among which ROMT2-3 were validated enzymatically. A high proportion of DAP-Seq bound genes were induced in the activated transcriptomes of transient MYB15-overexpressing grapevine leaves, validating our methodological approach for delimiting TF targets. Overall, Subgroup 2 R2R3-MYBs appear to play a key role in binding and directly regulating several primary and secondary metabolic steps leading to an increased flux towards stilbenoid production. The integration of DAP-Seq and reciprocal GCNs offers a rapid framework for gene function characterization using genome-wide approaches in the context of non-model plant species and stands up as a valid first approach for identifying gene regulatory networks of specialized metabolism.
Dietary phytochemicals are currently being studied with great interest due to their ability to regulate the epigenome resulting in prevention of cancer. Some natural botanicals have been reported to have enhanced and synergistic impact on cancer suppression when administered at optimum concentrations and in-conjunction. Sulforaphane (SFN) is an isothiocyanate found in cruciferous vegetables and sodium butyrate (NaB) is a short chain fatty acid produced by gut microbiota. They have been intensively explored due to numerous anti cancerous properties and ability to modulate epigenetic machinery by inhibition of histone deacetylase (HDAC). Genistein (GE), present in soy, is a known DNA methyltransferase (DNMT) inhibitor. While combined chemoprotective epigenetic effects induced by SFN and GE have been investigated, the key impact of combinatorial SFN-NaB, GE-NaB, and SFN-GE-NaB bioactive components in regulation of various mechanisms are poorly defined. In the present study, we found that combinations of dietary compounds had synergistic effects in decreasing cellular viability at lower dosages than their single dosages in breast cancer cell lines. The respective combinations limited growth and increased apoptosis and necrosis in cancerous cells among which the tricombination displayed the most significant impact. Additionally, the respective combinations of compounds arrested MDA-MB-231 and MCF-7 breast cancer cells at G2/M phase. Our further mechanistic evaluation revealed that respective di-combinations and tri-combination had higher impact in down-regulation of DNMTs (DNMT3A and DNMT3B), HDACs (HDAC1, HDAC6 and HDAC11), histone methyltransferases (EZH2 and SUV39H1) and histone acetyltransferases (GCN5, PCAF, P300 and CBP) levels as compared to singly administered compounds. We also found that these combinations exhibited global epigenetic changes by inhibition of DNMT and HDAC activity, histone H3 at lysine 27 methylation (H3K27me) and histone H3 at lysine 9 methylation (H3K9me) levels, and by induction of histone acetyltransferases activity. Collectively, our investigation indicates that combined SFN, GE and NaB is highly effective in inhibiting breast cancer genesis by, at least in part, regulating epigenetic modifications, which may have implications in breast cancer therapy.
Graphitic carbon nitride (g-CN), as a nonmetal semiconductor material, has been widely used in various fields, such as photocatalysis, electrocatalysis, batteries, light-emitting diodes, and solar cells, owing to its unique electronic and photophysical properties. However, the application of g-CN in practical devices remains limited because of the difficulties in fabricating g-CN films of high quality. In this work, we report a method for preparing a g-CN film with high optical quality on a substrate of indium tin oxide (ITO) glass and/or soda lime (NaCa) glass by using melamine as a precursor. First, we prepared the bulk g-CN from melamine in a muffle furnace via thermal polymerization. Then, we fabricated the g-CN film on the ITO and/or NaCa glass substrate with fine-milled, bulk g-CN in a tube furnace using thermal vapor deposition. With this two-step method, a yellow, transparent g-CN film with high optical quality was successfully fabricated on both the ITO and/or NaCa glass substrates. To check the quality of the film, we used scanning electron microscopy (SEM) to study the morphology of the fabricated gCN film on the ITO glass substrate. Both the high-resolution and low-resolution SEM image results show that the obtained g-CN film on the ITO glass substrate had a homogeneous and dense structure without a corrugated surface, illustrating that it had good surface roughness. Then, we investigated the thickness and surface roughness of the g-CN film via atomic force microscopy (AFM). The AFM results show that the thickness of the g-CN film deposited on the ITO glass substrate was around 300 nm and that the surface roughness of the g-CN film deposited on the ITO glass substrate was less than 40 nm. To verify the chemical composition of the obtained g-CN film on the ITO glass substrate, we performed X-ray photoelectron spectroscopy (XPS) and energy-dispersive spectroscopy (EDS) analyses. Both the XPS and EDS results demonstrate that the chemical composition of the g-CN film deposited on the ITO glass substrate was similar to that of bulk g-CN powder. More importantly, we determined the band structure for the g-CN film deposited on the ITO glass substrate by using a combination of steady-state absorption and high-resolution valence band XPS analysis. It was found that the determined band structure for the g-CN film deposited on the ITO glass substrate was close to that of bulk g-CN powder, also indicating that its chemical composition was similar to that of bulk g-CN. Meanwhile, we also found that the prepared g-CN film on the ITO glass substrate effectively degraded methylene blue dye under Xe lamp irradiation, which was similar to the effect of bulk g-CN powder. All analyses performed demonstrate that the two-step method presented in this study could successfully fabricate a g-CN film with high optical quality. In addition, we also analyzed the fluorescence lifetime of the g-CN film deposited on the ITO glass substrate by using a homemade time-correlated single-photon counting apparatus and found that it was much shorter than that of bulk g-CN.
A series of complex transport, storage and regulation mechanisms control iron metabolism and thereby maintain iron homeostasis in plants. Despite several studies on iron deficiency responses in different plant species, these mechanisms remain unclear in the allohexaploid wheat, which is the most widely cultivated commercial crop. We used RNA sequencing to reveal transcriptomic changes in the wheat flag leaves and roots, when subjected to iron limited conditions. We identified 5969 and 2591 differentially expressed genes (DEGs) in the flag leaves and roots, respectively. Genes involved in the synthesis of iron ligands i.e., nicotianamine (NA) and deoxymugineic acid (DMA) were significantly up-regulated during iron deficiency. In total, 337 and 635 genes encoding transporters exhibited altered expression in roots and flag leaves, respectively. Several genes related to MAJOR FACILITATOR SUPERFAMILY (MFS), ATP-BINDING CASSETTE (ABC) transporter superfamily, NATURAL RESISTANCE ASSOCIATED MACROPHAGE PROTEIN (NRAMP) family and OLIGOPEPTIDE TRANSPORTER (OPT) family were regulated, indicating their important roles in combating iron deficiency stress. Among the regulatory factors, the genes encoding for transcription factors of BASIC HELIX-LOOP-HELIX (bHLH) family were highly up-regulated in both roots and the flag leaves. The jasmonate biosynthesis pathway was significantly altered but with notable expression differences between roots and flag leaves. Homoeologs expression and induction bias analysis revealed subgenome specific differential expression. Our findings provide an integrated overview on regulated molecular processes in response to iron deficiency stress in wheat. This information could potentially serve as a guideline for breeding iron deficiency stress tolerant crops as well as for designing appropriate wheat iron biofortification strategies. (C) 2020 The Author(s). Published by Elsevier B.V. on behalf of Research Network of Computational and Structural Biotechnology.
Background: The LA hybrid lily Aladdin' has both excellent traits of Longiflorum hybrids and Asiatic hybridssuch as big and vivid flower, strong stem, high self-propagation coefficient, and shorter low temperature time required to release bulb dormancy in contrast to Oriental hybrids. A genome-wide transcriptional analysis using transcriptome RNA-Seq was performed in order to explore whether there is a gibberellin floral induction pathway in the LA hybrid lily. Subsequently, gene co-expression network analysis was used to analyze the possible interactions of key candidate genes screened from transcriptome data. At the same time, a series of physiological, biochemical, and cultivation tests were carried out. Results: The content of five endogenous hormones changed sharply in the shoot apex during the treatment of 200 mg/L exogenous gibberellin and the ratio of ABA/GA(3) dropped and stayed at a lower level after 4 hours' treatment from the higher levels initially, reaching a dynamic balance. In addition, the metabolism of carbohydrates in the bulbs increase during exogenous gibberellin treatment. A total of 124,041 unigenes were obtained by RNA-seq. With the transcriptome analysis, 48,927 unigenes and 48,725 unigenes respectively aligned to the NR database and the Uniprot database. 114,138 unigenes, 25,369 unigenes, and 19,704 unigenes respectively aligned to the COG, GO, and KEGG databases. 2148 differentially expression genes (DEGs) were selected with the indicators RPKM 0, FDR 0.05 and |log2(ratio)| 2. The number of the upregulated unigenes was significantly more than the number of the downregulated unigenes. Some MADS-box genes related to flowering transformationsuch as AGL20, SOC1, and COwere found to be upregulated. A large number of gibberellin biosynthesis related genes such as GA2ox, GA3ox, GA20ox, Cytochrome P450, CYP81, and gibberellin signal transduction genes such as DELLA, GASA, and GID1 were significantly differentially expressed. The plant hormones related genes such as NCED3 and sugar metabolism related genes such as -amylase, sucrose synthase hexokinase, and so on were also found expressing differentially. In addition, stress resistance related genes such as LEA1, LEA2, LEA4, serine/threonine protein kinase, LRR receptor-like serine/threonine protein kinase, P34 kinase, histidine kinase 3 and epigenetic related genes in DNA methylation, histone methylation, acetylation, ubiquitination of ribose were also found. Particularly, a large number of transcription factors responsive to the exogenous gibberellin signal including WRKY40, WRKY33, WRKY27, WRKY21, WRKY7, MYB, AP2/EREBP, bHLH, NAC1, NAC2, and NAC11 were found to be specially expressing. 30 gene sequences were selected from a large number of differentially expressed candidate genes for qRT-PCR expression verification (0, 2, 4, 8, and 16 h) and compared with the transcriptome expression levels. Conclusions: 200mg/L exogenous GA(3) can successfully break the bulb's dormancy of the LA hybrid lily and significantly accelerated the flowering process, indicating that gibberellin floral induction pathway is present in the LA lily Aladdin'. With the GCNs analysis, two second messenger G protein-coupled receptor related genes that respond to gibberellin signals in the cell were discovered. The downstream transport proteins such as AMT, calcium transport ATPase, and plasma membrane ATPase were also discovered participating in GA signal transduction. Transcription factors including WRKY7, NAC2, NAC11, and CBF specially regulated phosphorylation and glycosylation during the ubiquitination degradation process of DELLA proteins. These transcription factors also activated in abscisic acid metabolism. A large number of transcription factors such as WRKY21, WRKY22, NAC1, AP2, EREB1, P450, and CYP81 that both regulate gibberellin signaling and low-temperature signals have also been found. Finally, the molecular mechanism of GA floral induction pathway in the LA hybrid lily Aladdin' was constructed.
Background The prognostic value of preoperative systemic inflammatory markers, including the neutrophil-to-lymphocyte ratio (NLR), platelet-to-lymphocyte ratio (PLR), and lymphocyte-to-monocyte ratio (LMR), remains controversial in patients with intrahepatic cholangiocarcinoma (ICC). Therefore, this meta-analysis aimed to investigate the prognostic value of preoperative NLR, PLR, and LMR in patients with ICC who underwent hepatic resection. Methods We conducted a comprehensive search of four electronic databases. Two researchers assessed the quality of the available data using the Newcastle-Ottawa Scale. We selected overall survival (OS) as the primary outcome and recurrence-free survival (RFS) and disease-free survival (DFS) as secondary outcomes. Hazard ratios (HRs) and 95% confidence intervals (CIs) were merged to evaluate the associations between inflammatory markers and ICC patient prognosis. Results Fifteen studies (18 cohorts) with 4123 cases were included in this meta-analysis. The results revealed that a high preoperative NLR was associated with short OS and RFS (HR = 1.04, 95% CI: 1.01-1.07, and HR = 1.29, 95% CI: 1.04-1.60, respectively) in patients with ICC. However, the association between PLR or LMR and ICC prognosis was not statistically significant. In addition, the publication bias and sensitivity analyses demonstrated that the results were reliable and stable. Conclusion Our meta-analysis revealed that preoperative NLR may be a useful prognostic predictor for patients with ICC.
Background. Combined aerobic and resistance training has been demonstrated to benefit glycemic control and reverse nonalcoholic fatty liver disease in childhood obesity. General control nonderepressible 2 (GCN2) deficiency has been reported to attenuate hepatic steatosis and insulin resistance. However, whether GCN2 impacts the positive effects of combined aerobic and resistance exercise remains unknown. Objectives. To investigate whether combined aerobic and resistance exercise improves hepatic steatosis and glucose intolerance and the role GCN2 plays in mediating the metabolic regulation of exercise. Methods. Wild-type (WT) and GCN2 knockout (GCN2KO) mice were fed a high-fat diet (HFD) for 25 weeks. The WT and GCN2KO mice performed exercise (treadmill running + ladder climbing) during the last eight weeks. Their body and liver weights, their triglyceride content, and their levels of aspartate transaminase (AST), alanine transaminase (ALT), and blood glucose were measured, and the expressions of proteins involved in the GCN2/eIF2 alpha/ATF4 pathway and the glucolipid metabolism-related proteins (e.g., p-AMPK, SIRT1, PPAR alpha, PGC-1 alpha, GLUT4, and p-GSK-3 beta) were determined. Results. The body weight of WT and GCN2KO mice continued to increase until the end of the experiment. The liver weights, hepatic triglyceride content, and AST and ALT levels of the exercised mice were significantly reduced compared to those of the sedentary mice. Exercise improved blood glucose levels and glucose clearance ability in the WT mice, but the glucose intolerance of GCN2KO mice was not improved. Exercise increased PGC-1 alpha, GLUT4, and p-GSK-3 beta expressions in the WT rather than the GCN2KO mice. Interestingly however, exercise-trained GCN2KO mice were better protected against hepatic steatosis with downregulated expressions of p-eIF2 alpha and ATF4, upregulated expressions of p-AMPK and SIRT1, and the presence of PPAR alpha in the liver, compared to the exercised WT mice. Conclusion. Combined aerobic and resistance exercise had positive effects on hepatic steatosis and the control of glucose intolerance. GCN2 was found to be necessary for exercise-induced improved glucose intolerance. However, the better efficacy in improving hepatic steatosis by exercise in the GCN2-deficient mice enhanced liver lipid metabolism, at least partially, via the AMPK/SIRT1/PPAR alpha pathway.
The integrated stress response in eukaryotic cells is an orchestrated pathway that leads to eukaryotic Initiation Factor 2 alpha subunit (eIF2 alpha) phosphorylation at ser51 and ultimately activates pathways to mitigate cellular damages. Three putative kinases (Tck1, Tck2, and Tck3) are found in the Trypanosoma cruzi genome, the flagellated parasite that causes Chagas disease. These kinases present similarities to other eukaryotic eIF2 alpha kinases, exhibiting a typical insertion loop in the kinase domain of the protein. We found that this insertion loop is conserved among kinase 1 of several T. cruzi strains but differs among various Kinetoplastidae species, suggesting unique roles. Kinase 1 is orthologous of GCN2 of several eukaryotes, which have been implicated in the eIF2 alpha ser51 phosphorylation in situations that mainly affects the nutrients levels. Therefore, we further investigated the responses to nutritional stress of T. cruzi devoid of TcK1 generated by CRISPR/Cas9 gene replacement. In nutrient-rich conditions, replicative T. cruzi epimastigotes depleted of TcK1 proliferate as wild type cells but showed increased levels of polysomes relative to monosomes. Upon nutritional deprivation, the polysomes decreased more than in TcK1 depleted line. However, eIF2 alpha is still phosphorylated in TcK1 depleted line, as in wild type parasites. eIF2 alpha phosphorylation increased at longer incubations times, but KO parasites showed less accumulation of ribonucleoprotein granules containing ATP-dependent RNA helicase involved in mRNA turnover (DHH1) and Poly-A binding protein (PABP1). Additionally, the formation of metacyclic-trypomastigotes is increased in the absence of Tck1 compared to controls. These metacyclics, as well as tissue culture trypomastigotes derived from the TcK1 knockout line, were less infective to mammalian host cells, although replicated faster inside mammalian cells. These results indicate that GCN2-like kinase in T. cruzi affects stress granule formation, independently of eIF2 alpha phosphorylation upon nutrient deprivation. It also modulates the fate of the parasites during differentiation, invasion, and intracellular proliferation.
Motivation: Evaluating the blood-brain barrier (BBB) permeability of drug molecules is a critical step in brain drug development. Traditional methods for the evaluation require complicated in vitro or in vivo testing. Alternatively, in silico predictions based on machine learning have proved to be a cost-efficient way to complement the in vitro and in vivo methods. However, the performance of the established models has been limited by their incapability of dealing with the interactions between drugs and proteins, which play an important role in the mechanism behind the BBB penetrating behaviors. To address this limitation, we employed the relational graph convolutional network (RGCN) to handle the drug-protein interactions as well as the properties of each individual drug. Results: The RGCN model achieved an overall accuracy of 0.872, an area under the receiver operating characteristic (AUROC) of 0.919 and an area under the precision-recall curve (AUPRC) of 0.838 for the testing dataset with the drug-protein interactions and the Mordred descriptors as the input. Introducing drug-drug similarity to connect structurally similar drugs in the data graph further improved the testing results, giving an overall accuracy of 0.876, an AUROC of 0.926 and an AUPRC of 0.865. In particular, the RGCN model was found to greatly outperform the LightGBM base model when evaluated with the drugs whose BBB penetration was dependent on drug-protein interactions. Our model is expected to provide high-confidence predictions of BBB permeability for drug prioritization in the experimental screening of BBB-penetrating drugs.
In this trial, nine diets were formulated to investigate the effects of DL-methionine (DL-Met) and a methionine hydroxy analogue (MHA-Ca) on growth, amino acid profiles and the expression of genes related to taurine and protein synthesis in common carp. The basal diet was prepared without methionine supplementation and the other diets were formulated with 0.1%, 0.2%, 0.3% and 0.4% of DL-Met or MHA-Ca, respectively. After the eight-week feeding trial, fish fed with DL-Met or MHA-Ca supplemented diets had higher growth performance and feed utilization when compared with basal diet and two-way ANOVA showed the growth performance and feed utilization were significantly increased in fish fed DL-Met supplemented diets (P < 0.05). The concentrations of free amino acids in serum (Met, Leu, His, Lys, Val, Arg, Ile, Phe and Tau) and muscle (Tau) significantly increased as dietary DL-Met and MHA-Ca increased. Moreover, two-way ANOVA showed that taurine was higher in common carp fed with DL-Met diets compared with MHA-Ca diets. To find out how DL-Met and MHA-Ca affect taurine synthesis, genes involved in methionine degradation and taurine synthesis were further investigated. DL-Met or MHA-Ca supplementation decreased the expression of methionine adenosyltransferase II, alpha (MAT2A) and methionine synthase (MS) and increased the expression of the cysteine dioxygenase (CDO). Moreover, DL-Met supplementation significantly increased the expression of CDO and cysteine sulfinate acid decarboxylase (CSD) when compared with MHA-Ca supplementation. As for protein synthesis, the mRNA expression of mechanistic target of rapamycin (mTOR) in liver was not significantly different among all diet groups. But the expression of eukaryotic translation initiation factor 4E-Binding protein 1 (4EBP1), general control nonderepressible2 (GCN2) and asparagine synthetase (ASNS) in liver were significantly down-regulated as dietary DL-Met or MHA-Ca increased. Compared with MHA-Ca diets, the expression of S6 (ribosomal protein s6) and eIF4E (eukaryotic translation initiation factor 4E binding protein 2) were markedly elevated in DL-Met groups by the analysis of two-way ANOVA. This study indicated that dietary DL-Met or MHACa supplement could increase free essential amino acids in serum, as well as improve taurine synthesis and protein synthesis in common carp. Multi-exponential regression analysis showed that MHA-Ca was less utilized by common carp than DL-Met with bioavailability values of 41% to 50% on weight-for-weight basis.
The exopolysaccharide galactosaminogalactan (GAG) plays an important role in mediating adhesion, biofilm formation, and virulence in the pathogenic fungus Aspergillus fumigatus. Previous work showed that in A. fumigatus, the Lim domain-binding protein PtaB can form a complex with the sequence-specific transcription factor SomA for regulating GAG biosynthesis, biofilm formation, and asexual development. However, transcriptional coactivators required for biofilm formation in A. fumigatus remain uncharacterized. In this study, Spt20, an orthologue of the subunit of the Saccharomyces cerevisiae transcriptional coactivator Spt-Ada-Gcn5-acetyltransferase (SAGA) complex, was identified as a regulator of biofilm formation and asexual development in A. fumigatus. The loss of spt20 caused severe defects in the GAG biosynthesis, biofilm formation, conidiation, and virulence of A. fumigatus. RNA sequence data demonstrated that Spt20 positively regulates the expression of the GAG biosynthesis genes uge3 and agd3, the developmental regulator medA, and genes involved in the conidiation pathway. Moreover, more than 10 subunits of the SAGA complex (known from yeast) could be immunoprecipitated with Spt20, suggesting that Spt20 acts as a structural subunit of the SAGA complex. Furthermore, distinct modules of SAGA regulate GAG biosynthesis, biofilm formation, and asexual development in A. fumigatus to various degrees. In summary, the novel biofilm regulator Spt20 is reported, which plays a crucial role in the regulation of fungal asexual development, GAG biosynthesis, and virulence in A. fumigatus. These findings expand knowledge on the regulatory circuits of the SAGA complex relevant for the biofilm formation and asexual development of A. fumigatus. IMPORTANCE Eukaryotic transcription is regulated by a large number of proteins, ranging from sequence-specific DNA-binding factors to transcriptional coactivators (chromatin regulators and the general transcription machinery) and their regulators. Previous research indicated that the sequence-specific complex SomA/PtaB regulates the biofilm formation and asexual development of Aspergillus fumigatus. However, transcriptional coactivators working with sequence-specific transcription factors to regulate A. fumigatus biofilm formation remain uncharacterized. In this study, Spt20, an orthologue of the subunit of the Saccharomyces cerevisiae Spt-Ada-Gcn5-acetyltransferase (SAGA) complex, was identified as a novel regulator of biofilm formation and asexual development in A. fumigatus. The loss of spt20 caused severe defects in galactosaminogalactan (GAG) production, conidiation, and virulence. Moreover, nearly all modules of the SAGA complex were required for the biofilm formation and asexual development of A. fumigatus. These results establish the SAGA complex as a transcriptional coactivator required for the biofilm formation and asexual development of A. fumigatus.
Annotating object boundaries by humans demands high costs. Recently, polygon-based annotation methods with human interaction have shown successful performance. However, given the connected vertex topology, these methods exhibit difficulty predicting the disconnected components in an object. This article introduces Split-GCN, a novel architecture based on the polygon approach and self-attention mechanism. By offering the direction information, Split-GCN enables the polygon's vertices to move more precisely to the object boundary. Our model successfully predicts disconnected components of an object by transforming the initial topology using the context exchange about the dependencies of vertices. Split-GCN demonstrates competitive performance with the state-of-the-art models on Cityscapes and even higher performance with the baseline models. On four cross-domain datasets, we confirm our model's generalization ability.
Recently, graph convolutional network (GCN) has been widely used in hyperspectral image (HSI) classification due to its satisfactory performance. However, the number of labeled pixels is very limited in HSI, and thus, the available supervision information is usually insufficient, which will inevitably degrade the representation ability of most existing GCN-based methods. To enhance the feature representation ability, in this article, a GCN model with contrastive learning is proposed to explore the supervision signals contained in both spectral information and spatial relations, which is termed contrastive GCN (ConGCN), for HSI classification. First, in order to mine sufficient supervision signals from spectral information, a semisupervised contrastive loss function is utilized to maximize the agreement between different views of the same node or the nodes from the same land cover category. Second, to extract the precious yet implicit spatial relations in HSI, a graph generative loss function is leveraged to explore supplementary supervision signals contained in the graph topology. In addition, an adaptive graph augmentation technique is designed to flexibly incorporate the spectral-spatial priors of HSI, which helps facilitate the subsequent contrastive representation learning. The extensive experimental results on six typical benchmark datasets firmly demonstrate the effectiveness of the proposed ConGCN in both qualitative and quantitative aspects.
Cross-Domain Few-Shot Learning (CD-FSL) to recognize new categories in a new domain with few samples has attracted significant attention. Recently, task-specific CD-FSL emerges as promising research for its great generalization. However, the existing task-specific CD-FSL methods are not robust enough in task context modeling and task-specific feature learning, especially under the cross-domain setting. To tackle this problem, a Task Context Transformer and Graph Convolutional Network (TCT-GCN) method for CD-FSL is proposed. The proposed TCT-GCN constructs three modules: 1) Multi-Level Feature Fusion, which fuses domain-shared low-level features into domain-unshared high-level features; 2) Transformer-based Task Context Encoder, which models sample order-independent task context; 3) Graph Convolutional Network-based Adaptive Feature Learner, which adaptively learns task-specific features. Experiments on eight CD-FSL datasets reveal the effectiveness of our TCT-GCN. & COPY; 2023 Elsevier B.V. All rights reserved.
The growth of the Internet of Things makes it possible to share information on risky vehicles openly and freely. How to create dynamic knowledge graphs of continually changing risky vehicles has emerged as a crucial technology for identifying risky vehicles, as well as a research hotspot in both artificial intelligence and field knowledge graphs. The node information of the risky vehicle knowledge graph is not rich, and the graph structure plays a major role in its dynamic changes. The paper presents a fusion algorithm based on relational graph convolutional network (R-GCN) and Long Short-Term Memory (LSTM) to build the dynamic knowledge graph of risky vehicles and conducts a comparative experiment on the link prediction task. The results showed that the fusion algorithm based on R-GCN and LSTM had better performance than the other methods such as GCN, DynGEM, ROLAND, and RE-GCN, with the MAP value of 0.2746 and the MRR value of 0.1075. To further verify the proposed algorithm, classification experiments are carried out on the risky vehicle dataset. Accuracy, precision, recall, and F-values were used as heat-tolerance evaluation indexes in classification experiments, the values were 0.667, 0.034, 0.422, and 0.52 respectively.
Solar-driven seawater electrolysis for hydrogen fuel production holds an outstanding potential towards the development of a carbon-neutral and sustainable energy infrastructure, but the development of green, efficient and stable photoelectrocatalysts selectively promoting oxygen evolution remains a formidable challenge. Motivated by this issue, in this work we propose a tailored combination of two economically viable materials, alpha-Fe2O3 and graphitic carbon nitride (gCN), to fabricate promising anodes - eventually decorated with cobalt phosphate (CoPi) particles - for alkaline seawater photosplitting. The target systems were fabricated via an original multi-step route, involving the plasma-enhanced chemical vapor deposition of iron(iii) oxide on conducting glasses, the introduction of gCN in very small amounts by a rapid and facile electrophoretic process, and final annealing in air. A comprehensive characterization revealed the successful fabrication of composites featuring a tailored surface defectivity, a controlled nano-organization, and a close Fe2O3/gCN interfacial contact. After decoration with CoPi, the best performances corresponded to a Tafel slope of approximate to 100 mV dec-1 and overpotential values enabling us to rule out the competitive hypochlorite formation. In addition, photocurrent densities at 1.23 V vs. RHE showed a nearly 7-fold increase upon Fe2O3 functionalization with both gCN and CoPi. These amenable results, directly dependent on the electronic interplay at Fe2O3/gCN heterojunctions and on CoPi beneficial effects, are accompanied by a remarkable long-term stability, and may open up attractive avenues for clean energy production using natural resources. Sunlight-assisted seawater splitting can be successfully driven by specifically designed, cost-effective and eco-friendly Fe2O3-gCN electrocatalysts.
In this study, we aimed to develop an efficient photocatalyst utilizing a nanocomposite of silicon dioxide (SiO2) and graphitic carbon nitride (GCN) for the treatment of highly concentrated printing and dyeing wastewater. The nanocomposite of SiO2 and graphitic carbon nitride (GCN) was synthesized using a simple ultrasonic and solvothermal method. The SiO2/GCN nanocomposite demonstrated superior photocatalytic performance, efficiently degrading rhodamine B (RhB) at both low (20 mg L-1) and ultra-high concentrations (300 mg L-1). The catalyst exhibited effective charge separation, with SiO2 acting as an electron trap to suppress electron-hole recombination. Optimized synthesis conditions were achieved by adjusting the hydrothermal temperature and time. The SiO2/GCN nanocomposite showed good cycling stability, making it suitable for practical applications. To the best of our knowledge, this is the first time that photodegradation of RhB at a concentration of 300 mg L-1 has been achieved without relying on adsorbent materials. Therefore, this work contributes to the design and development of innovative environmentally-friendly photocatalysts for the effective degradation of highly concentrated pollutants.
Probabilistic analysis tool is important to quantify the impacts of the uncertainties on power system operations. However, the repetitive calculations of power flow are time-consuming. To address this issue, data-driven approaches are proposed but they are not robust to the uncertain injections and varying topology. This article proposes a model-driven graph convolution neural network (MD-GCN) for power flow calculation with high-computational efficiency and good robustness to topology changes. Compared with the basic graph convolution neural network (GCN), the construction of MD-GCN considers the physical connection relationships among different nodes. This is achieved by embedding the linearized power flow model into the layer-wise propagation. Such a structure enhances the interpretability of the network forward propagation. To ensure that enough features are extracted in MD-GCN, a new input feature construction method with multiple neighborhood aggregations and a global pooling layer are developed. This allows us to integrate both global features and neighborhood features, yielding the complete features representation of the system-wide impacts on every single node. Numerical results on the IEEE 30-bus, 57-bus, 118-bus, and 1354-bus systems demonstrate that the proposed method achieves much better performance as compared to other approaches in the presence of uncertain power injections and system topology.
Learning hidden topics from data streams has become absolutely necessary but posed challenging problems such as concept drift as well as short and noisy data. Using prior knowledge to enrich a topic model is one of potential solutions to cope with these challenges. Prior knowledge that is derived from human knowledge (e.g. Wordnet) or a pre-trained model (e.g. Word2vec) is very valuable and useful to help topic models work better. However, in a streaming environment where data arrives continually and infinitely, existing studies are limited to exploiting these resources effectively. Especially, a knowledge graph, that contains meaningful word relations, is ignored. In this paper, to aim at exploiting a knowledge graph effectively, we propose a novel graph convolutional topic model (GCTM) which integrates graph convolutional networks (GCN) into a topic model and a learning method which learns the networks and the topic model simultaneously for data streams. In each minibatch, our method not only can exploit an external knowledge graph but also can balance the external and old knowledge to perform well on new data. We conduct extensive experiments to evaluate our method with both a human knowledge graph (Wordnet) and a graph built from pre-trained word embeddings (Word2vec). The experimental results show that our method achieves significantly better performances than state-of-the-art baselines in terms of probabilistic predictive measure and topic coherence. In particular, our method can work well when dealing with short texts as well as concept drift. (c) 2021 Elsevier B.V. All rights reserved.
Underwater glider (UG) plays an important role in ocean observation and exploration for a more efficient and deeper understanding of complex ocean environment. Timely identifying the motion states of UG is conducive for timely attitude adjustment and detection of potential anomalies, thereby improving the working reliability of UG. Combining limited penetrable visibility graph (LPVG) and graph convolutional networks (GCN) with self-attention mechanisms, we propose a novel method for motion states identification of UG, which is called as visibility graph and self-attention mechanism-based graph convolutional network (VGSA-GCN). Based on the actual sea trial data of UG, we chose the attitude angle signals of motion states related sensors collected by the control system of UG as the research object and constructed complex networks based on the LPVG method from pitch angle, roll angle, and heading angle data in diving and climbing states. Then, we build a self-attention mechanism-based GCN framework and classify the graphs under different motion states constructed by a complex network. Compared with support vector machines, convolutional neural network, and GCN without self-attention pooling layer, the proposed VGSA-GCN method can more accurately distinguish the diving and climbing states of UG. Subsequently, we analyze the variation of the transitivity coefficient corresponding to these two motion states. The results suggest that the coordination of the various sensors in the attitude adjustment unit during diving becomes closer and more efficient, which corresponds to the higher network measure of the diving state compared to the climbing state.
Quality assessment of omnidirectional images has become increasingly urgent due to the rapid growth of virtual reality applications. Different from traditional 2D images and videos, omnidirectional contents can provide consumers with freely changeable viewports and a larger field of view covering the 360 degrees x 180 degrees spherical surface, which makes the objective quality assessment of omnidirectional images more challenging. In this paper, motivated by the characteristics of the human vision system (HVS) and the viewing process of omnidirectional contents, we propose a novel Viewport oriented Graph Convolution Network (VGCN) for blind omnidirectional image quality assessment (IQA). Generally, observers tend to give the subjective rating of a 360-degree image after passing and aggregating different viewports information when browsing the spherical scenery. Therefore, in order to model the mutual dependency of viewports in the omnidirectional image, we build a spatial viewport graph. Specifically, the graph nodes are first defined with selected viewports with higher probabilities to be seen, which is inspired by the HVS that human beings are more sensitive to structural information. Then, these nodes are connected by spatial relations to capture interactions among them. Finally, reasoning on the proposed graph is performed via graph convolutional networks. Moreover, we simultaneously obtain global quality using the entire omnidirectional image without viewport sampling to boost the performance according to the viewing experience. Experimental results demonstrate that our proposed model outperforms state-of-the-art full-reference and no-reference IQA metrics on two public omnidirectional IQA databases.
Now-a-days since number of vehicles are growing day by day on the roads in urban and metropolitan area, hence traffic jam is becoming very common problem which everyone is facing time to time. So it becomes very crucial to forecast traffic to avoid the regular traffic congestion situation in daily life. In today's intelligent traffic system, reliable and precise traffic forecasting in metropolitan road networks is critical. Many models based on classical methods have been presented to address this; however, they lag in certain circumstances, failing to incorporate spatial and temporal dependency in the environment. As a result, this research aims to solve the geographical and temporal dependency problem that plagues most traffic forecasting models. Graph Convolution Network (GCN) and Gated Recurrent Unit (GRU) are employed in conjunction with an attention-based model for more accurate traffic forecasts in cities. A combined model called Spatio-Temporal Attention-based Model with GCN and GRU (ST AGG) is employed to anticipate traffic. ST-AGG model mainly focuses on extracting the relevant information from all the input given to the attention-based model. The spatial dependency is determined by using GCN and the temporal dependency is determined by using GRU, used in the ST-AGG model. It assists in short-term traffic forecasting as well as long-term traffic forecasting. The results demonstrate that the suggested ST AGG has properly predicted the volume of traffic on city roadways in real time with greater accuracy. The model depicts how traffic is influenced by geography and time. The Shen Zhen (SZ) car dataset from China and the Los Angeles (LAS) dataset from California are used to test the suggested model. And the result shows that Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) have reduced by up to 2.7% less, and accuracy has increased by 2.7% more compared to the previous model ST GCN for the SZ vehicle dataset. Similarly, although the accuracy has not changed significantly for the Loss Angeles data set, RMSE and MAE have reduced by 3.71% less as compared to the previous ST GCN model. The proposed model is more effective than the prior models like GCN, GRU, and ST GCN.
Deep neural networks have revolutionized many machine learning tasks in power systems, ranging from pattern recognition to signal processing. The data in these tasks are typically represented in Euclidean domains. Nevertheless, there is an increasing number of applications in power systems, where data are collected from non-Euclidean domains and represented as graph-structured data with high-dimensional features and interdependency among nodes. The complexity of graph-structured data has brought significant challenges to the existing deep neural networks defined in Euclidean domains. Recently, many publications generalizing deep neural networks for graph-structured data in power systems have emerged. In this paper, a comprehensive overview of graph neural networks (GNNs) in power systems is proposed. Specifically, several classical paradigms of GNN structures, e.g., graph convolutional networks, are summarized. Key applications in power systems such as fault scenario application, time-series prediction, power flow calculation, and data generation are reviewed in detail. Furthermore, main issues and some research trends about the applications of GNNs in power systems are discussed.
Flight delays pose a worldwide challenge that significantly affect the safety and efficiency of air transportation systems. However, propagated delay prediction, as well as its causality among airport delay propagation net-works, has not considered some crucial issues regarding spatiotemporal dependence and propagation relation-ships. Thus, this study proposes a transport causality knowledge-guided extended graph convolutional network (GCN) framework to tackle these issues. In particular, a causality knowledge-guided airport delay propagation network (ADPN) is developed using the second modified transfer entropy (SMTE) principle. Furthermore, a causality-embedded adjacency matrix is utilized by an extended GCN for propagated delay prediction. Comprehensive validations and results indicate that the proposed method benefits significantly from the cau-sality knowledge, and increases the prediction performances up to 15.51%. Thus, transport causality is signifi-cant and efficient for understanding propagated delay features and airport delay propagation network characteristics.
Personality recognition is a classic and important problem in social engineering. Due to the small number and particularity of personality recognition databases, only limited research has explored convolutional neural networks for this task. In this paper, we explore the use of graph convolutional network techniques for inferring a user's personality traits from their Facebook status updates or essay information. Since the basic five personality traits (such as openness) and their aspects (such as status information) are related to a wide range of text features, this work takes the Big Five personality model as the core of the study. We construct a single user personality graph for the corpus based on user-document relations, document-word relations, and word co-occurrence and then learn the personality graph convolutional networks (personality GCN) for the user. The parameters or the inputs of our personality GCN are initialized with a one-hot representation for users, words and documents; then, under the supervision of users and documents with known class labels, it jointly learns the embeddings for users, words, and documents. We used feature information sharing to incorporate the correlation between the five personality traits into personality recognition to perfect the personality GCN. Our experimental results on two public and authoritative benchmark datasets show that the general personality GCN without any external word embeddings or knowledge is superior to the state-of-the-art methods for personality recognition. The personality GCN method is efficient on small datasets, and the average F1-score and accuracy of personality recognition are improved by up to approximately 3.6% and 2.4-2.57%, respectively.
The widespread application of surfactants and their subsequent discharge in the receiving water bodies is a very common issue in developing countries. In the present investigation, a composite of graphitic carbon nitride (GCN) and TiO2 was used as a photo-electro-catalyst in a microbial fuel cell (MFC)-based hybrid system for bio-electricity production and simultaneous pollutant removal (organic matter and sodium dodecyl sulphate, SDS). The GCN: TiO2 composite with a ratio of 70:30 (by wt. %) revealed a better electrochemical response; thus, it was used as a photo- electro- catalyst in MFC. Additionally, the photochemical characterization indicated a decrease in the band gap and charge recombination of GCN-TiO2 composite compared to standalone TiO2, which indicated a conducive effect of GCN addition. Further, on the actual use as a photoelectro-catalyst, the GCN-TiO2 catalysed MFC attained 58.2 +/- 9.6% and 86.5 +/- 7.1% of COD and SDS removal; while simultaneously harvesting a maximum power density of 1.07 W m(-3), which was higher than standalone TiO2- catalysed MFC. The follow-up treatment in the charcoal bio-filter and photo-cathodic chamber of the hybrid system further improved the overall COD and SDS removal efficiency to 92.1 +/- 2.7 and 95.6 +/- 1.5%, respectively. The electro-catalytic performance of the GCN-TiO2 can be attributed to the presence of nitrogen-active species in the composite. The results of this investigation demonstrated a potential MFC-based hybrid system for the simultaneous secondary and tertiary treatment of municipal wastewater. Consequently, the outcome of this investigation indicates an innovative research direction in the field of photoelectro-catalyst, which can fit into the role of a photo-catalyst as well as an electro-catalyst.
Introduction: Graph-based representations are becoming more common in the medical domain, where each node defines a patient, and the edges signify associations between patients, relating individuals with disease and symptoms in a node classification task. In this study, a Graph Convolutional Networks (GCN) model was utilized to capture differences in neurocognitive, genetic, and brain atrophy patterns that can predict cognitive status, ranging from Normal Cognition (NC) to Mild Cognitive Impairment (MCI) and Alzheimer's Disease (AD), on the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. Elucidating model predictions is vital in medical applications to promote clinical adoption and establish physician trust. Therefore, we introduce a decomposition-based explanation method for individual patient classification. Methods: Our method involves analyzing the output variations resulting from decomposing input values, which allows us to determine the degree of impact on the prediction. Through this process, we gain insight into how each feature from various modalities, both at the individual and group levels, contributes to the diagnostic result. Given that graph data contains critical information in edges, we studied relational data by silencing all the edges of a particular class, thereby obtaining explanations at the neighborhood level. Results: Our functional evaluation showed that the explanations remain stable with minor changes in input values, specifically for edge weights exceeding 0.80. Additionally, our comparative analysis against SHAP values yielded comparable results with significantly reduced computational time. To further validate the model's explanations, we conducted a survey study with 11 domain experts. The majority (71%) of the responses confirmed the correctness of the explanations, with a rating of above six on a 10-point scale for the understandability of the explanations. Discussion: Strategies to overcome perceived limitations, such as the GCN's overreliance on demographic information, were discussed to facilitate future adoption into clinical practice and gain clinicians' trust as a diagnostic decision support system.
We present a computational methodology for the screening of a chemical space of 10(25) substituted norbornadiene molecules for promising kinetically stable molecular solar thermal (MOST) energy storage systems with high energy densities that absorb in the visible part of the solar spectrum. We use semiempirical tight-binding methods to construct a dataset of nearly 34 000 molecules and train graph convolutional networks to predict energy densities, kinetic stability, and absorption spectra and then use the models together with a genetic algorithm to search the chemical space for promising MOST energy storage systems. We identify 15 kinetically stable molecules, five of which have energy densities greater than 0.45 MJ/kg, and the main conclusion of this study is that the largest energy density that can be obtained for a single norbornadiene moiety with the substituents considered here, while maintaining a long half-life and absorption in the visible spectrum, is around 0.55 MJ/kg.
Graph convolutional neural networks have aroused more and more attentions on account of the ability to handle the graph-structured data defined on irregular or non-Euclidean domains. Different from the data defined on regular grids, each node in the graph-structured data has different number of neighbors, and the interactions and correlations between nodes vary at different locations, resulting in complex graph structure. However, the existing graph convolutional neural networks generally pay little attention to exploiting the graph structure information. Moreover, most existing graph convolutional neural networks employ the weight sharing strategy which lies on the statistical assumption of stationarity. This assumption is not always verified on the graph-structured data. To address these issues, we propose a method that learns Graph Structure via graph Convolutional Networks (GSCN), which introduces the graph structure parameters measuring the correlation degrees of adjacent nodes. The graph structure parameters are constantly modified the graph structure during the training phase and will help the filters of the proposed method to focus on the relevant nodes in each neighborhood. Meanwhile by combining the graph structure parameters and kernel weights, our method, which relaxes the restriction of weight sharing, is better to handle the graph-structured data of non-stationarity. In addition, the non-linear activation function ReLU and the sparse constraint are employed on the graph structure parameters to promote GSCN to focus on the important links and filter out the insignificant links in each neighborhood. Experiments on various tasks, including text categorization, molecular activity detection, traffic forecasting and skeleton-based action recognition, illustrate the validity of our method. (C) 2019 Elsevier Ltd. All rights reserved.
The primary goal of aspect-based sentiment analysis is to identify sentiment polarity concerning the given aspect in a sentence. Recent investigations have demonstrated the superior performance of graph convolutional neural network (GCN) on dependency parsing tree. However, these GCN-based models fail to take the given aspect into account when calculating the hidden node representation vector, as well as lack exploration of contextual commonsense knowledge. On the contrary, the gating mechanism enables the interaction of the context and the given aspect to enhance the impact of the given aspect on the context. Nevertheless, such interactions are frequently inadequate resulting in insufficient extraction of sentiment information. This paper proposes a dualgated graph convolutional network via contextual affective knowledge (DGGCN) to address these issues. The core idea is to incorporate GCN into the gating mechanism to enhance GCN to fully aggregate node information while strengthening the concentration on the given aspect. Simultaneously, the incorporation of contextual affective knowledge into graph networks can refine the perception of affective features. Experimental findings on five benchmark datasets reveal that our proposed DGGCN surpasses state-of-the-art methods.
Recently, graph convolutional networks (GCNs) has attracted wide attention on the wetland classification with limited samples. However, traditional approaches of superpixel generation rely on artificial experience and the spatial information is ignored during the construction of graph structure, which limits the classification performance. To address these problems, a feature-guided dynamic graph convolutional network (FG-DGCN) is proposed for wetland classification. First, a learnable superpixel generation module is proposed to generate adaptive superpixel boundaries, which composed of a pixel-wise feature enhancement block and a superpixel generation block. The former is utilized to improve the discrimination of features and the latter is applied to adjust the representation of superpixels by training. Second, a feature-guided adjacency matrix update mechanism is designed to dynamically capture and fuse the spectral and spatial correlations of graph nodes, promoting the aggregation of neighborhood information. Finally, the features are differentially projected back to the pixel space for wetland classification. Experiments on three wetland datasets demonstrate the superiority of FG-DGCN over state-of-the-art methods.
In the recent years, the emotion recognition task has attracted a lot of attention in the field of human- computer interaction. Most existing research typically uses aural-visual analysis, which has been an effective approach to capturing emotional features. However, aural-visual signals are difficult to notice, in comparison to other human representations such as gait in remote situations. Recently, human gait can be effectively recognized in more complex backgrounds because of the advancement of Graph Convolutional Networks (GCNs). According to the anatomy of the human body, central torso joints play a key role in GCNs-based human gait recognition systems, instead of the body's marginal limb joints. As a result, there is a major issue of receptive field imbalance. In this study, we propose a method for perceiv-ing emotions based on the human gait skeleton. We present a multi-head pseudo nodes strategy to alle-viate the receptive field imbalance problem and capture the non-local dependencies among different joints. The strategy employs a series of extra nodes that link to all physical human body joints and obtain global information from different feature spaces. The results of the experiments on a public emotion-gait dataset demonstrate that our proposed method outperforms existing skeleton-based methods. Further, to verify the effectiveness of our method, we use publicly available human action recognition datasets. Our results show that our method significantly improves performance in comparison to other baseline methods.(c) 2022 Elsevier B.V. All rights reserved.
Detecting low cognitive scores at an early stage is important for delaying the progress of dementia. Investigations of early-stage detection have employed automatic assessment using dual-task (i.e., performing two different tasks simultaneously). However, current approaches to dual-task-based detection are based on either simple features or limited motion information, which degrades the detection accuracy. To address this problem, we proposed a framework that uses graph convolutional networks to extract spatio-temporal features from dual-task performance data. Moreover, to make the proposed method robust against data imbalance, we devised a loss function that directly optimizes the summation of the sensitivity and specificity of the detection of low cognitive scores (i.e., score≤ 23 or score≤ 27). Our evaluation is based on 171 subjects from 6 different senior citizens' facilities. Our experimental results demonstrated that the proposed algorithm considerably outperforms the previous standard with respect to both the sensitivity and specificity of the detection of low cognitive scores.
Skeleton-based action recognition is a widely used task in action related research because of its clear features and the invariance of human appearances and illumination. Furthermore, it can also effectively improve the robustness of the action recognition. Graph convolutional networks have been implemented on those skeletal data to recognize actions. Recent studies have shown that the graph convolutional neural network works well in the action recognition task using spatial and temporal features of skeleton data. The prevalent methods to extract the spatial and temporal features purely rely on a deep network to learn from primitive 3D position. In this paper, we propose a novel action recognition method applying high-order spatial and temporal features from skeleton data, such as velocity features, acceleration features, and relative distance between 3D joints. Meanwhile, a method of multi-stream feature fusion is adopted to fuse these high-order features we proposed. Extensive experiments on Two large and challenging datasets, NTU-RGBD and NTU-RGBD-120, indicate that our model achieves the state-of-the-art performance.
Graph convolutional networks (GCNs) and network embedding are the two main categories of popular methods for Semi-Supervised Node Classification (SSNC) in social network. However, the former is commonly oriented to attributed networks with efficient auxiliary information in nodes. The latter is usually not geared towards specific graph mining tasks. Therefore, these methods often perform poorly for specific tasks in non-attributed networks. To solve the above problems, in this paper, we propose a novel semi-supervised Node Classification method with Ladder Neural Networks named NCLNN for non-attributed network. We first preprocess the graph for capturing the structural information. Then we present and learn a deep ladder neural network for SSNC. Our trained ladder neural networks could combine supervised learning with unsupervised learning in deep neural networks via simultaneously minimizing the sum of supervised and unsupervised loss functions. Extensive experiments on three real-world network datasets demonstrate that the proposed NCLNN substantially outperforms the state-of-the-art methods on SSNC task.
Feature vectors, graph convolutional network, low-grade glioma, self-attention, similarity coefficient
Graph Convolutional Networks (GCNs) have achieved much success in various graph learning tasks. However, as the number of layers increases, the smoothing of GCNs will over-mix the neighbors' information, leading output towards space with low expressivity. It is known as the over-smoothing issue. Although several works have refined deep GCNs by optimizing network structure, receptive field, and topology, the over-smoothing issue cannot be completely avoided. In this paper, we propose a recurrent neural network framework for learning graph representation while avoiding over-smoothing effectively, which is the tree-structure aggregation and optimization framework named Treeago. Treeago firstly transforms the irregularly distributed graph into sequential trees. Then, Treeago adopts Tree-LSTM with attention to aggregate important neighbors' feature information to the graph representation. Tree-LSTM with attention can prevent the mixing of noise neighbors' information to avoid the over-smoothing issue. Finally, Treeago uses an edge pruning optimization framework based on reinforcement learning to enhance the model's performance further. Experimental results on multiple real-world datasets show that Treeago effectively avoids over-smoothing and yields state-of-the-art results. (c) 2022 Elsevier B.V. All rights reserved.
Graph convolutional network is now an effective tool to deal with non-Euclidean data, such as social behavior analysis, molecular structure analysis, and skeleton-based action recognition. Graph convolutional kernel is one of the most significant factors in graph convolutional networks to extract nodes' feature, and some variants of it have achieved highly satisfactory performance theoretically and experimentally. However, there was limited research about how exactly different graph structures influence the performance of these kernels. Some existing methods used an adaptive convolutional kernel to deal with a given graph structure, which still not explore the internal reasons. In this paper, we start from theoretical analysis of the spectral graph and study the properties of existing graph convolutional kernels, revealing the selfsmoothing phenomenon and its effect in specific structured graphs. After that, we propose the Poisson kernel that can avoid self-smoothing without training any adaptive kernel. Experimental results demonstrate that our Poisson kernel not only works well on the benchmark datasets where state-of-the-art methods work fine, but also is evidently superior to them in synthetic datasets. (c) 2021 Elsevier Ltd. All rights reserved.
Classification of polarimetric synthetic aperture radar (PolSAR) images has achieved good results due to the excellent fitting ability of neural networks with a large number of training samples. However, the performance of most convolutional neural networks (CNNs) degrades dramatically when only a few labeled training samples are available. As one well-known class of semi-supervised learning methods, graph convolutional networks (GCNs) have gained much attention recently to address the classification problem with only a few labeled samples. As the number of layers grows in the network, the parameters dramatically increase. It is challenging to determine an optimal architecture manually. In this paper, we propose a neural architecture search method based GCN (ASGCN) for the classification of PolSAR images. We construct a novel graph whose nodes combines both the physical features and spatial relations between pixels or samples to represent the image. Then we build a new searching space whose components are empirically selected from some graph neural networks for architecture search and develop the differentiable architecture search method to construction our ASGCN. Moreover, to address the training of large-scale images, we present a new weighted mini-batch algorithm to reduce the computing memory consumption and ensure the balance of sample distribution, and also analyze and compare with other similar training strategies. Experiments on several real-world PolSAR datasets show that our method has improved the overall accuracy as much as 3.76% than state-of-the-art methods.
We propose a novel framework for computing descriptors for characterizing points on three-dimensional surfaces. First, we present a new non-learned feature that uses graph wavelets to decompose the Dirichlet energy on a surface. We call this new feature Wavelet Energy Decomposition Signature (WEDS). Second, we propose a new Multiscale Graph Convolutional Network (MGCN) to transform a non-learned feature to a more discriminative descriptor. Our results show that the new descriptor WEDS is more discriminative than the current state-of-the-art non-learned descriptors and that the combination of WEDS and MGCN is better than the state-of-the-art learned descriptors. An important design criterion for our descriptor is the robustness to different surface discretizations including triangulations with varying numbers of vertices. Our results demonstrate that previous graph convolutional networks significantly overlit to a particular resolution or even a particular triangulation, but MGCN generalizes well to different surface discretizations. In addition, MGCN is compatible with previous descriptors and it can also be used to improve the performance of other descriptors, such as the heat kernel signature, the wave kernel signature, or the local point signature.
Text classification is an important task in natural language processing, and most of the recent approaches employ neural networks to learn and classify the texts. RNN and CNN based models, which are widely used for solving the task, involve reading and processing the text in a sequential manner. This creates inefficiency in learning dependencies between far-apart words. On the contrary, Graph Convolutional Network (GCN) architecture is capable of processing more complex graph-structured data, thus having potential to recognize and learn from complex linguistic structures.In the present work, we transform text sequences into graphs by assigning each word in the text as a node and representing the relationship between words as edges. We then propose a method for solving text classification that uses recent GCN architectures to take the transformed text-graph as input, learn hidden representations, and output a single hidden representation for classification. In our experiments, our proposed model outperformed RNN and CNN based models with regards to various text classification tasks.
This work investigates proactive edge caching for device-to-device (D2D)-assisted wireless networks, where user equipment (UE) can be selected as caching nodes to assist content delivery to reduce the content transmission latency. In doing so, there are two challenges: 1) how to precisely get the user's preference to cache the proper contents at UEs and 2) how to replace the contents cached at UEs when there are new popular contents emerging. To address these, we develop a user preference learning-based proactive edge caching (UPL-PEC) strategy. In the strategy, we first propose a novel context and social-aware user preference learning method to precisely predict user's dynamic preferences by jointly exploiting the context correlation among different contents, the influence of social relationships and the time-sequential patterns of user's content requests. Specifically, the bidirectional long short-term memory networks are adopted to capture the time-sequential patterns of the user's content requests. And, the graph convolutional networks are developed to capture the high-order similarity representation among different contents from the constructed content graph. To learn the social influence representation, an attention mechanism is designed to generate the social influence weights to users with different social relationship. Based on the learned user preference, a proactive edge caching architecture is proposed to integrate the offline caching content placement and the online caching content replacement policy to continuously cache the popular contents at UEs. Simulation results show that the proposed UPL-PEC strategy outperforms the existing similar caching strategies at about 3.13%-4.62% in terms of the average content transmission latency.
The results of aerial scene classification can provide valuable information for urban planning and land monitoring. In this specific field, there are always a number of object-level semantic classes in big remote-sensing pictures. Complex label-space makes it hard to detect all the targets and perceive corresponding semantics in the typical scene, thereby weakening the sensing ability. Even worse, the preparation of a labeled dataset for the training of deep networks is more difficult due to multiple labels. In order to mine object-level visual features and make good use of label dependency, we propose a novel framework in this article, namely a Cross-Modal Representation Learning and Label Graph Mining-based Residual Multi-Attentional CNN-LSTM framework (CM-GM framework). In this framework, a residual multi-attentional convolutional neural network is developed to extract object-level image features. Moreover, semantic labels are embedded by language model and then form a label graph which can be further mapped by advanced graph convolutional networks (GCN). With these cross-modal feature representations (image, graph and text), object-level visual features will be enhanced and aligned to GCN-based label embeddings. After that, aligned visual signals are fed into a bi-LSTM subnetwork according to the built label graph. The CM-GM framework is able to map both visual features and graph-based label representations into a correlated space appropriately, using label dependency efficiently, thus improving the LSTM predictor's ability. Experimental results show that the proposed CM-GM framework is able to achieve higher accuracy on many multi-label benchmark datasets in remote sensing field.
Spatial information regarding the arrangement of land cover objects plays an important role in distinguishing the land use types at land parcel or local neighborhood levels. This study investigates the use of graph convolutional networks (GCNs) in order to characterize spatial arrangement features for land use classification from high resolution remote sensing images, with particular interest in comparing land use classifications between different graph-based methods and between different remote sensing images. We examine three kinds of graph-based methods, i.e., feature engineering, graph kernels, and GCNs. Based upon the extracted arrangement features and features regarding the spatial composition of land cover objects, we formulated ten land use classifications. We tested those on two different remote sensing images, which were acquired from GaoFen-2 (with a spatial resolution of 0.8 m) and ZiYuan-3 (of 2.5 m) satellites in 2020 on Fuzhou City, China. Our results showed that land use classifications that are based on the arrangement features derived from GCNs achieved the highest classification accuracy than using graph kernels and handcrafted graph features for both images. We also found that the contribution to separating land use types by arrangement features varies between GaoFen-2 and ZiYuan-3 images, due to the difference in the spatial resolution. This study offers a set of approaches for effectively mapping land use types from (very) high resolution satellite images.
Aiming at the lack of effective quantitative model to support the analysis of terrorist attacks, a multilayer depth Neural network (NN) Graph convolutional networks (GCN) model (NNGCN) was put forward to realize the classification and early warning of terrorist attacks. The proposed model optimized the traditional GCN with the help of complex NN. The concept of link index was introduced into the NNGCN model. It is combined with the important information between event nodes. The information includes the similarity of events and link probability. Compared with the original unoptimized model, the improved model increased the classification accuracy of terrorist attacks. Because the model uses the node's feature information and the link relationship of graph structure, it can also warn the sudden terrorist attacks effectively.
Providing timely rescue when a fall occurs can greatly reduce fall mortality for older people. With the growing number of single-resided elders, real-time smart fall incident detection has become a new research hotspot. Accuracy, computational complexity and real-time response are key issues to be solved in this topic. A fall detection model that combines an improved Spatial-Temporal Graph Convolutional Network (ST-GCN) with the BlazePose algorithm is proposed in this paper. The computational speed is improved by removing four redundant layers from the ST-GCN network. Meanwhile, an attention mechanism focussing on the key joints involved in the falling action and their correlation is applied in the model, which introduces an Effective SE Block (ESE Block) to the residual structure of ST-GCN. It is achieved by fusing the original features with channel attention weights obtained by global average pooling and fully connected operations for the joint features. The BlazePose algorithm of the mediapipe framework is used to recognise human targets and locate the spatial coordinates of specific joints. Then the spatiotemporal graph features of the human body are extracted by the improved ST-GCN from the temporal and spatial displacements of 30 consecutive frames. Furthermore, fall behaviour is judged by the action type defined by the spatiotemporal graph. The accuracy of the proposed model for public datasets, such as Le2i Fall, Multicam Fall and UR Fall, is 99.29%, 99.22% and 98.64% respectively, which are higher than the Alphapose + ST-GCN model by 9.04%, 20% and 25.2%. Such accuracy is even better than the existing best algorithms by 0.89%, 0.92% and 1.04%. When running on the i5-10200H CPU and the Jetson Nano edge computing device, the Alphapose + ST-GCN model achieves frame rates of 11.42fps and 1.5fps, whilst the frame rates of this paper are up to 24.5fps and 9.37fps. The experimental results fully show that based on BlazePose with the improved ST-GCN makes the fall detection model higher accuracy, faster speed, real-time performance and high compatibility with the Jetson Nano edge computing device.
Aspect-level sentiment analysis (ALSA) is the process of collecting, processing, analyzing, inferring, and synthesizing subjective sentiments of entities contained in texts at the aspect level. The development of social networks has been driven by the on-going appearance of vast numbers of short documents, such as those in which opinions are expressed and comments are made. The text in these documents reflects users' emotions related to entities. The ALSA of these short texts plays an important role in solving various problems in life. Particularly in e-commerce, manufacturers can use sentiment analysis to determine users' orientations, adapt their products to perfection, identify potential users, and pinpoint users that influence other users. Therefore, improving the performance of ALSA methods has recently attracted the interest of researchers. Currently, four main types of ALSA methods are available: knowledge-based, machine learning-based, hybrid-based, and most recently, graph convolutional network (GCN)-based. This study is the first survey to focus on reviewing the proposed methods for ALSA using GCN methods. In this paper, we propose a novel taxonomy to divide GCN-based ALSA models into three categories based on the types of knowledge extraction. We present and compare GCN-based ALSA methods following our taxonomy comprehensively. Common benchmark datasets and text representations that are often used in GCN-based methods are also discussed. In addition, we discuss five challenges and suggest seven future research directions for GCN-based ALSA methods. The findings of our survey are expected to provide the necessary guidelines for beginners, practitioners, and new researchers to improve the performance of ALSA methods.
We report the fabrication of bismuth oxybromide/bismuth oxyiodide coupled to graphitic carbon nitride heterojunctions via a simple hydrothermal method to circumvent fast recombination of photogenerated charge carriers of pure BiOX. The obtained BiOxBry/BiOmIn/GCN with varied ratios and synthetic conditions were stable and achieved significant enhancement in visible-light driven catalytic activities for degradation of crystal violet and 2-hydroxybenzoic acid. BB2I1-200-7-10%GCN heterojunction also showed selective reduction of carbon dioxide to methane under UV-vis irradiation with 0.018 mu mol/g.h yield. The photocatalytic mechanism and major active species in crystal violet decomposition by BiOxBry/BiOmIn/GCN were investigated and proposed.
To combat cybercrimes and maintain financial security for the blockchain ecosystem", know your customer" (KYC) is an essential and also challenging process due to the pseudonymity nature of blockchain technology. To unlock the potential of KYC on blockchain-based platforms like Ethereum, account labeling is a powerful means which can de-anonymize addresses by mining public transaction records. Existing studies on account labeling are mainly conducted via machine learning (ML) methods fed with hand-crafted features or graph neural networks based on the modeled transaction network. However, ML approaches based on hand-crafted features ignore the global interaction information between accounts, making it easy for criminals to evade detection. Moreover, the performance of traditional GCN methods when applied to Ethereum transaction network encounters limitations due to label sparsity, network heterophily, and large network size of the transaction network. In this article, we first analyze Ethereum accounts involved in typical businesses, in terms of both account and topological features. Then based on the analytical results, we propose a novel GCN method named know-your-customer graph convolutional network (KYC-GCN) which contains two key designs: 1) multihop aggregators and importance-based sampling are designed to tackle the dilemma between accuracy and efficiency. 2) GCN architecture is improved to explicitly capture local and more global information. Experimental results on a realistic Ethereum dataset show that the proposed KYC-GCN (90.2% accuracy, 86.2% Marco-F1) achieves state-of-the-art classification performance, and results on six benchmarks demonstrate that it yields great performance under homophily and heterophily.
Graph convolutional neural network (GCN) has drawn increasing attention and attained good perfor-mance in various computer vision tasks, however, there is a lack of a clear interpretation of GCN's inner mechanism. For standard convolutional neural networks (CNNs), class activation mapping (CAM) meth-ods are commonly used to visualize the connection between CNN's decision and image region by gener-ating a heatmap. Nonetheless, such heatmap usually exhibits semantic-chaos when these CAMs are applied to GCN directly. In this paper, we proposed a novel visualization method particularly applicable to GCN, Vertex Semantic Class Activation Mapping (VS-CAM). VS-CAM includes two independent pipeli-nes to produce a set of semantic-probe maps and a semantic-base map, respectively. Semantic-probe maps are used to detect the semantic information from the semantic-base map to aggregate a semantic-aware heatmap. Qualitative results show that VS-CAM can obtain heatmaps where the high-lighted regions match the objects much more precisely than CNN-based CAM. The quantitative evalua-tion further demonstrates the superiority of VS-CAM.(c) 2023 Elsevier B.V. All rights reserved.
Graph convolutional network (GCN) is an effective tool for feature clustering. However, in the text classification task, the traditional TextGCN (GCN for Text Classification) ignores the context word order of the text. In addition, TextGCN constructs the text graph only according to the context relationship, so it is difficult for the word nodes to learn an effective semantic representation. Based on this, this paper proposes a text classification method that combines Transformer and GCN. To improve the semantic accuracy of word node features, we add a part of speech (POS) to the word-document graph and build edges between words based on POS. In the layer-to-layer of GCN, the Transformer is used to extract the contextual and sequential information of the text. We conducted the experiment on five representative datasets. The results show that our method can effectively improve the accuracy of text classification and is better than the comparison method.
Predicting terrorism risk is crucial for formulating detailed counter-strategies. However, this task is challenging mainly because the risk of the concerned potential victim is not isolated. Terrorism risk has a spatiotemporal interprovincial contagious characteristic. The risk diffusion mechanism comes from three possibilities: cross-provincial terrorist attacks, internal and external echoes, and internal self-excitation. This study proposed a novel spatiotemporal graph convolutional network (STGCN)-based extension method to capture the complex and multidimensional non-Euclidean relationships between different provinces and forecast the daily risks. Specifically, three graph structures were constructed to represent the contagious process between provinces: the distance graph, the province-level root cause similarity graph, and the self-excited graph. The long short-term memory and self-attention layers were extended to STGCN for capturing context-dependent temporal characters. At the same time, the one-dimensional convolutional neural network kernel with the gated linear unit inside the classical STGCN can model single-node-dependent temporal features, and the spectral graph convolution modules can capture spatial features. The experimental results on Afghanistan terrorist attack data from 2005 to 2020 demonstrate the effectiveness of the proposed extended STGCN method compared to other machine learning prediction models. Furthermore, the results illustrate the crucial of capturing comprehensive spatiotemporal correlation characters among provinces. Based on this, this article provides counter-terrorism management insights on addressing the long-term root causes of terrorism risk and performing short-term situational prevention.
Computing the similarity between graphs is a longstanding and challenging problem with many real-world applications. Recent years have witnessed a rapid increase in neural-network-based methods, which project graphs into embedding space and devise end-to-end frameworks to learn to estimate graph similarity. Nevertheless, these solutions usually design complicated networks to capture the fine-grained interactions between graphs, and hence have low efficiency. Additionally, they rely on labeled data for training the neural networks and overlook the useful information hidden in the graphs themselves. To address the aforementioned issues, in this work, we put forward a contrastive neural graph similarity learning framework, Conga. Specifically, we utilize vanilla graph convolutional networks to generate the graph representations and capture the cross-graph interactions via a simple multilayer perceptron. We further devise an unsupervised contrastive loss to discriminate the graph embeddings and guide the training process by learning more expressive entity representations. Extensive experiment results on public datasets validate that our proposal has more robust performance and higher efficiency compared with state-of-the-art methods.
Network Slice placement with the problem of allocation of resources from a virtualized substrate network is an optimization problem which can be formulated as a multi-objective Integer Linear Programming (ILP) problem. However, to cope with the complexity of such a continuous task and seeking for optimality and automation, the use of Machine Learning (ML) techniques appear as a promising approach. We introduce a hybrid placement solution based on Deep Reinforcement Learning (DRL) and a dedicated optimization heuristic based on the "Power of Two Choices" principle. The DRL algorithm uses the so-called Asynchronous Advantage Actor Critic (A3C) algorithm for fast learning, and Graph Convolutional Networks (GCN) to automate feature extraction from the physical substrate network. The proposed Heuristically-Assisted DRL (HA-DRL) allows for the acceleration of the learning process and substantial gain in resource usage when compared against other state-of-the-art approaches, as evidenced by evaluation results.
In recent years, graph convolutional networks (GCNs) have been extensively applied in numerous fields, demonstrating strong performances. Although existing GCN-based models have extraordinary feature representation capabilities in spatial modeling and perform exceptionally well in skeleton-based action recognition, they work poorly for fine-grained recognition. The key issue involves tiny distinctions between multiple classes. To address this issue, we propose a novel module named the topology-embedded temporal attention module (TE-TAM). Through embedding the temporal-different topology modeled with local area skeleton points in spatial and temporal dimensions, the TE-TAM achieves dynamical attention learning for the temporal dimensions of distinct data samples, to capture minor differences among intra-frames and inter-frames, making the characteristics more discriminating, and increasing the distances between various classes. To verify the validity of the proposed module, we inserted the module into the GCN-based models and tested them on FSD-30. Experimental results show that the GCN-based models with TE-TAMs outperformed the property of pred GCN-based models.
Generative Artificial Intelligence can be an important asset in the drug discovery process to meet the demand for novel medicines. This work outlines the optimization and fine-tuning steps of MedGAN, a deep learning model based on Wasserstein Generative Adversarial Networks and Graph Convolutional Networks, developed to generate new quinoline-scaffold molecules from complex molecular graphs, including hyperparameter adjustments and evaluations of drug-likeness attributes such as pharmacokinetics, toxicity, and synthetic accessibility. The best model was capable of generating 25% valid molecules, 62% fully connected, from which 92% were quinolines, 93% were novel, and 95% unique, preserving chirality, atom charge, and favorable drug-like properties while generating 4831 novel quinolines. These results provide valuable insights into how activation functions, optimizers, learning rates, neuron units, molecule size and constitution, and scaffold structure affect the performance of generative models and their potential to create new molecular structures, enhancing deep learning applications in computational drug design.
The pressure prediction technology whereby represents the rock pressure law in the excavation is fundamental to safety in production and industrial intelligentization. A growing number of researchers dedicate that machine learning is used to accurate prediction of underground pressure changes. However, the existing research which based on the classical machine learning rarely considers the cause between inducement of underground pressure and the underground pressure change. In this paper, we propose a novel Reinforced and Causal Graph Neural Network, namely RC-GNN, for the prediction task, to overcome the shortage of causal logic. First, we build a causal graph by considering internal relations between inducement and display of pressure and employ prior knowledge to erect the early and properties of the graph. Second, we construct the prediction network for underground pressure by graph convolutional networks and long short-term memory. Finally, we use the performance index of underground pressure prediction to design a reinforcement learning algorithm, which achieves optimization of the causal graph. Compared to six representative methods, experimental results with 18-60% increases in performance on the real prediction task.
In the case of limited energy, the waste of energy and economic loss caused by abnormal electricity consumption should not be underestimated and its detection plays an important role. However, abnormal electricity consumption detection also faces many challenges. On the one hand, labeled abnormal data are difficult to obtain. On the other hand, building different models for different users undoubtedly increases the demand for data and the burden of training. To tackle these challenges, in this paper, we propose a transfer learning based graph convolutional network with self-attention mechanism method to detect abnormal electricity consumption. With the help of transfer learning, we firstly pre-train the source domain network using the sufficient data. Then, a small amount of data in the target domain is utilized to fine-tune the pre-training model to get the final detection model. This can not only effectively alleviate the problem of insufficient data, but also reduce the training burden caused by building different models for different users. In addition, to improve the effect of feature extraction and enhance the performance of the network, we employ the self-attention mechanism to enhance the network's attention to different data information. Finally, we adopt the graph convolutional networks to discover the relationships of electricity consumption data among different moments and to classify the electricity consumption data. We have done detailed experiments to verify the effectiveness of the proposed method, and experimental results show that the proposed method is effective and robust. (c) 2023 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
Human action recognition has a wide range of applications, including Ambient Intelligence systems and user assistance. Starting from the recognized actions performed by the user, a better human-computer interaction can be achieved, and improved assistance can be provided by social robots in real-time scenarios. In this context, the performance of the prediction system is a key aspect. The purpose of this paper is to introduce a neural network approach based on various types of convolutional layers that can achieve a good performance in recognizing actions but with a high inference speed. The experimental results show that our solution, based on a combination of graph convolutional networks (GCN) and temporal convolutional networks (TCN), is a suitable approach that reaches the proposed goal. In addition to the neural network model, we design a pipeline that contains two stages for obtaining relevant geometric features, data augmentation and data preprocessing, also contributing to an increased performance.
Weather recognition is a significant technique for many potential computer vision applications in our daily lives. Generally, most existing works treat weather recognition as a single-label classification task, which cannot describe the weather conditions comprehensively due to the complex co-occurrence dependencies between different weather conditions. In this paper, we propose a novel Graph Convolution Networks with Attention (GCN-A) model for multi-label weather recognition. To our best knowledge, this is the first attempt to introduce GCN into weather recognition. Specifically, we employ GCN to capture weather co-occurrence dependencies via a directed graph. The graph is built over weather labels, where each node (weather label) is represented by word embeddings of a weather label. Furthermore, we design a re-weighted mechanism to build weather correlation matrix for information propagation among different nodes in GCN. In addition, we develop a channel-wise attention module to extract informative semantic features of weather for effective model training. Compared with the state-of-the-art methods, experiment results on two widely used benchmark datasets demonstrate that our proposed GCN-A model achieves promising performance.
With the continuous development of technology and networks, real-life interactions are gradually being abstracted into social networks for study. Social circles are a fundamental structural feature that is prevalent on social networks. Thus, exploring social circle structure plays an important role in revealing the characteristics of complex social networks and provides guidance for understanding social behavior in real life. For example, it can aid in precision marketing, personalized recommendation, and knowledge dissemination within social circles. One of the important means of identifying social network circles lies on community detection algorithms. However, real-world social networks are often dynamic and can be studied and analyzed by building dynamic networks, while existing dynamic network community detection methods tend to ignore the global structure information and time-series information of nodes. To address this problem, this paper proposes a dynamic network community detection algorithm based on graph convolutional neural networks and contrastive learning, which fully captures the adjacent characteristics between nodes based on the correlation information and leverages the feature smoothing strategy to efficiently extract node representations of dynamic networks under unsupervised scenario. Specifically, the proposed algorithm first utilizes node correlation based aggregation strategy to compute the feature matrix for single time-step of the dynamic network. Then, mutual information maximization is implemented based on cross-entropy between learned local and global representations. To reduce the computational overhead in the optimization process, an additional LSTM module is further equipped for updating the parameters of graph convolutional networks in each time-step. Additionally, a contrastive learning based network smoothing strategy is designed to minimize the feature differences between neighboring nodes. Comparative experiments demonstrate that the proposed algorithm achieves excellent performance on both synthetic and real networks.
Learning vector embeddings of users and items is the core of modern recommender systems. Recently the collaborative filtering recommender systems based on graph convolutional networks, which integrates the bipartite graph of user-item interaction into the embedding process, has achieved significant success. However, such feature as item-item interaction sequence is neglected in the bipartite graph, which limits the ability to model sequential orders for embedding of items. In this work, we propose a novel item-item interaction sequential graph to globally aggregate the hidden interactions sequence among all items. It is derived from the order of all user-item interactions and can give a supplement for user-item interaction modeling in CF. We also propose an item enhanced graph collaborative network (IEGCN) to mix item-item sequences with user-item interactions for collaborative filtering. We performed experiments on three open datasets, and IEGCN shows substantial improvements in recall and normalized discounted cumulative gain when compared with existing mainstream models. Further analysis verifies the importance of item-item sequence graph to improve the recommendation effect.
The halogen, bromine (Br) doped layered graphitic carbon nitride (gCN) nanosheets are constructed for a novel electrochemical detection of dopamine (DA). The Br is successfully immobilized in the gCN host lattice, in which Br provides an N-vacancy for -C-N bonding to improve electron transfer and enhance its electrocatalytic properties. The prepared nanosheets are studied by various analytical analyses and the electrochemical behavior of the designed electrode is studied using cyclic voltammetry (CV). The Br-gCN decorated screen-printed carbon electrode (SPCE) has superior electrochemical activity and is stable during exposure to varied pH, however, exhibited better catalytic activity at pH 7. The Br-gCN/SPEC electrodes and their high electrocatalytic performance are used for the detection of dopamine with a lower limit of detection (LoD) of 5 nM concentration. The Br-gCN decorated electrodes exhibited satisfactory results for cyclic stability (up to 100th cycle), repeatability (up to 6 cycles), reproducibility of similarly constructed 6 electrodes, and their electrochemical performance. Furthermore, the fabricated sensor also exhibited a better recovery (>80%) for real-time urine sample analyses.
In this paper, we propose a dynamic graph modeling approach to learn spatial-temporal representations for video summarization. Most existing video summarization methods extract image-level features with ImageNet pre-trained deep models. Differently, our method exploits object-level and relation-level information to capture spatial-temporal dependencies. Specifically, our method builds spatial graphs on the detected object proposals. Then, we construct a temporal graph by using the aggregated representations of spatial graphs. Afterward, we perform relational reasoning over spatial and temporal graphs with graph convolutional networks and extract spatial-temporal representations for importance score prediction and key shot selection. To eliminate relation clutters caused by densely connected nodes, we further design a self-attention edge pooling module, which disregards meaningless relations of graphs. We conduct extensive experiments on two popular benchmarks, including the SumMe and TVSum datasets. Experimental results demonstrate that the proposed method achieves superior performance against state-of-the-art video summarization methods.
Human video prediction is still a challenging problem due to the uncertainty of future actions and complexity of frame details. Recent methods tackle this problem in two steps: firstly to forecast future human poses from the initial ones, and then to generate realistic frames conditioned on predicted poses. Following this framework, we propose a novel Graph Convolutional Network (GCN) based pose predictor to comprehensively model human body joints and forcast their positions holistically, and also a stacked generative model with a temporal discriminator to iteratively refine the quality of the generated videos. The GCN based pose predictor fully considers the relationships among body joints and produces more plausible pose predictions. With the guidance of predicted poses, a temporal discriminator encodes temporal information into future frame generation to achieve high-quality results. Furthermore, stacked residual refinement generators make the results more realistic. Extensive experiments on benchmark datasets demonstrate that the proposed method produces better predictions than state-of-the-arts and achieves up to 15% improvement in PSNR.
An important task in the early stage of drug discovery is the identification of mutagenic compounds. Mutagenicity prediction models that can interpret relationships between toxicological endpoints and compound structures are especially favorable. In this research, we used an advanced graph convolutional neural network (GCNN) architecture to identify the molecular representation and develop predictive models based on these representations. The predictive model based on features extracted by GCNNs can not only predict the mutagenicity of compounds but also identify the structure alerts in compounds. In fivefold cross-validation and external validation, the highest area under the curve was 0.8782 and 0.8382, respectively; the highest accuracy (Q) was 80.98% and 76.63%, respectively; the highest sensitivity was 83.27% and 78.92%, respectively; and the highest specificity was 78.83% and 76.32%, respectively. Additionally, our model also identified some toxicophores, such as aromatic nitro, three-membered heterocycles, quinones, and nitrogen and sulfur mustard. These results indicate that GCNNs could learn the features of mutagens effectively. In summary, we developed a mutagenicity classification model with high predictive performance and interpretability based on a data-driven molecular representation trained through GCNNs.
As a deep learning method, graph convolution network (GCN) has the advantage of dealing with non-Euclidean domain problems and is constantly applied in the research of computer-aided diagnosis of Alzheimer's disease (AD). In graph-based methods for AD diagnosis, nodes can represent potential subjects with a set of vectors, and edges combine the interaction and similarity between subjects. However, for the three-dimensional neuroimage like structural Magnetic Resonance Imaging (sMRI) or Positron Emission Tomography (PET), due to the nonsequential of ROI (Region of Interest) features (compared with four-dimensional neuroimage), which makes the graph-based analysis approach more difficult. In this study, we obtained individual features by constructing brain network via health group indirectly, and then constructed a population-based GCN framework by expressing the subject population as adjacency matrix in graph to achieve the diagnosis of AD. The nodes in graph are associated with individual features, and edges are weighted by combining the phenotypic information, we further discuss the influence of phenotypic information on the classification performance of GCN. Compared with acquiring the ROI features of the brain regions as the input features of GCN, our proposed method remarkably improved the prediction accuracy based on both sMRI and PET images by about 5 to 10 percentage. Through our testing and experimental analysis on the public ADNI dataset, our method achieved improved performance for AD diagnosis and mild cognitive impairment conversion prediction tasks. Our proposed method also provides technical support for AD diagnosis using GCN method based on three-dimensional brain images.
Artificial intelligence for graph-structured data has achieved remarkable success in applications such as recommendation systems, social networks, drug discovery, and circuit annotation. Graph convolutional networks (GCNs) are an effective way to learn representations of various graphs. The increasing size and complexity of graphs call for in-memory computing (IMC) accelerators for GCN to alleviate massive data transmission between off-chip memory and processing units. However, GCN implementation with IMC is challenging because of the large memory consumption, irregular memory access, and device nonidealities. Herein, a fully binarized GCN (BGCN) accelerator based on computational resistive random-access memory (RRAM) through software-hardware codesign is presented. The essential operations including aggregation and combination in GCN are implemented on the RRAM crossbar arrays with cooperation between multiply-and-accumulation and content-addressable memory operations. By leveraging the model quantization and IMC on the RRAM, the BGCN accelerator demonstrates less RRAM usage, high robustness to the device variations, high energy efficiency, and comparable classification accuracy compared to the current state-of-the-art GCN accelerators on both graph classification task using the MUTAG and PTC datasets and node classification task using the Cora and CiteSeer datasets. These results provide a promising approach for edge intelligent systems to efficiently process graph-structured data. This article presents a fully binarized graph convolutional network accelerator based on computational resistive random-access memory (RRAM). By leveraging the model quantization and in-memory computing, less RRAM usage, high robustness, high energy efficiency, and comparable classification accuracy are demonstrated on both graph and node classifications, providing a promising approach for edge intelligent systems.image (c) 2024 WILEY-VCH GmbH
With the increasing use of open-source libraries and secondary development, software projects face security vulnerabilities. Existing studies on source code vulnerability detection rely on natural language processing techniques, but they overlook the intricate dependencies in programming languages. To address this, we propose a framework called Context and Multi-Features-based Vulnerability Detection (CMFVD). CMFVD integrates source code graphs and textual sequences, using a novel slicing method called Context Slicing to capture contextual information. The framework combines graph convolutional networks (GCNs) and bidirectional gated recurrent units (BGRUs) with attention mechanisms to extract local semantic and syntactic information. Experimental results on Software Assurance Reference Datasets (SARDs) demonstrate CMFVD's effectiveness, achieving the highest F1-score of 0.986 and outperforming other models. CMFVD offers a promising approach to identifying and rectifying security flaws in large-scale codebases.
Background New drugs are costly, time-consuming, and often accompanied by safety concerns. With the development of deep learning, computer-aided drug design has become more mainstream, and convolutional neural networks and graph neural networks have been widely used for drug-target affinity (DTA) prediction.Objective The paper proposes a method of predicting DTA using graph convolutional networks and multiscale convolutional neural networks.Methods We construct drug molecules into graph representation vectors and learn feature expressions through graph attention networks and graph convolutional networks. A three-branch convolutional neural network learns the local and global features of protein sequences, and the two feature representations are merged into a regression module to predict the DTA.Results We present a novel model to predict DTA, with a 2.5% improvement in the consistency index and a 21% accuracy improvement in terms of the mean squared error on the Davis dataset compared to DeepDTA. Morever, our method outperformed other mainstream DTA prediction models namely, GANsDTA, WideDTA, GraphDTA and DeepAffinity.Conclusion The results showed that the use of multiscale convolutional neural networks was better than a single-branched convolutional neural network at capturing protein signatures and the use of graphs to express drug molecules yielded better results.
A novel mechanism for skeleton-based action recognition is proposed in this paper by enhancing and fusing diverse skeleton features from distinct levels. Graph convolutional neural networks (GCNs) have been proven to be efficient in skeleton-based action recognition. However, most graph convolutional networks tend to capture and fuse discriminative information from different forms of data in spatial neighborhoods. In that case, the deeper interactions among different forms of data as well as the extraction of information in the temporal and channel dimensions are limited. To tackle the issue, we propose the ternary adaptive graph convolution (TAGC) module to capture spatiotemporal information by graph convolution. A novel skeleton information, called parallax information, is explored from original joints or bones with little computation to further improve the performance of action recognition. In addition, in order to make better use of multiple streams, multi-stream feature fusion (MSFF) is proposed to mine deeper-level hybrid features supplementing the original streams. And a graph-based ternary enhance (GTE) module is proposed to further refine the extracted discriminative features. Finally, the proposed multi-stream ternary enhanced graph convolutional network (MS-TEGCN) achieves the state-of-the-art results through extensive experiments on three challenging datasets for skeleton-based action recognition, NTU-60, NTU-120 and Kinetics-Skeleton.
Face clustering groups massive unlabeled face images according to their underlying identities and has proven to be a valuable tool for data analysis. Most recent studies have utilized graph convolutional networks (GCNs) to explore the structural properties of faces, thereby effectively achieving improved clustering performance. However, these methods usually suffer from computational intractability for large-scale graphs and tend to be sensitive to some postprocessing thresholds that serve to purify the clustering results. To address these issues, in this paper, we consider each pairwise relationship between two samples as a learning unit and infer clustering assignments by evaluating a group of pairwise connections. Specifically, we propose a novel clustering framework, named structure-enhanced pairwise feature learning (SEPFL), which mixes neighborhood information to adaptively produce pairwise representations for cluster identification. In addition, we design a combined density strategy to select representative pairs, thus ensuring training effectiveness and inference efficiency. The extensive experimental results show that SEPFL achieves better performance than other advanced face clustering techniques.
Interactions between drugs can occur when two or more drugs are used for the same patient. This may result in changes in the drug's pharmacological activity, some of which are beneficial and some of which are harmful. Thus, identifying possible drug-drug interactions (DDIs) has always been a crucial research topic in the field of clinical pharmacology. As clinical trials are time-consuming and expensive, current approaches for predicting DDIs are mainly based on knowledge mining from the literature using computational methods. However, since the literature contain a large amount of unrelated information, the task of identifying drug interactions with high confidence has become challenging. Thus, here, we present a novel graph-convolutional-network-based method called DDINN to detect potential DDIs. Combining cBiLSTM, graph convolutional networks and weight-rebalanced dependency matrix, DDINN is able to extract both contexture and syntactic information efficiently from the extensive biomedical literature. At last, we compare our DDINN with some other state-of-the-art models, and it is proved that our work is more effective. In addition, the ablation experiments demonstrate the advantages of DDINN's optimization techniques as well.
We develop a memory graph convolutional network (MGCN) framework for sea surface temperature (SST) prediction. The MGCN consists of two memory layers: one graph layer and one output layer. The memory layer captures SST temporal changes via temporal convolution units and gate linear units. The graph layer encodes SST spatial changes in terms of characteristics derived from graph Laplacian. The output layer encapsulates information from the previous layers and produces SST prediction results. The MGCN characterizes both the temporal and spatial changes, rendering a comprehensive SST prediction strategy. We use daily mean SST data for two areas near the Bohai Sea and the East China Sea for experimental evaluations and validate that the MGCN performs better than other traditional machine learning methods for nearshore SST prediction. In addition, we test the MGCN on weekly and monthly mean SST datasets and validate that the MGCN is robust and suitable for SST prediction.
Aerial scene classification can be treated as the problem of acquiring high-level semantic interpretations of the earth-surface images, remotely captured from the space or from the aerial vehicles. Although the topic is already extensively explored thus far, due to the high complexities and diversities in geometrical and spatial texture of aerial scenes, there still remain several open challenges. This paper primarily focuses on a comparatively new challenge of aerial scene classification under labelled sample scarcity, which restricts the promising deep network models, such as convolutional neural networks, to attain the desired accuracy. Even the graph convolutional networks, which have added strength of capturing spatial relationships, fail to perform well when trained with limited training samples. We address this issue by generating hierarchical semantics-driven multiple graph representations for each image, and subsequently, employing graph representation learning over these multitude of graphs which act as augmented training samples. Our graph-based hierarchical semantics-driven model (GrapHiSM) is evaluated using benchmark UC-Merced and AID datasets. Experimental results exhibit efficacy of GrapHiSM, in handling labelled sample scarcity at the time of aerial scene classification.
The condition of sensors is critical to ensure the safe operation and product quality of industrial processes, but fault detection and diagnosis techniques for sensors have received little attention. To alleviate this problem, we introduce a novel deep-learning (DL) framework that combines process knowledge and graph convolutional networks (KDGCNs) for process sensor fault detection and diagnosis. We inject process knowledge into a data-based modeling approach through graph neural networks (GNNs) and use attention mechanisms to model the dependencies between sensors. We implement sensor fault detection using residuals and determine the location of the faulty sensor using a directed graph. Finally, we set up several sensor faults based on the Tennessee Eastman simulation, and the KDGCN shows satisfactory performance in both detection rate and diagnosis results, indicating that the injected knowledge and graph structure help to achieve accurate sensor fault detection and diagnosis.
Graph neural networks (GNNs) have gradually become an important research branch in graph learning since 2005, and the most active one is unquestionably graph convolutional neural networks (GCNs). Although convolutional neural networks have successfully learned for images, voices, and texts, over-smoothing remains a significant obstacle for non-grid graphs. In particular, because of the over-smoothing problem, most existing GCNs are only effective below four layers. This work proposes a novel GCN named DII-GCN that originally integrates Dropedge, Initial residual, and Identity mapping methods into traditional GCNs for mitigating over-smoothing. In the first step of the DII-GCN, the Dropedge increases the diversity of learning sample data and slows down the network's learning speed to improve learning accuracy and reduce over-fitting. The initial residual is embedded into the convolutional learning units under the identity mapping in the second step, which extends the learning path and thus weakens the over-smoothing issue in the learning process. The experimental results show that the proposed DII-GCN achieves the purpose of constructing deep GCNs and obtains better accuracy than existing shallow networks. DII-GCN model has the highest 84.6% accuracy at 128 layers of the Cora dataset, highest 72.5% accuracy at 32 layers of the Citeseer dataset, highest 79.7% accuracy at 32 layers of the Pubmed dataset.
Object-based image classification (OBIC) on very-high-resolution (VHR) remote sensing (RS) images is utilized in a wide range of applications. Nowadays, many existing OBIC methods only focus on features of each object itself, neglecting the contextual information among adjacent objects and resulting in low classification accuracy. Inspired by a spectral graph theory, we construct a graph structure from objects generated from VHR RS images and propose an OBIC framework based on truncated sparse singular value decomposition and graph convolutional network (GCN) model, aiming to make full use of relativities among objects and produce an accurate classification. Through conducting experiments on two annotated RS image data sets, our framework obtained 97.2% and 66.9% overall accuracy, respectively, in automatic and manual object segmentation circumstances, within a processing time of about 1/100 of convolutional neural network (CNN)-based methods' training time.
Despite the great progress in 3D pose estimation from videos, there is still a lack of effective means to extract spatio-temporal features of different granularity from complex dynamic skeleton sequences. To tackle this problem, we propose a novel, skeleton-based spatio-temporal U-Net(STUNet) scheme to deal with spatio-temporal features in multiple scales for 3D human pose estimation in video. The proposed STUNet architecture consists of a cascade structure of semantic graph convolution layers and structural temporal dilated convolution layers, progressively extracting and fusing the spatio-temporal semantic features from fine-grained to coarse-grained. This U-shaped network achieves scale compression and feature squeezing by downscaling and upscaling, while abstracting multi-resolution spatio-temporal dependencies through skip connections. Experiments demonstrate that our model effectively captures comprehensive spatio-temporal features in multiple scales and achieves substantial improvements over mainstream methods on real-world datasets.
Grasping point detection has traditionally been a core robotic and computer vision problem. In recent years, deep learning based methods have been widely used to predict grasping points, and have shown strong generalization capabilities under uncertainty. Particularly, approaches that aim at predicting object affordances without relying on the object identity, have obtained promising results in random bin-picking applications. However, most of them rely on RGB/RGB-D images, and it is not clear up to what extent 3D spatial information is used. Graph Convolutional Networks (GCNs) have been successfully used for object classification and scene segmentation in point clouds, and also to predict grasping points in simple laboratory experimentation. In the present proposal, we adapted the Deep Graph Convolutional Network model with the intuition that learning from n-dimensional point clouds would lead to a performance boost to predict object affordances. To the best of our knowledge, this is the first time that GCNs are applied to predict affordances for suction and gripper end effectors in an industrial bin-picking environment. Additionally, we designed a bin-picking oriented data preprocessing pipeline which contributes to ease the learning process and to create a flexible solution for any bin-picking application. To train our models, we created a highly accurate RGB-D/3D dataset which is openly available on demand. Finally, we benchmarked our method against a 2D Fully Convolutional Network based method, improving the top-1 precision score by 1.8% and 1.7% for suction and gripper respectively.
Recently, graph convolutional networks have achieved remarkable performance with skeleton-based action recognition methods. However, there is potential correlation between different parts of the human body. Many studies have ignored the fact that different actions are the result of the interaction of different human body parts, and that operating on the whole graph provides inadequate information to characterize the action category. In this study, to pay more attention to this problem and further improve the accuracy of action recognition models, sub-graphs based on the depth-first tree traversal order were used to represent the importance and correlation characteristics of joint and bone parts. In addition, beyond the physical structure of the body, joint and bone motion information was also introduced to represent changes in human body parts with movement. To improve the performance of this method, an adaptive-attentional mechanism was added to learn unique topology autonomously for each sample and channel domain. The multi-stream adaptive-attentional sub-graph convolution network was thus proposed for action recognition. The resulting model achieved competitive results on the NTU-RGB + D60 dataset based on 2D or 3D skeleton poses. The experimental results demonstrated the efficacy of our proposed method.
Forecasting tasks involving multi-channel time series data pervade numerous practical applications and have attracted significant attention. Spatio-temporal graph neural network models for multi-channel time series forecasting have recently gained traction, owing to their ability in capturing both spatial and temporal features. A common practice is the integration of graph convolutional networks with recurrent neural networks. However, the discrete intervals of recurrent neural networks pose limitations on the temporal resolution of time series forecasting, impeding the model's ability to capture subtle changes in the data. To address this challenge, we introduce a continuous spatio-temporal framework, termed Graph Ordinary Differential Equation Recurrent Network (GODERN). GODERN incorporates continuous recurrent neural networks with a learnable and directed graph convolution layer to model the spatio-temporal dynamics in latent space. Furthermore, given the actual time representation in GODERN, we propose a novel augmented method of neural ordinary differential equation with fast-slow dynamics, thus allowing the encapsulation of multi-scale information. Through our experiments, we demonstrate that GODERN achieves superior accuracy on four real-life datasets, outperforming 13 baseline models.
Introduction: Necitumumab plus gemcitabine and cisplatin (GCN) is a standard therapy for patients with advanced lung squamous cell carcinoma (LSqCC). However, the efficacy and tolerability of GCN in second-line or later treatment for patients previously treated with immune checkpoint inhibitors (ICIs) remain unknown. Methods: This multicenter, retrospective, cohort study assessed the efficacy and tolerability of GCN initiated between November 1, 2019 and March 31, 2022 as second-line to fourth-line treatment in patients with advanced LSqCC who had been pretreated with ICIs. The primary end point was progression-free survival (PFS). Results: A total of 93 patients from 35 institutions in Japan were enrolled. The median PFS, median overall survival (OS), and objective response rate were 4.4 months (95% confidence interval [CI]: 3.8-5.3), 13.3 months (95% CI: 9.6-16.5), and 27.3% (95% CI: 18.3-37.8), respectively. The median PFS, median OS, and objective response rate for second-line, third-line, and fourth-line treatment groups were 4.8 months, 3.8 months, and 4.3 months (p= 0.24); 15.7 months, 11.6 months, and 10.1 months (p= 0.06); and 31.0%, 13.6%, and 37.5% (p= 0.22), respectively. The severity of GCN-related skin disorders was associated with longer PFS (p < 0.05) and OS (p < 0.05). The frequencies of grade ≥3 skin disorders, hypomagnesemia, pneumonitis, and febrile neutropenia were 16.1%, 7.5%, 1.1%, and 4.3%, respectively. There were no treatment-related deaths. Conclusions: GCN for ICI-pretreated patients with LSqCC seems tolerable and offers promising efficacy regardless of treatment line, and ICI pretreatment might enhance GCN efficacy.
The task of discovering equivalent entities in knowledge graphs (KGs), so-called KG entity alignment, has drawn much attention to overcome the incompleteness problem of KGs. The majority of existing techniques learns the pointwise representations of entities in the Euclidean space with translation assumption and graph neural network approaches. However, real vectors inherently neglect the complex relation structures and lack the expressiveness of embeddings; hence, they may guide the embeddings to be falsely generated which results in alignment performance degradation. To overcome these problems, we propose a novel KG alignment framework, ComplexGCN, which learns the embeddings of both entities and relations in complex spaces while capturing both semantic and neighborhood information simultaneously. The proposed model ensures richer expressiveness and more accurate embeddings by successfully capturing various relation structures in complex spaces with high-level computation. The model further incorporates relation label and direction information with a low degree of freedom. To compare our proposal against the state-of-the-art baseline techniques, we conducted extensive experiments on real-world datasets. The empirical results show the efficiency and effectiveness of the proposed method.
With the rapid development of transportation systems, traffic data have been largely produced in daily lives. Finding the insights of all these complex data is of great significance to vehicle dispatching and public safety. In this work, we propose a multitask deep learning model called Multitask Recurrent Graph Convolutional Network (MRGCN) for accurately predicting traffic flows in the city. Specifically, we design a multitask framework consisting of four components: a region-flow encoder for modeling region-flow dynamics, a transition-flow encoder for exploring transition-flow correlations, a context modeling component for contextualized fusion of two types of traffic flows and a task-specific decoder for predicting traffic flows. Particularly, we introduce Dual-attention Graph Convolutional Gated Recurrent Units (DGCGRU) to simultaneously capture spatial and temporal dependencies, which integrate graph convolution and recurrent model as a whole. Extensive experiments are carried out on two real-world datasets and the results demonstrate that our proposed method outperforms several existing approaches.
Facial expression recognition (FER) is of great interest to the current studies of human-computer interaction. In this paper, we propose a novel geometry-guided facial expression recognition framework, based on graph convolutional networks and transformers, to perform effective emotion recognition from videos. Specifically, we detect and utilize facial landmarks to construct a spatial-temporal graph, based on both the landmark coordinates and local appearance, for representing a facial expression sequence. The graph convolutional blocks and transformer modules are employed to produce high-semantic emotion-related representations from the structured facial graphs, which facilitate the framework to establish both the local and non-local dependency between the vertices. Moreover, spatial and temporal attention mechanisms are introduced into graph-based learning to promote FER reasoning, via the emphasis on the most informative facial components and frames. Extensive experiments demonstrate that the proposed framework achieves promising performance for geometry-based FER and shows great generalization and robustness in real-world applications.
The obfuscation detection technology is an important auxiliary means of malware detection. Also, for security practitioners, it can carry out automatic obfuscation detection before manual reverse analysis, which helps reverse engineers to perform reverse analysis more specifically. Existing obfuscation detection methods are mainly for Android applications and based on traditional machine learning, whose detection granularity is coarse, generality is poor, and the performance is not good enough. To address these issues, in this paper, we propose a function-level obfuscation detection method based on Graph Convolutional Networks for X86 assembly code and Android applications. Firstly, our method is function-level obfuscation detection, and we extract the Control Flow Graph (CFG) of each function as its feature, including the adjacency matrix and the basic block feature matrix. Secondly, we build a hybrid neural network model GCN-LSTM as our obfuscation detection model, which combines the Graph Convolutional Network (GCN) and the Long Short-Term Memory (LSTM). Finally, we conduct experiments using real-world open-source programs and compare results with baseline methods. For function-level detection, the accuracy of our method is 94.7575% for X86 assembly code and 98.9457% for Android applications, both of which are better than baseline methods. For APKlevel detection, our method can almost completely detect the obfuscated APKs. Experimental results show that our method performs well for both X86 assembly code and Android applications and is superior to the baseline methods in both function-level detection and APK-level detection. Our research showcases a successful application of the Graph Convolutional Network and the Control Flow Graph on code obfuscation detection problems.
The ever-growing available visual data (i.e., uploaded videos and pictures by internet users) has attracted the research community's attention in the computer vision field. Therefore, finding efficient solutions to extract knowledge from these sources is imperative. Recently, the BlazePose system has been released for skeleton extraction from images oriented to mobile devices. With this skeleton graph representation in place, a Spatial-Temporal Graph Convolutional Network can be implemented to predict the action. We hypothesize that just by changing the skeleton input data for a different set of joints that offers more information about the action of interest, it is possible to increase the performance of the Spatial-Temporal Graph Convolutional Network for HAR tasks. Hence, in this study, we present the first implementation of the BlazePose skeleton topology upon this architecture for action recognition. Moreover, we propose the Enhanced-BlazePose topology that can achieve better results than its predecessor. Additionally, we propose different skeleton detection thresholds that can improve the accuracy performance even further. We reached a top-1 accuracy performance of 40.1% on the Kinetics dataset. For the NTU-RGB+D dataset, we achieved 87.59% and 92.1% accuracy for Cross-Subject and Cross-View evaluation criteria, respectively.
Mobile traffic prediction enables the efficient utilization of network resources and enhances user experience. In this paper, we propose a state transition graph-based spatial-temporal attention network (STG-STAN) for cell-level mobile traffic prediction, which is designed to exploit the underlying spatial-temporal dynamic information hidden in the historical mobile traffic data. Specifically, we first identify the semantic context information over different segments of the historical data by constructing the state transition graphs, which may reveal different patterns of random fluctuation. Then, based on the state transition graphs, a spatial attention extraction module using graph convolutional networks (GCNs) is designed to aggregate the spatial information of different nodes in the state transition graph. Moreover, a temporal extraction module is employed to capture the dynamic evolution and temporal correlation of the state transition graphs over time. Such a spatial-temporal attention network can be further integrated with a parallel long short-term memory (LSTM) module to improve the accuracy of mobile traffic prediction. Extensive experiments demonstrate that the STG-STAN can better exploit the spatial-temporal information hidden in the state transition graphs, achieving superior performance compared with several baselines.
Recently, several studies have reported that Graph Convolutional Networks (GCN) exhibit defects in integrating node features and topological structures in graphs. Although the proposal of AMGCN compensates for the drawbacks of GCN to some extent, it still cannot solve GCN's insufficient fusion abilities fundamentally. Thus it is essential to find a network component with stronger fusion abilities to substitute GCN. Meanwhile, a Deep Adaptive Graph Neural Network (DAGNN) proposed by Liu et al. can adaptively aggregate information from different hops of neighborhoods, which remarkably benefits its fusion abilities. To replace GCN with DAGNN network in AMGCN model and further strengthen the fusion abilities of DAGNN network itself, we make further improvements based on DAGNN model to obtain DAGNN variant. Moreover, experimentally the fusion abilities of the DAGNN variant are verified to be far stronger than GCN. And then build on that, we propose a Deep Adaptive Multi-channel Graph Neural Network (DAMGNN). The results of lots of comparative experiments on multiple benchmark datasets show that the DAMGNN model can extract relevant information from node features and topological structures to the maximum extent for fusion, thus significantly improving the accuracy of node classification.
Action recognition in real-world scenarios is a challenging task which involves the action localization and classification for untrimmed video. Since the untrimmed video in real scenarios lacks fine annotation, existing supervised learning methods have limited effectiveness and robustness in performance. Moreover, state-of-the-art methods discuss each action proposal individually, ignoring the exploration of semantic relationship between different proposals from continuity of video. To address these issues, we propose a weakly supervised approach to explore the proposal relations using Graph Convolutional Networks (GCNs). Specifically, the method introduces action similarity edges and temporal similarity edges to represent the context semantic relationship between different proposals for graph constructing, and the similarity of action features is used to weakly supervise the spatial semantic relationship between labeled and unlabeled samples to achieve the effective recognition of actions in the video. We validate the effectiveness of the proposed method on public benchmarks for untrimmed video (THUMOS14 and ActivityNet). The experimental results demonstrate that the proposed method in this paper has achieved state-of-the-art results, and achieves better robustness and generalization performance.
Outlier detection is a significant research direction in machine learning and has many applications in finance, network security, and other areas. Outlier detection of Euclidean datasets is a mainstream problem in outlier detection. Most detection methods often ignore the connection of its nodes. To collect the representation information of feature sets and node connections to improve the detection of outliers in Euclidean datasets Accuracy rate, we propose a novel Graph Convolutional and Attention-Based Outlier Detection (GCA).The GCA first converts the Euclidean structure data into directed graphs using locally sensitive hashing; then, by applying a Graph Convolutional Network, the data features and their connectivity graph are fed into the neural network; secondly, it fuses the extracted features and the features reconstructed by the attention mechanism; finally, calculating the outlier factors of the objects. Comparing eight state-of-art algorithms on ten real-world datasets shows that GCA achieves the highest Area Under ROC Curve (AUC) on datasets and also achieves equally good results in Accuracy (ACC) and False Alarm Rate (FAR). This study fills the gap of upgraded GCNs in detecting outliers to the best of our knowledge and provides a new way to convert Euclidean data to graphs.
Since human pose can be naturally represented by a graph, graph convolutional networks (GCNs) have recently been proposed for 3D human pose estimation and achieved promising results. But most GCN-based methods use vanilla graph convolution which aggregates features of 1-hop neighbors and long-range dependencies between joints can only be captured by stacking multiple layers of graph convolution. To alleviate this problem, we propose a multi-scale graph convolution to aggregate features of neighbors at different distances and apply it to nodes with specified neighbor types. We further propose a hierarchical-body-pooling to aggregate and share body-level and body-part-level context information. Based on these components, we finally develop a light-weighted GCN for 3D pose lifting by repeatedly stacking a residual block of multi-scale graph convolution and a hierarchical-body-pooling layer. The experimental results on Human3.6M dataset indicate that our network can achieve state-of-the-art performance with much less model complexity.
In present study, 1D carbon coated tungsten doped molybdenum oxide nanowires (WMO@C) were prepared by one step hydrothermal scheme to overcome the harmful effects of toxic dyes and infectious bacterial strains. The WMO@C nanowires were then integrated with graphitic carbon nitride (gCN) to synthesize their ternary nanocomposites to boost up photocatalytic and antibacterial activities for environmental remediation. XRD results indicated orthorhombic structure of WMO@C with crystallite size 4.3 which reduced to 3.53 by integration of gCN. SEM micrograph revealed 1D nanowires of synthesized nanophotocatalyst with average diameter of 192.33 nm. The WMO, WMO@C and WMO@C/gCN nanocomposites were effectively employed for the degradation of colored organic contaminants methylene blue (MB), crystal violet (CV), malachite green (MG) and colorless diverse effluents benzimidazole and benzoic acid and more for inhibition sterilization of P. aeruginosa and S. aureus microbes. After 120 min, 91% of MB, 89% of CV, 92% of MG, 65% of benzimidazole and 69% of benzoic acid were degraded by WMO@C/gCN nanocomposites under visible light. The superior photocatalytic competency of WMO@C/gCN was attributed to the enlarged surface area, slow photo-induced electron-hole recombination rate, significant charge transfer capacity and strong redox ability due to chemical bonds developed between gCN and 1D WMO@C nanowires. Different important reaction parameters such as pH effect, temperature effect, change in dye concentration and photocatalyst dose were studied. Facile synthetic route and outstanding photodegradation and antimicrobial performance proposes that WMO@C/gCN nanocomposites possess high potential for environmental remediation.
Gait has unique physiological characteristics and supports long-distance recognition, so gait recognition is ideal for areas such as home security and identity detection. Methods using graph convolutional networks usually extract features in the spatial and temporal dimensions by stacking GCNs and TCNs, but different joints are interconnected at different moments, so splitting the spatial and temporal dimensions can cause the loss of gait information. Focus on this problem, we propose a gait recognition network, Multi-scale Spatio-Temporal Gait (MST-Gait), which can learn multi-scale gait information simultaneously from spatial and temporal dimensions. We design a multi-scale spatio-temporal groups Transformer (MSTGT) to model the correlation of intra-frame and inter-frame joints simultaneously. And a multi-scale segmentation strategy is designed to capture the periodic and local features of the gait. To fully exploit the temporal information of gait motion, we design a fusion temporal convolution (FTC) to aggregate temporal information at different scales and motion information. Experiments on the popular CASIA-B gait dataset and OUMVLP-Pose dataset show that our method outperforms most existing skeleton-based methods, verifying the effectiveness of the proposed modules.
Many real-world problems can be abstracted into graph classification problems. Recently, graph convolutional networks have achieved great success in the task of node classification and link prediction. However, when using graph convolution network to process the task of graph classification, either global topology information or local information is ignored. Therefore, designing graph convolutional networks to improve the accuracy of graph classification has attracted more and more attention. Inspired by the use of convolutional neural networks to process graph-structured data, we put forward a new spatial convolutional neural network architecture for graph classification. To be specific, we first design a comprehensive weighting method to measure the significance of vertices in the graph based on multiple indicators to choose the central node sequence. Then, the normalization process of the graph is realized by constructing the same size neighborhood graphs for the central vertices. After that, the structural characteristics of the graph are extracted from both local and global aspects. Finally, the tensors obtained after the above steps are respectively input into the following two spatial convolutional neural network architectures to perform classification, one is a simple CNN structure, which has only two convolution layers, one dense layer and one softmax layer. The other is to modify the architecture of CNN, and the channel concatenation layer is introduced to determine the classification result of the entire graph according to the category of the neighborhood graphs. Experimental results on two kinds of real-world datasets, bioinformatics and social network datasets, indicate that our approach obtains competitive results and is superior to some classic kernels and similar deep learning-based algorithms on 6 out of 8 benchmark data sets. (c) 2020 Elsevier B.V. All rights reserved.
As the rolling mill often encounters variable and complicated working conditions and shock loads, unsupervised domain adaptive (UDA) methods are imperative in its health monitoring. However, efforts of applying UDA methods on the rolling mill are negligible, and many existing approaches have constraints in domain adaptation, domain label, and data construction that prevent meaningful features from being extracted. Hence, a multi-source domain adversarial graph convolutional networks framework (MSDAGCNs) is presented to overcome these challenges and combine three essential elements to achieve cross-domain health states diagnosis under variable working conditions. First, a shared feature extract module is introduced to extract common features. Then, the features are input to a multi-source feature extract module to extract the data construction from the graphs generated by a graph construction module. Meanwhile, a multi-source domain adversarial classifier module is modeled to extract multi-source invariant features and classify them. After that, the local maximum mean discrepancy is employed to align the domain categories. Next, a task classifier module integrates the results of the multi-source classifier for reliable health state diagnosis. Results on the two cases can verify that the proposed MSDAGCNs can not only outperform other state-of-the-art methods, but also extract domain-invariant knowledge. Compared with the best-performing method, the proposed method can boost accuracy by 0.53% and 0.83% in the simplest task of the two case studies, respectively. Furthermore, the arrangement of sensors on the rolling mill is discussed to select the optimal location for collecting vibrations.
Three-dimensional mesh post-processing is an important task because low-precision hardware and a poor capture environment will inevitably lead to unordered point clouds with unwanted noise and holes that should be suitably corrected while preserving the original shapes and details. Although many 3D mesh data-processing approaches have been proposed over several decades, the resulting 3D mesh often has artifacts that must be removed and loses important original details that should otherwise be maintained. To address these issues, we propose a novel 3D mesh completion and denoising system with a deep learning framework that reconstructs a high-quality mesh structure from input mesh data with several holes and various types of noise. We build upon SpiralNet by using a variational deep autoencoder with anisotropic filters that apply different convolutional filters to each vertex of the 3D mesh. Experimental results show that the proposed method enhances the reconstruction quality and achieves better accuracy compared to previous neural network systems.
An effective catalyst for the removal of antibiotic pollutants which severely impact water bodies and the environment is most favorable. In this study, g-C3N4 (gCN) and nitrogen-doped Bi2MoO6 (gCN-NBM) heterostructures are developed using a solvothermal process with enhanced photocatalytic degradation of tetracycline (TC) pollutants under visible-light irradiation. The experimental results confirm that nitrogen-doped Bi2MoO6 (NBM) nanomaterials were dispersed on the gCN surface, and a close combination of NBM and gCN leads to the efficient photocatalytic performance of TC. The photocatalytic efficiency of the heterostructure catalysts is four-fold higher than those of the pristine Bi2MoO6 catalysts owing to the excellent photogenerated charge separation and reduced recombination rate. Photocurrent measurements and electrochemical impedance spectra results disclose that the prepared heterostructure catalysts exhibit efficient photo-induced charge transfer. The electron spin resonance spectra and quenching experiments results reveal that superoxide radicals (.O2-) play a major role in TC degradation. This study presents a promising approach for designing efficient visible-light photocatalysts for environmental remediation applications.
Session-based recommendation (SBR) aims to predict the next item at a certain time point based on anonymous user behavior sequences. Existing methods typically model session representation based on simple item transition information. However, since session-based data consists of limited users' short-term interactions, modeling session representation by capturing fixed item transition information from a single dimension suffers from data sparsity. In this paper, we propose a novel contrastive multi-level graph neural networks (CM-GNN) to better exploit complex and high-order item transition information. Specifically, CM-GNN applies local-level graph convolutional network (L-GCN) and global-level graph convolutional network (G-GCN) on the current session and all the sessions respectively, to effectively capture pairwise relations over all the sessions by aggregation strategy. Meanwhile, CM-GNN applies hyper-level graph convolutional network (H-GCN) to capture high-order information among all the item transitions. CM-GNN further introduces an attention-based fusion module to learn pairwise relation-based session representation by fusing the item representations generated by L-GCN and G-GCN. CM-GNN averages the item representations obtained by H-GCN to obtain high-order relation-based session representation. Moreover, to convert the high-order item transition information into the pairwise relation-based session representation, CM-GNN maximizes the mutual information between the representations derived from the fusion module and the average pool layer by contrastive learning paradigm. We conduct extensive experiments on several widely used benchmark datasets to validate the efficacy of the proposed method. The encouraging results demonstrate that our proposed method outperforms the state-of-the-art SBR techniques.
To address the problem of poor detection and under-utilization of the spatial relationship between nodes in human pose estimation, a method based on an improved spatial temporal graph convolutional network (ST-GCN) model is proposed. Firstly, upsampling and segmented random sampling strategies are used to effectively solve the problems of class imbalance and the large sequence length of the dataset. Secondly, an improved detection transformer (DETR) structure is added to effectively suppress the generation of non-maximal suppression (NMS) and anchor points, a multi-head attention (M-ATT) module is introduced into each ST-GCN cell to capture richer feature information, and a residual module is introduced into the 9th ST-GCN cell to avoid possible network degradation in deep networks. In addition, strategies such as warmup, regularization, loss functions, and optimizers are configured to improve the model's performance. The experimental results show that the average percentage of correct keypoints (PCK) of this method are 93.2% and 92.7% for the FSD and MPII datasets, respectively, which is 1.9% and 1.7% higher than the average PCK of the original ST-GCN method. Moreover, the confusion matrix corresponding to this method also indicated that the model has high recognition accuracy. In addition, comparison experiments with ST-GCN and other methods show that the computation of the model corresponding to this method is about 1.7 GFLOPs and the corresponding MACs are about 6.4 GMACs, which is a good performance.
Due to the significant concentration of heavy metals in the contaminated area, it presents an imminent threat to both living organisms and the environment. In this research, we concentrate on finding an effective solution for eliminating Cd(II) and U(VI) from water. Our approach involves utilizing MgFe-layered double hydroxide (LDH) nanosheets combined with graphitic carbon nitride (GCN) nanosheets to ensure the effective elimination of these hazardous metal ions. The characterization techniques, including SEM, XPS, XRD, and BET analysis, confirmed the hierarchical layered structure of GCN/MgFe LDH with a significant surface area of 127.91 m(2)/g. Batch investigations demonstrated that the pH of the solution influences the elimination of both metal ions, while kinetics and equilibrium data well align with a pseudo-second-order model and the Langmuir model (R-2 = 0.996-1.0), respectively. GCN/MgFe LDH demonstrated impressive removal capacities of 312.30 mg/g and 273.42 mg/g for Cd(II) and U(VI) respectively. A thermodynamic analysis indicated that the adsorption process of both metal ions was endothermic and spontaneous. Furthermore, the GCN/MgFe LDH can be reused for over five cycles. In the fourth cycle, it maintained a removal percentage of over 95 % for both metal ions when 0.1 M HNO3 was used for desorption. In continuous column tests, the GCN/MgFe LDH reduced metal ion concentrations to levels below USEPA standards (<0.005 mg/L and 0.003 mg/L for Cd(II) and U(VI), respectively) for up to 4000 bed volumes, demonstrating its potential for wastewater treatment.
Herein, an effective template assisted calcination procedure has been adopted to synthesize the Sulphur-doped graphitic carbon nitride (S(X)GCN). Furthermore, the S(X)GCN/GCE was then utilized for the electrochemical determination of 2,4-Dinitrophenol (2,4-DNP). It has been inferred that among the variously prepared S(X)GCN (x=0 %, 20 %, 40 %, 60 %, 80 %, and 100 %), S(80)GCN afforded the excellent electrochemical response for detection of 2,4-DNP. The synthesized S(X)GCN/GCE (x=80 %) demonstrates with a low detection limit of 0.9083 mu M with linear range of 1-90 mu M. Furthermore, the practical application of this sensor was successfully proved by detecting spiked 2,4-dinitrophenol in a real gym supplements sample.
As isoelectronic counterparts of carbon fullerenes, medium-sized boron nitride clusters also prefer cage structures composed of even-sized polygons. As the cluster size increases, the number of cage isomers grows rapidly, and determining the ground state structure requires a tremendous amount of DFT calculations. Herein, we develop a graph convolutional network (GCN) that can describe the energy of a (BN) n cage by its topology connection. We define a vertex feature vector on a dual polyhedron by the permutation of the neighbor vertices' degree and aggregate the information on vertices by two graph convolutional layers to learn the local feature of the dual polyhedron. The GCN is trained on (BN)28 and subsequently tested on (BN)23 and (BN)24 data sets, which satisfactorily reproduce the order of isomer energies from DFT calculations. We further employ the trained GCN to predict the ground state structures within the size range of n = 25-32, which agree well with DFT results. Using the same GCN framework, we also successfully trained the highest-occupied or lowest-unoccupied orbital energies of (BN)28 isomers. The present graph convolutional network establishes a direct mapping between the topological connection and the energetic or electronic properties of a cage-like cluster or molecule.
Learning powerful discriminative features is the key for machine fault diagnosis. Most existing methods based on convolutional neural network (CNN) have achieved promising results. However, they primarily focus on global features derived from sample signals and fail to explicitly mine relationships between signals. In contrast, graph convolutional network (GCN) is able to efficiently mine data relationships by taking graph data with topological structure as input, making them highly effective for feature representation in non-Euclidean space. In this article, to make good use of the advantages of CNN and GCN, we propose a graph attentional convolutional neural network (GACNN) for effective intelligent fault diagnosis, which includes two subnetworks of fully CNN and GCN to extract the multilevel features information, and uses Efficient Channel Attention (ECA) attention mechanism to reduce information loss. Extensive experiments on three datasets show that our framework improves the representation ability of features and fault diagnosis performance, and achieves competitive accuracy against other approaches. And the results show that GACNN can achieve superior performance even under a strong background noise environment.
Graph convolutional network (GCN) has led to state-of-the-art performance for structured data. The superior performance would be partly due to the convolutional operations that operate over local neighborhoods. However, the distant long-range dependencies in data are still challenging to capture since it requires deep stacks of convolutional operations. Moreover, missing links in structured data might further hurt the performance. This paper introduces non-locality augmented graph convolution blocks into GCN to capture long-range or even disconnected dependencies. Specifically, we propose a dictionary-based non-locality encoding approach in which the non-local information is encoded by both graph convolution and dictionary-based implicit convolution. Unlike previous non-local approaches, our non-local block does not rely on the exhaustive computation of the relationship of data pairs. Thus, it is suitable for GCN, which typically models a large number of data samples. What's more, the proposed non-local blocks could be embedded into arbitrarily GCN architectures. We demonstrate the efficacy of our non-local block on four benchmark datasets.
L-methionine (L-Me) deficiency in human body leads to several complications. In the present work, graphitic carbon nitride nanosheets (GCN-S) modified glassy carbon electrode (GC/GCN-S) was developed as a cost effective electrochemical sensor for L-Me. The oxidation of L-Me at bare GC electrode shows an ill-defined peak and it was unstable whereas a well-defined stable oxidation peak was obtained at GC/GCN-S electrode. While increasing L-Me concentration from 100 nM to 0.2 mM, the amperometric current increases linearly with R-2=0.9901 and LOD was found to be 0.32 nM (S/N=3). Finally, GC/GCN-S electrode was used to determine L-Me in blood serum samples.
This study compares the performance of graph convolutional neural network (GCN) models with conventional natural language processing (NLP) models for classifying scientific literature related to radio frequency electromagnetic field (RF-EMF). Specifically, the study examines two GCN models: BertGCN and the citation-based GCN. The study concludes that the model achieves consistently good performance when the input text is long enough, based on the attention mechanism of BERT. When the input sequence is short, the composition parameter ?, which combines output values of the two subnetworks of BertGCN, plays a crucial role in achieving high classification accuracy. As the value of ? increases, the classification accuracy also increases. The study also proposes and tests a simplified variant of BertGCN, revealing performance differences among the models under two different data conditions by the existence of keywords. This study has two main contributions: (1) the implementation and testing of a variant of BertGCN and citation-based GCN for document classification tasks related to radio frequency electromagnetic fields publications, and (2) the confirmation of the impact of model conditions, such as the existence of keywords and input sequence length, in the original BertGCN. Although this study focused on a specific domain, our approaches have broader implications that extend beyond scientific publications to general text classification.
Background: Early detection of complex diseases like hepatocellular carcinoma remains challenging due to their network-driven pathology. Dynamic network biomarkers (DNB) based on monitoring changes in molecular correlations may enable earlier predictions. However, DNB analysis often overlooks disease heterogeneity.Methods: We integrated DNB analysis with graph convolutional neural networks (GCN) to identify critical transitions during hepatocellular carcinoma development in a mouse model. A DNB-GCN model was constructed using transcriptomic data and gene expression levels as node features.Results: DNB analysis identified a critical transition point at 7 weeks of age despite histological examina-tions being unable to detect cancerous changes at that time point. The DNB-GCN model achieved 100% accuracy in classifying healthy and cancerous mice, and was able to accurately predict the health status of newly introduced mice.Conclusion: The integration of DNB analysis and GCN demonstrates potential for the early detection of complex diseases by capturing network structures and molecular features that conventional biomarker discovery methods overlook. The approach warrants further development and validation.& COPY; 2023 The Author(s). Published by Elsevier B.V. on behalf of Research Network of Computational and Structural Biotechnology. This is an open access article under the CC BY-NC-ND license (http://creative-commons.org/licenses/by-nc-nd/4.0/).
Security-constrained unit commitment (SCUC) is a complex optimization problem in power system operation, which is computationally intensive. To bring significant time-savings, this paper presents a graph convolutional network (GCN)-based SCUC approach (GCN-SCUC) using the information of power grid topology. Instead of tackling the mixed integer linear programming (MILP)-based SCUC (MILP-SCUC), the GCN learner predicts the unit decisions first, and then the MILP-SCUC problem is transformed into a continuous convex one. Numerical experiments are performed on the modified IEEE-30 and IEEE-118 systems to verify the feasibility of our approach both in terms of accuracy and computation time. Moreover, compared with the state-of-the-art MILP-SCUC, the proposed approach achieves speedups of between 13x and 17x on different testing examples with high accuracy.(c) 2023 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
Multiple faults often occur in the operation of rotating machinery transmission systems. The fault signals of multiple bearings interfere with each other, which makes feature extraction and diagnosis of complex compound fault signals difficult. Because the graph convolution networks (GCN) can effectively map the structural information from complex data and its model has a certain generalization ability, this paper proposes a multiple fault diagnosis method for rolling bearings employing complete ensemble empirical mode decomposition (CEEMD) and a GCN (CEEMD-GCN) based on a horizontal visibility graph (HVG). Firstly, in order to highlight the effective feature information in the multiple fault signal and reduce noise interference, multiple indicators of correlation and kurtosis are used to reconstruct the decomposed signals through CEEMD; secondly, the reconstructed signals are constructed as an HVG, and the HVG maps the time series signal to the graphic structure data, reflecting the local geometric characteristics of the vibration signal through the horizontal visibility relationship; finally, taking the signal samples obtained by the HVG algorithm as the input data of the model, the GCN model is trained to realize the diagnosis of multiple faults. The experimental results show that the presented methodology is superior to other methods and exhibits generalization ability for multiple fault diagnosis.
IntroductionEstablishing a driving fatigue monitoring system is of utmost importance as severe fatigue may lead to unimaginable consequences. Fatigue detection methods based on physiological information have the advantages of reliable and accurate. Among various physiological signals, EEG signals are considered to be the most direct and promising ones. However, most traditional methods overlook the functional connectivity of the brain and fail to meet real-time requirements.MethodsTo this end, we propose a novel detection model called Attention-Based Multi-Semantic Dynamical Graph Convolutional Network (AMD-GCN). AMD-GCN consists of a channel attention mechanism based on average pooling and max pooling (AM-CAM), a multi-semantic dynamical graph convolution (MD-GC), and a spatial attention mechanism based on average pooling and max pooling (AM-SAM). AM-CAM allocates weights to the input features, helping the model focus on the important information relevant to fatigue detection. MD-GC can construct intrinsic topological graphs under multi-semantic patterns, allowing GCN to better capture the dependency between physically connected or non-physically connected nodes. AM-SAM can remove redundant spatial node information from the output of MD-GC, thereby reducing interference in fatigue detection. Moreover, we concatenate the DE features extracted from 5 frequency bands and 25 frequency bands as the input of AMD-GCN.ResultsFinally, we conduct experiments on the public dataset SEED-VIG, and the accuracy of AMD-GCN model reached 89.94%, surpassing existing algorithms.DiscussionThe findings indicate that our proposed strategy performs more effectively for EEG-based driving fatigue detection.
The construction of Schottky junctions is considered to be an efficient way to boost spatial charge separation and transfer in photocatalytic systems. In this work, we construct the Schottky junction using zero-dimensional (0D) Ti2CO2 nanoclusters (TCO) and two-dimensional (2D) g-C3N4 (GCN), denoted as TCO/GCN. The interfacial interaction, separation of photogenerated carriers, and reaction driving force of the TCO/GCN have been investigated based on density functional theory (DFT) calculations. TCO can serve as an electron acceptor due to the larger work function relative to the semiconductor GCN. The band bending caused by the interfacial charge prevents the electrons from flowing back to the semiconductor, which can effectively separate the photo-excited carriers. The metal sites exposed at the edge of TCO exhibit high hydrogen evolution reaction (HER) activity. This study provides a new idea for the development of 0D/2D Schottky junction photocatalysts.
A metal-free graphitic carbon nitride (GCN-T) photocatalyst obtained through a microwave-assisted technique was immobilised on cotton fabrics by an exhaustion method. Coated-cotton with only 0.81 % (w/w) of GCN-T (CO/GCN-T) presented effective antimicrobial properties against pathogenic bacteria, P. aeruginosa and E. coli, eradicating the retained bacteria after 60 min of direct irradiation with visible light. The self-cleaning activity of CO/GCN-T samples was also proved for the degradation of Rhodamine B (RhB) stains after 60 min of irradiation with a cost-effective Light Emitting Diode (LED) (lambda max = 417 nm). In addition, CO/GCN-T did not hinder the growth of commensal skin bacteria Staphylococcus spp. and presented non-cytotoxicity to skin cell lines, such as fibroblasts (L929) and keratinocytes (HaCaT), so it can be stated that these textiles are promising for applications in direct contact with the skin. Therefore, these are relevant findings since a textile substrate, with the ability to remove or eliminate harmful microorganisms, is an asset for the healthcare area.
Graph convolutional neural networks (GCNs) have emerged as an effective approach to extending deep learning for graph data analytics, but they are computationally challenging given the irregular graphs and the large number of nodes in a graph. GCNs involve chain sparse-dense matrix multiplications with six loops, which results in a large design space for GCN accelerators. Prior work on GCN acceleration either employs limited loop optimization techniques, or determines the design variables based on random sampling, which can hardly exploit data reuse efficiently, thus degrading system efficiency. To overcome this limitation, this paper proposes GShuttle, a GCN acceleration scheme that maximizes memory access efficiency to achieve high performance and energy efficiency. GShuttle systematically explores loop optimization techniques for GCN acceleration, and quantitatively analyzes the design objectives (e.g., required DRAM accesses and SRAM accesses) by analytical calculation based on multiple design variables. GShuttle further employs two approaches, pruned search space sweeping and greedy search, to find the optimal design variables under certain design constraints. We demonstrated the efficacy of GShuttle by evaluation on five widely used graph datasets. The experimental simulations show that GShuttle reduces the number of DRAM accesses by a factor of 1.5 and saves energy by a factor of 1.7 compared with the state-of-the-art approaches.
The working condition of high-speed train wheelset bearings is complex and bad, which makes its vibration signal contain strong noise. To obtain more information of samples, signals are constructed into graphs and fit by graph convolution network (GCN). The existing GCN-based models still have some problems, such as insufficient theoretical basis of graph and the unstable and overfitting during training of models, which significantly limits the diagnosis accuracy. To address these issues, first, a weighted e-recurrence network is proposed to construct the recurrence graph (RG). The recurrence relationship between samples is analyzed by the recursive nature of vibration signals. Maximum mean discrepancy (MMD) is used to obtain the regenerated Hilbert spatial distribution distance between two samples to reduce the weight gap between different recursive pairs. Also, the proposed method has better ex ante interpretability. Second, a vertex mean normalization (MN) layer is proposed to normalize individual vertex features to introduce some spatial perturbations and reduce the variance of vertex features, which can improve training stability and reduce overfitting. In addition, multichannel MN-GCN is proposed to fit multiscale graph features. Analyze recurrence nature of samples at different scales through RGs with varying densities of connection to improve the antinoise ability. Experimental results show that the proposed model can obtain spatial topology information accurately and improve the wheelset-bearing system fault diagnosis performance.
We address the problem of robust face alignment in the presence of occlusions, which remains a lingering problem in facial analysis despite intensive long-term studies. This paper proposes an adaptive attention-based graph convolutional network for face alignment. Different from most existing methods that ignore the structural information, we combine local features and global structural relationships to construct the landmark-connection graph and optimize the graph to improve the robustness of the model under occlusion conditions. Specifically, we introduce a novel graph convolutional network architecture consisting of three parts: GCN-global, GCN-local, and the adaptive channel attention module. GCN-global estimates the global transformation of landmarks through 3D face fitting to obtain initial coordinates. Considering the interaction between vertexes and edges in the graph, GCN-local jointly trains local edges and vertexes to improve the accuracy. The channel attention module can adaptively select essential features to enhance the performance. In addition, to reduce the influence of occlusion parts on the other landmarks and improve the working efficiency, we apply the preprocessing module to select which keypoints need to be connected. Our method achieves 5.17% mean error with 1.89% failure rate on COFW dataset and 4.16% mean error on 300W-Full dataset. Extensive experiments demonstrate that our method outperforms most state-of-the-art models on three public datasets, including WFLW, COFW, and 300W.
Nowadays, with the rapid expansion of social media as a means of quick communication, real-time disaster information is widely disseminated through these platforms. Determining which real-time and multi-modal disaster information can effectively support humanitarian aid has become a major challenge. In this paper, we propose a novel end-to-end model, named GCN-based Multi-modal Domain Adaptation (GMDA), which consists of three essential modules: the GCN-based feature extraction module, the attention-based fusion module and the MMD domain adaptation module. The GCN-based feature extraction module integrates text and image representations through GCNs, while the attention-based fusion module then merges these multi-modal representations using an attention mechanism. Finally, the MMD domain adaptation module is utilized to alleviate the dependence of GMDA on source domain events by computing the maximum mean discrepancy across domains. Our proposed model has been extensively evaluated and has shown superior performance compared to state-of-the-art multi-modal domain adaptation models in terms of F1 score and variance stability.
This study constructed a new aqueous solubility dataset and a solubility regression model which was ensembled by GCN and machine learning models. Aqueous solubility is a key physiochemical property of small molecules in drug discovery. In the past few decades, there have been many studies about solubility prediction. However, many of these studies have high root mean squared error (RMSE). Meanwhile, their dataset always contains salt compounds and solubility data obtained from different experimental conditions. In this paper, we constructed a clean dataset with 2609 compounds, which was small but contains only solubility records without salts at the same temperatures (25 degrees C). Here, we applied graph convolutional neural network (GCN) to construct an aqueous solubility prediction model. To enhance the performance of the model, the molecular MACCS key fingerprints and physiochemical descriptors were also combined with the GCN model to build a multi-channel model. Additionally, the authors also built two machine learning models (support vector regression and gradient boost decision tree) and assembled them to the GCN model to improve the root mean squared error (RMSE= 0.665). Finally, comparative experiments have shown that our framework achieved the best performance on ESOL dataset (RMSEval = 0.56, RMSEtest = 0.44) and surpassed four established software on aqueous solubility prediction of new compounds. [GRAPHICS] .
BiFe1-2xMnxMgxO3 (BFMM, x - 0-8%) was mixed with exfoliated g-C3N4 (GCN) to form a composite for establishing an S-scheme heterojunction for photodegradation. BFMM was synthesized by sol-gel method, and showed a decreased band gap from 2.24 eV to 1.75 eV as x increased from 0% to 7%, allowing a more efficient absorption of sunlight. GCN was prepared by thermal polymerization of melamine and then exfoliated to form nanosheets by sulfur acid in order to increase the specific surface area and thus increase reaction sites. A composite with a weight ratio of BFMM/GCN equal to 1 : 3 was prepared by sintering the powder mixture at 300 degrees C. Such a composite showed a greatly improved efficiency in photodegradation of methylene blue, which was over 6 times faster than pristine BiFeO3, and the Mn/Mg co-doping improved the efficiency by 48%. The Mott-Schottky plots showed that both GCN and BFMM are n-type semiconductors with flat-band potentials of -0.79 and +0.11 V (vs. NHE), respectively. So, the band alignment allowed the S-scheme to work, leading to an efficient separation of photogenerated electrons and holes, which was confirmed by the greatly increased photocurrents measured with the composites.
Graph convolutional network (GCN) has gained widespread attention in semisupervised classification tasks. Recent studies show that GCN-based methods have achieved decent performance in numerous fields. However, most of the existing methods generally adopted a fixed graph that cannot dynamically capture both local and global relationships. This is because the hidden and important relationships may not be directed exhibited in the fixed structure, causing the degraded performance of semisupervised classification tasks. Moreover, the missing and noisy data yielded by the fixed graph may result in wrong connections, thereby disturbing the representation learning process. To cope with these issues, this article proposes a learnable GCN-based framework, aiming to obtain the optimal graph structures by jointly integrating graph learning and feature propagation in a unified network. Besides, to capture the optimal graph representations, this article designs dual-GCN-based meta-channels to simultaneously explore local and global relations during the training process. To minimize the interference of the noisy data, a semisupervised graph information bottleneck (SGIB) is introduced to conduct the graph structural learning (GSL) for acquiring the minimal sufficient representations. Concretely, SGIB aims to maximize the mutual information of both the same and different meta-channels by designing the constraints between them, thereby improving the node classification performance in the downstream tasks. Extensive experimental results on real-world datasets demonstrate the robustness of the proposed model, which outperforms state-of-the-art methods with fixed-structure graphs.
Monitoring the land covers in complex landscapes is of great significance for the sustainable development of mine geo-environments. As most existing remote sensing scene datasets are composed of RGB images, there is a lack of multimodal datasets for complex landscapes with mining land covers (MLCs) at a fine-scale. In this study, a new dataset was created by the China University of Geosciences (CUG), Wuhan (named CUG-MLCs) using ZiYuan-3 imagery-based multispectral and topographic data. Moreover, the characteristics of multisize objects, irregular or blurred edges, and spectral-spatial-topographic heterogeneity and variability limited the classification accuracy. Therefore, an edge enhanced channel attention-based graph convolution network (ECA-GCN) was proposed and tested. The proposed ECA-GCN includes three key modules. 1) Multiscale and shallow feature fusion, used to fuse the multiscale convolutional features and shallow features, which helps present the MLC features with various scales; 2) edge enhanced channel attention, used to further select effective channels after a spatial edge feature enhancement, which helps identify irregular or blurred MLCs; and 3) edge detection-based GCN, used for edge feature-based adjacency matrix and feature maps from (2) to construct GCN, which can obtain edge node relation and global contextual information. This framework improved the representation of complex landscape characteristics. The proposed ECA-GCN achieved an overall accuracy of 66.60% +/- 1.39%, averaged accuracy of 36.25% +/- 1.50%, and Kappa of 55.91% +/- 2.05%, thus, outperforming other models. In general, the proposed dataset and model were positive for the fine classification of complex landscapes.
A novel analysis was conducted on the friction and wear properties of a commercial friction material formulation with the addition of bulk (named: gCN) and exfoliated (named: TEX6) graphitic carbon nitride in varying quantities: 4.5, 9, 13.5, and 18 wt%. The analysis was two-fold. In the first part, the samples were tested in the form of pins on a pin on disc testing equipment. The typical trend was that the friction coefficient magnitude increased with the addition of gCN. On the other hand, the friction coefficient decreased with the TEX6 addition. The pin wear reduced with the addition of gCN until 9 wt%. Beyond this amount, an increase in pin wear was observed. The TEX6 samples generally noted a decrease in pin wear with the increase in its content. An improvement in the characteristics of the secondary plateaus was seen with the increase in both gCN and TEX6 content. Through this study, the 13.5 wt% addition of both gCN and TEX6 was considered to display permissible friction and wear magnitude, and desirable extension and compaction of secondary contact plateaus. In the second part of the study, the formulation with 13.5 wt% of gCN and TEX6 was tested on a subscale dynamometer to replicate a real-life braking scenario. The friction and wear magnitudes were similar to the pin on disc study and the extension of the secondary contact plateaus was better than the virgin formulation. This study provides a complete analysis of the feasibility of the inclusion of g-C3N4 variations in automotive braking applications.
Objective. Whole-body positron emission tomography/computed tomography (PET/CT) scans are an important tool for diagnosing various malignancies (e.g. malignant melanoma, lymphoma, or lung cancer), and accurate segmentation of tumors is a key part of subsequent treatment. In recent years, convolutional neural network based segmentation methods have been extensively investigated. However, these methods often give inaccurate segmentation results, such as oversegmentation and undersegmentation. To address these issues, we propose a postprocessing method based on a graph convolutional network (GCN) to refine inaccurate segmentation results and improve the overall segmentation accuracy. Approach. First, nnU-Net is used as an initial segmentation framework, and the uncertainty in the segmentation results is analyzed. Certain and uncertain pixels are used to establish the nodes of a graph. Each node and its 6 neighbors form an edge, and 32 nodes are randomly selected as uncertain nodes to form edges. The highly uncertain nodes are used as the subsequent refinement targets. Second, the nnU-Net results of the certain nodes are used as labels to form a semisupervised graph network problem, and the uncertain part is optimized by training the GCN to improve the segmentation performance. This describes our proposed nnU-Net + GCN segmentation framework. Main results. We perform tumor segmentation experiments with the PET/CT dataset from the MICCIA2022 autoPET challenge. Among these data, 30 cases are randomly selected for testing, and the experimental results show that the false-positive rate is effectively reduced with nnU-Net + GCN refinement. In quantitative analysis, there is an improvement of 2.1% for the average Dice score, 6.4 for the 95% Hausdorff distance (HD95), and 1.7 for the average symmetric surface distance. Significance. The quantitative and qualitative evaluation results show that GCN postprocessing methods can effectively improve the tumor segmentation performance.
Microplastics (MPs) are pollutants generated by plastic debris of diameters <= 5 mm and are a global concern that can pose severe threats to human and environmental health in both aquatic and terrestrial areas. In this study, low-density polyethylene (LDPE, MW = similar to 35000) blended with Ru-incorporated g-C3N4 (Ru-gCN) was fabricated to examine its degradation efficiency. Plastic film (Ru-gCN@PE) degradation was performed by adding an aqueous medium with pH values ranging from 1 to 6 and at different temperatures (0, 35, 50, and 70 degrees C). The Ru-gCN@PE showed a significant weight loss of approximately 66.04, 74.51, and 69.64 wt% in pH 3 at 0, 50, and 70 degrees C, respectively, upon light irradiation for 24 h. The high activity of Ru-gCN can result from the formation of a heterojunction of Ru and g-C3N4 (Ru-gCN), which facilitates the transfer of the photoinduced pi electrons of g-C3N4. Moreover, H+ is produced at an appropriate pH and temperature to further convert into hydroperoxides and accelerate the formation of macroradicals ((ROO)-R-center dot, (RO)-R-center dot, and (OH)-O-center dot) for plastic degradation, which follows the Norrish Type I and II mechanisms. Our study demonstrated the outstanding efficacy of the photocatalytic degradation of LDPE.
Graph convolutional network (GCN) as a combination of deep learning (DL) and graph learning has gained increasing attention in hyperspectral image (HSI) classification. However, most GCN methods consider the simple point-to-point structure between two pixels rather than the high-order structure of multiple pixels, which is contradict with the real feature distribution of ground object. And the nonlinear property of HSI also brings challenge for precise structural representation in GCN. To tackle these problems, this work proposes a structure-preserved hyper GCN (SPHGCN). It first builds a multiple neighborhood reconstruction (MNR) model to reveal the essential resemblance of multiple pixels in nonlinear spectral feature space. With the high-order structure, SPHGCN designs the hypergraph convolution operation for irregular feature aggregation among similar pixels from different regions, which achieves more discriminative features from multiple pixel nodes. Meanwhile, a structure preservation layer (SPL) is built to optimize the distribution of convolutional features under the guidance of high-order structure. Moreover, SPHGCN integrates local regular convolution and irregular hypergraph convolution to learn the structured semantic feature of HSI. This strategy breaks the boundary restriction in traditional convolution and aggregates semantic feature across different image patches. Experiments on three HSI datasets indicate that SPHGCN outperforms a few state-of-the-art methods for HSI classification.
The growing demand for energy, as well as the impact on the environment as a result of human activity, has prompted a renewed focus on the development of cleaner alternative fuels. Because of its pure combustion products, hydrogen gas is being used as an alternative in the development of sustainable energy sources. A simple hydrothermal technique was used to prepare copper nickel tin sulphide (CNTS) decorated graphitic carbon nitride (gCN). CNTS-gCN samples were further prepared on different concentrations of gCN that varies from CNTS-gCN(10 mg-50mg) and analyzed under various characterization for its structural, morphological, and electrochemical properties. Field Emission Scanning Electron Microscopy (FESEM), Raman and HR-TEM (High Resolution-Transmitting Electron Microscopy) techniques were used to examine the morphology and surface structure of CNTS-gCN. Owing to its exclusive electrocatalytic property as low charge transfer resistance and high electrochemically active surface area, the composite material reveals a superior catalytic stability for the production of hydrogen energy. The hierarchical flower like structures were still maintained even after the addition of g-CN at different loading concentrations (10-50) respectively. The objective of this research is to prepare a new electrocatalyst based on CNTS with an increased HER activity.& COPY; 2023 Hydrogen Energy Publications LLC. Published by Elsevier Ltd. All rights reserved.
Methane is one of the most dangerous gases produced in the process of coal mining. Because of its flammable and explosive characteristics, it has seriously threatened the life and property safety of coal miners. As a result, accurate and real-time gas concentration forecasting is becoming a crucial but challenging issue for reducing methane risks and accidents. To further improve the efficiency and accuracy of methane concentration forecasting, this paper proposes a graph convolutional encoder-decoder (GCN-ED) network, which can train and infer all the sensors of a coal face as a unified entity. The proposed GCN-ED is composed of the GCN module and the ED module with a parallel structure. The GCN module constructs a priori graph structure through the adjacency relation between sensors in reality and uses a learnable self-adaptive dependency matrix to precisely capture the hidden spatial dependency in the data. The ED module is used to learn complex temporal features with LSTM cells and generate multi-step results of the gas concentration prediction. Experiments are conducted on real coal mine datasets, whose results demonstrate that the GCN-ED achieves the better performance than various state-of-the-art solutions and largely improves the efficiencies of training processes.
Accurate house price prediction allows construction investors to make informed decisions about the housing market and understand the growth opportunities for development and the risks and rewards of different construction projects. Machine learning (ML) models have been utilized as house price predictors, reducing decision-making costs, and increasing reliability. To further improve the reliability of the existing predictors, this study develops a hybrid multiedge graph convolutional network (GCN) that considers the various relationships between house price records. The developed hybrid multiedge GCN receives richer input from the multidependency information and thus provides a more reliable prediction that accounts for price changes based on the neighborhood, building age, and number of bedrooms. Compared to other ML approaches, the developed multiedge GCN house price predictor displayed good prediction accuracy while providing valuable insights into the factors that affect the house price, such as the desirability of different neighborhoods and building age. In the context of construction management and property valuation, the multiedge GCN model introduces an enhanced level of reliability for house price prediction. It stands out with its improved interpretability, rooted in its ability to maintain the inherent structure of the house price data set. This added transparency provides professionals with a more profound understanding and trust in prediction outcomes. By encompassing the richer content of the house price data set that includes the multidependency information, the model presents a comprehensive view of house price data sets, facilitating a more accurate and thorough understanding of housing market patterns. As a result, the GCN model matches the accuracy of other ML models while providing greater interpretability and transparency. This model's capabilities are expected to arm investors, contractors, and policymakers with valuable insights, aiding informed decision-making. It is also envisaged as a beneficial tool for construction project owners and contractors in refining budgets and informed investment decisions. The synthesis of transparency, representativeness, and accuracy makes this model a dependable tool for construction managers to make informed decisions, ultimately enhancing their operational efficacy.
Emotion classification along with sentimental analysis in dialogues is a complex task that has currently attained immense popularity. When communicating their thoughts and feelings, humans are prone to having many emotions of varying intensities. The task is complicated and fascinating since emotions in a dialogue utterance can be independent or based on the preceding utterances. Additional details such as audio and video, along with text facilitates in the identification of the right emotions with the corresponding intensity and appropriate sentiments in a dialogue. In this work, we focus on the task of predicting multiple emotions and their corresponding intensity along with sentiments in a given utterance of a dialogue. With the release of MEISD dataset, the task of simultaneously predicting the sentiments along with multiple emotions with intensity from a given utterance of a conversation utilizing the knowledge from textual, audio and visual cues has gained significance in conversational systems. We design an Affect-GCN framework that utilizes an RNN-GCN network as an utterance encoder followed by Multimodal Factorized Bilinear (MFB) pooling for enhance representation of different modalities. The proposed Affect-GCN framework shows an improvement of 0.7 in terms of Jaccard index for multi-label emotion classification while an increase of 0.3 for intensity prediction. Experimental analysis shows that our proposed Affect-GCN framework outperforms the existing approaches and several baselines for the task of multi-label emotion classification, intensity prediction and sentiment analysis in dialogues.
Carbon-based heterojunctions, because of their low toxicity and non-polluting properties, are considered as metal-free alternatives to the traditional metal oxide semiconductors for energy and environmental ap-plications especially in acidic conditions. In this work, an all-carbon heterojunction using exfoliated gra-phitic carbon nitride (GCN) and porous carbon derived from zeolitic imidazolate framework (CZ8) is developed for chromium (VI) decontamination. The enhanced charge-transfer in the GCN:CZ8 hetero-junctions, due to the suppressed electron-hole pair recombination, is evidenced from photoluminescence (PL) spectroscopy, transient photocurrent (TP) measurements and electrochemical impedance spectroscopy (EIS). This phenomenon significantly contributes towards improving the photo-induced decontamination of the noxious Cr(VI). Moreover, the band gap of the optimized GCN:CZ8 heterojunction is 2.48 eV which is relatively narrow than that of the GCN (2.79 eV). Nearly 100 % removal is achieved with the as-synthesized GCN:CZ8 heterojunction even with chromium solution of 100 ppm concentration. The X-Ray photoelectron spectroscopy (XPS) results suggest the facile reduction of Cr(VI) to Cr(III) under the influence of incident photons, and most importantly, the performance efficiency of the heterojunction is maintained similar to 100 % up to five continuous cycles. Herein, the optimized GCN:CZ8 heterojunction is established as a potential ma-terial towards efficient decontamination of Cr(VI) from water.(c) 2023 Elsevier B.V. All rights reserved.
Hyperspectral image (HSI) classification methods based on the graph convolutional network (GCN) have received more attention because they can handle irregular regions by graph encoding techniques. However, GCN-based HSI classification methods are highly sensitive to the quality of the graph structure. Its performance degrades in the case of underdeveloped graphs because it cannot excavate the intrinsic adjacency relationships. Thus, it is necessary to improve the quality of graph structure in GCN-based methods. In this article, a novel diversity-connected GCN (DCGCN) method is proposed to improve the quality of the graph structure for HSI classification, and its basic idea can be adopted by other GCN-based methods. First, the potential neighbors are excavated by performing topological extensions based on the given graph. The diversity of surrounding neighbors is maintained by adaptively smoothing operation via a global threshold value from Kullback-Leibler (KL) divergence to eliminate weak interclass connections caused by weakly spectral variability. Second, another key connectivity restriction is imposed on the diverse neighbors to further refine the ambiguous connections of hard samples aiming at removing strong interclass connections where the spectral information is heavily confounded. Finally, the DCGCN method is analyzed theoretically to demonstrate its low-pass filter property. The comprehensive experiments demonstrate the effectiveness of the proposed DCGCN method and the basic idea of the diversity-connected graph in terms of overall accuracy (OA), kappa coefficient (KC), and average accuracy (AA) indices.
As a complex neural network system, the brain regions and genes collaborate to effectively store and transmit information. We abstract the collaboration correlations as the brain region gene community network (BG-CN) and present a new deep learning approach, such as the community graph convolutional neural network (Com-GCN), for investigating the transmission of information within and between communities. The results can be used for diagnosing and extracting causal factors for Alzheimer's disease (AD). First, an affinity aggregation model for BG-CN is developed to describe intercommunity and intracommunity information transmission. Second, we design the Com-GCN architecture with intercommunity convolution and intracommunity convolution operations based on the affinity aggregation model. Through sufficient experimental validation on the AD neuroimaging initiative (ADNI) dataset, the design of Com-GCN matches the physiological mechanism better and improves the interpretability and classification performance. Furthermore, Com-GCN can identify lesioned brain regions and disease-causing genes, which may assist precision medicine and drug design in AD and serve as a valuable reference for other neurological disorders.
As one of foundation technologies for massive data processing for AI, event mining is attracting more and more attention, mainly including event detection (event trigger identification and event classification) and argument extraction. At present, EE-GCN is one of the most effective methods for event detection. However, since EE-GCN only focuses on event detection, complete event multi-tuple extraction needs to be improved. Inspired by the EE-GCN event detection method, this paper proposes an effective event extraction method via graph convolutional network indication with a hierarchical argument selection strategy. The method mainly includes the following steps. (1) Based on the ACE2005 argument extraction template, a new argument extraction template is established for the Baidu event extraction dataset. (2) The trigger events and event classification detected by EE-GCN are used as indicators to determine the argument extraction template, and the alternative arguments are extracted via named entity recognition based on the determined template. (3) Making full use of the side information of EE-GCN graph to solve the local and global correlation degree, and based on the local and global correlation degrees, the final argument multi-tuple is determined. (4) Finally, several experiments are conducted on the Baidu event extraction dataset to compare the proposed method with other methods. The experimental results show that the proposed method has improved the accuracy and completeness of the event extraction compared to other existing methods.
With the powerful representative ability of learning human skeleton, the graph convolutional network (GCN) is a popular baseline for 3D human pose estimation (HPE). However, current GCN-based 3D HPE methods primarily use "message-passing" architectures to aggregate the node information through the edges of the graph at "one scale". In such architectures, the learnt node features are uniform and cannot learn hierarchical representation of the graph-structured data. In this study, a hierarchically stacked graph network (HSGNet) with attention constraint for 3D HPE was proposed. An attention-constrained GCN layer (AGCN) was designed as the basic unit for constructing the HSGNet. With the specially designed AGCN layer, we computed the attention coefficients for each node to pick the most important node and suppressed the redundant information from the neighbors in feature aggregation. Then, a coarse graph layer with pooling map was devised for stacking the multiple GCN layers in a hierarchical manner, where a pooling map matrix was used to cluster the nodes for graph representation according to the human skeleton structure. Finally, an HSGNet was constructed in an encoder-decoder framework to further embed the global and local information of the full skeleton to achieve the final embedding feature for 3D pose regression. Our method was validated on two benchmark datasets: Human3.6M and MPI-INF-3DHP. Experimental results showed that the proposed method yielded good performance for 3D HPE.
Studies have shown that contextual information can promote the robustness of trackers. However, trackers based on convolutional neural networks (CNNs) only capture local features, which limits their performance. We propose a novel relevant context block (RCB), which employs graph convolutional networks to capture the relevant context. In particular, it selects the k largest contributors as nodes for each query position (unit) that contain meaningful and discriminative contextual information and updates the nodes by aggregating the differences between the query position and its contributors. This operation can be easily incorporated into the existing networks and can be easily end-to-end trained using a standard backpropagation algorithm. To verify the effectiveness of RCB, we apply it to two trackers, SiamFC and GlobalTrack, respectively, and the two improved trackers are referred to as Siam-RCB andGlobalTrack-RCB. Extensive experiments onOTB, VOT, UAV123, LaSOT, TrackingNet, OxUvA, and VOT2018LT show the superiority of our method. For example, our Siam-RCB outperforms SiamFC by a very large margin (up to 11.2% in the success score and 7.8% in the precision score) on the OTB-100 benchmark.
Decomposing a 3D face shape into different attribute components is usually beneficial to many applications, such as 3D face generation and attribute transfer. In this paper, we propose a novel method to learn independent latent representations of 3D face shapes to decompose a given 3D face shape into identity and expression components. We assume that the identity describes the intrinsic geometry of a face while the expression captures the extrinsic one, and thus they are independent of each other. Based on this assumption, we encode a 3D face shape into its identity and expression representations by a variational inference framework, that is equipped with Graph Convolutional Networks (GCN). Furthermore, we introduce a binary discriminator to enforce the latent representations of identity and expression to be distribution independent by adversarial learning. Both qualitative and quantitative experimental results show that the proposed approach can achieve state-of-the-art results in 3D face shape decomposition. Extensive applications on 3D facial expression transfer, 3D face recognition, and 3D face generation further demonstrate that the proposed method can achieve visually better transferred expressions, purer identity representations, and more diverse 3D face shapes, compared with existing state-of-the-art methods.
Entity alignment is an effective means of matching entities from various knowledge graphs (KGs) that represent the equivalent real-world object. With the development of representation learning, recent entity alignment methods learn entity structure representation by embedding KGs into a low-dimensional vector space, and then entity alignment relies on the distance between entity vectors. In addition to the graph structures, relations and attributes are also critical to entity alignment. However, most existing approaches ignore the helpful features included in relations and attributes. Therefore, this paper presents a new solution RAEA (Relation Awareness and Attribute Involvement for Entity Alignment), which includes relation and attribute features. Relation representation is incorporated into entity representation by Dual-Primal Graph CNN (DPGCNN), which alternates convolution-like operations on the original graph and its dual graph. Structure representation and attribute representation are learned by graph convolutional networks (GCNs). To further enrich the entity embedding, we integrate the textual information of the entity into the entity graph embedding. Moreover, we fine-tune the entity similarity matrix by integrating fine-grained features. Experimental results on three benchmark datasets from real-world KGs show that our approach has superior performance to other representative entity alignment approaches in most cases.
With the increasing number of software bugs, bug fixing plays an important role in software development and maintenance. To improve the efficiency of bug resolution, developers utilize bug reports to resolve given bugs. Especially, bug triagers usually depend on bugs' descriptions to suggest priority levels for reported bugs. However, manual priority assignment is a time-consuming and cumbersome task. To resolve this problem, recent studies have proposed many approaches to automatically predict the priority levels for the reported bugs. Unfortunately, these approaches still face two challenges that include words' nonconsecutive semantics in bug reports and the imbalanced data. In this article, we propose a novel approach that graph convolutional networks (GCN) based on weighted loss function to perform the priority prediction for bug reports. For the first challenge, we build a heterogeneous text graph for bug reports and apply GCN to extract words' semantics in bug reports. For the second challenge, we construct a weighted loss function in the training phase. We conduct the priority prediction on four open-source projects, including Mozilla, Eclipse, Netbeans, and GNU compiler collection. Experimental results show that our method outperforms two baseline approaches in terms of the F-measure by weighted average of 13.22%.
Complex networks necessitate the identification of key nodes owing to their ubiquity across the network. Traditional methodologies, such as machine learning-based and centrality-based techniques, evaluate node relevance only on network topologies or node properties. Nevertheless, both network topologies and node attributes must be considered at the time of evaluating the relevance of nodes. As a solution to this problem, this study presents OlapGN, a deep learning model that uses Graph Convolutional Networks to identify the most significant nodes in a complicated network. By integrating the two modules (deep learning and probabilistic nature), the proposed technique identifies overlapping groups and the most significant nodes within a complex network. The suggested approach determines the most significant individuals of the overlapping community after identifying their overlap. Several experiments have been conducted on actual social networks, such as VAST, Facebook, Medicine, Computer Science, and DBLP to evaluate the efficacy of the proposed model. In locating the overlapping communities and most significant nodes in heterogeneous complex networks, the proposed method has produced far better results than all other prevailing methods used for the purpose.
The need for computational models that can incorporate imaging data with non-imaging data while investigating inter-subject associations arises in the task of population-based disease analysis. Although off-the-shelf deep convolutional neural networks have empowered representation learning from imaging data, incorporating data of different modalities complementarily in a unified model to improve the disease diagnostic quality is still challenging. In this work, we propose a generalizable graph-convolutional framework for population-based disease prediction on multi-modal medical data. Unlike previous methods constructing a static affinity population graph in a hand-crafting manner, the proposed framework can automatically learn to build a population graph with variational edges, which we show can be optimized jointly with spectral graph convolutional networks. In addition, to estimate the predictive uncertainty related to the constructed graph, we propose Monte-Carlo edge dropout uncertainty estimation. Experimental results on four multi-modal datasets demonstrate that the proposed method can substantially improve the predictive accuracy for Autism Spectrum Disorder, Alzheimer's disease, and ocular diseases. A sufficient ablation study with in-depth discussion is conducted to evaluate the effectiveness of each component and the choice of algorithmic details of the proposed method. The results indicate the potential and extendability of the proposed framework in leveraging multi-modal data for population based disease prediction. (c) 2022 Elsevier B.V. All rights reserved.
Human action recognition based on skeleton currently has attracted a wide range of attention. The structure of skeleton data exists in the form of graph, thus most researchers use graph convolutional networks (GCN) to model skeleton sequences. However, the graph convolution network shares the same weight for all neighbor nodes and relies on the connection of graph edges. We introduce a method, a spatial-temporal graph attention networks (ST-GAT), to overcome the disadvantages of GCN. First, the ST-GAT defines the spatial-temporal neighbor nodes of the root node and the aggregation function through the attention mechanism. The adjacency matrix is only used in GAT to define related nodes, and the calculation of association weight is dependent on the feature expression of nodes. Then ST-GAT network attaches the obtained attention coefficient to each neighbor node to automatically learn the representation of spatiotemporal skeletal features and output the classification results. Extensive experiments on two challenging datasets consistently demonstrate the superiority of our method. (C) 2020 SPIE and IS&T
Recently, graph convolutional networks (GCNs) have been employed for graph matching problem. It can integrate graph node feature embedding, node-wise affinity learning and matching optimization together in a unified end-to-end model. However, first, the matching graphs feeding to existing graph matching networks are generally fixed and independent of graph matching task, which thus are not guaranteed to be optimal for the graph matching task. Second, existing methods generally employ smoothing-based graph convolution to generate graph node embeddings, in which extensive smoothing convolution operation may dilute the desired discriminatory information of graph nodes. To overcome these issues, we propose a novel Graph Learning-Matching Network (GLMNet) for graph matching problem. GLMNet has three main aspects. (1) It integrates graph learning into graph matching which thus adaptively learns a pair of optimal graphs for graph matching task. (2) It further employs a Laplacian sharpening graph convolution to generate more discriminative node embeddings for graph matching. (3) A new constraint regularized loss is designed for GLMNet training which can encode the desired one-to-one matching constraints in matching optimization. Experiments demonstrate the effectiveness of GLMNet. (c) 2021 Elsevier Ltd. All rights reserved.
This paper discusses shadow detection problem, and proposes a light-weight network to achieve both accurate detection results and high computation efficiency. Firstly, we begin by presenting a compact network for realtime shadow detection. Secondly, to improve the performance of our light-weight networks, we propose two complementary and necessary strategies, i.e., the use of extra training data and knowledge distillation. Note that collecting a large amount of extra data will lead to the following challenge: shadow scenes is various, while annotating for those complex scenarios is time-consuming and expensive, sometimes even need expert help. To solve it, in the first step, we introduce a novel shadow annotation strategy based on graph convolutional networks, namely Anno-GCN, to provide extra training pairs, which obtains a complete shadow mask via only several annotation scribbles. In the second step, we can combine knowledge distillation with these sufficient GCN-labeled training data to further improve the performance of the light-weight network. Extensive experiments demonstrate that our method can achieve a state-of-the-art inference accuracy, computational efficiency, and generalizability with only about 2.97 M parameters.
Learning-based shadow detection methods have achieved an impressive performance, while these works still struggle on complex scenes, especially ambiguous soft shadows. To tackle this issue, this work proposes an efficient shadow detection network (ESDNet) and then applies uncertainty analysis and graph convolutional networks for detection refinement. Specifically, we first aggregate global information from high-level features and harvest shadow details in low-level features for obtaining an initial prediction. Secondly, we analyze the uncertainty of our ESDNet for an input shadow image and then take its intensity, expectation, and entropy into account to formulate a semi-supervised graph learning problem. Finally, we solve this problem by training a graph convolution network to obtain the refined detection result for every training image. To evaluate our method, we conduct extensive experiments on several benchmark datasets, i.e., SBU, UCF, ISTD, and even on soft shadow scenes. Experimental results demonstrate that our strategy can improve shadow detection performance by suppressing the uncertainties of false positive and false negative regions, achieving state-of-the-art results.
Attributed graph clustering is a challenging task as it requires to jointly model graph structure and node attributes. Although recent advances in graph convolutional networks have shown the effectiveness of graph convolution in combining structural and content information, there is limited understanding of how to properly apply it for attributed graph clustering. Previous methods commonly use a fixed and low order graph convolution, which only aggregates information of few-hop neighbours and hence cannot fully capture the cluster structures of diverse graphs. In this paper, we first propose an adaptive graph convolution method (AGC) for attributed graph clustering, which exploits high order graph convolutions to capture global cluster structures and adaptively selects an appropriate order k via intra-cluster distance. While AGC can find a reasonable k and avoid over-smoothing, it is not sensitive to the gradual decline of clustering performance as k increases. To search for a better k , we further propose an improved adaptive graph convolution method (IAGC) that not only observes the variation of intra-cluster distance, but also considers the inconsistencies of filtered features with graph structure and raw features, respectively. We establish the validity of our methods by theoretical analysis and extensive experiments on various benchmark datasets.
Human action recognition based on the graph convolution network (GCN) is a hot topic in computer vision. Existing GCN-based methods fail to capture internal implicit information when extracting action features, thereby leading to over-smoothing in the training stage. These issues result in poor performance and inaccurate extraction of action features. To address these problems, a new GCN is constructed. In this paper, a human skeleton feature optimizer (SFO) and adaptive structure enhancement graph convolution network (ASE-GCN) for action recognition are proposed in an end-to-end manner. To obtain discriminative features, the SFO is proposed to construct a new skeleton representation for action recognition through the connection criterion, which extracts the internal implicit information of action. The action feature of the joint coordinates is extracted by graph structure mask (GSM), directed graph mapping (DGM), and adaptive pooling operation (APO) in the proposed ASE-GCN network. The GSM acts as the regularizer of skeleton structure information to strengthen the representation of the graph structure. The DGM correlates the directed graph with human motion information through kinematic principle, and the APO strengthens the global high-frequency features to alleviate over-smoothing. The proposed method achieves comparable or superior results over state-of-the-art methods when used in experiments on two large public-scale datasets, NTU-RGB+D and Kinetics.
Traffic flow prediction is of paramount importance in the field of spatio-temporal forecasting. In recent years, research efforts have primarily been directed towards developing intricate graph convolutional networks (GCNs) to capture spatial complexities. However, this has inadvertently led to the neglect of the inherent temporal correlations in traffic prediction, as well as the heterogeneity of graph structures. As a result, existing models show limited efficacy when dealing with the complex nature of traffic data. To address this issue, this paper introduces a novel traffic prediction model: the Fourier-enhanced heterogeneous graph convolution attention recurrent network (FEHGCARN). This model integrates historical information and incorporates a graph convolution attention recurrent unit (GCARU), meticulously engineered to effectively capture spatio-temporal dependencies. Additionally, it features a Fourier-enhanced heterogeneous graph learning module, which facilitates the acquisition of complex relationships among nodes in the frequency domain. Notably, this memory network excels at recognizing abrupt traffic conditions. To validate our approach, we conducted comprehensive comparisons using three authentic datasets and benchmarked our model against six state-of-the-art baseline methods. The experimental results unequivocally demonstrate the superior performance of our model across all evaluation metrics.
Graph convolutional networks (GCNs) have been widely used for representation learning on graph data, which can capture structural patterns on a graph via specifically designed convolution and readout operations. In many graph classification applications, GCN-based approaches have outperformed traditional methods. However, most of the existing GCNs are inefficient to preserve local information of graphs - a limitation that is especially problematic for graph classification. In this work, we propose a locality-preserving dense GCN with graph context-aware node representations. Specifically, our proposed model incorporates a local node feature reconstruction module to preserve initial node features into node representations, which is realized via a simple but effective encoder-decoder mechanism. To capture local structural patterns in neighborhoods representing different ranges of locality, dense connectivity is introduced to connect each convolutional layer and its corresponding readout with all previous convolutional layers. To enhance node representativeness, the output of each convolutional layer is concatenated with the output of the previous layer's readout to form a global context-aware node representation. In addition, a self-attention module is introduced to aggregate layer-wise representations to form the final graph-level representation. Experiments on benchmark datasets demonstrate the superiority of the proposed model over state-of-the-art methods in terms of classification accuracy. (C) 2021 Elsevier Ltd. All rights reserved.
Knowledge graph (KG) embedding models map nodes and edges to fixed-length vectors and obtain the similarity of nodes as the output of a scoring function to predict missing links between nodes. KG embedding methods based on graph convolutional networks (GCNs) have recently gained significant attention due to their ability to add information of neighboring nodes into the nodes' embeddings. However, existing GCNs are primarily based on real-valued embeddings, which have high distortion, particularly when modeling graphs with varying geometric structures. In this paper, we propose complex graph convolutional network (ComplexGCN), a novel extension of the standard GCNs in complex space to combine the expressiveness of complex geometry with GCNs for improving the representation quality of KG components. The proposed ComplexGCN comprises a set of complex graph convolutional layers and a complex scoring function based on PARATUCK2 decomposition: the former includes information of neighboring nodes into the nodes' embeddings, while the latter leverages these embeddings to predict new links between nodes. The proposed model demonstrates enhanced performance compared to existing methods on the two recent standard link prediction datasets.
Knowledge graph embedding models are used to learn low-dimensional representations of entities and relations in knowledge graphs. In this paper, we propose Multi-RAttE, an attention-based learning method for multiple relational knowledge graph embedding representation, which divides the information transfer in the knowledge graph into cross-relational information transfer and relation-specific information transfer, and divides the embedding of knowledge graph entities into structural embedding and multi-relational embedding for joint learning. To objectively analyse the performance of the Multi-RAttE model, we select two typical datasets and different representative baseline models for experimental evaluation on several tasks such as link prediction, multi-relation prediction and node classification. The experimental results show that the Multi-RAttE model improves 8% over the state-of-the-art model Composition-based Multi-Relational Graph Convolutional Networks (CompGCN) in terms of Hits@1 metric on the link prediction task on FB15k-237 dataset; on the multi-relation prediction task, the accuracy improves by 1.8% and 3.7% in the auc metric and F1 metric, respectively. The experimental results have proved that the Multi-RAttE model can effectively perform the representation of multiple relations.
Extreme Learning Machine (ELM) has been widely used for various classification problems. However, the traditional ELMs are typically based on the regular Euclidean data, thus ignoring the intrinsic structured information among data and resulting in poor robustness. In this paper, we present a novel semi-supervised learning framework, termed Graph Convolutional Extreme Learning Machines (GCELM), based on extending the traditional ELM to the non-Euclidean domain. Technically, we recast ELM layers into a randomized graph convolutional embedding layer followed by a graph convolutional regression layer, which endows ELM with the capability to handle graphs in the non-Euclidean domain. Benefiting from the diversity of the randomized graph convolution, we further propose an enhanced GCELM, i.e., Voting-based GCELM (V-GCELM), by using a simple voting ensemble strategy. The proposed methods preserve the advantages of ELMs, thus being more efficient than the gradient-based graph convolutional networks but without loss of graph learning ability. Extensive experiments on 36 benchmark datasets demonstrate that the proposed methods significantly outperform many previous semi-supervised classification methods.
Major Depressive Disorder (MDD) is a pervasive disorder affecting millions of individuals, presenting a significant global health concern. Functional connectivity (FC) derived from resting-state functional Magnetic Resonance Imaging (rs-fMRI) serves as a crucial tool in revealing functional connectivity patterns associated with MDD, playing an essential role in precise diagnosis. However, the limited data availability of FC poses challenges for robust MDD diagnosis. To tackle this, some studies have employed Deep Neural Networks (DNN) architectures to construct Generative Adversarial Networks (GAN) for synthetic FC generation, but this tends to overlook the inherent topology characteristics of FC. To overcome this challenge, we propose a novel Graph Convolutional Networks (GCN)-based Conditional GAN with Class-Aware Discriminator (GC-GAN). GC-GAN utilizes GCN in both the generator and discriminator to capture intricate FC patterns among brain regions, and the class-aware discriminator ensures the diversity and quality of the generated synthetic FC. Additionally, we introduce a topology refinement technique to enhance MDD diagnosis performance by optimizing the topology using the augmented FC dataset. Our framework was evaluated on publicly available rs-fMRI datasets, and the results demonstrate that GC-GAN outperforms existing methods. This indicates the superior potential of GCN in capturing intricate topology characteristics and generating high-fidelity synthetic FC, thus contributing to a more robust MDD diagnosis.
Aspect-based sentiment analysis is a fine-grained sentiment analysis task, which needs to detection the sentiment polarity towards a Ygiven aspect. Recently, graph neural models over the dependency tree are widely applied for aspect-based sentiment analysis. Most existing works, however, they generally focus on learning the dependency information from contextual words to aspect words based on the dependency tree of the sentence, which lacks the exploitation of contextual affective knowledge with regard to the specific aspect. In this paper, we propose a graph convolutional network based on SenticNet to leverage the affective dependencies of the sentence according to the specific aspect, called Sentic GCN. To be specific, we explore a novel solution to construct the graph neural networks via integrating the affective knowledge from SenticNet to enhance the dependency graphs of sentences. Based on it, both the dependencies of contextual words and aspect words and the affective information between opinion words and the aspect are considered by the novel affective enhanced graph model. Experimental results on multiple public benchmark datasets illustrate that our proposed model can beat state-of-the-art methods. (C) 2021 Elsevier B.V. All rights reserved.
Due to complex spatial correlations, dynamic temporal trends, and heterogeneities, accurate remaining useful life (RUL) prediction is a challenging task for multi-sensor complex systems. Existing frameworks usually design complex graph convolutional networks (GCNs) for multi-sensor information fusion to capture shared patterns with predefined graphs. However, predefined graphs do not necessarily reflect correct and complete correlations among sensors. Furthermore, dynamic temporal trend extraction based on an iterative mechanism will bring the challenge of error accumulation from a global perspective and ignore the heterogeneous correlations. To overcome these limitations, a novel graph neural network framework, namely, Spatial- temporal Dual-channel Adaptive Graph Convolutional Network (SDAGCN), is proposed for RUL prediction. It mainly consists of dual channels, including the local and global spatial-temporal modules with learnable graphs, which adaptively capture hidden spatial correlations. Benefiting from these two modules, SDAGCN can effectively extract hidden spatial correlations along the local and global time axis and heterogeneities. Finally, the superior performance of our model is verified by two simulated aircraft engine dataset with multiple sensors.
Building indoor dangerous behavior recognition is a specific application in the field of abnormal human recogni-tion. A human dangerous behavior recognition method based on LSTM-GCN with attention mechanism (GLA) model was proposed aiming at the problem that the existing human skeleton-based action recognition methods cannot fully extract the temporal and spatial features. The network connects GCN and LSTM network in series, and inputs the skeleton sequence extracted by GCN that contains spatial information into the LSTM layer for time sequence feature extraction, which fully excavates the temporal and spatial features of the skeleton sequence. Finally, an attention layer is designed to enhance the features of key bone points, and Softmax is used to classify and identify dangerous behaviors. The dangerous behavior datasets are derived from NTU-RGB+D and Kinetics data sets. Experimental results show that the proposed method can effectively identify some dangerous behaviors in the building, and its accuracy is higher than those of other similar methods.
The rapid development in knowledge graph (KG) technology and its popularity in the field of artificial intelligence (AI) have significantly increased the support for similar KG-based applications. However, there is a concerning problem regarding KGs; most of them are often incomplete. This motivated us to study knowledge graph completion (KGC). Some recent studies have used graph neural networks (GNN) such as graph convolutional networks (GCN) to model graph-structured data, providing good results on KGC tasks. However, the edge weights in GCN models are controlled by degree, a measure that moderately ignores the differences among relation information. To address the above limitations and obtain better KGC, we propose a model based on graph attention networks (GATs) and contrastive learning (CL), called the CLGAT-KGC model. This model introduces the graph attention mechanism and adds different representations of entities under the same entity corresponding to different relations to enhance the entity-relation message function. Additionally, a new CL method is proposed under the CLGAT-KGC model to better learn the embedding of entities and relations in the KG domain. We have completely verified the effectiveness of this model through extensive experiments.(c) 2022 Elsevier B.V. All rights reserved.
This study aimed to formulate mucoadhesive antimicrobial nanoparticles using natural antimicrobials and biopolymers for oral health and verify their antimicrobial activity in clinical studies. A combination of grapefruit seed extract and cinnamon oil (GCN) and chitosan/carrageenan (CS/CR) were selected as synergistic antimicrobial combinations and mucoadhesive wall materials for nanoparticles, respectively. GCN nanoparticles (NPs; size = 357 nm and polydispersity index = 0.188) prepared by ionic gelation between CS and CR exhibited synergistic antimicrobial activity between grapefruit seed extract and cinnamon oil and significantly higher antimicrobial activity against Streptococcus mutans and sobrinus than free GCN in a time-kill assay. The clinical antibacterial activity of GCN was significantly increased and sustained by nanoencapsulation in the mouth-rinse test and GCN NP-treated drinking yogurt. These results suggest that GCN-loaded CS/CR nanoencapsulation is a promising technique that can inhibit oral bacteria with or without the presence of other food ingredients.
Online car-hailing has become an indispensable transportation means for residents. The short-term origin and destination (OD) prediction of online car-hailing trips is conducive to understanding the inflow and outflow of online car-hailing trips in a region and provides data support for the delivery and scheduling of vehicles. Accordingly, this article takes the data of car-hailing trips in the central area of Haikou, China, as the research data; makes an in-depth analysis of the regularities of car-hailing trips; and divides the central area of Haikou into 84 grids with a length of 3 km. This article constructs three adjacency matrices, Am01, Sam, and Amn, to reflect the complex spatial relationships of the OD matrixes of online car-hailing from different perspectives. Then, a model, based on the graph convolutional network (GCN) and gated recurrent unit, denoted as the temporal GCN (T-GCN), is introduced for the grid-based short-term OD prediction. The case study in Haikou shows that T-GCNs based on the three adjacency matrices are better than other models, wherein the Amn-based T-GCN is more consistent with the OD flows' spatial relationship, achieves the best prediction performance, and shows that there exists a proportional relationship between flows on different OD pairs. The application of the research results is beneficial for the car-hailing platform to perform the dynamic scheduling of vehicles in advance, further improving the operating efficiency and reducing the waiting time of passengers so as to effectively alleviate the problem of the imbalance between the supply and demand of online car-hailing travel.
Text classification is an important and classic application in natural language processing (NLP). Recent studies have shown that graph neural networks (GNNs) are effective in tasks with rich structural relationships and serve as effective transductive learning approaches. Text representation learning methods based on large-scale pretraining can learn implicit but rich semantic information from text. However, few studies have comprehensively utilized the contextual semantic and structural information for Chinese text classification. Moreover, the existing GNN methods for text classification did not consider the applicability of their graph construction methods to long or short texts. In this work, we propose Chinese-BERTology-wwm-GCN, a framework that combines Chinese bidirectional encoder representations from transformers (BERT) series models with whole word masking (Chinese-BERTology-wwm) and the graph convolutional network (GCN) for Chinese text classification. When building text graph, we use documents and words as nodes to construct a heterogeneous graph for the entire corpus. Specifically, we use the term frequency-inverse document frequency (TF-IDF) to construct the word-document edge weights. For long text corpora, we propose an improved pointwise mutual information (PMI & DBLBOND;) measure for words according to their word co-occurrence distances to represent the weights of word-word edges. For short text corpora, the co-occurrence information between words is often limited. Therefore, we utilize cosine similarity to represent the word-word edge weights. During the training stage, we effectively combine the cross-entropy and hinge losses and use them to jointly train Chinese-BERTology-wwm and GCN. Experiments show that our proposed framework significantly outperforms the baselines on three Chinese benchmark datasets and achieves good performance even with few labeled training sets.
To unravel the role of active site type and its coordination environment in regulating catalytic performance, C2H2 selective hydrogenation over a series of single-atom Pt1/Cu catalysts was fully investigated using DFT calcula-tions and microkinetic modeling. Four types of Pt active site, including the defect, step, corner, and terrace sites with the generalized coordination number (GCN) from 2.5 to 7.5, are examined. Our results indicate that Pt1/Cu catalysts with four types of active sites favor gas phase C2H4 formation in C2H2 hydrogenation process. C2H4 activity has an inverted volcanic-type curve relationship with d-band center and GCN of Pt active site. For the polymerization process, the corner and terrace sites with larger GCN values could prevent green oil. The screened PtGCN3.0 catalyst with corner site exhibits better C2H4 selectivity and activity and prevents green oil. Hence, tuning the type and GCN value of Pt active site well regulate C2H4 activity and selectivity, as well as catalyst stability, which provide useful structure information to rationally design Pt-based catalysts in C2H2 selective hydrogenation.
As human actions can be characterized by the trajectories of skeleton joints, skeleton-based action recognition techniques have gained increasing attention in the field of intelligent recognition and behavior analysis. With the emergence of large datasets, graph convolutional network (GCN) approaches have been widely applied for skeleton-based action recognition and have achieved remarkable performances. In this paper, a novel GCN-based approach is proposed by introducing a convolutional block attention module (CBAM)-based graph attention block to compute the semantic correlations between any two vertices. By considering semantic correlations, our model can effectively identify the most discriminative vertex connections associated with specific actions, even when the two vertices are physically unconnected. Experimental results demonstrate that the proposed model is effective and outperforms existing methods.
In pristine graphitic carbon nitride (g-CN), amino groups often function as structural defects that trap photogenerated charges, resulting in low photocatalytic activity as well as reaction with nitrite, aldehyde, etc., ensuing in poor product yield. Without significantly altering the optical characteristics, the removal of amino groups is necessary to increase the photocatalytic activity and structural stability of pristine g-CN. The deamino graphitic carbon nitride (DA-gCN-5) was prepared by tert-butyl nitrite (TBN)treatment, characterized and used as a photocatalyst for the radical C-H arylation of heteroarenes using anilines as radical source. Indeed, the photophysical characteristics of DA-gCN-5 and those of pristine g-CN are very comparable, except that DA-gCN-5 has a fewer residual amino groups, higher crystallinity, and compressed structure with a different morphology. Moreover, DA-gCN-5- catalyzed C-H arylation reaction offers greater product yield in a shorter reaction time compared to that of pristine g-CN in the coupling between heteroarenes and the in situ generated aryl diazonium salts from anilines under visible light irradiation. The amino groups in pristine g-CN absorbed the TBN that was added to convert aniline into the appropriate diazonium ions during the reaction. As a result, deamino graphitic carbon nitride produced by chemical treatment has better photophysical properties and catalytic activity than pristine g-CN. Additionally, this is the first method that uses diazotization reaction for the preparation of deamino graphitic carbon nitride, as far as we are aware.
Machine-learned ranking models have been developed for the prediction of substrate-specific cross-coupling reaction conditions. Data sets of published reactions were curated for Suzuki, Negishi, and C-N couplings, as well as Pauson-Khand reactions. String, descriptor, and graph encodings were tested as input representations, and models were trained to predict the set of conditions used in a reaction as a binary vector. Unique reagent dictionaries categorized by expert-crafted reaction roles were constructed for each data set, leading to context-aware predictions. We find that relational graph convolutional networks and gradient-boosting machines are very effective for this learning task, and we disclose a novel reaction-level graph attention operation in the top-performing model.
The demand for high-energy storage supercapacitors with appropriate designs has been emerging in recent times. Aimed at enhancing the electrochemical storage performance of supercapacitors, g-C3N4/WO3(H2O)0.33 (GCN/ WO) nanostructures have been prepared in a simple wet impregnation process by mixing the synthesized g-C3N4, and WO3(H2O)0.33 materials and their performances were compared systematically with their individual components. The successful formation of C3N4/WO3(H2O)0.33 nanostructure has been confirmed by the XRD, SEM, EDS, HR-TEM, HAADF and XPS spectroscopy analyses. The prepared GCN/WO nanostructures showed greater specific capacitance of 466.88C g-1 at 1.5 A g-1 than their counterparts (GCN 87.87C g-1 and WO 140.64C g-1) with remarkable cyclic stability of 98.6% over 10000 cycles. Notably, the fabricated hybrid asymmetric supercapacitor devices (HASDs) exhibited ultrahigh power density of 255.23 W kg-1 at energy density of 10.07 Wh kg-1. The enhanced electrochemical capacitor characteristics of GCN/WO nanostructures could be attributed to the positive synergistic effect of GCN and WO. Thus, the strategy utilizing this synergistic effect between GCN and WO in a simple impregnation process is a viable alternative to fabricate the high capacitance electrodes for application in supercapacitors.
Fast oil recovery from the ocean after an oil spill is crucial before permanent damage happens to the ecological balance and marine life. Sorbents that are usually used to recover oil from water are not environmentally friendly and involve complicated synthesis routes. Against this backdrop, we have discovered that pristine porous graphitic carbon nitride (GCN), as developed here via a one-step one precursor (i.e., melamine) facile synthesis route, is a high-capacity and stable oil sorbent. The GCN, sans any additive/support, has exhibited > 100% oil adsorption, at a rapid rate, for different types of oils from the surface of as-prepared artificial sea water; with the capability of it being reused multiple times, without any detectable change in the structure or drop in adsorption %, after simply burning off the adsorbed oil in air. As established here, the 'oil take-up' happens via physisorption, sans any chemical reaction/change of GCN structure/bonds post-adsorption, which renders the sorbent material highly stable. Hence, this work demonstrates the superior oil adsorption capabilities of easy-to-synthesize, scalable, and environmentally friendly GCN, toward a straightforward, eco-friendly, and widespread oil recovery solution. [GRAPHICS] .
Machine learning methods are becoming increasingly popular to anticipate critical risks in patients under surveillance reducing the burden on caregivers. In this paper, we propose an original modeling that benefits of recent developments in Graph Convolutional Networks: a patient's journey is seen as a graph, where each node is an event and temporal proximities are represented by weighted directed edges. We evaluated this model to predict death at 24 hours on a real dataset and successfully compared our results with the state of the art.
This research endeavor aims to fabricate a novel ternary heterojunction interface to enhance photoelectrochemical water Oxidation. ZnSe/GCN/MoS2 heterostructure series is prepared via the ultrasonication method. Confirmation of as-prepared heterostructures was done through FTIR, XRD, SEM, EDS, XPS, Raman, UVDRS, and PL techniques. The best photoresponse among the ternary series was found for 1% ZnSe/GCN/MoS2 (1ZGM), showing the highest photocurrent density of 1.73 mA during linear sweep voltammetric studies. This is an increase of 7 times in the photoresponse than the pure GCN. These outcomes are reinforced by the EIS results, showing the smallest semicircle for 1ZGM in a Nyquist plot and an enhanced lifetime of 100.7 ms in a bode plot. The smallest Tafel slope, higher donor density, and reduced electron-hole recombination, suggest that a ternary heterojunction is successfully fabricated for PEC water oxidation.
Despite extensive research, 3D face reconstruction from a single image remains an open research prob-lem due to the high degree of variability in pose, occlusions and complex lighting conditions. While deep learning-based methods have achieved great success, they are usually limited to near frontal images and images that are free of occlusions. Also, the lack of diverse training data with 3D annotations considerably limits the performance of such methods. As such, existing methods fail to recover, with high fidelity, the facial details especially when dealing with images captured under extreme conditions. To address this issue, we propose an unsupervised coarse-to-fine framework for the reconstruction of 3D faces with detailed textures. Our core idea is that multiple images of the same person but captured under different viewing conditions should provide the same 3D face. We thus propose to leverage a self-augmentation learning technique to train a model that is robust to diverse variations. In addition, instead of directly employing image pixels, we use a set of discriminative features describing the identity and attributes of the face as input to the refinement module, making the model invariant to viewing conditions. This combination of self-augmentation learning with rich face-related features allows the reconstruction of plausible facial details even under challenging viewing conditions. We train the model end-to-end and in a self-supervised manner, without any 3D annotations, landmarks or identity labels, using a combina-tion of an image-level photometric loss and a perception-level loss that is identity and attribute-aware. We evaluate the proposed approach on CelebA and AFLW2000 datasets, and demonstrate its robustness to appearance variations despite learning from unlabeled images. The qualitative comparisons indicate that our method produces detailed 3D faces even under extreme occlusions, out of plane rotations and noise perturbations where existing state-of-the-art methods often fail. We also quantitatively show that our method outperforms SOTA with more than 30.14%, 9.87% and 11.3% in terms of PSNR, SSIM and IDentity similarity, respectively. (c) 2022 Elsevier B.V. All rights reserved.
Water ecosystems are highly sensitive to environmental conditions, including meteorological factors, which influence dissolved oxygen (DO) concentrations, a critical indicator of water quality. However, the complex relationships between multiple meteorological factors from various sites and DO concentrations pose a significant challenge for accurate prediction. This study introduces an innovative framework for enhancing DO concentration predictions in water bodies by integrating multi-station meteorological data. We first construct a dynamic meteorological graph with station-specific factors as node features and geographic distances as edge weights. This graph is processed using a Geo-Contextual Graph Embedding Module, leveraging a Graph Convolutional Network (GCN) to distill geographical and meteorological features from multi-station data. Extracted features are encoded and then temporally merged with historical DO values to form time-series data. Finally, a Temporal Transformer module is used for future DO concentration predictions. The proposed model shows superior performance compared to traditional methods, successfully capturing the complex relationships between meteorological factors and DO levels. It provides an effective tool for environmental scientists and policymakers in water quality monitoring and management. This study suggests that the integration of graph-based learning and a Temporal Transformer in environmental modeling is a promising direction for future research.
Establishing the structure-property relationship by machine learning (ML) models is extremely valuable for accelerating the molecular design of polymers. However, existing ML models for the polymers are subject to scarcity issues of training data and fewer variations of graph structures of molecules. In addition, limited works have explored the interpretability of ML models to infer the latent knowledge in the field of polymer science that could inspire ML-assisted molecular design. In this contribution, we integrate graph convolutional neural networks (GCNs) with data augmentation strategy to predict the glass transition temperature T-g of polymers. It is demonstrated that the data-augmented GCN model outperforms the conventional models and achieves a higher accuracy for the prediction of T-g despite a small amount of training data. Furthermore, taking advantage of molecular graph representations, the data-augmented GCN model has the capability to infer the importance of atoms or substructures from the understanding of T-g, which generally agrees with the experimental findings in the field of polymer science. The inferred knowledge of the GCN model is used to advise on the design of functional polymers with specific T-g. The data-augmented GCN model possesses prominent superiorities in the establishment of structure-property relationship and also provides an efficient way for accelerating the rational design of polymer molecules.
Graphs are widely used to model various practical applications. In recent years, graph convolution networks (GCNs) have attracted increasing attention due to the extension of convolution operation from traditional grid data to graph one. However, the representation ability of current GCNs is undoubtedly limited because existing work fails to consider feature interactions. Toward this end, we propose a Dual Feature Interaction-based GCN. Specifically, it models feature interaction in the aspects of 1) node features where we use Newton's identity to extract different-order cross features implicit in the original features and design an attention mechanism to fuse them; and 2) graph convolution where we capture the pairwise interactions among nodes in the neighborhood to expand a weighted sum operation. We evaluate the proposed model with graph data from different fields, and the experimental results on semi-supervised node classification and link prediction demonstrate the effectiveness of the proposed GCN. The data and source codes of this work are available at https://github.com/ZZY-GraphMiningLab/DFI-GCN.
Sparse tensor-times-vector (SpTV) is the core computation of tensor decomposition. Optimizing the computational performance of SpTV on CPU-GPU becomes a challenge due to the complexity of the non-zero element sparse distribution of the tensor. To solve this problem, we propose IAP-SpTV, an input aware adaptive pipeline SpTV via Graph Convolutional Network (GCN) on CPU-GPU. We first design the hybrid tensor format (HTF) and explore the challenges of the HTF-based Pipeline SpTV algorithm. Second, we construct Slice-GCN to overcome the challenge of selecting a suitable format for each slice of HTF. Third, we construct an IAP-SpTV performance model for pipelining to achieve the maximum overlap between transfer and computation time during pipelining. Finally, we conduct experiments on two CPU-GPU platforms of different architectures to verify the correctness, effectiveness, and portability of IAP-SpTV. Overall, IAP-SpTV provides a significant performance improvement of about 24.85% to 58.42% compared to the state-of-the-art method.& COPY; 2023 Elsevier Inc. All rights reserved.
Incorporating knowledge graphs (KGs) into recommender systems to provide explainable recommendation has attracted much attention recently. The multi-hop paths in KGs can provide auxiliary facts for improving recommendation performance as well as explainability. However, existing studies may suffer from two major challenges: error propagation and weak explainability. Considering all paths between every user-item pair might involve irrelevant ones, which leads to error propagation of user preferences. Defining meta-paths might alleviate the error propagation, but the recommendation performance would heavily depend on the pre-defined meta-paths. Some recent methods based on graph convolution network (GCN) achieve better recommendation performance, but fail to provide explainability. To tackle the above problems, we propose a novel method named Knowledge-aware Reasoning with Graph Convolution Network (KR-GCN). Specifically, to alleviate the effect of error propagation, we design a transition-based method to determine the triple-level scores and utilize nucleus sampling to select triples within the paths between every user-item pair adaptively. To improve the recommendation performance and guarantee the diversity of explanations, user-item interactions and knowledge graphs are integrated into a heterogeneous graph, which is performed with the graph convolution network. A path-level self-attention mechanism is adopted to discriminate the contributions of different selected paths and predict the interaction probability, which improves the relevance of the final explanation. Extensive experiments conducted on three real-world datasets show that KR-GCN consistently outperforms several state-of-the-art baselines. And human evaluation proves the superiority of KR-GCN on explainability.
A novel heterojunction between Sn-based perovskite and graphitic carbon nitride (gCN) is synthesized to achieve an enhanced spatial charge separation. The interfacial coupling between cube-shaped nickel tin oxide (NSO) and gCN is achieved through the surface sites in NSO. An improved hydrogen production rate of 646 & mu;mol g-1 h-1 is measured in the composite (NSO-gCN), which is twice that in gCN, using triethanolamine (TEOA) and chlor-oplatinic acid (1% w/w) as holes scavenger and the precursor for the Pt cocatalyst, respectively. Such significant improvement in H2 production performance of the composite is benefited by the high reductive electrons generated via an S-scheme charge transfer pathway, as evidenced by radical trapping experiments and XPS elemental analysis. The composite shows good stability in hydrogen evolution, with marginal (3%) decrease measured in the materials activity after 5 cycles. This study provides an opportunity to develop an S-scheme heterojunction with the Sn-based perovskite anchored in gCN, as an alternative to Ti-based perovskite for various photocatalytic reactions.
Human motion prediction is challenging due to the complex spatiotemporal feature modeling. Among all methods, graph convolution networks (GCNs) are extensively utilized because of their superiority in explicit connection modeling. Within a GCN, the graph correlation adjacency matrix drives feature aggregation, and thus, is the key to extracting predictive motion features. State-of-the-art methods decompose the spatiotemporal correlation into spatial correlations for each frame and temporal correlations for each joint. Directly parameterizing these correlations introduces redundant parameters to represent common relations shared by all frames and all joints. Besides, the spatiotemporal graph adjacency matrix is the same for different motion samples, and thus, cannot reflect samplewise correspondence variances. To overcome these two bottlenecks, we propose dynamic spatiotemporal decompose GC (DSTD-GC), which only takes 28.6% parameters of the state-of-the-art GC. The key of DSTD-GC is constrained dynamic correlation modeling, which explicitly parameterizes the common static constraints as a spatial/temporal vanilla adjacency matrix shared by all frames/joints and dynamically extracts correspondence variances for each frame/joint with an adjustment modeling function. For each sample, the common constrained adjacency matrices are fixed to represent generic motion patterns, while the extracted variances complete the matrices with specific pattern adjustments. Meanwhile, we mathematically reformulate GCs on spatiotemporal graphs into a unified form and find that DSTD-GC relaxes certain constraints of other GC, which contributes to a better representation capability. Moreover, by combining DSTDGC with prior knowledge like body connection and temporal context, we propose a powerful spatiotemporal GCN called DSTD-GCN. On the Human3.6M, Carnegie Mellon University (CMU) Mocap, and 3D Poses in the Wild (3DPW) datasets, DSTD-GCN outperforms state-of-the-art methods by 3.9%-8.7% in prediction accuracy with 55.0%-96.9% fewer parameters. Codes are available at https://github.com/Jaakk0F/DSTD-GCN.
Most rumor detection methods extract the features of rumor through two aspects of text semantics and propagation structure to achieve automatic rumor classification, while most of the existing methods do not realize that false and irrelevant interactions in the propagation structure will reduce the accuracy of rumor detection. In addition, most of the existing rumor detection methods failed to effectively extract key clues from the comments of social network users. In response to these phenomena, this article proposes a social network rumor detection method combining a dual attention mechanism and graph convolutional network (GCN) (dual-attention GCN, DA-GCN). First, build an event propagation graph; then, the GCN is used to extract the propagation structure information of each event-related microblog (tweet), and the attention mechanism is combined to suppress the false and irrelevant interactive relationships. Therefore, the anti-interference propagation structure features are extracted from the propagation graph. Second, to fully utilize the clues in users' comments, this article makes use of the attention mechanism to fuse source microblog (tweet) with the comment-retweet information and extract interactive semantic features from it. Finally, the above two features are fused to generate a new event representation. Experimental results show that the proposed DA-GCN has an accuracy of 94.4%, 90.5%, and 90.2% on the Weibo dataset, the Twitter15 dataset, and the Twitter16 dataset, respectively, and has achieved excellent performance in the early rumor detection task, which proves that the proposed method is reasonable and effective.
Featured ApplicationProtein and peptide identification based on tandem mass spectrometry is a pillar technology in proteomics research. In recent years, increasing numbers of researchers have utilized deep learning to tackle challenges in proteomics. For example, catalyzed by deep learning, AlphaFold has achieved unparalleled levels of accuracy in protein-structure prediction. Prior to studying the structure and function of proteins in cells or tissues, it is essential to determine the sequences of amino acids in peptides or proteins. De novo peptide sequencing can be used to directly infer the peptide sequence from a tandem mass spectrum without the requirement for a reference sequence database, making it particularly suitable for the determination of protein sequences of unknown species, monoclonal antibodies, and cancer neoantigens.The de novo peptide-sequencing method can be used to directly infer the peptide sequence from a tandem mass spectrum. It has the advantage of not relying on protein databases and plays a key role in the determination of the protein sequences of unknown species, monoclonal antibodies, and cancer neoantigens. In this paper, we propose a method based on graph convolutional neural networks and convolutional neural networks, Denovo-GCN, for de novo peptide sequencing. We constructed an undirected graph based on the mass difference between the spectral peaks in a tandem mass spectrum. The features of the nodes on the spectrum graph, which represent the spectral peaks, were the matching information of the peptide sequence and the mass spectrum. Next, the Denovo-GCN used CNN to extract the features of the nodes. The correlation between the nodes was represented by an adjacency matrix, which aggregated the features of neighboring nodes. Denovo-GCN provides a complete end-to-end training and prediction framework to sequence patterns of peptides. Our experiments on various data sets from different species show that Denovo-GCN outperforms DeepNovo with a relative improvement of 13.7-25.5% in terms of the peptide-level recall.
Traffic prediction is an important part of intelligent transportation system. Recently, graph convolution network (GCN) is introduced for traffic flow forecasting and achieves good performance due to its superiority of representing the graph traffic road structure network. Moreover, the dynamic GCN is put forward to model the temporal property of the traffic flow. Although great progress has been made, most GCN based traffic flow forecasting methods utilize a single graph for convolution, which is considered not enough to reveal the inherent property of traffic graph as it is influenced by many factors, for example weather, season and traffic accidents etc. In this paper, an exotic graph transformer based dynamic multiple graph convolution networks (GTDMGCN) is conceived for traffic flow forecasting. Instead of the single graph, multiple graphs are constructed to modulate the complex traffic network by the proposed graph transformer network. Additionally, a temporal gate convolution is proposed to get the temporal property of traffic flow. The proposed GTDMGCN model is evaluated on four real traffic datasets of PEMS03, PEMS04, PEMS07, PEMS08, and there are average increments of 9.78%, 7.80%, 5.96% under MAE, RMSE, and MAPE metrics compared with the current results.
Synthesis of 2D carbon-based layered structures materials is highly desirable for higher-photocatalytic activities. Here in this regard, we use commercially exhausted urea for the fabrication activated carbons and graphitic carbon nitride (GCN) layered structures doped with sulphur to accumulate activated carbon with S for pollutants degradation using the thermal decomposition method. The synthesized material contains activated carbon in a small amount, which does not accumulate with nitrogen to form GCN and cause a higher energy bandgap (3.31 eV - 3.38 eV). However, through S, we have modified the bandgap and reduced it to (2.84 eV - 3.06 eV) for visible light. The S with activated carbon system along with GCN enhances the synergetic contribution in degradation. The reaction constant (K) is increased from (3.5 x 10-3 - 4.1 x 10-2) owing to synergic effect. Most notably, a significant amount of sulphur accumulated with activated carbon and GCN, altered the charge transfer route and enhanced optical absorption and higher photocatalytic activity, and i considered a novel approach for environmental remediation.
Chemisorption is an effective method to remove Hg0 from coal-fired flue gas. During this process, Hg0 will convert to Hg2+ and be solidified on sorbent surface. The number of adsorption sites and the electron transfer between Hg0 and sorbents play an important role in the removal process. In the present work, GO with a rapid electron transfer was compounded with NS-g-C3N4 to improve the electron donating ability of NS-g-C3N4. After that, Co3O4 nanosheets were grown in-situ in the interlayer space of GO and NS-g-C3N4 composites. A series of sorbents were successfully synthesized by changing GO concentration. SEM and TEM results show that the corresponding Co3O4/GCN (GCN denote the GO and NS-g-C3N4 composites) sorbent has better Co3O4 nanosheet dispersibility when GO concentration is 5 mg/mL. This results in a large amount of chemisorbed oxygen, which is favor to the oxidation of Hg0 to HgO. In addition, XPS results show that the interaction between Co3O4 and GCN give a rapid electrons transfer from GCN to Co3O4, thus improving the activation of gaseous oxygen. Therefore, Co3O4/GCN-5 has excellent Hg0 removal efficiency of about 95 % at 200 degrees C and high stability under different flue gas conditions. A probable reaction path way was deduced by the results of XPS and Hg0 adsorption-desorption experiment.
Graphitic carbon nitride (gCN) is a promising n-type semiconductor widely investigated for photo-assisted water splitting, but less studied for the (photo)electrochemical degradation of aqueous organic pollutants. In these fields, attractive perspectives for advancements are offered by a proper engineering of the material properties, e.g., by depositing gCN onto conductive and porous scaffolds, tailoring its nanoscale morphology, and functionalizing it with suitable cocatalysts. The present study reports on a simple and easily controllable synthesis of gCN flakes on Ni foam substrates by electrophoretic deposition (EPD), and on their eventual decoration with Co-based cocatalysts [CoO, CoFe2O4, cobalt phosphate (CoPi)] via radio frequency (RF)-sputtering or electrodeposition. After examining the influence of processing conditions on the material characteristics, the developed systems are comparatively investigated as (photo)anodes for water splitting and photoelectrocatalysts for the degradation of a recalcitrant water pollutant [potassium hydrogen phthalate (KHP)]. The obtained results highlight that while gCN decoration with Co-based cocatalysts boosts water splitting performances, bare gCN as such is more efficient in KHP abatement, due to the occurrence of a different reaction mechanism. The related insights, provided by a multi-technique characterization, may provide valuable guidelines for the implementation of active nanomaterials in environmental remediation and sustainable solar-to-chemical energy conversion.
IntroductionAlthough the method of visualizing eye-tracking data as a time-series might enhance performance in the understanding of gaze behavior, it has not yet been thoroughly examined in the context of rapid automated naming (RAN). MethodsThis study attempted, for the first time, to measure gaze behavior during RAN from the perspective of network-domain, which constructed a complex network [referred to as gaze-time-series-based complex network (GCN)] from gaze time-series. Hence, without designating regions of interest, the features of gaze behavior during RAN were extracted by computing topological parameters of GCN. A sample of 98 children (52 males, aged 11.50 +/- 0.28 years) was studied. Nine topological parameters (i.e., average degree, network diameter, characteristic path length, clustering coefficient, global efficiency, assortativity coefficient, modularity, community number, and small-worldness) were computed. ResultsFindings showed that GCN in each RAN task was assortative and possessed "small-world" and community architecture. Additionally, observations regarding the influence of RAN task types included that: (i) five topological parameters (i.e., average degree, clustering coefficient, assortativity coefficient, modularity, and community number) could reflect the difference between tasks N-num (i.e., naming of numbers) and N-cha (i.e., naming of Chinese characters); (ii) there was only one topological parameter (i.e., network diameter) which could reflect the difference between tasks N-obj (i.e., naming of objects) and N-col (i.e., naming of colors); and (iii) when compared to GCN in alphanumeric RAN, GCN in non-alphanumeric RAN may have higher average degree, global efficiency, and small-worldness, but lower network diameter, characteristic path length, clustering coefficient, and modularity. Findings also illustrated that most of these topological parameters were largely independent of traditional eye-movement metrics. DiscussionThis article revealed the architecture and topological parameters of GCN as well as the influence of task types on them, and thus brought some new insights into the understanding of RAN from the perspective of complex network.
Background: There has been a growing interest in discovering a viable drug for the new coronavirus (SARS-CoV-2) since the beginning of the pandemic. Protein-ligand interaction studies are a crucial step in the drug discovery process, as it helps us narrow the search space for potential ligands with high drug-likeness. Derivatives of popular drugs like Remdesivir generated through tools employing evolutionary algorithms are usually considered potential candidates. However, screening promising molecules from such a large search space is difficult. In a conventional screening process, for each ligand-target pair, there are time-consuming interaction studies that use docking simulations before downstream tasks like thermodynamic, kinetic, and electrostatic-potential evaluation.Objective :This work aims to build a model based on deep learning applied over the graph structure of the molecules to accelerate the screening process for novel potential candidates for SARS-CoV-2 by predicting the binding energy of the protein-ligand complex.Methods :In this work, 'Graph Convolutional Capsule Regression' (GCCR), a model which uses Capsule Neural Networks (CapsNet) and Graph Convolutional Networks (GCN) to predict the binding energy of a protein-ligand complex is being proposed. The model's predictions were further validated with kinetic and free energy studies like Molecular Dynamics (MD) for kinetic stability and MM/GBSA analysis for free energy calculations.Results :The GCCR showed an RMSE value of 0.0978 for 81.3% of the concordance index. The RMSE of GCCR converged around the iteration of just 50 epochs scoring a lower RMSE than GCN and GAT. When training with Davis Dataset, GCCR gave an RMSE score of 0.3806 with a CI score of 87.5%.Conclusion :The proposed GCCR model shows great potential in improving the screening process based on binding affinity and outperforms baseline machine learning models like DeepDTA, KronRLS, SimBoost, and other Graph Neural Networks (GNN) based models like Graph Convolutional Networks (GCN) and Graph Attention Networks (GAT).
Unbalanced interaction relationships at personal and group levels play a pivotal role in collective activity recognition, which has not been adaptively and jointly explored by previous approaches. In this paper, we propose a graph attention interaction model (GAIM) embedded with the graph attention block (GAB) to explicitly and adaptively infer unbalanced interaction relations at personal and group levels in a unified architecture, and further to learn the spatial and temporal evolutions of the collective activity from these interactions to predict the activity labels. We first design the spatiotemporal graphs tailored to the collective activity where the concurrent person and group nodes, respectively, represent individuals' actions and the collective activity. The graphs provide both spatial structures and semantic appearance features for the collective activity. Then, GAB performs convolution-like filters on the graphs to infer unequal and two-level interaction relations in the collective activity by implementing graph convolutional networks with a shared attention mechanism. At the personal level, the GAB learns different levels of interactions for each person node from its neighbor person nodes under the guidance from the group node. At the group level, the GAB assesses various degrees of interactions to the group node contributed by person nodes. Equipped with the GRUs network, the GAIM learns the spatial and temporal evolutions of individuals' actions as well as the collective activity from the captured interactions, and finally predicts the label of the collective activity. Experiments on four publicly available datasets and ablation studies are conducted to evaluate the performance of our GAIM, and the improved performance demonstrates the effectiveness of our model.
Disease prediction is a well-known classification problem in medical applications. Graph Convolutional Networks (GCNs) provide a powerful tool for analyzing the patients' features relative to each other. This can be achieved by modeling the problem as a graph node classification task, where each node is a patient. Due to the nature of such medical datasets, class imbalance is a prevalent issue in the field of disease prediction, where the distribution of classes is skewed. When the class imbalance is present in the data, the existing graph-based classifiers tend to be biased towards the major class(es) and neglect the samples in the minor class(es). On the other hand, the correct diagnosis of the rare positive cases (true-positives) among all the patients is vital in a healthcare system. In conventional methods, such imbalance is tackled by assigning appropriate weights to classes in the loss function which is still dependent on the relative values of weights, sensitive to outliers, and in some cases biased towards the minor class(es). In this paper, we propose a Re-weighted Adversarial Graph Convolutional Network (RA-GCN) to prevent the graph-based classifier from emphasizing the samples of any particular class. This is accomplished by associating a graph-based neural network to each class, which is responsible for weighting the class samples and changing the importance of each sample for the classifier. Therefore, the classifier adjusts itself and determines the boundary between classes with more attention to the important samples. The parameters of the classifier and weighting networks are trained by an adversarial approach. We show experiments on synthetic and three publicly available medical datasets. Our results demonstrate the superiority of RA-GCN compared to recent methods in identifying the patient's status on all three datasets. The detailed analysis of our method is provided as quantitative and qualitative experiments on synthetic datasets. (c) 2021 Elsevier B.V. All rights reserved.
Due to the cost and complexity of biological experiments, many computational methods have been proposed to predict potential miRNA-disease associations by utilizing known miRNA-disease associations and other related information. However, there are some challenges for these computational methods. First, the relationships between miRNAs and diseases are complex. The computational network should consider the local and global influence of neighborhoods from the network. Furthermore, predicting disease-related miRNAs without any known associations is also very important. This study presents a new computational method that constructs a heterogeneous network composed of a miRNA similarity network, disease similarity network, and known miRNA-disease association network. The miRNA similarity considers the miRNAs and their possible families and clusters. The information of each node in heterogeneous network is obtained by aggregating neighborhood information with graph convolutional networks (GCNs), which can pass the information of a node to its intermediate and distant neighbors. Disease-related miRNAs with no known associations can be predicted with the reconstructed heterogeneous matrix. We apply 5-fold cross-validation, leave-one-disease-out cross-validation, and global and local leave-one-out cross-validation to evaluate our method. The corresponding areas under the curves (AUCs) are 0.9616, 0.9946, 0.9656, and 0.9532, confirming that our approach significantly outperforms the state-of-the-art methods. Case studies show that this approach can effectively predict new diseases without any known miRNAs.
Network embedding has been an effective tool to analyze heterogeneous networks (HNs) by representing nodes in a low-dimensional space. Although many recent methods have been proposed for representation learning of HNs, there is still much room for improvement. Random walks based methods are currently popular methods to learn network embedding; however, they are random and limited by the length of sampled walks, and have difficulty capturing network structural information. Some recent researches proposed using meta paths to express the sample relationship in HNs. Another popular graph learning model, the graph convolutional network (GCN) is known to be capable of better exploitation of network topology, but the current design of GCN is intended for homogenous networks. This paper proposes a novel combination of meta-graph and graph convolution, the meta-graph based graph convolutional networks (MGCN). To fully capture the complex long semantic information, MGCN utilizes different meta-graphs in HNs. As different meta-graphs express different semantic relationships, MGCN learns the weights of different meta-graphs to make up for the loss of semantics when applying GCN. In addition, we improve the current convolution design by adding node self-significance. To validate our model in learning feature representation, we present comprehensive experiments on four real-world datasets and two representation tasks: classification and link prediction. WMGCN's representations can improve accuracy scores by up to around 10% in comparison to other popular representation learning models. What's more, WMGCN'feature learning outperforms other popular baselines. The experimental results clearly show our model is superior over other state-of-the-art representation learning algorithms.
Due to the high dimensionality and sparsity of the gene expression matrix in single-cell RNA-sequencing (scRNA-seq) data, coupled with significant noise generated by shallow sequencing, it poses a great challenge for cell clustering methods. While numerous computational methods have been proposed, the majority of existing approaches center on processing the target dataset itself. This approach disregards the wealth of knowledge present within other species and batches of scRNA-seq data. In light of this, our paper proposes a novel method named graph-based deep embedding clustering (GDEC) that leverages transfer learning across species and batches. GDEC integrates graph convolutional networks, effectively overcoming the challenges posed by sparse gene expression matrices. Additionally, the incorporation of DEC in GDEC enables the partitioning of cell clusters within a lower-dimensional space, thereby mitigating the adverse effects of noise on clustering outcomes. GDEC constructs a model based on existing scRNA-seq datasets and then applying transfer learning techniques to fine-tune the model using a limited amount of prior knowledge gleaned from the target dataset. This empowers GDEC to adeptly cluster scRNA-seq data cross different species and batches. Through cross-species and cross-batch clustering experiments, we conducted a comparative analysis between GDEC and conventional packages. Furthermore, we implemented GDEC on the scRNA-seq data of uterine fibroids. Compared results obtained from the Seurat package, GDEC unveiled a novel cell type (epithelial cells) and identified a notable number of new pathways among various cell types, thus underscoring the enhanced analytical capabilities of GDEC.Availability and implementation: https://github.com/YuzhiSun/GDEC/tree/main
Graphitic carbon nitride (GCN) has been demonstrated to be a potential visible-light-driven photocatalyst for eliminating organic pollutants. However, its practical application is limited by low photocatalytic effi-ciency originating from high recombination of photogenerated charges. In this work, the electronic struc-ture of GCN was regulated by doping aminobenzaldehyde (ABA) into the skeleton through a solid-state Schiff base reaction. Photoelectrochemical characterizations illustrated that the obtained catalyst (CNABA) exhibited narrower band gap, lower recombination rate of photoinduced electron-hole pair and higher charge transfer ability than the pristine GCN, further indicating its excellent photocatalytic activity. Using moxifloxacin (MOX) as a model pollutant, the ABA doping content was firstly optimized and the optimal activity of the CNABA photocatalyst was 3.1 times higher than that of the GCN. Subsequently, the effects of pH value, photocatalyst dosage and MOX concentration on the photocatalytic behavior were also studied. Superior stability and photocatalytic reusability were confirmed by five repeated tests. By substituting tap water/natural lake water for deionized water and sunlight for xenon light, the CNABA also exhibited high elimination efficiency, implying its good practicability. Superoxide radical, hydroxyl radical and photogenerated hole were identified as the main active species to degrade MOX. Finally, possible degradation pathways for MOX to mineralize small molecules were proposed by determining intermediate products during photocatalysis. This work provides a solid-state method to rationally design aromatic system-modified GCN photocatalysts, and the obtained CNABA is a promising visible-light-driven photocatalyst for eliminating antibiotics.(c) 2022 Elsevier Inc. All rights reserved.
The rational design of PROTACs is difficult due to their obscure structure-activity relationship. This study introduces a deep neural network model - DeepPROTACs to help design potent PROTACs molecules. It can predict the degradation capacity of a proposed PROTAC molecule based on structures of given target protein and E3 ligase. The experimental dataset is mainly collected from PROTAC-DB and appropriately labeled according to the DC50 and Dmax values. In the model of DeepPROTACs, the ligands as well as the ligand binding pockets are generated and represented with graphs and fed into Graph Convolutional Networks for feature extraction. While SMILES representations of linkers are fed into a Bidirectional Long Short-Term Memory layer to generate the features. Experiments show that DeepPROTACs model achieves 77.95% average prediction accuracy and 0.8470 area under receiver operating characteristic curve on the test set. DeepPROTACs is available online at a web server (https://bailab.siais.shanghaitech.edu.cn/services/deepprotacs/) and at github (https://github.com/fenglei104/DeepPROTACs).
As a fine-grained and challenging subtask in the natural language processing (NLP) community, aspectbased sentiment analysis (ABSA) aims to predict the sentiment polarity towards a given aspect term. In previous ABSA research, most works utilized the pre-trained language model (PLM) as the backbone of their proposed methods, without any specific task-related instructions. Besides, some works focused on learning the dependency information or the external knowledge-enhanced dependency information separately, which lacked the exploitation of the mutual interaction between the normal dependency and knowledge-enhanced dependency. Therefore, we propose a novel ABSA method namely prompted representation joint contrastive learning enhanced graph convolutional networks (PRCL-GCN) to strengthen the robustness of the ABSA model. Specifically, to achieve the task-oriented contextual representation, we design the task-specific prompt template to guide the fine-tuning process of PLM in the ABSA task. And a biaffine attention mechanism is employed to further extract the essential sentiment feature from the prompted representation. Moreover, we introduce the syntax dependency graph as prior knowledge, and construct an affective syntactic dependency graph by injecting the affective knowledge from SenticNet into the graph. Then, we utilize the multi-layer GCNs to process the above two syntactic graphs independently, which aims to learn multi-granularity syntactic features. Subsequently, a novel designed attention variant is leveraged to integrate these syntax features with the guided contextual representation, separately. Eventually, through designing a Kullback-Leibler divergencebased contrastive learning to encourage the model's learning, we improve the model's accuracy in modeling contextual representation by integrating the designed dual-ways information. Extensive experiments are conducted on five benchmark datasets, and the outstanding experiment results validate the effectiveness of our proposed model.
The diagnosis of chest diseases is a challenging task for assessing thousands of radiology subjects. Their diagnosis decisions heavily rely on the expert radiologists' manual annotations. It is important to develop automated analysis methods for the computer-aided diagnosis of chest diseases on chest radiography. To explore the label relationship and improve the diagnosis performance, we present an end-to-end multi-label learning framework for jointly modeling the global and local label correlation, called GL-MLL that (1) explores the label correlation from a globally static view and a locally adaptive view, (2) considers the imbalanced class distribution, and (3) focuses on capturing label-specific features in image-level representation. We validate the performance of the proposed framework on the CheXpert dataset. The results demonstrate that the proposed GL-MLL outperforms state-of-the-art approaches. The code is available at https://github.com/llt1836/GL-MLL.
Graph neural networks (GNNs) have achieved significant success in graph representation learning. Nevertheless, the recent work indicates that current GNNs are vulnerable to adversarial perturbations, in particular structural perturbations. This, therefore, narrows the application of GNN models in real-world scenarios. Such vulnerability can be attributed to the model's excessive reliance on incomplete data views (e.g., graph convolutional networks (GCNs) heavily rely on graph structures to make predictions). By integrating the information from multiple perspectives, this problem can be effectively addressed, and typical views of graphs include the node feature view and the graph structure view. In this paper, we propose C(2)oG, which combines these two typical views to train sub-models and fuses their knowledge through co-training. Due to the orthogonality of the views, sub-models in the feature view tend to be robust against the perturbations targeted at sub-models in the structure view. C(2)oG allows sub-models to correct one another mutually and thus enhance the robustness of their ensembles. In our evaluations, C(2)oG significantly improves the robustness of graph models against adversarial attacks without sacrificing their performance on clean datasets.
Randomized neural networks (NNs), such as random vector functional link (RVFL) and extreme learning machine (ELM), have been widely applied in various classification problems owing to their computational efficiency and universal approximation capability. However, such approaches are designed for regular Euclidean data and lack the ability to generalize to complex structured data. Moreover, their randomly generated parameters often lead to a suboptimal decision boundary with a growing requirement of hidden neurons. In this article, we first propose a plain framework, termed randomized graph convolutional networks (RGCNs), to generalize the classic randomized NNs to the non-Euclidean domain. Then, a hybrid framework called evolution-driven RGCN (EvoRGCN) is presented by using adaptive differential evolution with novelty search strategy to seek the globally optimal graph embedding for the plain RGCN. Finally, we recast the classic ELM and RVFL under the proposed frameworks, resulting in four novel semi-supervised models, including the plain models [i.e., graph convolutional extreme learning machines (GCELMs) and graph convolutional RVFL (GCRVFL)] and the optimized models (i.e., O-GCELM and O-GCRVFL). We show that our approaches are the natural generalization of the traditional randomized NNs in the non-Euclidean domain. Furthermore, our approaches not only retain the advantages of the classic approaches but also enable them to handle graph data. We compare our approaches against many existing methods across regular datasets and graph benchmarks, demonstrating that the proposed approaches dramatically outperform the compared methods with better generalization ability and robustness. Particularly, we quantitatively show the performance ranking of different randomized NNs, i.e., O-GCRVFL > O-GCELM approximate to GCRVFL > GCELM approximate to RVFL > ELM.
In this study, we propose a new approach for automatically generating high-quality non-uniform meshes based on supervised learning. The proposed framework, GMR-Net, is based on training a graph convolutional neural network (GCN) that learns local error density around each interior vertex in the mesh. The target edge length is then estimated using the predicted local error density. GMR-Net performs vertex-based error estimation as a preprocessing step to avoid expensive error estimation. The proposed GCN-based neural net has new input features for learning the local error density with various polygonal geometries, a range of partial differential equation parameters, and boundary conditions. During the test process, it predicts the target edge length around each interior vertex for the coarse input mesh, and the final non-uniform meshes are generated over the domain using Gmsh. To demonstrate the effectiveness of the GMR-Net, we tested the GMR-Net on Poisson's equations and linear elasticity problems to previously unseen and new polygonal geometries and a range of PDE coefficients and boundary conditions.
Entity alignment refers to matching entities with the same realistic meaning in different knowledge graphs. The structure of a knowledge graph provides the global signal for entity alignment. But in the real world, a knowledge graph provides insufficient structural information in general. Moreover, the problem of knowledge graph heterogeneity is common. The semantic and string information can alleviate the problems caused by the sparse and heterogeneous nature of knowledge graphs, yet both of them have not been fully utilized by most existing work. Therefore, we propose an entity alignment model based on multiple information (EAMI), which employs structural, semantic and string information. EAMI learns the structural representation of a knowledge graph by using multi-layer graph convolutional networks. To acquire more accurate entity vector representation, we incorporate the attribute semantic representation into the structural representation. In addition, to further improve entity alignment, we study the entity name string information. There is no training required to calculate the similarity of entity names. Our model is tested on publicly available cross-lingual datasets and cross-resource datasets, and the experimental results demonstrate the effectiveness of our model.(c) 2023 Elsevier Ltd. All rights reserved.
Transformer has been widely used in classification tasks for hyperspectral images (HSIs) in recent years. Because it can mine spectral sequence information to establish long-range dependence, its classification performance can be comparable with the convolutional neural network (CNN). However, both CNN and Transformer focus excessively on spatial or spectral domain features, resulting in an insufficient combination of spatial-spectral domain information from HSI for modeling. To solve this problem, we propose a new end-to-end graph convolutional network (GCN) and Transformer fusion network (GTFN) with the spatial-spectral feature extraction in this article, which combines the strengths of GCN and Transformer in both spatial and spectral domain feature extraction, taking full advantage of the contextual information of classified pixels while establishing remote dependencies in the spectral domain compared with previous approaches. In addition, GTFN uses Follow Patch as an input to the GCN and effectively solves the problem of high model complexity while mining the relationship between pixels. It is worth noting that the spectral attention module is introduced in the process of GCN feature extraction, focusing on the contribution of different spectral bands to the classification. More importantly, to overcome the problem that Transformer is too scattered in the frequency domain feature extraction, a neighborhood convolution module is designed to fuse the local spectral domain features. On Indian Pines, Salinas, and Pavia University datasets, the overall accuracies (OAs) of our GTFN are 94.00%, 96.81%, and 95.14%, respectively. The core code of GTFN is released at https://github.com/1useryang/GTFN.
Stock prices movement prediction has been a longstanding research topic. Many studies have introduced several kinds of external information like relations of stocks, combined with internal information of trading characteristics to promote forecasting. Different from previous cases, this article proposes a reasonable assumption that major fluctuations of stock prices are mainly triggered by high-volume transactions which usually occur on a group of stocks that share some common features (e.g., stocks in the same industry, region, concept or yield similar volatility), and further develops an integrated GCN-LSTM method to achieve more precise predictions from the perspective of modelling capital flows. First, we construct four kinds of graphs incorporating various relational knowledge (edge) and utilize graph convolutional network (GCN) to extract stock (node) embeddings in multiple time-periods. Then, the obtained temporal sequences of stock embeddings are put into long short-term memory recurrent neural network (LSTM) to discriminate the moving direction of prices. Extensive experiments on major Chinese stock indexes have demonstrated the effectiveness of our model with best accuracy of 57.81% acquired, which is much better than baselines. Moreover, experimental results of GCN-LSTM under different graphs and various node embedding dimensions have been compared and analyzed, indicating the selection of key parameters to achieve optimal performances. Our research findings provide an improved model to forecast stock prices movement directions with a reliable theoretical interpretation, and in depth exhibit insights for further applications of graph neural networks and graph data in business analytics, quantitative finance, and risk management decision-makings.
Influence maximization is an important technique for its significant value on various social network applications, such as viral marketing, advertisement, and recommendation. Traditional heuristic algorithms for influence maximization suffer from different issues, such as accuracy descent and information loss during network exploration. Besides, recently proposed deep learning-based approaches cannot extract the in-depth structural information of social networks well. In light of these problems, we propose a novel heuristic method called the network dynamic GCN influence maximization algorithm based on the leader fake labeling mechanism. To exploit the in-depth network topology information for the influence maximization task, we design a network dynamic GCN that owns adaptive layer numbers in terms of different network scales to obtain node representations. Then, considering that there are few labels in the network or the labels are irrelevant to the task of influence maximization, we establish a leader fake labeling mechanism to automatically generate node labels that are helpful to seed nodes selecting for model training. Finally, a heuristic method based on the Mahalanobis distance is developed to quickly select influential seed nodes with the learned node representations. Three real-world datasets are used in our experiments, and the experimental results demonstrate that our algorithm has a better performance for seed set identification under the premise of high efficiency compared with some latest heuristic influence maximization algorithms.
Skeleton-based human action cognition (HAR) has drawn increasing attention recently. As an emerging approach for skeleton-based HAR tasks, Spatial-Temporal Graph Convolution Network (STGCN) achieves remarkable performance by fully exploiting the skeleton topology information via graph convolution. Unfortunately, existing GCN accelerators lose efficiency when processing STGCN models due to two limitations. (1) At the dataflow level, the hardware parallelism of GCN accelerators cannot match the computation parallelism of STGCN models, leading to computing resource under-utilization. (2) At the computation level, GCN accelerators fail to exploit the inherent temporal redundancy in STGCN models. To overcome the limitations, this paper proposes STAR, an STGCN architecture for skeleton-based human action recognition. STAR is designed based on the characteristics of different computation phases in STGCN. For limitation (1), a spatial-temporal dimension consistent (STDC) dataflow is proposed to fully exploit the data reuse opportunities in all the different dimensions of STGCN. For limitation (2), we propose a node-wise exponent sharing scheme and a temporal-structured redundancy elimination mechanism, to exploit the inherent temporal redundancy specially introduced by STGCN. To further address the under-utilization induced by redundancy elimination, we design a dynamic data scheduler to manage the feature data storage and schedule the features and weights for valid computation in real time. STAR achieves 4.48x, 5.98x, 2.54x, and 103.88x energy savings on average over the HyGCN, AWB-GCN, TPU, and Jetson TX2 GPU.
To explore an efficient strategy for intelligent bedrock mapping that can be applied in the areas with coexisting Quaternary coverages and bedrock outcrops, a graph convolutional network (GCN) was implemented for bedrock classification using stream sediment geochemical samplings in the Chahanwusu River area, Qinghai Province, China. The sampling points were organized into a terrain weighted directed graph (TWDG) using Delaunay triangulation to capture the upstream-downstream relationships among the geochemical sampling points. The experimental results indicate that the semi-supervised GCN models, only using 20% of the labeled sampling points, achieved accuracies of 68.20% and 78.31% in ten-type and five-type bedrock discrimination, respectively. In conclusion, it is feasible to map the bedrock type through the concentrations of elements on the stream sediment geochemical sampling points. The proposed data-driven GCN bedrock classification method not only improves the efficiency of bedrock mapping but also may be applied in a large area.
This study proposes a hybrid deep learning approach for dynamic attitude and position prediction of the tunnel boring machine (TBM) with high accuracy. By utilizing the key operational parameters as well as the historical value of TBM's positions, the proposed deep learning model with graph convolutional network (GCN) and long short-term memory (LSTM), named GCN-LSTM, is constructed and trained to predict the vertical and horizontal deviations at the articulation and tail of TBM. Shapley Additive exPlanations (SHAP) analysis is then performed to improve the model's interpretability and determine the key contributing factors. Data obtained from a realistic tunnel project in Singapore's Thomson-East Coast line is utilized as a case study. The results indicate that: (1) The proposed GCN-LSTM approach provides accurate prediction with an average MAE of 1.009 mm, RMSE of 1.445 mm and R2 of 0.941. (2) The historical values of the deviation and adjustment are the major contributions to the current deviations, while the present adjustment could only influence the deviation in the future. (3) The pro-posed GCN-LSTM model outperforms the state-of-the-art methods in most metrics for the four outputs and thus is the most suitable method for the prediction. The proposed approach provides a reliable estimation of TBM's position which assists in improving the overall project quality and reduces the risk of tunnel misalignments.
Herein, a 3D/2D/2D of a-Fe2O3/r-GO/GCN composites were synthesized by combined reflux condensation and sonochemical-assisted wet-impregnation techniques. The physicochemical properties of the prepared materials were inspected by various analytical techniques. Morphology analysis techniques of different electron micro-scopes were employed to confirm the rhombohedral (3D) and two-dimensional (2D) sheets' morphology. The electrochemical behaviour of the as-synthesised electrode materials was assessed for use in a redox electrolyte -based energy storage system. Electrochemical measurements in a 6M KOH solution revealed that the electrode exhibited good supercapacitive behaviour. The 3D/2D/2D-a-Fe2O3/r-GO/GCN composite had a higher capac-itance rate of roughly 810 F g(-1) than a-Fe2O3 nanoparticles at 1Ag(-1). From cyclic stability, ternary composite has good cyclic retention (98.9%) after 10,000 cycles at 10 Ag-1. The surface characteristics of metal oxide nanostructures and the efficient conductive networks of r-GO and GCN sheets are primarily responsible for the ternary a-Fe2O3/r-GO/GCN composite's superior electrochemical performance. Asymmetric supercapacitor (ASC) devices were constructed using 3D/2D/2D anodic material and activated carbon as a cathode material with a power density of 929 Wkg- 1, energy density of 40 WhKg-1, and 92 % of capacity retention.
Single-view 3D human pose estimation (HPE) based on Graph Convolutional Networks currently suffers from problems such as insufficient feature representation and depth ambiguity. To address these issues, this letter proposes a hierarchical spatial-temporal adaptive graph fusion framework to improve monocular 3D HPE performance. Firstly, to enhance the spatial semantic feature representation of human nodes, a progressive adaptive graph feature capture strategy is developed, which adaptively constructs global-to-local attention graph features of all human joints in a coarse-to-fine manner. A spatial-temporal attention fusion module is then constructed to model long-term sequential dependencies and mitigate depth ambiguity. The temporal attention factors of related frames are captured and utilized to intermediately supervise the joint depth. The spatial semantic information among all joints in the same frame and temporal contextual knowledge of the joints across relevant frames are fused to build spatial-temporal correlations and optimize the final features. Extensive experiments on two popular benchmarks show that our method outperforms several state-of-the-art approaches and improves 3D HPE performance.
Graph convolutional networks (GCNs) have well-documented performance in various graph learning tasks, but their analysis is still at its infancy. Graph scattering transforms (GSTs) offer training-free deep GCN models that extract features from graph data, and are amenable to generalization and stability analyses. The price paid by GSTs is exponential complexity in space and time that increases with the number of layers. This discourages deployment of GSTs when a deep architecture is needed. The present work addresses the complexity limitation of GSTs by introducing an efficient so-termed pruned (p)GST approach. The resultant pruning algorithm is guided by a graph-spectrum-inspired criterion, and retains informative scattering features on-the-fly while bypassing the exponential complexity associated with GSTs. Stability of the novel pGSTs is also established when the input graph data or the network structure are perturbed. Furthermore, the sensitivity of pGST to random and localized signal perturbations is investigated analytically and experimentally. Numerical tests showcase that pGST performs comparably to the baseline GST at considerable computational savings. Furthermore, pGST achieves comparable performance to state-of-the-art GCNs in graph and 3D point cloud classification tasks. Upon analyzing the pGST pruning patterns, it is shown that graph data in different domains call for different network architectures, and that the pruning algorithm may be employed to guide the design choices for contemporary GCNs.
In graph-structured data, the node content contains rich information. Therefore, how to effectively utilize the content is crucial to improve the performance of graph convolutional networks (GCNs) on various analytical tasks. However, current GCNs do not fully utilize the content, especially multi-order content. For example, graph attention networks (GATs) only focus on low-order content, while high-order content is completely ignored. To address this issue, we propose a novel graph attention network with adaptability that could fully utilize the features of multi-order content. Its core idea has the following novelties: First, we constructed a high-order content attention mechanism that could focus on high-order content to evaluate attention weights. Second, we propose a multi-order content attention mechanism that can fully utilize multi-order content, i.e., it combines the attention mechanisms of high- and low-order content. Furthermore, the mechanism has adaptability, i.e., it can perform a good trade-off between high- and low-order content according to the task requirements. Lastly, we applied this mechanism to constructing a graph attention network with structural symmetry. This mechanism could more reasonably evaluate the attention weights between nodes, thereby improving the convergence of the network. In addition, we conducted experiments on multiple datasets and compared the proposed model with state-of-the-art models in multiple dimensions. The results validate the feasibility and effectiveness of the proposed model.
Social influence prediction has permeated many domains, including marketing, behavior prediction, recommendation systems, and more. However, traditional methods of predicting social influence not only require domain expertise, they also rely on extracting user features, which can be very tedious. Additionally, graph convolutional networks (GCNs), which deals with graph data in non-Euclidean space, are not directly applicable to Euclidean space. To overcome these problems, we extended DeepInf such that it can predict the social influence of COVID-19 via the transition probability of the page rank domain. Furthermore, our implementation gives rise to a deep learning-based personalized propagation algorithm, called DeepPP. The resulting algorithm combines the personalized propagation of a neural prediction model with the approximate personalized propagation of a neural prediction model from page rank analysis. Four social networks from different domains as well as two COVID-19 datasets were used to analyze the proposed algorithm's efficiency and effectiveness. Compared to other baseline methods, DeepPP provides more accurate social influence predictions. Further, experiments demonstrate that DeepPP can be applied to real-world prediction data for COVID-19.
Skeleton-based action recognition can achieve a relatively high performance by transforming the human skeleton structure in an image into a graph and applying action recognition based on structural changes in the body. Among the many graph convolutional network (GCN) approaches used in skeleton-based action recognition, semantic-guided neural networks (SGNs) are fast action recognition algorithms that hierarchically learn spatial and temporal features by applying a GCN. However, because an SGN focuses on global feature learning rather than local feature learning owing to the structural characteristics, there is a limit to an action recognition in which the dependency between neighbouring nodes is important. To solve these problems and simultaneously achieve a real-time action recognition in low-end devices, in this study, a single head attention (SHA) that can overcome the limitations of an SGN is proposed, and a new SGN-SHA model that combines SHA with an SGN is presented. In experiments on various action recognition benchmark datasets, the proposed SGN-SHA model significantly reduced the computational complexity while exhibiting a performance similar to that of an existing SGN and other state-of-the-art methods.
Autism Spectrum Disorder (ASD) is one common developmental disorder with great variations in symptoms and severity, making the diagnosis of ASD a challenging task. Existing deep learning models using brain connectivity features to classify ASD still suffer from degraded performance for multi-center data due to limited feature representation ability and insufficient interpretability. Given that Graph Convolutional Network (GCN) has demonstrated superiority in learning discriminative representations of brain connectivity networks, in this paper, we propose an invertible dynamic GCN model to identify ASD and investigate the alterations of connectivity patterns associated with the disease. In order to select explainable features from the model, invertible blocks are introduced in the whole network, and we are able to reconstruct the input dynamic features from the network's output. A pre-screening of connectivity features is adopted to reduce the redundancy of the input information, and a fully-connected layer is added to perform classification. The experimental results on 867 subjects show that our proposed method achieves superior disease classification performance. It provides an interpretable deep learning model for brain connectivity analysis and is of great potential in studying brain-related disorders.
Traditional convolution neural networks have achieved great success in human action recognition. However, it is challenging to establish effective associations between different human bone nodes to capture detailed information. In this paper, we propose a dual attention-guided multiscale dynamic aggregate graph convolution neural network (DAG-GCN) for skeleton-based human action recognition. Our goal is to explore the best correlation and determine high-level semantic features. First, a multiscale dynamic aggregate GCN module is used to capture important semantic information and to establish dependence relationships for different bone nodes. Second, the higher level semantic feature is further refined, and the semantic relevance is emphasized through a dual attention guidance module. In addition, we exploit the relationship of joints hierarchically and the spatial temporal correlations through two modules. Experiments with the DAG-GCN method result in good performance on the NTU-60-RGB+D and NTU-120-RGB+D datasets. The accuracy is 95.76% and 90.01%, respectively, for the cross (X)-View and X-Subon the NTU60dataset.
As skeleton data becomes increasingly available, Graph Convolutional Networks (GCNs) are popularly adapted to extract the spatial and temporal features for skeleton-based action recognition. However, there are still limitations to be addressed in GCN-based methods. First, the multi-level semantic features fail to be connected, making fine-grained information loss as the network deepens. Second, the cross-scale spatiotempral features fail to be simultaneously considered and refined to focus on informative areas. These limitations lead to the challenge in distinguishing the confusing actions. To address these issues, we propose a cross-scale connection (CSC) structure and a spatiotemporal refinement focus (STRF) module. The CSC aims to bridge the gap between multi-level semantic features. The STRF module refines the cross-scale spatiotemporal features to focus on informative joints in each frame. Both are embedded into the standard GCNs to form the cross-scale spatiotemporal refinement network (CSR-Net). Our proposed CSR-Net explicitly models the cross-scale spatiotemporal information among multi-level semantic representations to boost the distinguishing capability for ambiguous actions. We conduct extensive experiments to demonstrate the effectiveness of our proposed method and it outperforms state-of-the-art methods on the NTU RGB+D 60, NTU-RGB+D 120 and NW-UCLA datasets.
Deep neural networks, especially graph neural networks, have made great progress in aspect-based sentiment analysis. Knowledge graphs can provide rich auxiliary information for aspect-based sentiment analysis. However, existing models cannot effectively learn aspect-specific sentiment features from the review text and external knowledge. They cannot accurately select knowledge entities that are highly relevant to the aspect. They also ignore the semantic interaction between the review text and external knowledge. To address these issues, we propose a knowledge-enhanced interactive graph convolutional network (KE-IGCN). First, we introduce a subgraph construction strategy to construct a syntax-guided knowledge subgraph, which can guide KE-IGCN in selecting highly relevant knowledge entities. Second, we propose a knowledge interaction mechanism to exploit the semantic interaction between external knowledge and the review text. We then use multilayer graph convolutional networks to learn aspect-specific sentiment features from the review text and external knowledge jointly and interactively. We also use a multilevel feature fusion mechanism to aggregate aspect-specific sentiment features from semantic and syntactic information of the review and external knowledge. Experimental results on four public datasets demonstrate that KE-IGCN outperforms other state-of-the-art baseline models.
Hand gesture recognition methods play an important role in human-computer interaction. Among these methods are skeleton-based recognition techniques that seem to be promising. In literature, several methods have been proposed to recognize hand gestures with skeletons. One problem with these methods is that they consider little the connectivity between the joints of a skeleton, constructing simple graphs for skeleton connectivity. Observing this, we built a new model of hand skeletons by adding three types of edges in the graph to finely describe the linkage action of joints. Then, an end-to-end deep neural network, hand gesture graph convolutional network, is presented in which the convolution is conducted only on linked skeleton joints. Since the training dataset is relatively small, this work proposes expanding the coordinate dimensionality so as to let models learn more semantic features. Furthermore, relative coordinates are employed to help hand gesture graph convolutional network learn the feature representation independent of the random starting positions of actions. The proposed method is validated on two challenging datasets, and the experimental results show that it outperforms the state-of-the-art methods. Furthermore, it is relatively lightweight in practice for hand skeleton-based gesture recognition.
Graph convolutional networks (GCNs), which extend convolutional neural networks (CNNs) to non-Euclidean structures, have been utilized to promote skeleton-based human action recognition research and have made substantial progress in doing so. However, there are still some challenges in the construction of recognition models based on GCNs. In this paper, we propose an enhanced adjacency matrix-based graph convolutional network with a combinatorial attention mechanism (CA-EAMGCN) for skeleton-based action recognition. Firstly, an enhanced adjacency matrix is constructed to expand the model's perceptive field of global node features. Secondly, a feature selection fusion module (FSFM) is designed to provide an optimal fusion ratio for multiple input features of the model. Finally, a combinatorial attention mechanism is devised. Specifically, our spatial-temporal (ST) attention module and limb attention module (LAM) are integrated into a multi-input branch and a mainstream network of the proposed model, respectively. Extensive experiments on three large-scale datasets, namely the NTU RGB+D 60, NTU RGB+D 120 and UAV-Human datasets, show that the proposed model takes into account both requirements of light weight and recognition accuracy. This demonstrates the effectiveness of our method.
Predicting pedestrian trajectories in urban scenarios is a challenging task that has a wide range of applications, from video surveillance to autonomous driving. The task is difficult since pedestrian behavior is affected by both their individual path's history, their interactions with others, and with the environment. For predicting pedestrian trajectories, an attention-based interaction-aware spatio-temporal graph neural network is introduced. This paper introduces an approach based on two components: a spatial graph neural network (SGNN) for interaction-modeling and a temporal graph neural network (TGNN) for motion feature extraction. The SGNN uses an attention method to periodically collect spatial interactions between all pedestrians. The TGNN employs an attention method as well, this time to collect each pedestrian's temporal motion pattern. Finally, in the graph's temporal dimension characteristics, a time-extrapolator convolutional neural network (CNN) is employed to predict the trajectories. Using a lower variable size (data and model) and a better accuracy, the proposed method is compact, efficient, and better than the one represented by the social-STGCNN. Moreover, using three video surveillance datasets (ETH, UCY, and SDD), D-STGCN achieves better experimental results considering the average displacement error (ADE) and final displacement error (FDE) metrics, in addition to predicting more social trajectories.
Graph Convolutional Network (GCN) which models the potential relationship between non-Euclidean spatial data has attracted researchers' attention in deep learning in recent years. It has been widely used in different computer vision tasks by modeling the latent space, topology, semantics, and other information in Euclidean spatial data and has achieved significant success. To better understand the work principles and future GCN applications in the computer vision field, this study reviewed the basic principles of GCN, summarized the difficulties and solutions using GCN in different visual tasks, and introduced in detail the methods for constructing graphs from the Euclidean spatial data in different visual tasks. At the same time, the review divided the application of GCN in basic visual tasks into image recognition, object detection, semantic segmentation, instance segmentation and object tracking. The role and performance of GCN in basic visual tasks were summarized and compared in detail for different tasks. This review emphasizes that the application of GCN in computer vision faces three challenges: computational complexity, the paradigm of constructing graphs from the Euclidean spatial data, and the interpretability of the model. Finally, this review proposes two future trends of GCN in the vision field, namely model lightweight and fusing GCN with other models to improve the performance of the visual model and meet the higher requirements of vision tasks.
Graph convolutional networks (GCNs), which are capable of effectively processing graph-structural data, have been successfully applied in text classification task. Existing studies on GCN based text classification model largely concerns with the utilization of word co-occurrence and Term Frequency-Inverse Document Frequency (TF-IDF) information for graph construction, which to some extent ignore the context information of the texts. To solve this problem, we propose a gating context-aware text classification model with Bidirectional Encoder Representations from Transformers (BERT) and graph convolutional network, named as Gating Context GCN (GC-GCN). More specifically, we integrate the graph embedding with BERT embedding by using a GCN with gating mechanism to enable the acquisition of context coding. We carry out text classification experiments to show the effectiveness of the proposed model. Experimental results shown our model has respectively obtained 0.19%, 0.57%, 1.05% and 1.17% improvements over the Text-GCN baseline on the 20NG, R8, R52, and Ohsumed benchmark datasets. Furthermore, to overcome the problem that word co-occurrence and TF-IDF are not suitable for graph construction for short texts, Euclidean distance is used to combine with word co-occurrence and TF-IDF information. We obtain an improvement by 1.38% on the MR dataset compared to Text-GCN baseline.
To better learn the dependency relationship between nodes, we address the relationship extraction task by capturing rich contextual dependencies based on the attention mechanism, and using distributional reinforcement learning to generate optimal relation information representation. This method is called Dual Attention Graph Convolutional Network (DAGCN), to adaptively integrate local features with their global dependencies. Specifically, we append two types of attention modules on top of GCN, which model the semantic interdependencies in spatial and relational dimensions, respectively. The position attention module selectively aggregates the feature at each position by a weighted sum of the features at all positions of nodes internal features. Meanwhile, the relation attention module selectively emphasizes interdependent node relations by integrating associated features among all nodes. We sum the outputs of the two attention modules and use reinforcement learning to predict the classification of nodes relationship to further improve feature representation which contributes to more precise extraction results. The results on the TACRED and SemEval datasets show that the model can obtain more useful information for relational extraction tasks, and achieve better performances on various evaluation indexes.
Accurate traffic flow forecasting is a prerequisite guarantee for the realization of intelligent transportation, but it is a challenging task due to the complex spatial-temporal dependence and uncertainty of traffic flow. In most existing approaches, spatial correlation is captured using graph convolution networks in a pre-determined graph structure. However, some nodes in such a graph structure have spatial correlations between them but are missing a connection, so the hidden spatial correlations between these nodes cannot be captured. Traffic flow has dynamic characteristics, showing different characteristics over time. Most methods ignore the dynamics of traffic flow when modeling the spatio-temporal correlation of traffic flow. We proposed a new network model (MSTA-GCN) to solve the above problem. The model presents a gated adaptive graph convolutional network that captures the hidden spatial correlations between graph nodes from the adaptive. In addition, the model introduces a multi-head spatial-temporal attention mechanism to pay attention to spatial-temporal information of different historical moments and different spatial dimensions to effectively capture the dynamics of spatial-temporal correlation of traffic flow. Extensive experiments were conducted on four datasets of PEMS. The experimental results show that the MSTA-GCN model has better forecasting performance compared with the baseline methods.
Skeleton-based action recognition is a research hotspot in the field of computer vision. Currently, the mainstream method is based on Graph Convolutional Networks (GCNs). Although there are many advantages of GCNs, GCNs mainly rely on graph topologies to draw dependencies between the joints, which are limited in capturing long-distance dependencies. Meanwhile, Transformer-based methods have been applied to skeleton-based action recognition because they effectively capture long-distance dependencies. However, existing Transformer-based methods lose the inherent connection information of human skeleton joints because they do not yet focus on initial graph structure information. This paper aims to improve the accuracy of skeleton-based action recognition. Therefore, a Graph Skeleton Transformer network (GSTN) for action recognition is proposed, which is based on Transformer architecture to extract global features, while using undirected graph information represented by the symmetric matrix to extract local features. Two encodings are utilized in feature processing to improve joints' semantic and centrality features. In the process of multi-stream fusion strategies, a grid-search-based method is used to assign weights to each input stream to optimize the fusion results. We tested our method using three action recognition datasets: NTU RGB+D 60, NTU RGB+D 120, and NW-UCLA. The experimental results show that our model's accuracy is comparable to state-of-the-art approaches.
Crowd counting has received significant attention in recent years due to its practical applications. In order to address the specific characteristics of RGB and thermal images, we have developed the graph enhancement and transformer aggregation network (GETANet) for generating representative density maps. Our approach incorporates several innovative modules to enhance accuracy. First, we introduced a position-adaptive module (PAM) that effectively counts individuals' positions and integrates features extracted from the main framework. Furthermore, we leveraged the advantages of graph convolutional networks (GCNs), which integrate spatial information and exploit relationships between nodes. Specifically, we designed a dual GCN module that further improves the model's performance by considering the spatial context and relationships among individuals in the crowd. To capture global image information and improve overall performance, we integrated a vision transformer into our model architecture. The vision transformer effectively captures global dependencies and enhances the model's ability to understand complex crowd scenes. Additionally, we designed a transformer information aggregation module (TIAM) that integrates information from multiple levels, resulting in a highly precise prediction map. Through comprehensive experiments on benchmark datasets, such as RGBT-CC and DroneRGBT, our GETANet demonstrated its effectiveness in RGB-thermal crowd counting tasks. Moreover, GETANet showcased remarkable generalization results on the ShanghaiTech-RGBD dataset. Our code has been made publicly available on GitHub at https://github.com/panyi95/GETANet.
Understanding the evolutionary mechanisms of dynamic graphs is crucial since dynamic is a basic characteristic of real-world networks. The challenges of modeling dynamic graphs are as follows: (1) Real-world dynamics are frequently characterized by group effects, which essentially emerge from high-order interactions involving groups of entities. Therefore, the pairwise interactions revealed by the edges of graphs are insufficient to describe complex systems. (2) The graph data obtained from real systems are often noisy, and the spurious edges can interfere with the stability and efficiency of models. To address these issues, we propose a high-order topology-enhanced graph convolutional network for modeling dynamic graphs. The rationale behind it is that the symmetric substructure in a graph, called the maximal clique, can reflect group impacts from high-order interactions on the one hand, while not being readily disturbed by spurious links on the other hand. Then, we utilize two independent branches to model the distinct influence mechanisms of the two effects. Learnable parameters are used to tune the relative importance of the two effects during the process. We conduct link predictions on real-world datasets, including one social network and two citation networks. Results show that the average improvements of the high-order enhanced methods are 68%, 15%, and 280% over the corresponding backbones across datasets. The ablation study and perturbation analysis validate the effectiveness and robustness of the proposed method. Our research reveals that high-order structures provide new perspectives for studying the dynamics of graphs and highlight the necessity of employing higher-order topologies in the future.
Background Complex and diverse microbial communities play a pivotal role in human health and have become a new drug target. Exploring the connections between drugs and microbes not only provides profound insights into their mechanisms but also drives progress in drug discovery and repurposing. The use of wet lab experiments to identify associations is time-consuming and laborious. Hence, the advancement of precise and efficient computational methods can effectively improve the efficiency of association identification between microorganisms and drugs.Objective In this experiment, we propose a new deep learning model, a new multiview comparative hypergraph attention network (MCHAN) method for human microbe-drug association prediction.Methods First, we fuse multiple similarity matrices to obtain a fused microbial and drug similarity network. By combining graph convolutional networks with attention mechanisms, we extract key information from multiple perspectives. Then, we construct two network topologies based on the above fused data. One topology incorporates the concept of hypernodes to capture implicit relationships between microbes and drugs using virtual nodes to construct a hyperheterogeneous graph. Next, we propose a cross-contrastive learning task that facilitates the simultaneous guidance of graph embeddings from both perspectives, without the need for any labels. This approach allows us to bring nodes with similar features and network topologies closer while pushing away other nodes. Finally, we employ attention mechanisms to merge the outputs of the GCN and predict the associations between drugs and microbes.Results To confirm the effectiveness of this method, we conduct experiments on three distinct datasets. The results demonstrate that the MCHAN model surpasses other methods in terms of performance. Furthermore, case studies provide additional evidence confirming the consistent predictive accuracy of the MCHAN model.Conclusion MCHAN is expected to become a valuable tool for predicting potential associations between microbiota and drugs in the future.
Graph convolutional networks (GCN) have emerged as a powerful alternative tool for analyzing hyperspectral images (HSIs). Despite their impressive performance, current works strive to make GCN more sophisticated through either elaborate architecture or fancy training tricks, making them prohibitive for HSI data in practice. In this paper, we present a Graph Convolutional RVFL Network (GCRVFL), a simple but efficient GCN for hyperspectral image classification. Specifically, we generalize the classic RVFL network into the graph domain by using graph convolution operations. This not only enables RVFL to handle graph-structured data, but also avoids iterative parameter adjustment by employing an efficient closed-form solution. Unlike previous works that perform HSI classification under a transductive framework, we regard HSI classification as a graph-level classification task, which makes GCRVFL scalable to large-scale HSI data. Extensive experiments on three benchmark data sets demonstrate that the proposed GCRVFL is able to achieve competitive results with fewer trainable parameters and adjustable hyperparameters and higher computational efficiency. In particular, we show that our approach is comparable to many existing approaches, including deep CNN models (e.g., ResNet and DenseNet) and popular GCN models (e.g., SGC and APPNP).
Graph Convolutional Networks (GCNs) are widely used in medical images diagnostic research, because they can automatically learn powerful and robust feature representations. However, their performance might be significantly deteriorated by trivial or corrupted medical features and samples. Moreover, existing methods cannot simultaneously interpret the significant features and samples. To overcome these limitations, in this paper, we propose a novel dual interpretable graph convolutional network, namely FSNet, to simultaneously select significant features and samples, so as to boost model performance for medical diagnosis and interpretation. Specifically, the proposed network consists of three modules, two of which leverage one simple yet effective sparse mechanism to obtain feature and sample weight matrices for interpreting features and samples, respectively, and the third one is utilized for medical diagnosis. Extensive experiments on the Alzheimer's Disease Neuroimaging Initiative (ADNI) datasets demonstrate the superior classification performance and interpretability over the recent state-of-the-art methods.
Anticipating pedestrians' activity is a necessary task for providing a safe and energy efficient environment in an urban area. By locating strategically sensors throughout the city useful information could be obtained. By knowing the average activity of those throughout different days of the week we could identify the typology of the buildings neighboring those sensors. For these type of purposes, clustering methods show great capability forming groups of items that have great similarity intra clusters and dissimilarity inter cluster. Different approaches are made to classify sensors depending on the typology of buildings surrounding them and the mean pedestrians' counts for different time intervals. By this way, sensors could be classified in different groups according to their activation patterns and the environment in which they are located through clustering processes and using graph convolutional networks. This study reveals that there is a close relationship between the activity pattern of the pedestrians' and the type of environment sensors that collect pedestrians' data are located. By this way, institutions could alleviate a great amount of effort needed to ensure safe and energy efficient urban areas, only knowing the typology of buildings of an urban zone.
GCN is a widely-used representation learning method for capturing hidden features in graph data. However, traditional GCNs suffer from the over-smoothing problem, hindering their ability to extract high-order information and obtain robust data representation. To overcome this limitation, we propose a novel graph model, the high-order graph attention network. Compared to other existing graph attention networks, our model can adaptively aggregate node features from multi-hop neighbors through an attention mechanism. Moreover, the edges in the original graph may not accurately represent the relationships between nodes. We implement a new approach to update the graph by using the aggregated node representation to adjust the edges with small step sizes. Additionally, we perform a theoretical analysis to demonstrate the relationships between our proposed model and other GCN models. Finally, we evaluate our proposed model against eight variants of GCN models on multiple widely-used benchmark datasets. The experimental results show the superiority of our proposed model over other models.
Wind forecasting is a typical and fundamental problem in the efficient operation of wind power-generation systems. Despite the developed brilliant techniques, current methods for wind forecasting still rely heavily on numerical weather prediction. To investigate the huge amount of meteorological data and to improve the forecasting ability, this letter proposes a temporal dynamic network with a learnable coupled adjacent matrix (TCNet), which takes observations of multiple meteorological elements as predictors for wind forecasting. Specifically, to better illustrate the inner property of wind components, a learnable coupled adjacent matrix (CAM) module is introduced. A spatially stable adjacent matrix is built to model the low-frequency part, while a temporally dynamic adjacent matrix is developed to extract the high-frequency one. Casting on this mechanism, the CAM can be embedded in a vanilla graph convolution network. Apart from that, a simple but effective temporal weights allocating strategy, named temporal dynamic (TED) module, is proposed to depict the cyclicity. By integrating TED with CAM, TCNet can effectively extract the spatiotemporal feature of wind speed and its correlation with other meteorological elements. Using observed datasets of meteorological elements in Denmark and the Netherlands, we conduct experiments to validate the performance and efficiency of our proposed model. The results indicate the proposed TCNet outperforms the state-of-the-art graph convolutional networks (GCNs) methods and wind forecasting methods.
Recent studies have revealed the vulnerability of graph convolutional networks (GCNs) to edge-perturbing attacks, such as maliciously inserting or deleting graph edges. However, theoretical proof of such vulnerability remains a big challenge, and effective defense schemes are still open issues. In this article, we first generalize the formulation of edge-perturbing attacks and strictly prove the vulnerability of GCNs to such attacks in node classification tasks. Following this, an anonymous GCN, named AN-GCN, is proposed to defend against edge-perturbing attacks. In particular, we present a node localization theorem to demonstrate how GCNs locate nodes during their training phase. In addition, we design a staggered Gaussian noise-based node position generator and a spectral graph convolution-based discriminator (in detecting the generated node positions). Furthermore, we provide an optimization method for the designed generator and discriminator. It is demonstrated that the AN-GCN is secure against edge-perturbing attacks in node classification tasks, as AN-GCN is developed to classify nodes without the edge information (making it impossible for attackers to perturb edges anymore). Extensive evaluations verify the effectiveness of the general edge-perturbing attack (G-EPA) model in manipulating the classification results of the target nodes. More importantly, the proposed AN-GCN can achieve 82.7% in node classification accuracy without the edge-reading permission, which outperforms the state-of-the-art GCN.
Lymphomas are a group of malignant tumors developed from lymphocytes, which may occur in many organs. Therefore, accurately distinguishing lymphoma from solid tumors is of great clinical significance. Due to the strong ability of graph structure to capture the topology of the micro-environment of cells, graph convolutional networks (GCNs) have been widely used in pathological image processing. Nevertheless, the softmax classification layer of the graph convolutional models cannot drive learned representations compact enough to distinguish some types of lymphomas and solid tumors with strong morphological analogies on H&E-stained images. To alleviate this problem, a prototype learning based model is proposed, namely graph convolutional prototype network (GCPNet). Specifically, the method follows the patch-to-slide architecture first to perform patch-level classification and obtain image-level results by fusing patch-level predictions. The classification model is assembled with a graph convolutional feature extractor and prototype-based classification layer to build more robust feature representations for classification. For model training, a dynamic prototype loss is proposed to give the model different optimization priorities at different stages of training. Besides, a prototype reassignment operation is designed to prevent the model from getting stuck in local minima during optimization. Experiments are conducted on a dataset of 183 Whole slide images (WSI) of gastric mucosa biopsy. The proposed method achieved superior performance than existing methods.Clinical relevance- The work proposed a new deep learning framework tailored to lymphoma recognition on pathological image of gastric mucosal biopsy to differentiate lymphoma, adenocarcinoma and inflammation.
Automatically assessing academic papers has enormous potential to reduce peer-review burden and individual bias. Existing studies strive for building sophisticated deep neural networks to identify academic value based on comprehensive data, e.g., academic graphs and full papers. However, these data are not always easy to access. And the content of the paper rather than other features outside the paper should matter in a fair assessment. Furthermore, while BERT models can maintain general semantics by pre-training on large-scale corpora, they tend to be over-smoothing due to stacked self-attention layers among unfiltered input tokens. Therefore, it is nontrivial to figure out distinguishable value of an academic paper from its limited content. In this study, we propose a novel deep neural network, namely Dual-view Graph Convolutions Enhanced BERT (DGC-BERT), for academic paper acceptance estimation. We combine the title and abstract of the paper as input. Then, a pre-trained BERT model is employed to extract the paper's general representations. Apart from hidden representations of the final layer, we highlight the first and last few layers as lexical and semantic views. In particular, we re-examine the dual-view filtered self-attention matrices via constructing two graphs, respectively. After that, two multi-hop Graph Convolutional Networks (GCNs) are separately employed to capture pivotal and distant dependencies between the tokens. Moreover, the dual-view representations are facilitated by each other with biaffine attention modules. And a re-weighting gate is proposed to further streamline the dual-view representations with the help of the original BERT representation. Finally, whether the submitted paper could be acceptable is predicted based on the original language model features cooperated with the dual-view dependencies. Extensive data analyses and the full paper based MHCNN studies provide insights into the task and structural functions. Comparison experiments on two benchmark datasets demonstrate that the proposed DGC-BERT significantly outperforms alternative approaches, especially the state-of-the-art models like MHCNN and BERT variants. Additional analyses reveal significance and explainability of the proposed modules in the DGC-BERT. Our codes and settings have been released on Github (https://github.com/ECNU-Text-Computing/DGC-BERT).
The cerebral cortex is folded as gyri and sulci, which provide the foundation to unveil anatomo-functional relationship of brain. Previous studies have extensively demonstrated that gyri and sulci exhibit intrinsic functional difference, which is further supported by morphological, genetic, and structural evidences. Therefore, systematically investigating the gyro-sulcal (G-S) functional difference can help deeply understand the functional mechanism of brain. By integrating functional magnetic resonance imaging (fMRI) with advanced deep learning models, recent studies have unveiled the temporal difference in functional activity between gyri and sulci. However, the potential difference of functional connectivity, which represents functional dependency between gyri and sulci, is much unknown. Moreover, the regularity and variability of the G-S functional connectivity difference across multiple task domains remains to be explored. To address the two concerns, this study developed new anatomy-guided spatio-temporal graph convolutional networks (AG-STGCNs) to investigate the regularity and variability of functional connectivity differences between gyri and sulci across multiple task domains. Based on 830 subjects with seven different task-based and one resting state fMRI (rs-fMRI) datasets from the public Human Connectome Project (HCP), we consistently found that there are significant differences of functional connectivity between gyral and sulcal regions within task domains compared with resting state (RS). Furthermore, there is considerable variability of such functional connectivity and information flow between gyri and sulci across different task domains, which are correlated with individual cognitive behaviors. Our study helps better understand the functional segregation of gyri and sulci within task domains as well as the anatomo-functional-behavioral relationship of the human brain.
MicroRNAs (miRNAs) play an important role in various biological processes and their abnormal expression could lead to the occurrence of diseases. Exploring the potential relationships between miRNAs and diseases can contribute to the diagnosis and treatment of complex diseases. The increasing databases storing miRNA and disease information provide opportunities to develop computational methods for discovering unobserved disease-related miRNAs, but there are still some challenges in how to effectively learn and fuse information from multi-source data. In this study, we propose a multi-view information fusion based method for miRNA-disease association (MDA)prediction, named MVIFMDA. Firstly, multiple heterogeneous networks are constructed by combining the known MDAs and different similarities of miRNAs and diseases based on multi-source information. Secondly, the topology features of miRNAs and diseases are obtained by using the graph convolutional network to each heterogeneous network view, respectively. Moreover, we design the attention strategy at the topology representation level to adaptively fuse representations including different structural information. Meanwhile, we learn the attribute representations of miRNAs and diseases from their similarity attribute views with convolutional neural networks, respectively. Finally, the complicated associations between miRNAs and diseases are reconstructed by applying a bilinear decoder to the combined features, which combine topology and attribute representations. Experimental results on the public dataset demonstrate that our proposed model consistently outperforms baseline methods. The case studies further show the ability of the MVIFMDA model for inferring underlying associations between miRNAs and diseases.
The complexes of long non-coding RNAs bound to proteins can be involved in regulating life activities at various stages of organisms. However, in the face of the growing number of lncRNAs and proteins, verifying LncRNA-Protein Interactions(LPI) based on traditional biological experiments is time-consuming and laborious. Therefore, with the improvement of computing power, predicting LPI has met new development opportunity. In virtue of the state-of-the-art works, a framework called LncRNA-Protein Interactions based on Kernel Combinations and Graph Convolutional Networks (LPI-KCGCN) has been proposed in this article. We first construct kernel matrices by taking advantage of extracting both the lncRNAs and protein concerning the sequence features, sequence similarity features, expression features, and gene ontology. Then reconstruct the existent kernel matrices as the input of the next step. Combined with known LPI interactions, the generated similarity matrices, which can be used as features of the topology map of the LPI network, are exploited in extracting potential representations in the lncRNA and protein space using a two-layer Graph Convolutional Network. The predicted matrix can be finally obtained by training the network to produce scoring matrices w.r.t. lncRNAs and proteins. Different LPI-KCGCN variants are ensemble to derive the final prediction results and testify on balanced and unbalanced datasets. The 5-fold cross-validation shows that the optimal feature information combination on a dataset with 15.5% positive samples has an AUC value of 0.9714 and an AUPR value of 0.9216. On another highly unbalanced dataset with only 5% positive samples, LPI-KCGCN also has outperformed the state-of-the-art works, which achieved an AUC value of 0.9907 and an AUPR value of 0.9267. The code and dataset can be downloaded from https://github.com/6gbluewind/LPI-KCGCN.
Skeleton-based action recognition has attracted significant attentions in recent years. To model the skeleton data, most popular methods utilize graph convolutional networks to fuse nodes located in different parts of the graph to obtain rich geometric information. However, these methods cannot be generalized to different graph structures due to their dependencies on the input of the topological structure. In this article, we design a novel hyperbolic manifold aware network without introducing a dynamic graph. Instead, it leverages Riemannian geometry attributes of a hyperbolic manifold. Specifically, this method utilizes the Poincare model to embed the tree-like structure of the skeleton into a hyperbolic space to automatically capture hierarchical features, which may explore the underlying manifold of the data. To extract spatio-temporal features in the network, the features in manifold space are projected to a tangent space, and a tangent space features translation method based on the Levi-Civita connection was proposed. In addition, we introduce the geometric knowledge of Riemannian manifolds to further explain how features are transformed in the tangent space. Finally, we conduct experiments on several 3-D skeleton data sets with different structures, successfully verifying the effectiveness and advancement of the proposed method.
In order to carry out more accurate retrieval across image-text modalities, some scholars use fine-grained feature to align image and text. Most of them directly use attention mechanism to align image regions and words in the sentence, and ignore the fact that semantics related to an object is abstract and cannot be accurately expressed by object information alone. To overcome this weakness, we propose a hierarchical feature aggregation algorithm based on graph convolutional networks (GCN) to facilitate object semantic integrity by integrating attributes of an object and relations between objects hierarchically in both image and text modalities. In order to eliminate the semantic gap between modalities, we propose a cross-modal feature fusion method based on transformer to generate modal-specific feature representations by integrating both the object feature and global feature from the other modality. Then we map the fusion feature into a common space. Experiment results on the most frequently-used datasets MSCOCO and Flickr30K show the effectiveness of the proposed model compared with the latest methods.
Rainstorm prediction is of considerable importance for a wide range of applications, such as weather forecasting, disaster management, and flood monitoring. Predicting rare and extreme rainstorm events is challenging because only sparse historical samples are available for training. Additionally, rainstorm events are caused by many complex meteorological factors, involving heterogeneous meteorological observations. The interactions between these factors are also difficult to handle when making predictions. To address these challenges, we propose an integrated deep learning-driven prediction method based on adaptive attributed spatio-temporal affinities between spatio-temporal nodes, including spatio-temporal proximity and multi-dimensional meteorological attribute similarity using graph embedding. Based on the learned spatio-temporal affinity matrices, we apply graph convolutional networks to implement non-linear predictions. In particular, we develop an integrated loss function to address the class imbalance caused by rare rainstorm events. Our empirical evaluation results show that the proposed prediction method outperforms several competing state-of-the-art methods on two rainstorm datasets. We attribute the performance improvements of the proposed method to its ability to capture complex rainstorm development patterns using limited historical rainstorm samples and using heterogeneous spatio-temporal information.
Privacy image classification (PIC) has attracted increasing attention as it can help people make appropriate privacy decisions when sharing images. Most recently, some pioneer research efforts have been made to utilize multimodal information for PIC, since multi-modality can provide richer information than single modality. Those research efforts on multimodal PIC are under the assumption of independently identically distribution. However, connections between different modalities commonly exist in real-world cases. Taking the modalities of scene and object as example, in the scene of 'library/indoor', the object 'book jacket' resides with high probabilities. To this end, in this paper, a novel PIC approach, called CoupledPIC, is proposed to bridge this gap by comprehensively capturing the coupling relations between different modalities. In CoupledPIC, two submodules are designed to capture explicit and implicit coupling relations between different modalities respectively. The explicit modality coupling is learned with a tensor fusion networks based submodule, via the direct interaction of features. For the implicit modality coupling, a graph convolutional networks based submodule is proposed to learn on both the initial graphs and attention guided graphs, via information aggregation on graphs. Extensive experiments on the public benchmark, PicAlert, demonstrate the effectiveness of the proposed CoupledPIC, yielding significant improvement by modeling inter-modality coupling information.
Recently, skeleton-based human action recognition has attracted a lot of research attention in the field of computer vision. Graph convolutional networks (GCNs), which model the human body skeletons as spatial-temporal graphs, have shown excellent results. However, the existing methods only focus on the local physical connection between the joints, and ignore the non-physical dependencies among joints. To address this issue, we propose a hypergraph neural network (Hyper-GNN) to capture both spatial-temporal information and high-order dependencies for skeleton-based action recognition. In particular, to overcome the influence of noise caused by unrelated joints, we design the Hyper-GNN to extract the local and global structure information via the hyperedge (i.e., non-physical connection) constructions. In addition, the hypergraph attention mechanism and improved residual module are induced to further obtain the discriminative feature representations. Finally, a three-stream Hyper-GNN fusion architecture is adopted in the whole framework for action recognition. The experimental results performed on two benchmark datasets demonstrate that our proposed method can achieve the best performance when compared with the state-of-the-art skeleton-based methods.
Social networks are an essential component of the Internet of People (IoP) and play an important role in stimulating interactive communication among people. Graph convolutional networks provide methods for social network analysis with its impressive performance in semi-supervised node classification. However, the existing methods are based on the assumption of balanced data distribution and ignore the imbalanced problem of social networks. In order to extract the valuable information from imbalanced data for decision making, a novel method named minority-weighted graph neural network (mGNN) is presented in this article. It extends imbalanced classification ideas in the traditional machine learning field to graph-structured data to improve the classification performance of graph neural networks. In a node feature aggregation stage, the node membership values among nodes are calculated for minority nodes' feature aggregation enhancement. In an oversampling stage, the cost-sensitive learning is used to improve edge prediction results of synthetic minority nodes, and further raise their importance. In addition, a Gumbel distribution is adopted as an activation function. The proposed mGNN is evaluated on six social network data sets. Experimental results show that it yields promising results for imbalanced node classification.
Extracting entity relations from unstructured medical texts is a fundamental task in the field of medical information extraction. In relation extraction, dependency trees contain rich structural information that helps capture the long-range relations between entities. However, many models cannot effectively use dependency information or learn sentence information adequately. In this paper, we propose a relation extraction model based on syntactic dependency structure information. First, the model learns sentence sequence information by Bi-LSTM. Then, the model learns syntactic dependency structure information through graph convolutional networks. Meanwhile, in order to remove irrelevant information from the dependencies, the model adopts a new pruning strategy. Finally, the model adds a multi-head attention mechanism to focus on the entity information in the sentence from multiple aspects. We evaluate the proposed model on a Chinese medical entity relation extraction dataset. Experimental results show that our model can learn dependency relation information better and has higher performance than other baseline models.
Graph embedding based methods have been used in recommendation systems recently, owing to their advances in modeling nodes as embeddings in a low-dimensional space. By effective neighborhood aggregation, graph convolutional networks can exploit high-order connections of neighbors such that the learned embeddings could be more informative thus improve the recommendation performance. However, user and item representations learned by graph aggregation inherently contain uncertainty due to sparsity of user-item interactions and noise of item features. To address these challenges, we propose a multi-modal variational graph auto-encoder (MVGAE) method. Specifically, we design modality-specific variational encoders that learn a Gaussian variable for each node whereas the mean vector represents semantic information and the variance vector denotes the noise level of the corresponding modality. Moreover, with the conditional independence assumption, the modality-specific Gaussian node embeddings are fused according to the product-of-experts principle, where the semantic information in each modality is weighted based on the estimated uncertainty level. Extensive experiments on three public datasets, Amazon Movies, Amazon Electronics and AliShop-7 C, demonstrate that our proposed method achieves competitive performance when compared with the state-of-the-art algorithms.
Existing methods in relation extraction have leveraged the lexical features in the word sequence and the syntactic features in the parse tree. Though effective, the lexical features extracted from the successive word sequence may introduce some noise that has little or no meaningful content. Meanwhile, the syntactic features are usually encoded via graph convolutional networks which have restricted receptive field. In addition, the relation between lexical and syntactic features in the representation space has been largely neglected. To address the above limitations, we propose a multi-scale representation and metric learning framework to exploit the feature and relation hierarchy for RE tasks. Methodologically, we build a lexical and syntactic feature and relation hierarchy in text data. Technically, we first develop a multi-scale convolutional neural network to aggregate the non-successive lexical patterns in the word sequence. We also design a multi-scale graph convolutional network to increase the receptive field via the coarsened syntactic graph. Moreover, we present a multi-scale metric learning paradigm to exploit both the feature-level relation between lexical and syntactic features and the sample-level relation between instances with the same or different classes. Extensive experiments on three public datasets for two RE tasks prove that our model achieves a new state-of-the-art performance.
This article presents FLGC, a simple yet effective fully linear graph convolutional network for semi-supervised and unsupervised learning. Instead of using gradient descent, we train FLGC based on computing a global optimal closed-form solution with a decoupled procedure, resulting in a generalized linear framework and making it easier to implement, train, and apply. We show that (1) FLGC is powerful to deal with both graph-structured data and regular data, (2) training graph convolutional models with closed-form solutions improve computational efficiency without degrading performance, and (3) FLGC acts as a natural generalization of classic linear models in the non-Euclidean domain (e.g., ridge regression and subspace clustering). Furthermore, we implement a semi-supervised FLGC and an unsupervised FLGC by introducing an initial residual strategy, enabling FLGC to aggregate long-range neighborhoods and alleviate over-smoothing. We compare our semi-supervised and unsupervised FLGCs against many state-of-the-art methods on a variety of classification and clustering benchmarks, demonstrating that the proposed FLGC models consistently outperform previous methods in terms of accuracy, robustness, and learning efficiency. The core code of our FLGC is released at https://github.com/AngryCai/FLGC.
Human skeleton contains intuitive information of motions, therefore, it has been widely studied in action analysis tasks. As a part of action analysis, traditional models human action assessment by handcrafted-feature-based methods, such as dynamic time warping (DTW). These methods only extract the similarity of particular spatiotemporal features, whereas the global spatio-temporal relevance of action analysis tends to be ignored. In this paper, we propose a regression assessment model for action spatio-temporal features, which encodes the temporal features, spatial features and fused features respectively. The self-attention mechanism is taken advantage of to fuse the decoupling features, and then the overall score of action was calculated by regression. Specifically, via structure-feature fusion adaptive graph convolutional networks (SFAGCN), our action assessment network models the deep dependence of global spatio-temporal feature to address the difficulties of limited expressive ability and generalization. Furthermore, the topology of the skeletal graph and the features of the joints are merged by decoupling the spatio-temporal correlations. To confirm the effectiveness of our assessment model, we conduct experiments on six Olympic Games assessment tasks and exceed the state-of-the-art performance in Spearman's rank correlation analysis.
Sarcasm detection remains a challenge for numerous Natural Language Processing (NLP) tasks, such as sentiment classification or stance prediction. Existing sarcasm detection studies attempt to capture the subtle semantic incongruity patterns by using contextual information and graph information through Graph Convolutional Networks (GCN). However, direct application of dependence may inevitably introduce noisy information and inferiorly in modeling long-distance or disconnected words in the dependency tree. To better learn the sentiment inconsistencies between terms, we propose an Affection Enhanced Relational Graph Attention network (ARGAT) by jointly considering the affective information and the dependency information. Specifically, we use Relational Graph Attention Networks (RGAT) to integrate relation information guided by a trainable matrix of relation types and synchronously use GCNs to integrate affection information explicitly donated by affective adjacency matrixes. The employment of RGAT contributes to information interaction of structural relevant word pairs with a long distance. With the enhancement of affective information, the proposed model can capture complex forms of sarcastic expressions. Experimental results on six benchmark datasets show that our proposed approach outperforms state-of-the-art sarcasm detection methods. The best-improved results of accuracy and F1 are 4.19% and 4.33%, respectively.
Accurate short-term passenger flow prediction in urban rail transit is critical in ensuring the stable operation of urban rail systems. However, accurate passenger flow prediction still faces challenges, including modeling the dynamics of passenger flow data in spatial and temporal dimensions and capturing the interactions between the inflows and outflows. To solve these problems, a novel model called the multi-feature fusion graph convolutional network (MFGCN) is proposed. Firstly, parallel graph branch networks are established to describe inflow and outflow information from geographic and semantic perspectives. Then, in the spatial dimension, the graph convolutional networks with spatial attention are designed to learn the dynamic spatial correlations of nodes in the two graphs. In the temporal dimension, the long short-term memory networks with temporal attention are developed to learn the dynamic temporal dependencies of passenger flow data. Finally, a three-dimensional residual network is established to capture the spatial-temporal interactive dependencies between inflows and outflows. Experiments on Nanning Metro Line 1 passenger flow datasets demonstrated that MFGCN outperformed the existing baseline models, which could provide technical support for URT network operation management.
With the emergence of blockchain technology, the cryptocurrency market has experienced significant growth in recent years, simultaneously fostering environments conducive to cybercrimes such as phishing scams. Phishing scams on blockchain platforms like Ethereum have become a grave economic threat. Consequently, there is a pressing demand for effective detection mechanisms for these phishing activities to establish a secure financial transaction environment. However, existing methods typically utilize only the most recent transaction record when constructing features, resulting in the loss of vast amounts of transaction data and failing to adequately reflect the characteristics of nodes. Addressing this need, this study introduces a multiscale feature fusion approach integrated with a graph convolutional network model to detect phishing scams on Ethereum. A node basic feature set comprising 12 features is initially designed based on the Ethereum transaction dataset in the basic feature module. Subsequently, in the edge embedding representation module, all transaction times and amounts between two nodes are sorted, and a gate recurrent unit (GRU) neural network is employed to capture the temporal features within this transaction sequence, generating a fixed-length edge embedding representation from variable-length input. In the time trading feature module, attention weights are allocated to all embedding representations surrounding a node, aggregating the edge embedding representations and structural relationships into the node. Finally, combining basic and time trading features of the node, graph convolutional networks (GCNs), SAGEConv, and graph attention networks (GATs) are utilized to classify phishing nodes. The performance of these three graph convolution-based deep learning models is validated on a real Ethereum phishing scam dataset, demonstrating commendable efficiency. Among these, SAGEConv achieves an F1-score of 0.958, an AUC-ROC value of 0.956, and an AUC-PR value of 0.949, outperforming existing methods and baseline models.
This study focuses on enhancing the prediction of regulatory functional sites in DNA and RNA sequences, a crucial aspect of gene regulation. Current methods, such as motif overrepresentation and machine learning, often lack specificity. To address this issue, the study leverages evolutionary information and introduces Graphylo, a deep -learning approach for predicting transcription factor binding sites in the human genome. Graphylo combines Convolutional Neural Networks for DNA sequences with Graph Convolutional Networks on phylogenetic trees, using information from placental mammals' genomes and evolutionary history. The research demonstrates that Graphylo consistently outperforms both single -species deep learning techniques and methods that incorporate inter -species conservation scores on a wide range of datasets. It achieves this by utilizing a species -based attention model for evolutionary insights and an integrated gradient approach for nucleotide -level model interpretability. This innovative approach offers a promising avenue for improving the accuracy of regulatory site prediction in genomics.
Multimodal retrieval has received widespread consideration since it can commendably provide massive related data support for the development of computational social systems (CSSs). However, the existing works still face the following challenges: 1) rely on the tedious manual marking process when extended to CSS, which not only introduces subjective errors but also consumes abundant time and labor costs; 2) only using strongly aligned data for training, lacks concern for the adjacency information, which makes the poor robustness and semantic heterogeneity gap difficult to be effectively fit; and 3) mapping features into real-valued forms, which leads to the characteristics of high storage and low retrieval efficiency. To address these issues in turn, we have designed a multimodal retrieval framework based on web-knowledge-driven, called unsupervised and robust graph convolutional hashing (URGCH). The specific implementations are as follows: first, a "secondary semantic self-fusion" approach is proposed, which mainly extracts semantic-rich features through pretrained neural networks, constructs the joint semantic matrix through semantic fusion, and eliminates the process of manual marking; second, a "adaptive computing" approach is designed to construct enhanced semantic graph features through the knowledge-infused of neighborhoods and uses graph convolutional networks for knowledge fusion coding, which enables URGCH to sufficiently fit the semantic modality gap while obtaining satisfactory robustness features; Third, combined with hash learning, the multimodality data are mapped into the form of binary code, which reduces storage requirements and improves retrieval efficiency. Eventually, we perform plentiful experiments on the web dataset. The results evidence that URGCH exceeds other baselines about 1%-3.7% in mean average precisions (MAPs), displays superior performance in all the aspects, and can meaningfully provide multimodal data retrieval services to CSS.
Learning embeddings representations of users and items lies at the core of modern recommender systems. Existing methods based on Graph Convolutional Network (GCN) and sequential recommendation typically obtain a user's or an item's embedding by mapping from pre-existing features into better embeddings for users and items, such as ID and attributes. GCN integrates the user-item interaction as the bipartite graph structure into the embedding process, which can better represent sparse data, but cannot capture users' long-term interests. Sequential recommendation seek to capture the "context" of users' activities based on their historical actions, but requires dense data to support it. The goal of our work is to combine the advantages of GCN and sequential recommendation models by proposing a novel Self-Attention based Sequential recommendation with Graph Convolutional Networks (SASGCN). It uses multiple lightweight GCN layers to capture high-order connectivity between users and items, and by introducing ratings as auxiliary information into the user-item interaction matrix, it provides richer information. By incorporating self-attention based methods, the proposed model capture long-term semantics through relatively few actions. Extensive experiments on three benchmark datasets show that our model outperforms various state-of-the-art models consistently.
With the advances of data-driven machine learning research, a wide variety of prediction problems have been tackled. It has become critical to explore how machine learning and specifically deep learning methods can be exploited to analyse healthcare data. A major limitation of existing methods has been the focus on grid-like data; however, the structure of physiological recordings are often irregular and unordered, which makes it difficult to conceptualise them as a matrix. As such, graph neural networks have attracted significant attention by exploiting implicit information that resides in a biological system, with interacting nodes connected by edges whose weights can be determined by either temporal associations or anatomical junctions. In this survey, we thoroughly review the different types of graph architectures and their applications in healthcare. We provide an overview of these methods in a systematic manner, organized by their domain of application including functional connectivity, anatomical structure, and electrical-based analysis. We also outline the limitations of existing techniques and discuss potential directions for future research.
Due to the continuing colossal socio-economic losses caused by traffic accidents, it is of prime importance to precisely forecast the traffic accident risk to reduce future accidents. In this paper, we use dangerous driving statistics from driving log data and multi-graph learning to enhance predictive performance. We first conduct geographical and temporal correlation analyses to quantify the relationship between dangerous driving and actual accidents. Then, to learn various dependencies between districts besides the traditional adjacency matrix, we simultaneously model both static and dynamic graphs representing the spatio-temporal contextual relationships with heterogeneous environmental data, including the dangerous driving behavior. A graph is generated for each type of the relationships. Ultimately, we propose an end-to-end framework, called MG-TAR, to effectively learn the association of multiple graphs for accident risk prediction by adopting multi-view graph neural networks with a multi-attention module. Thorough experiments on ten real-world datasets show that, compared with state-of-the-art methods, MG-TAR reduces the error of predicting the accident risk by up to 23% and improves the accuracy of predicting the most dangerous areas by up to 27%.
In this study, we consider fully automated action recognition based on deep learning in the industrial environment. In contrast to most existing methods, which rely on professional knowledge to construct complex hand-crafted features, or only use basic deep-learning methods, such as convolutional neural networks (CNNs), to extract information from images in the production process, we exploit a novel and effective method, which integrates multiple deep-learning networks including CNNs, spatial transformer networks (STNs), and graph convolutional networks (GCNs) to process video data in industrial workflows. The proposed method extracts both spatial and temporal information from video data. The spatial information is extracted by estimating the human pose of each frame, and the skeleton image of the human body in each frame is obtained. Furthermore, multi-frame skeleton images are processed by GCN to obtain temporal information, meaning the action recognition results are predicted automatically. By training on a large human action dataset, Kinetics, we apply the proposed method to the real-world industrial environment and achieve superior performance compared with the existing methods.
Traffic flow forecasting is an essential task of an intelligent transportation system (ITS), closely related to intelligent transportation management and resource scheduling. Dynamic spatial-temporal dependencies in traffic data make traffic flow forecasting to be a challenging task. Most existing research cannot model dynamic spatial and temporal correlations to achieve well-forecasting performance. The multi-head self-attention mechanism is a valuable method to capture dynamic spatial-temporal correlations, and combining it with graph convolutional networks is a promising solution. Therefore, we propose a multi-head self-attention spatiotemporal graph convolutional network (MSASGCN) model. It can effectively capture local correlations and potential global correlations of spatial structures, can handle dynamic evolution of the road network, and, in the time dimension, can effectively capture dynamic temporal correlations. Experiments on two real datasets verify the stability of our proposed model, obtaining a better prediction performance than the baseline algorithms. The correlation metrics get significantly reduced compared with traditional time series prediction methods and deep learning methods without using graph neural networks, according to MAE and RMSE results. Compared with advanced traffic flow forecasting methods, our model also has a performance improvement and a more stable prediction performance. We also discuss some problems and challenges in traffic forecasting.
Purpose: Unruptured intracranial aneurysms (UIAs) can cause aneurysmal subarachnoid hemorrhage, a severe and often lethal type of stroke. Automated labeling of intracranial arteries can facilitate the identification of risk factors associated with UIAs. This study aims to improve intracranial artery labeling using atlas-based features in graph convolutional networks. Approach: We included three-dimensional time-of-flight magnetic resonance angiography scans from 150 individuals. Two widely used graph convolutional operators, GCNConv and GraphConv, were employed in models trained to classify 12 bifurcations of interest. Cross-validation was applied to explore the effectiveness of atlas-based features in node classification. The results were tested for statistically significant differences using a Wilcoxon signed-rank test. Model repeatability and calibration were assessed on the test set for both operators. In addition, we evaluated model interpretability and node feature contribution using explainable artificial intelligence. Results: Atlas-based features led to statistically significant improvements in node classification (p<0.05). The results showed that the best discrimination and calibration performances were obtained using the GraphConv operator, which yielded a mean recall of 0.87, precision of 0.90, and expected calibration error of 0.02. Conclusions: The addition of atlas-based features improved node classification results. The GraphConv operator, which incorporates higher-order structural information during training, is recommended over the GCNConv operator based on the accuracy and calibration of predicted outcomes.
In recent years, great achievements have been made in graph convolutional network (GCN) for non-Euclidean spatial data feature extraction, especially the skeleton-based feature extraction. However, the fixed graph structure determined by the fixed adjacency matrix usually causes the problems such as the weak spatial modeling ability, the unsatisfactory generalization performance, the excessively large number of model parameters, and so on. In this paper, a spatially adaptive residual graph convolutional network (SARGCN) is proposed for action recognition based on skeleton feature extraction. Firstly, the uniform and fixed topology is not required in our graph. Secondly, a learnable parameter matrix is added to the GCN operation, which can enhance the model's capabilities of feature extraction and generalization, while reducing the number of parameters. Therefore, compared with the several existing models mentioned in this paper, the least number of parameters are used in our model while ensuring the comparable recognition accuracy. Finally, inspired by the ResNet architecture, a residual connection is introduced in GCN to obtain higher accuracy at lower computational costs and learning difficulties. Extensive experimental on two large-scale datasets results validate the effectiveness of our proposed approach, namely NTU RGB+D 60 and NTU RGB+D 120.
Social networks are a crucial component of the Internet of People (IoP), which represents cutting-edge of Internet of Things (IoT). Predicting a large number of unknown node labels with few known labels is one of the challenging problems in social network analysis. Fortunately, the graph convolutional network (GCN) and subsequent variants have achieved remarkable performance on semi-supervised node classification (SSNC). However, previous works only focus on the case of clean labels and rarely study the problem of SSNC under noisy labels (SSNCNL), which is a more challenging and practical problem in the realm of weakly supervised learning. To cope with the aforementioned challenge, we present a novel dual mutual robust GCN named DMRGCN with inspiration from deep mutual learning and robust learning in the domain of image recognition. Specifically, we first employ two GCNs with different learning abilities to construct network architecture. Then, we define a joint loss function which consists of a weighted combination of supervised loss, mutual loss, and robust loss. Finally, we train the network under the pseudo-siamese network paradigm. Experimental results on three social network benchmark datasets with different levels of noise on labels demonstrate that DMRGCN outperforms the vanilla GCN and several variants on classification accuracy. In particular, under the two conditions of labels without noise and with noise, the node classification accuracy obtained by our proposed DMRGCN can be 3.05% and 6.44% higher than that of the vanilla GCN, respectively.
Passenger flow anomaly detection in urban rail transit networks (URTNs) is critical in managing surging demand and informing effective operations planning and controls in the network. Existing studies have primarily focused on identifying the source of anomalies at a single station by analysing the time-series characteristics of passenger flow. However, they ignored the high-dimensional and complex spatial features of passenger flow and the dynamic behaviours of passengers in URTNs during anomaly detection. This article proposes a novel anomaly detection methodology based on a deep learning framework consisting of a graph convolution network (GCN)-informer model and a Gaussian naive Bayes model. The GCN-informer model is used to capture the spatial and temporal features of inbound and outbound passenger flows, and it is trained on normal datasets. The Gaussian naive Bayes model is used to construct a binary classifier for anomaly detection, and its parameters are estimated by feeding the normal and abnormal test data into the trained GCN-informer model. Experiments are conducted on a real-world URTN passenger flow dataset from Beijing. The results show that the proposed framework has superior performance compared to existing anomaly detection algorithms in detecting network-level passenger flow anomalies.This article is part of the theme issue 'Artificial intelligence in failure analysis of transportation infrastructure and materials'.
The development of efficient and stable photocatalysts for degradation of refractory pollutants using minimal amounts of metal remains a major challenge. Herein, we synthesize a novel catalyst by fabrication of manganese (III) acetylacetonate complex [Mn (acac)3] over graphitic carbon nitride (GCN) denoted as 2-Mn/GCN by facile ultra-sonication method. The fabrication of the metal complex enables the migration of electrons from the conduction band of graphitic carbon nitride to Mn (acac)3, and migration of holes from valence band of Mn (acac)3 to GCN upon irradiation. Exploiting the improved surface properties, light absorption, and charge separation ensure generation of superoxide and hydroxyl radicals resulting in the rapid degradation of a variety of pollutants. The designed 2-Mn/GCN catalyst realized 99.59% rhodamine b (RhB) degradation in 55 min and 97.6% metronidazole (MTZ) degradation in 40 min with 0.7% Mn content. The influence of catalyst amount, different pH and presence of anions on the degradation kinetics was also explored to offer insights into photoactive material design.
Modeling sequences with spatial-temporal graph convolutional networks has become a mainstream paradigm in skeleton-based action recognition. However, many existing methods adopt redundant or cluttered structures to mine the key action features, thus making it difficult to achieve a balanced or leading performance in accuracy and efficiency. In this paper, we propose a novel framework, referred to as Motion Complement and Temporal Multifocusing Network (MCTM-Net), to capture the relationships within skeleton sequences by means of an efficient decomposition of the spatiotemporal graph model. Specifically, for spatial modeling, we introduce a motion-related relational descriptor that extends the channel dimension so as to enhance the modeling of motion salient regions as a complement to the conventional physical adjacency relationships. An improved parameterized physical relationship model is also proposed to better fit the data characteristics. As for temporal modeling, we propose an efficient multi-focus temporal information acquisition strategy that aggregates the information from multiple temporal spans and adjacent regions. We conduct extensive experiments on multiple representative datasets, including NTU-RGB+D (60&120), Northwestern-UCLA, and UWA3D Multiview Activity II, to validate our innovations. The experimental results show the effectiveness of our method.
Spatiotemporal safety forecasting has various applications in the neuroscience, climate and transportation domains. It is challenging due to (1) the complex spatial dependency on networks, (2) non-linear temporal dynamics with changing conditions and (3) the inherent difficulty of long-term forecasting. To address these challenges, a safety prediction model called the Spatial-Temporal Mixed Attention Graph-based Convolution model (STMAG) is proposed. Specifically, STMAG captures spatial dependency using graph convolutional networks (GCN), and temporal dependency using the sequence-to-sequence (Seq2Seq) architecture with the mixed attention mechanisms. A case study on the implementation of this model in traffic safety prediction is given as an example. Traffic safety forecasting is one canonical example of such a learning task, which is also a crucial problem to improving transportation and public safety. A number of detailed features (such as vehicle type, braking state, whether changing lanes or not) and exogenous variables (such as weather, time and road condition) are extracted from our big datasets. Finally, we conduct extensive experiments to evaluate the STMAG framework on real-world large-scale road network traffic datasets. Extensive experiments on our dataset show that the STMAG framework makes reasonably accurate predictions and significantly improves the prediction accuracy over baseline approaches. (C) 2020 Elsevier Inc. All rights reserved.
This paper introduces a generative model named the travel time reliability-generative adversarial network (TTRGAN) model for predicting network-wide TTR using automatic vehicle identification data. The TTR-GAN model is capable of generating predicted travel time samples, enabling the assessment of network-wide TTR without the need to assume a specific travel time distribution. In the TTR-GAN model, a combination of graph convolutional networks and long short-term memory (LSTM) neural networks is employed within the GAN framework. When training the TTR-GAN model, special attention is given to adjusting the mean and standard deviation of the generated samples, aiming for a closer resemblance to real samples. Experiments conducted on a road network in China demonstrate the predictive capability of the proposed TTR-GAN model, surpassing several benchmark models such as the LSTM neural network, moving average model, and GAN model in terms of statistical, buffer time, and probability distribution measures. By incorporating the mean and standard deviation into the loss function, the TTR-GAN model achieves an 18.2% reduction in Jensen-Shannon divergence between predicted and real samples. Furthermore, the model's performance in real-world applications is illustrated through a sensitivity test.
Pharmaceuticals, which have been praised for protecting countless lives, have become a new category of envi-ronmental pollutants in recent decades as most of these pharmaceutical compounds are discovered in water bodies in concentrations ranging from ng/L to mg/L. Recently, metal-free g-C3N4 (GCN)-based composites have received considerable attention for the degradation of pharmaceutical compounds. In this study, GCN/BiOCl composite was prepared using a simple ultrasonication-assisted stirring method and characterized using various analytical and spectroscopic techniques including XRD, FTIR, PL, Elemental mapping, UV-DRS, FESEM, HRTEM, and TGA. The as-prepared composite was utilized to degrade levofloxacin (LVX) under solar light irradiation and showed excellent stability for the degradation of LVX. Furthermore, the universality of the GCN/BiOCl composite was investigated by degrading diverse pharmaceuticals such as ofloxacin (OFX), norfloxacin (NOX), ciproflox-acin (COX), and ketorolac tromethamine (KTC) in an aqueous phase. Therefore, this work provides an effective method to degrade pharmaceutical contaminants simultaneously in water using GCN/BiOCl composite.
We propose a novel and flexible roof modeling approach that can be used for constructing planar 3D polygon roof meshes. Our method uses a graph structure to encode roof topology and enforces the roof validity by optimizing a simple but effective planarity metric we propose. This approach is signifficantly more efficient than using general purpose 3D modeling tools such as 3ds Max or SketchUp, and more powerful and expressive than specialized tools such as the straight skeleton. Our optimization-based formulation is also flexible and can accommodate different styles and user preferences for roof modeling. We showcase two applications. The first application is an interactive roof editing framework that can be used for roof design or roof reconstruction from aerial images. We highlight the efficiency and generality of our approach by constructing a mesh-image paired dataset consisting of 2539 roofs. Our second application is a generative model to synthesize new roof meshes from scratch. We use our novel dataset to combine machine learning and our roof optimization techniques, by using transformers and graph convolutional networks to model roof topology, and our roof optimization methods to enforce the planarity constraint.
Current cryptocurrencies, such as Bitcoin and Ethereum, enable anonymity by using public keys to represent user accounts. On the other hand, inferring blockchain account types (i.e., miners, smart contracts or exchanges), which are also referred to as blockchain identities, is significant in many scenarios, such as risk assessment and trade regulation. Existing work on blockchain deanonymization mainly focuses on Bitcoin that supports simple transactions of cryptocurrencies. As the popularity of decentralized application (DApp) platform blockchains with Turing-complete smart contracts, represented by Ethereum, identity inference in blockchain faces new challenges because of user diversity and complexity of activities enabled by smart contracts. In this paper, we propose I(2)GL, an identify inference approach based on big graph analytics and learning to address these challenges. Specifically, I(2)GL constructs a transaction graph and aims to infer the identity of nodes using the graph learning technique based on Graph Convolutional Networks. Furthermore, a series of enhancement has been proposed by exploiting unique features of blockchain transaction graph. The experimental results on Ethereum transaction records show that I(2)GL significantly outperforms other state-of-the-art methods.
Automatic modulation classification (AMC) of underwater acoustic communication signals is of great significance in national defense and marine military. Accurate modulation classification methods can make great contributions to accurately grasping the parameters and characteristics of enemy communication systems. While a poor underwater acoustic channel makes it difficult to classify the modulation types correctly. Feature extraction and deep learning methods have proven to be effective methods for the modulation classification of underwater acoustic communication signals, but their performance is still limited by the complex underwater communication environment. Graph convolution networks (GCN) can learn the graph structured information of the data, making it an effective method for processing structured data. To improve the stability and robustness of AMC in underwater channels, we combined the feature extraction and deep learning methods by fusing the multi-domain features and deep features using GCN. The proposed method takes the relationships among the different multi-domain features and deep features into account. Firstly, a feature graph was built using the properties of the features. Secondly, multi-domain features were extracted from the received signals and deep features were extracted from the signals using a deep neural network. Thirdly, we constructed the input of GCN using these features and the graph. Then, the multi-domain features and deep features were fused by the GCN. Finally, we classified the modulation types using the output of GCN by way of a softmax layer. We conducted the experiments on a simulated dataset and a real-world dataset, respectively. The results show that the AMC based on GCN can achieve a significant improvement in performance compared to the current state-of-the-art methods. Our approach is robust in underwater acoustic channels.
To handle more challenging operation security problems in today's power system, pre-fault transient stability assessment (TSA) is essentially required to promote the awareness of the system stability risks. Fast and analyzable data-driven methods draw much attention in intelligent TSA schemes, but most of them either lack generalization to various operation topologies and fault locations, or fail to operate on developing systems with changeable scales. Some schemes based on graph convolutional networks (GCNs) enjoy promising topology learning but suffer from poor scale reduction, which affects the robustness against system-scale changes. With this in mind, we propose a novel Attention-based Hierarchical Dynamic grAph Pooling nEtwork (AH-DAPE), where a graph-based hierarchical pooling strategy is initiated for effective scale reduction in power systems. The expressive power of hierarchical pooling is enhanced by a spectral unsupervised loss related to power system simplification, while the temporal learning across dynamic coarsened graphs are enabled by integration of inter-graph convolution and mean/maximum operations. Test results on small IEEE 39 Bus system and large IEEE 300 Bus system validate our scheme's superiority over existing TSA models and robustness against various operation scenarios, especially when applied to new system scales.
Aiming Graph convolutional networks (GCNs) have achieved outstanding performances on skeleton- based action recognition. However, several problems remain in existing GCN-based methods, and the problem of low recognition rate caused by single input data information has not been effectively solved. In this article, we propose a Dual-stream fusion method that combines video data and skeleton data. The two networks respectively identify skeleton data and video data and fuse the probabilities of the two outputs to achieve the effect of information fusion. Experiments on two large dataset, Kinetics and NTU-RGBC+D Human Action Dataset, illustrate that our proposed method achieves state-of-the-art. Compared with the traditional method, the recognition accuracy is improved better.
Most graph convolutional network (GCN)-based social recommendation frameworks fuse social links with user-item interactions to enrich user representations, which alleviate the cold-start problem and data sparsity problem. However, GCN-based recommender systems still suffer from two limitations. First, Excessive reliance on social graphs to extract user interests for rating predictions is unreliable due to social inconsistency. Second, GCN-based models suffer from over-smoothing problems, node embeddings become more similar when going deeper to enable larger receptive fields. To address the two aforementioned problems simultaneously, we propose a Deep Adaptive Collaborative Graph Neural Network for Social Recommendation (DUI-SoRec). First, the graph generation module decomposes the user-item interaction to generate two subgraphs: an u2u graph and an i2i graph. Secondly, the graph learning module utilizes a deep adaptive graph neural network to learn user and item embeddings on the two subgraphs and the existing social graph, while solving the over -smoothing problem. Finally, we designed a refined fusion module to aggregate the social graph and u2u graph to address the social inconsistency. We conducted extensive experiments on four real-world datasets and the results demonstrate the model's effectiveness.
The fine-grained task of emotion analysis, emotion cause extraction, is a current research hotspot. It aims to discover the underlying reasons behind the emotional expression in texts. Most of the existing work regards the task as an independent text clause classification problem, ignoring the relationship between the clauses and failing to use the indicative relationship between emotional sentences and emotional cause sentences. The existence of these problems greatly affects the accuracy of the task. In this work, an emotion cause extraction method based on a hierarchical network emotional assistance mechanism is proposed. This method uses a hierarchical network composed of bidirectional gated recurrent units, attention mechanism, and graph convolutional networks to capture clause context information, deep semantic information, and structural information between clause neighborhoods. At the same time, by enhancing the emotional information representation of the graph convolutional network nodes, the clause features of the text emotional keywords are introduced into the discovery of candidate cause sentences. Thus, a model of the deep neural network combined with the emotional assistance mechanism is established. Compared with the existing methods, the model established in this paper has better classification performance on the Chinese emotion cause dataset.
Graph convolutional networks (GCNs) are a family of neural network models that perform inference on graph data by interleaving vertexwise operations and message-passing exchanges across nodes. Concerning the latter, two key questions arise: 1) how to design a differentiable exchange protocol (e.g., a one-hop Laplacian smoothing in the original GCN) and 2) how to characterize the tradeoff in complexity with respect to the local updates. In this brief, we show that the state-of-the-art results can be achieved by adapting the number of communication steps independently at every node. In particular, we endow each node with a halting unit (inspired by Graves' adaptive computation time [1]) that after every exchange decides whether to continue communicating or not. We show that the proposed adaptive propagation GCN (AP-GCN) achieves superior or similar results to the best proposed models so far on a number of benchmarks while requiring a small overhead in terms of additional parameters. We also investigate a regularization term to enforce an explicit tradeoff between communication and accuracy. The code for the AP-GCN experiments is released as an open-source library.
Most existing object detection models are restricted to detecting objects from previously seen categories, an approach that tends to become infeasible for rare or novel concepts. Accordingly, in this paper, we explore object detection in the context of zero-shot learning, i.e., Zero-Shot Object Detection (ZSD), to concurrently recognize and localize objects from novel concepts. Existing ZSD algorithms are typically based on a strict mapping-transfer strategy that suffers from a significant visual-semantic gap. To bridge the gap, we propose a novel Semantics-Preserving Graph Propagation model for ZSD based on Graph Convolutional Networks (GCN). More specifically, we develop a graph construction module to flexibly build category graphs by leveraging diverse correlations between category nodes; this is followed by two semantics-preserving graph propagation modules that enhance both category and region representations. Benefiting from the multi-step graph propagation process, both the semantic description and structural knowledge exhibited in prior category graphs can be effectively leveraged to boost the generalization capability of the learned projection function. Experiments on existing seen/unseen splits of three popular object detection datasets demonstrate that the proposed approach performs favorably against state-of-the-art ZSD methods.
Game theory can employ reinforcement learning algorithms to identify the optimal policy or equilibrium solution. Potential-based reward shaping (PBRS) methods are prevalently used for accelerating reinforcement learning, ensuring the optimal policy remains consistent. Existing PBRS research performs message passing based on graph convolution neural networks (GCNs) to propagate information from rewarding states. However, in an irreversible time-series reinforcement learning problem, undirected graphs will not only mislead message-passing schemes but also lose a distinctive direction structure. In this paper, a novel approach called directed graph convolution neural networks for reward shaping phi DCN has been proposed to tackle this problem. The key innovation of phi DCN is the extension of spectral-based undirected graph convolution to directed graphs. Messages can be efficiently propagated by leveraging a directed graph Laplacian as a substitute for the state transition matrix. As a consequence, potential-based reward shaping can then be implemented by the propagated messages. The incorporation of temporal dependencies between states makes phi DCN more suitable for real-world scenarios than existing potential-based reward shaping methods based on undirected graph convolutional networks. Preliminary experiments demonstrate that the proposed phi DCN exhibits a substantial improvement compared to other competing algorithms on both Atari and MuJoCo benchmarks.
Previous speech emotion recognition (SER) methods normally deal with variable-length utterance inputs by padding shorter ones or clipping longer ones into equal-length utterances, which may introduce invalid information or discard useful emotional segments. To address this issue, in this paper, we cast the SER problem into a graph classification task by transforming variable-length utterances into graphs to avoid padding or cutting. In our approach, frames (short windowed segments) in an utterance are presented as nodes in a graph. Acoustic features extracted from frames are treated as node feature vectors and nodes are connected according to their temporal relationship. Different graph convolutional networks (GCNs) are explored for node/frame embedding learning, and kinds of graph pooling methods are compared to obtain graph/utterance-level emotional representation from node embeddings. Extensive experiments with different GCN components and pooling mechanisms are conducted on the IEMOCAP and MSP-IMPRO datasets. The experimental results show that a combination of GraphSAGE with multi-head attention pooling (MHAPool) achieves the best weighted accuracy (WA) and comparable unweighted accuracy (UA) on both datasets compared with other state-of-the-art SER models, which demonstrates the effectiveness of the proposed graph-based network for SER task. (C) 2022 Elsevier B.V. All rights reserved.
Analyzing the vulnerability of power systems in cascading failures is generally regarded as a challenging problem. Although existing studies can extract some critical rules, they fail to capture the complex subtleties under different operational conditions. In recent years, several deep learning methods have been applied to address this issue. However, most of the existing deep learning methods consider only the grid topology of a power system in terms of topological connections, but do not encompass a power system's spatial information such as the electrical distance to increase the accuracy in the process of graph convolution. In this paper, we construct a novel power-weighted line graph that uses power system topology and spatial information to optimize the edge weight assignment of the line graph. Then we propose a multi-graph convolutional network (MGCN) based on a graph classification task, which preserves a power system's spatial correlations and captures the relationships among physical components. Our model can better handle the problem with power systems that have parallel lines, where our method can maintain desirable accuracy in modeling systems with these extra topology features. To increase the interpretability of the model, we present the MGCN using layer-wise relevance propagation and quantify the contributing factors of model classification.
Graph convolutional network has been extensively employed in semi-supervised classification tasks. Although some studies have attempted to leverage graph convolutional networks to explore multi-view data, they mostly consider the fusion of feature and topology individually, leading to the underutilization of the consistency and complementarity of multi-view data. In this paper, we propose an end-to-end joint fusion framework that aims to simultaneously conduct a consistent feature integration and an adaptive topology adjustment. Specifically, to capture the feature consistency, we construct a deep matrix decomposition module, which maps data from different views onto a feature space obtaining a consistent feature representation. Moreover, we design a more flexible graph convolution that allows to adaptively learn a more robust topology. A dynamic topology can greatly reduce the influence of unreliable information, which acquires a more adaptive representation. As a result, our method jointly designs an effective feature fusion module and a topology adjustment module, and lets these two modules mutually enhance each other. It takes full advantage of the consistency and complementarity to better capture the more intrinsic information. The experimental results indicate that our method surpasses state-of-the-art semi-supervised classification methods.
Message passing neural networks such as graph convolutional networks (GCN) can jointly consider various types of features for social bot detection. However, the expressive power of GCN is upper-bounded by the 1st-order Weisfeiler-Leman isomorphism test, which limits the detection performance for the social bots. In this paper, we propose a subgraph encoding based GCN model, SEGCN, with stronger expressive power for social bot detection. Each node representation of this model is computed as the encoding of a surrounding induced subgraph rather than encoding of immediate neighbors only. Extensive experimental results on two publicly available datasets, Twibot-20 and Twibot-22, showed that the proposed model improves the accuracy of the state-of-the-art social bot detection models by around 2.4%, 3.1%, respectively.
Graph Convolutional Network (GCN) has become a hotspot in graph-based machine learning due to its powerful graph processing capability. Most of the existing GCN-based approaches are designed for single-view data. In numerous practical scenarios, data is expressed through multiple views, rather than a single view. The ability of GCN to model homogeneous graphs is indisputable, while it is insufficient in facing the heterophily property of multi-view data. In this paper, we revisit multi-view learning to propose an implicit heterogeneous graph convolutional network that efficiently captures the heterogeneity of multi-view data while exploiting the powerful feature aggregation capability of GCN. We automatically assign optimal importance to each view when constructing the meta-path graph. High-order cross-view meta-paths are explored based on the obtained graph, and a series of graph matrices are generated. Combining graph matrices with learnable global feature representation to obtain heterogeneous graph embeddings at various levels. Finally, in order to effectively utilize both local and global information, we introduce a graph-level attention mechanism at the meta-path level that allocates private information to each node individually. Extensive experimental results convincingly support the superior performance of the proposed method compared to other state-of-the-art approaches.
Acid leachate from steel sludge was used as a source of zinc oxide (ZnO-L) for the preparation of photo -catalytically active composites based on GO/ZnO-L and g-C3N4/ZnO-L (further denoted as gCN/ZnO-L). The prepared composites were characterized using UV-Vis spectrophotometry, SBET, XRD, FTIR and DRS. The photocatalytic efficiency was tested using the photodegradation of azo dye Acid Orange 7. The obtained results were confronted with model composites prepared from pure components. For GO/ZnO-L and gCN/ZnO-L sam-ples, the degradation efficiency was found to be 60.2 % and 51.5 %, respectively. While in the case of gCN/ZnO-L composites, it was purely photochemical degradation, in the case of GO/ZnO-L composites adsorption was significantly co-applied. For both composites containing ZnO-L, a higher photo-degradation activity against azo dye was found compared to the model composites. The reason is the modification of the electronic structure and the emergence of new quantum levels between the valence band and the conduction band of ZnO and gCN due to the presence of other metal oxides in ZnO-L, which leads to a more efficient separation of photo-generated charge carriers.
Graph Neural Network (GNN) is a promising technique in representation learning on graph data. Graph Convolution Network (GCN) and Graph Attention Network (GAT) are two main representative techniques in GNN, which can learn node embedding on the graph by aggregating the embedding of the neighborhoods. However, the complex computation process of existing GCN and GAT makes them less effective for tasks with complex graph structures. Moreover, traditional GCN and GAT ignore the time factor in user representation learning, so the obtained user preference model is static and cannot reflect the dynamics of user preferences. In this work, we propose a time-aware Lightweight Graph Convolutional Attention Network (LightGCAN), which can capture static and dynamic user preferences efficiently by using different GNN strategies. Specifically, static user preferences are modeled by a GCN with only neighborhood aggregation, and dynamic user preferences are extracted by a time-aware GAT based on recently interacted items. Static and dynamic user preferences are then combined and fed into a dual-channel Deep Neural Network (DNN) model for feature interaction learning and matching score prediction. Extensive experiments on different datasets show that LightGCAN is superior to the SOTA recommendation method.
BackgroundSpinal cord injury (SCI) may lead to impaired motor function, autonomic nervous system dysfunction, and other dysfunctions. Brain-computer Interface (BCI) system based on motor imagery (MI) can provide more scientific and effective treatment solutions for SCI patients. MethodsAccording to the interaction between brain regions, a coherence-based graph convolutional network (C-GCN) method is proposed to extract the temporal-frequency-spatial features and functional connectivity information of EEG signals. The proposed algorithm constructs multi-channel EEG features based on coherence networks as graphical signals and then classifies MI tasks. Different from the traditional graphical convolutional neural network (GCN), the C-GCN method uses the coherence network of EEG signals to determine MI-related functional connections, which are used to represent the intrinsic connections between EEG channels in different rhythms and different MI tasks. EEG data of SCI patients and healthy subjects have been analyzed, where healthy subjects served as the control group. ResultsThe experimental results show that the C-GCN method can achieve the best classification performance with certain reliability and stability, the highest classification accuracy is 96.85%. ConclusionThe proposed framework can provide an effective theoretical basis for the rehabilitation treatment of SCI patients.
Urban functional zones (UFZs) contain abundant landscape information that can be adopted to better understand the surroundings. Various landscape compositions and configurations reflect different human activities, which may affect the particulate matter (PM2.5) concentrations. The very high -resolution (VHR) image features can reflect the physical and spatial structures of the UFZs. However, the existing PM2.5 estimation methods neither have been based on the scale of UFZs, nor have the VHR image features of UFZs as independent vari-ables. Hence, this article proposes a spatiotemporal interpolation graph convolutional network (STI-GCN) model and introduces VHR image features to achieve PM2.5 estimation in UFZs. First, UFZs are split, and VHR image features are extracted by the visual geometry group 16 (VGG16). Subsequently, meteorological factors, aerosol optical depth (AOD), and VHR image features are used to estimate the PM2.5 concentrations at the scale of the UFZs. The two metropolises, Beijing and Shanghai, are chosen to assess the validity of the STI-GCN model. As for Beijing and Shanghai, the overall accuracy R-2 of the STI-GCN model can reach 0.96 and 0.89, the root-mean-square errors (RMSEs) are 8.15 and 6.40 mu g/m(3), the mean absolute errors (MAEs) are 5.51 and 4.78 mu g/m(3), and the relative prediction errors (RPEs) are 18.53% and 17.38%, respectively. Experiments show that the STI-GCN consistently outperforms other models. What's more, the PM2.5 values are relatively high in commercial and official zones (COZs) and relatively low in urban green zones (UGZs).
Breast cancer is a heterogeneous disease and can be divided into several subtypes with unique prognostic and molecular characteristics. The classification of breast cancer subtypes plays an important role in the precision treatment and prognosis of breast cancer. Benefitting from the relation-aware ability of a graph convolution network (GCN), we present a multi-omics integrative method, the attention-based GCN (AGCN), for breast cancer molecular subtype classification using messenger RNA expression, copy number variation and deoxyribonucleic acid methylation multi-omics data. In the extensive comparative studies, our AGCN models outperform state-of-the-art methods under different experimental conditions and both attention mechanisms and the graph convolution subnetwork play an important role in accurate cancer subtype classification. The layer-wise relevance propagation (LRP) algorithm is used for the interpretation of model decision, which can identify patient-specific important biomarkers that are reported to be related to the occurrence and development of breast cancer. Our results highlighted the effectiveness of the GCN and attention mechanisms in multi-omics integrative analysis and the implement of the LRP algorithm can provide biologically reasonable insights into model decision.
Graph Convolutional Network (GCN) have been widely used in the field of skeleton-based action recognition and have achieved exciting results. Introducing attention mechanism in the process of extracting skeleton features has always been a hot spot in GCN-related research. In this article, we design a new graph convolutional network, which combines the advanced decoupling graph convolutional network (DC-GCN) with spatial, temporal, channel (STC) series attention module and adaptive normalization (AN). The STC attention module helps the network tend to extract important information from skeleton features. In addition, in order to improve the adaptability of the normalization method to GCN, we design the AN module instead of the BN module, which can train the weights of different normalization methods, so that each normalization layer in the network adopts the most suitable normalization operation. The experimental results show that the accuracy of our method is competitive with the state-of-the-art action recognition methods.
Blockchain technology has generated an influx of transaction data and complex interactions, posing significant challenges for traditional machine learning methods, which struggle to capture high-dimensional patterns in transaction networks. In this paper, we present the disentangled prototypical graph convolutional network (DP-GCN), an innovative approach to account classification in Ethereum transaction records. Our method employs a unique disentanglement mechanism that isolates relevant features, enhancing pattern recognition within the network. Additionally, we apply prototyping to disentangled representations, to classify scam nodes robustly, despite extreme class imbalances. We further employ a joint learning strategy, combining triplet loss and prototypical loss with a gamma coefficient, achieving an effective balance between the two. Experiments on real Ethereum data showcase the success of our approach, as the DP-GCN attained an F1 score improvement of 32.54%p over the previous best-performing GCN model and an area under the ROC curve (AUC) improvement of 4.28%p by incorporating our novel disentangled prototyping concept. Our research highlights the importance of advanced techniques in detecting malicious activities within large-scale real-world cryptocurrency transactions.
Finding new enzyme variants with the desired substrate scope requires screening through a large number of potential variants. In a typical in silico enzyme engineering workflow, it is possible to scan a few thousands of variants, and gather several candidates for further screening or experimental verification. In this work, we show that a Graph Convolutional Neural Network (GCN) can be trained to predict the binding energy of combinatorial libraries of enzyme complexes using only sequence information. The GCN model uses a stack of message-passing and graph pooling layers to extract information from the protein input graph and yield a prediction. The GCN model is agnostic to the identity of the ligand, which is kept constant within the mutant libraries. Using a miniscule subset of the total combinatorial space (204-208 mutants) as training data, the proposed GCN model achieves a high accuracy in predicting the binding energy of unseen variants. The network's accuracy was further improved by injecting feature embeddings obtained from a language module pretrained on 10 million protein sequences. Since no structural information is needed to evaluate new variants, the deep learning algorithm is capable of scoring an enzyme variant in under 1 ms, allowing the search of billions of candidates on a single GPU.
The increasing integration of Inverter Interfaced Distributed Generators (IIDGs) into distribution networks has led to a more active nature of the grid. However, the accuracy-speed trade-off caused by iterative algorithms and simplified models in the short-circuit current calculation method for active distribution networks (ADNs) is becoming more prominent. To address this issue, we propose a novel approach that utilizes Graph Convolutional Neural Networks (GCNs) for short-circuit current calculation in ADNs. Our study explores the characteristics of short-circuit current in different network structures and evaluates the feasibility of representing electrical quantities using a graph data format. The proposed method employs the GCN model to calculate multi-output ADN short-circuit current and investigates the block construction of the GCN model. Algorithm analysis demonstrates that our method effectively calculates network-wide short-circuit current under various network structures, IIDG penetration rates, and fault conditions, meeting both accuracy and computational speed requirements. The proposed method offers several advantages, including superior precision, rapid computation, minimal hardware resource utilization, and robust resistance to interference.
Clustering is a basic task of data analysis and decision making. Recently, graph convolution network (GCN) based deep clustering frameworks have produced the state-of-the-art performance. However, the traditional GCN has not fully learnt the structural information of the neighbors. Therefore, in this paper, we propose an attention-based hierarchical denoised deep clustering (AHDDC) algorithm to solve the problem, which enables GCN to learn multiple layers of hidden information and uses the attention mechanism to strengthen the information. Besides, we use a denoising autoencoder to reduce the influence of the data noise on the clustering. In AHDDC, Firstly, we input the feature vector of the original data into a denoising autoencoder (DAE) to learn the hidden representation; secondly, the representation information of the autoencoder and the structure information constructed by the KNN graph are passed into a hierarchical attentional graph convolutional network; finally, a self-supervision module is used to optimize the clustering results. Experimental results show the superiorities of our method over most advanced algorithms. Besides, the effectiveness of the proposed hierarchical, attention based and denoising improving strategies are also verified experimentally.
Due to the prevailing trend of globalization, the competition for social employment has escalated significantly. Moreover, the job market has become exceedingly competitive for students, warranting immediate attention. In light of this, a novel prognostic model employing big data technology is proposed to facilitate a bilateral employment scenario for graduates, aiding college students in promptly gauging the prevailing social employment landscape and providing precise employment guidance. Initially, the focus lies in meticulously analyzing pivotal aspects of college students' employment by constructing a specialized employment platform. Subsequently, a classification model grounded in a graph convolution network (GCN) is built, leveraging big data technology to comprehensively comprehend graduates' strengths and weaknesses in the employment milieu. Furthermore, based on the outcomes derived from the comprehensive classification of college students' qualities, a college students' employment trend prediction method employing long and short term memory (LSTM) is proposed. This method supplements the analysis of graduates' employability and enables accurate forecasting of college students' employment trends. Empirical evidence substantiates that my proposed methodology effectively evaluates graduates' comprehensive qualities and successfully predicts their employment prospects. The achieved F-values, 82.45% and 69.89%, respectively, demonstrate the efficacy of anticipating the new paradigm in graduates' dual-line employment.
Traffic flow prediction plays an important role in intelligent transportation systems and is of great significance in the applications of traffic control and urban planning. Due to the complexity of road traffic flow data, traffic flow prediction has been one of the challenging tasks to fully exploit the spatiotemporal characteristics of roads to improve prediction accuracy. In this study, a combined flow direction level traffic flow prediction graph convolutional network (GCN) and long short-term memory (LSTM) model based on spatiotemporal characteristics is proposed. First, a GCN model is employed to capture the topological structure of the data graph and extract the spatial features of road networks. Additionally, due to the capability to handle long-term dependencies, the longterm memory is used to predict the time series of traffic flow and extract the time features. The proposed model is evaluated using real-world data, which are obtained from the intersection of Liuquan Road and Zhongrun Avenue in the Zibo High-Tech Zone of China. The results show that the developed combined GCNLSTM flow direction level traffic flow prediction model can perform better than the single models of the LSTM model and GCN model, and the combined ARIMA-LSTM model in traffic flow has a strong spatiotemporal correlation.
The photocatalytic performance of graphitic carbon nitride (g-C3N4) is improved by the introduction of mo-lybdenum disulfide (MoS2) quantum dots (QDs), aiming the enhanced visible light absorbance in resultant 2 -dimensional g-C3N4/MoS2, termed as GCN/MoS2 hereafter. A novel synthetic approach i.e., pseudo-successive ionic layer adsorption and reaction (p-SILAR) was employed to deposit MoS2 QDs on g-C3N4 and to salvage 2 -dimensional MoS2 concomitantly. The results of the photocatalytic activity affirm that GCN/MoS2 worked as a better photocatalyst than the pure g-C3N4, while salvaged MoS2 also showed reasonable degradation of Rhodamine-B (RhB) dye. The average pore size (measured with BET analysis) of GCN/MoS2 was reduced to 31.91 nm from 33.11 nm (for g-C3N4), indicating effectual nanoscale deposition of MoS2 which resulted in a decrease in the overall bandgap alignment of the composite from 2.8 eV to 2.2 eV. In-depth material charac-terization and photocatalytic analysis was carried out to affirm that p-SILAR serves as a suitable synthesis route for the development of GCN/MoS2 nanocomposite as well as salvaged MoS2.
Early recognition of abnormal gait enables physicians to determine a prompt rehabilitation plan for patients for the most effective treatment and care. The Kinect depth sensor can easily collect skeleton data describing the position of joints in the human body. However, the default human skeleton model of Kinect includes an excessive number of many joints, which limits the accuracy of the gait recognition methods and increases the computational resources required. In this study, we propose an optimized human skeleton model for the Kinect system and streamline the joints using a center-of-mass calculation. We integrate several techniques to propose an end-to-end, spatial-temporal, joint attention graph convolutional network (STJA-GCN) architecture. We conducted experiments with a fivefold cross-validation on two common datasets of information on abnormal gaits to evaluate the performance of the proposed method. The results show that the STJA-GCN achieved 93.17 and 92.08% accuracy on the two datasets, and compared to the original spatial-temporal graph convolutional network (ST-GCN), the recognition accuracy increases by 9.22 and 20.65%, respectively. Overall, the results demonstrate that the STJA-GCN can accurately recognize abnormal gaits and, thus, can support low-cost rehabilitation assessments at community hospitals or in patients' homes.
The classical co-precipitation technique was carried out for the preparation of cobalt ferrite (CFN), and Ag-doped cobalt ferrite (AgCFN). Composite with graphitic carbon nitride (AgCFN@gCN) was prepared by employing the ultrasonication method. Photocatalytic degradation activity of synthesized materials was evaluated using crystal violet (coloured compound) and benzimidazole (colourless compound) under sunlight. Various physiochemical methods such as UV-Visible, XRD, SEM, and FT-IR spectroscopy were employed for the characterization of prepared samples. XRD was used for structural characterization. The prepared nanomaterials were sized up to be < 09 nm. FT-IR spectroscopy was exploited for the functional group characterization. Surface morphology was perceived through Scanning Electron Microscope. Optical analysis was carried out using a UV-Visible spectrophotometer. The photodegradation efficiencies for crystal violet and benzimidazole were ascertained to be in the order of CFN < AgCFN < AgCFN@gCN, under sunlight. Among the synthesized photocatalysts, AgCFN@gCN was discovered to have the highest photocatalytic degradation efficiency of 52.72% and 84.21% for benzimidazole and crystal violet, respectively. The higher catalytic activity of AgCFN@gCN can be associated with its high surface area and the presence of active sites of the gCN sheets. Role of electrons (e(-)), holes (h(+)), and hydroxyl radicals (OH & lowast;) in the photocatalytic activity was also assessed.
Graph Convolutional Network (GCN) with the powerful capacity to explore graph-structural data has gained noticeable success in recent years. Nonetheless, most of the existing GCN-based models suffer from the notorious over-smoothing issue, owing to which shallow networks are extensively adopted. This may be problematic for complex graph datasets because a deeper GCN should be beneficial to propagating information across remote neighbors. Recent works have devoted effort to addressing over-smoothing problems, including establishing residual connection structure or fusing predictions from multi-layer models. Because of the indistinguishable embeddings from deep layers, it is reasonable to generate more reliable predictions before conducting the combination of outputs from various layers. In light of this, we propose an Alternating Graph-regularized Neural Network (AGNN) composed of Graph Convolutional Layer (GCL) and Graph Embedding Layer (GEL). GEL is derived from the graph-regularized optimization containing Laplacian embedding term, which can alleviate the over-smoothing problem by periodic projection from the low-order feature space onto the high-order space. With more distinguishable features of distinct layers, an improved Adaboost strategy is utilized to aggregate outputs from each layer, which explores integrated embeddings of multi-hop neighbors. The proposed model is evaluated via a large number of experiments including performance comparison with some multi-layer or multi-order graph neural networks, which reveals the superior performance improvement of AGNN compared with state-of-the-art models.
Graph convolution networks (GCNs) play an increasingly vital role in recommender systems, due to their remarkable relation modeling and representation capabilities. Concretely, they can capture high-order semantic correlations within sparse bipartite interaction graphs, thereby enhancing user-item collaborative encodings. Despite the exciting prospects, the existing GCN-based models mainly focus on user-item interactions and seldom consider effectiveness of the side item co-occurrence information on user behavior guidance, resulting in limited performance improvement. Therefore, we propose a novel side item co-occurrence information-aware GCN model. Specifically, we first decouple the original heterogeneous relation graph into corresponding user-item and item-item subgraphs for user-item interaction and item co-occurrence relation modeling. Thereafter, we conduct adaptive iterative aggregation on these subgraphs for user intention understanding and co-occurring item correlation perception. Finally, we present two semantic fusion strategies for sufficient user-item semantic collaborative learning, thereby boosting the overall recommendation performance. Extensive comparison experiments are conducted on three benchmark datasets to justify the superiority of our model.
The future detection of gravitational waves (GWs) from a Galactic core-collapse supernova will provide information on the physics inside protoneutron stars (PNS). In this work, we apply three different classification methods for the PNS non-radial oscillation modes: Cowling classification, Generalized Cowling Nomenclature (GCN), and a classification based on modal properties (CBMP). Using PNS models from 3D simulations of core-collapse supernovae, we find that in the early stages of the PNS evolution, typically 0.4 s after the bounce, the Cowling classification is inconsistent, but the GCN and the CBMP provide complementary information that helps to understand the evolution of the modes. In the GCN, we note several avoided crossings as the mode frequencies evolve at early times, while the CBMP tracks the modes across the avoided crossings. We verify that the strongest emission of GWs by the PNS corresponds to the f mode in the GCN, indicating that the mode trapping region alternates between the core and the envelope at each avoided crossing. At later times, approximately 0.4 s after the bounce, the three classification methods present a similar description of the mode spectrum. We use our results to test universal relations for the PNS modes according to their classification and find that the behaviour of the universal relations for f and p modes is remarkably simple in the CBMP.
A simple cost-effective sono-chemical method was used for the synthesis of gCN/TeO2-ZnO ternary (2%, 5%, and 10%) nanocomposites, having crystallite size of 12 nm. FE-SEM and transmission electron microscopy images revealed the formation of core-shell type nanocomposites with an average size of 50 nm. Further, E. coli MTCC 443 strain is used as a model organism to study the antibacterial activity of the prepared nanocomposites, using disc diffusion method. Among all the concentrations, 2% gCN/TeO2-ZnO showed maximum zone of inhibition of 23 +/- 0.10 mm and its antibacterial activity is like third-generation antibiotic cefotaxime. In addition, the prepared nanocomposites were used as nanofertilizer for the growth of gram seeds Chickpea (Cicer arietinum). The effect of nanocomposite concentration and its sterilising properties are studied on the rate of germination of Chickpea using both in vitro and in vivo studies (pot study). The root length of the gCN/TeO2-ZnO treated plants showed increase in seed germination (3.30 cm) compared to untreated plants (3.22 cm). In addition, enhancement in the shoot length about 28% is noticed in pot studies, compared to control batch samples. The accumulation of nanomaterial in plant roots was confirmed using SEM-EDX and ICP-MS. Finally, a 14-day experiment was conducted to ascertain the role of gCN/TeO2-ZnO in the controlled release of nutrients from the synthesised nanofertilizer. Owing to its excellent water holding capacity, sterilizing properties, and low toxicity this material can be used as a growth promoter in plants.
Dense granule proteins (GRAs) are secreted by Apicomplexa protozoa, which are closely related to an extensive variety of farm animal diseases. Predicting GRAs is an integral part in prevention and treatment of parasitic diseases. Considering that biological experiment approach is time-consuming and labor-intensive, computational method is a superior choice. Hence, developing an effective computational method for GRAs prediction is of urgency. In this paper, we present a novel computational method named GRA-GCN through graph convolutional network. In terms of the graph theory, the GRAs prediction can be regarded as a node classification task. GRA-GCN leverages k-nearest neighbor algorithm to construct the feature graph for aggregating more informative representation. To our knowledge, this is the first attempt to utilize computational approach for GRAs prediction. Evaluated by 5-fold cross-validations, the GRA-GCN method achieves satisfactory performance, and is superior to four classic machine learning-based methods and three state-of-the-art models. The analysis of the comprehensive experiment results and a case study could offer valuable information for understanding complex mechanisms, and would contribute to accurate prediction of GRAs. Moreover, we also implement a web server at http://dgpd.tlds.cc/GRAGCN/index/, for facilitating the process of using our model.
A potential replacement for two-dimensional (2D)-inorganic semiconductors in photocatalysis has developed quickly in the form of graphitic carbon nitride [g-C3N4 (GCN)], a 2D-organic semiconductor; nevertheless, very few investigations have been conducted to date about its use in optoelectronic devices. In light of the demands of light-emitting diodes (LED) with effective injected carrier recombination, we propose the report on the fabrication of B-doped exfoliated g-C3N4 (BEGCN) with substantially altered optical/electronic characteristics and a unique structural backbone and illustrate their potential applications in LED devices. The role of exploitation and boron incorporation toward modulating the optical properties of GCN was studied. BEGCN has very high photoluminescence (PL); EGCN and GCN exhibit vanishingly low PL and 2.67 and 2.73 eV smaller bandgap than BEGCN (E-g = 2.81 eV) and manifest visibly white emission. An interesting electronic structure derived from the native defect states of hBN and p, p*, and n states of GCN is bestowed by the occurrence of these two distinct domain types in BEGCN nanosheets. The BEGCN nanosheets demonstrate distinctive optical features in PL emission, which makes the material incredible for the development of high-performance LEDs. The photocatalytic performance was also carried out to correlate the PL characteristics with light-induced RhB degradation of GCN (93%), EGCN (86%), and BEGCN (82%) within 180 min. Degradation efficiency decreased due to the boron incorporation, which directly affects the absorption of photons by creating a blocking effect between the catalyst surface and the light source. Next-generation light-emitting and display devices featuring exceptional luminescence stability may be possible with the construction of BEGCN nanosheets with doped EGCN and B-nanodomains and the emergence of outstanding light-emission properties.
OPC is a very time consuming process for mask synthesis. Quick and accurate OPC using GCN with layout encoder and mask decoder is proposed. (1) GCN performs a series of aggregation with MLP for correction process. A feature of a particular polygon is aggregated with weighted features of neighbor polygons; this is a key motivation of using GCN since one polygon should be corrected while its neighbors are taken into account for more accurate correction. (2) GCN inputs are provided by a layout encoder, which extracts a feature from each layout polygon. GCN outputs, features corresponding to corrected polygons, are processed by a mask decoder to yield the final mask pattern. (3) The encoder and decoder originate from respective autoencoders. High fidelity of decoder is a key for OPC quality. This is achieved by collective training of the two autoencoders with a single loss function while the encoder and decoder are connected. Experiments demonstrate that the proposed OPC achieves 47% smaller EPE than OPC using a simple MLP model.
The growing risk of death associated with kidney dysfunction underlines the requirement for a cost-effective and precise point-of-care (POC) diagnostic tool to identify chronic kidney disease (CKD) at an early stage. This work reports the development of a non-invasive POC diagnostic based on cost-efficient, disposable electrodes and in situ-designed biomimetic nanozymes. The nanozymes are composed of graphitic carbon nitride nanosheets (gCN) and creatinine-imprinted polythiophene nanofibers (miPTh). Microscopic analyses reveal porous nanofibrous surface morphology of biomimetic miPTh/gCN nanozymes. Bulk imprinting and the inclusion of conductive gCN nanosheets drastically reduced the charge transfer resistance and improved the electron exchange kinetics at the nanozyme-electrolyte interface. The electrochemical oxidation of creatinine is studied via cyclic voltammetry (CV), and differential pulse voltammetry (DPV), which exhibit excellent creatinine recognition ability of bio-mimetic miPTh/gCN nanozyme sensors compared to pristine polymeric or non-imprinted nanozymes. The sensor reveals linear response toward 200-1000 nmol L-1 creatinine, high sensitivity (4.27 mu A cm-2 nmol-1 L), sub-nanomolar detection limit (340 pmol L-1), and excellent selectivity over common salivary analytes. To corroborate its real-world utility, the miPTh/gCN nanozyme sensor shows an impressive 94.8% recovery of spiked creatinine concentrations in microliter droplets of human saliva samples. This disposable sensor reveals great potential in the realm of reliable and efficient non-invasive POC diagnostics for healthcare delivery.
The state of charge (SoC) of a vehicle battery can tend to vary depending on the driver's driving patterns and circumstances. To accurately predict the SoC level, it is necessary to consider various circumstances. That is why traditional statistical models may not be sufficient. To address this issue, recurrent neural network (RNN) models have been proposed for time series prediction tasks due to their superior performance. In this paper, we propose a new approach using a graph convolutional network (GCN)-based model that shows better performance than RNN-based models. The GCN requires an adjacency matrix as input, which represents the relationships between variables. We set this matrix to be learnable during model training rather than predefined. We also use two different adjacency matrices: one with variables as nodes, and the other with timestamps as nodes, to enhance the interpretability of the data by considering different elements as nodes. This allows the model to interpret the data from different perspectives. The proposed GCN model was tested using real-world electric vehicle (EV) data and demonstrated improved performance compared to RNN-based baselines. In addition, the GCN model has advantage of being able to clearly express the relationships between variables in a graph, improving interpretabilty.
The past few years have seen the dramatic adoption of the Internet of Things (IoT) in everyday life, from manufacturing to healthcare. With the emergence of various new Internet of Things applications, it is a challenging problem to meet the different QoS requirements of Internet of Things applications in shared substrate networks. Recently, Network Virtualization (NV) has attracted a large amount of attention from academia and industry. NV enables multiple virtual networks to coexist on the same substrate network, thus providing IoT users with customized end-to-end services. The main challenge of NV is the Virtual Network Embedding (VNE) problem, which refers to embed different virtual networks into one substrate network. Inspired by the recent success of graph convolutional network (GCN) in graph structured data processing, in this paper, we propose a GCN aided VNE algorithm. The GCN can extract high-order spatial structure information among substrate nodes through the convolution kernel. Considering that the training data of VNE has no label, we introduce the policy gradient algorithm to optimize the GCN model. In addition, three evaluation metrics are designed to evaluate the performance of the network embedding policy. Some simulations are implemented to evaluate our proposed algorithm in comparison to the other state-of-the-art solutions.
With the construction of a new-type power system under the China "double carbon" target and the increasing diversification of the energy demand on the user side, the short-term load forecasting of the power system is facing new challenges. To fully exploit the massive information contained in data, based on the graph convolutional network (GCN) and long short-term memory network (LSTM), this paper presents a new short-term load forecasting method for power systems considering multiple factors. The Spearman rank correlation coefficient was used to analyse the correlation between load and meteorological factors, and a model including meteorology, dates, and regions was established. Secondly, GCN and LSTM are jointly used to extract the spatial and temporal characteristics of massive data, respectively, and finally achieve short-term power load prediction. Historical electrical load data from 2020 to 2022 public data of a real industrial park in southern China were selected to verify the validity of the proposed method from the aspects of forecasting accuracy, feature dimension, and training time.
Incipient faults for analogue circuits in modern electronic systems are difficult to diagnose due to poor fault features. To address this issue, a method based on the attention weighted graph convolution network (Att-GCN) is proposed in this paper. The structural and data features of samples are jointly extracted to mine the effective characteristics from incipient faults. First, a wavelet packet energy transform and a probabilistic principal component analysis (ProbPCA) are employed to enhance the sample fault information. Then, the distance clustering method is deployed to construct the sample set into a non-European structure sample graph, where the structural features of fault samples are preserved. Second, an Att-GCN, which combines the spatial-domain graph convolution network and improved self-attention mechanism, is constructed to extract the structural features and data features to obtain more effective fault information. Additionally, the multisample dropout method is introduced to reduce network overfitting in the training process. To assess the method's actual performance for fault diagnosis, experiments are carried out in the Sallen-Key bandpass filter circuit, the four-op-amp biquadratic filter circuit and the amplifier board circuit. The outcomes indicate that this method improves the incipient fault diagnosis accuracy for analogue circuits.
The upstream and downstream dependence of air traffic flow networks (ATFN) is a key step in identifying the changing characteristics and interaction patterns of air traffic flow. This requires mining the flow state and operation information of en route flights from multiple angles. However there have been challenges in terms of methodology and practical application. In this study, we propose a hybrid model which combines fuzzy c-means (FCM) and graph convolution network (GCN) for air traffic dependence. Practice has proven that the ATFN graph structure generated by clustering trajectory data using FCM can clearly reflect crossing points and mainstream paths. The GCN is used to detect the trajectory deviation, time delay, and tolerance of the ATFN at different times or paths and visualise the output characteristic layer, which can effectively identify the temporal and spatial correlation of the flow state. Experimental results on real data show that FCM-GCN is significantly better than other baseline models in medium-and long-term traffic prediction tasks. It achieved its best performance in the 60-min traffic prediction compared with existing methods. The experimental results in the selected case area propose a general research framework on the upstream and downstream dependence of ATFN and reflect the efficiency of the organisation and differentiation of ATFN. Its integration with air traffic flow management is conducive to the optimisation of highly interconnected and interdependent flow networks. (c) 2022 Elsevier B.V. All rights reserved.
Photocatalysisis an effective technology to convert solar energyinto chemical energy, which has attracted great attention for thedegradation of water pollutants and the hydrogen production by watersplitting. The nonmetallic polymer g-C3N4 (GCN)can meet the thermodynamic conditions of photocatalytic water splitting,but its performances are not satisfying due to its narrow light absorptionrange and high recombination rate of photogenerated charge carriers.Among metal sulfide semiconductors, Ag-In sulfide quantum dots(AIS QDs), such as AgInS2, show excellent visible lightabsorption and promising photoactivity. In this work, AIS QDs-modifiedGCN is synthesized by an in situ growth method in mild conditions.The photocatalytic activity of the AIS-QDs/GCN nanocomposite is notablyhigher than that of the pure phase g-C3N4. Especially,the sample containing 10 wt % AIS QDs has the best activity in bothtetracycline degradation and hydrogen generation, reaching 48.5% degradationefficiency in 1 h of visible light exposure (3.2 times that of GCN)and a hydrogen evolution rate of 62.3 & mu;mol & BULL;g(-1)& BULL;h(-1) (that of bare GCN being negligible).The optical and photoelectrochemical characterization highlights theinterplay between the two components, suggesting that the enhancedphotocatalytic activity of AIS-QDs/GCN is mainly due to the broadeningof the light absorption range, the acceleration of charge transfer,and the reduction of the carrier pair recombination rate due to theformation of a type-II heterojunction inside the composite catalyst.This work is among the first attempts to modify g-C3N4 with polysulfide quantum dots to improve its catalytic performance,and the results provide an important step for advances in the applicationof these systems.
Most bacterial disinfectants contain high levels of extremely toxic and environmental hazardous chemicals, which pose a significant threat to the ecosystem. Semiconductor photocatalysis exhibits attractive prospects as an emerging greener technology for waste water disinfection. However, the fast recombination of charge carriers limits its practical application. Herein, self-assembled polymeric feather-like g-C3N4 (GCN) nanosheets modified with ferromagnetic CuFe2O4 (CFO) nanospheres were successfully applied as a reusable visible light photo catalytic disinfectant. As expected, the g-C3N4/CuFe2O4 (GCF) nanohybrid displayed superior photocatalytic inactivation efficiency of 0.157log within 120 min towards Escherichia coli DH5 alpha (E. coli) compared with pristine GCN and CFO. The characterization results revealed the synergistic heterostructure interfaces, high surface area, and the transformative self-assembly of GCN to feather-like structure providing a rich active site for improved charge separation efficiency, and wide spectral response, therefore the superior performance of GCF. The radical trapping assay proclaimed that both O2 center dot-and center dot OH radical played major role in the photocatalytic inactivation among the other reactive oxygen species (ROS). Furthermore, the chemical oxygen demand (COD), protein estimation, and DNA estimation assay results validated the cell damage caused by the photocatalyst. Besides that, GCN showed applicability in real-time wastewater samples with improved efficiency than in the saline solution. The excellent magnetic characteristics facilitated the recycling of the catalyst with insignificant leaching, magnetic induction, and distinguished separation. The results of this work signify the well-designed GCF as a highperformance and reusable photocatalyst for real-world pathogenic bacterial disinfection operations.
A synergetic adsorption-photocatalytic-activated Fenton system using an iron-doped g-C3N4/GO (GO/Fe-GCN) hybrid with highly efficient performance was established. The highly dispersed iron species with a Fe2+/Fe3+ ratio (1.67) and mesopores (3.7 nm) with a relative higher specific area and pore volume benefited the reaction efficiency and the contact of organic pollutants with the active sites. In the dynamic adsorption-photo-coordinated Fenton system, the maximum removal rate of GO/Fe-GCN reached 96.5% and equilibrium was 83.6% for Rhodamine B. The GO component not only enhanced the adsorption but also provided a higher efficiency of photo-generated carrier separation and transport. The hybrid structure of GO/Fe-GCN and the high efficiency of circulation of Fe(III)/Fe(II) played an essential role in the synergy of the adsorption-enrichment and the photo-coordinated Fenton reaction. GO/Fe-GCN can also be used to treat complex waste-water containing metallic ions, metal complexes, and organic pollutants, which could allow potential applications in the treatment of water pollution.
The Internet of Things (IoT) will be widely used in all areas of life and transportation as the 5th Generation (5G) communication technology matures and becomes commercially available. Especially in the field of railway transportation, the IoT technology can alleviate the challenge caused by insufficient wireless spectrum resources and improve the railway communication performance. However, the existing IoT is made up of a large heterogeneous network. In such a super-dense heterogeneous network scenario, how to allocate the most appropriate access point (AP) according to the needs of users has become a problem demanding prompt solution, which also brings additional challenges for the intelligent transportation system (ITS) to develop green and efficient network communication technology. Therefore, focusing on the selection and access of heterogeneous networks in the Railway IoT, this article studies the spatial characteristics of the intelligent spectrum situation of the Internet of Mobile Things in the railway scenario, and establishes the opportunistic access situation of Railway IoT based on the graph convolutional neural (GCN) network. Furthermore, we utilize the GCN network to mine the spatial correlation between different APs, and propose a railway communication AP decision algorithm based on the GCN network combined with the traditional heterogeneous network multiattribute decision algorithm. Our experimental results prove that the proposed algorithm can effectively reduce transmission delay and improve the throughput of the communication system.
Herein, we report synthesis of Ni0.5-Co0.5Fe2O4 (NCF), CuxNi0.5-Co0.5Fe2-xO4 where x = 0.6 (CNCF) via co-precipitation followed by annealing, and its composite with g-C3N4 (CNCF@gCN) via ultra-sonication tech-nique. The spectral and structural characteristics of the manufactured samples were assessed by applying a variety of characterization methods. The X-ray diffraction (XRD) analysis indicated that both the NCF and CNCF samples has a cubic crystal structure. The use of Fourier Transform Infrared Spectroscopy (FT-IR) successfully verified the existence of functional groups and vibrational modes inside the mixed spinel ferrites. The objective of this study was to assess the photocatalytic efficacy of the synthesized samples by the degradation of rhodamine B (Rh-B) dye and pendimethalin (PDM) herbicide using photocatalysis. The CNCF@gCN materials demonstrate significantly enhanced photocatalytic activity in comparison to both NCF and CNCF counterparts when used for the degradation of Rh-B and PDM. Moreover, Charge transfer resistance and flat band potential for all samples were also calculated via electrochemical measurements. The photocatalysts, namely Bare NCF, doped CNCF, and CNCF@gCN nanocomposite, exhibited degradation efficiencies of 48%, 75%, and 92% for Rh-B, and 41%, 52%, and 86% for PDM, respectively, when exposed to solar light for a duration of 105 min. The high photocatalytic activity of CNCF@gCN nanocomposite is due to presence of graphitic carbon nitride (g-C3N4) which provide large surface area and prevent electron-hole pair recombination. In addition, recyclability experiment was also performed to determine the stability of CNCF@gCN nanocomposite. The catalyst's remarkable chemical stability made it possible to regenerate and remove it from the dye without losing its photocatalytic efficiency.
Anatomical resection (AR) based on anatomical sub-regions is a promising method of precise surgical resection, which has been proven to improve long-term survival by reducing local recurrence. The fine-grained segmentation of an organ's surgical anatomy (FGS-OSA), i.e., segmenting an organ into multiple anatomic regions, is critical for localizing tumors in AR surgical planning. However, automatically obtaining FGS-OSA results in computeraided methods faces the challenges of appearance ambiguities among sub-regions (i.e., inter-sub-region appearance ambiguities) caused by similar HU distributions in different sub-regions of an organ's surgical anatomy, invisible boundaries, and similarities between anatomical landmarks and other anatomical information. In this paper, we propose a novel fine-grained segmentation framework termed the "anatomic relation reasoning graph convolutional network" (ARR-GCN), which incorporates prior anatomic relations into the framework learning. In ARR-GCN, a graph is constructed based on the sub-regions to model the class and their relations. Further, to obtain discriminative initial node representations of graph space, a sub-region center module is designed. Most importantly, to explicitly learn the anatomic relations, the prior anatomic-relations among the sub-regions are encoded in the form of an adjacency matrix and embedded into the intermediate node representations to guide framework learning. The ARR-GCN was validated on two FGS-OSA tasks: i) liver segments segmentation, and ii) lung lobes segmentation. Experimental results on both tasks outperformed other state-of-the-art segmentation methods and yielded promising performances by ARR-GCN for suppressing ambiguities among sub-regions.
As a natural extension of link prediction on graphs, hyperlink prediction aims for the inference of missing hyperlinks in hypergraphs, where a hyperlink can connect more than two nodes. Hyperlink prediction has applications in a wide range of systems, from chemical reaction networks and social communication networks to protein-protein interaction networks. In this article, we provide a systematic and comprehensive survey on hyperlink prediction. We adopt a classical taxonomy from link prediction to classify the existing hyperlink prediction methods into four categories: similarity-based, probability-based, matrix optimization-based, and deep learning-based methods. To compare the performance of methods from different categories, we perform a benchmark study on various hypergraph applications using representative methods from each category. Notably, deep learning-based methods prevail over other methods in hyperlink prediction.
In this manuscript "Feed two birds with one seed" strategy was followed to study the electrochemical ability and photocatalytic Degradation of pharmaceutical effluent nimesulide (NIM) drugs. Heterogeneous solid-direct Z -scheme catalysts experienced many efforts in generating new materials to tackle environmental issues by exhibiting appropriate catalysts. Currently, graphitic carbon nitride (gCN) with its unique characteristics has attracted tremendous kindness among researchers due to its excellent potential for utilization as a bi-functional catalyst. In this research, the part of surface morphological engineering and band gap evolution in heterojunction solid-direct Z-scheme formation of vanadium and phosphorous doped gCN (V/P-gCN (VP)) will be considered. The proposed material is prepared by thermal decomposition and the analytical analysis was utilized to study the physio-chemical characteristics. These newly developed strategies are more useful to enhance the electrocatalytic and photocatalytic activity of gCN. In addition, specific information on the application of gCN-based catalysts in the bi-functional simultaneous process will be obtained in different reactions. The analytical parameters of the proposed sensor were adequate, with higher recovery values, and the detection limits and quantification range are 0.2 - 80 mu M and 3 nM, respectively for the detection of NIM. Photocatalytic Degradation of NIM targets harmful pollutants obtained 98% within a short treatment time under visible light illumination. In addition, the possible degradation pathways of NIM drugs were studied using GC-MS analysis, which exhibited the degra-dation of NIM molecules with small fragments. These dual-functional approaches could provide sustainable and efficient strategies for both electro and photocatalyst to rectify environmental issues.
Classification methods that are based on hyperspectral images (HSIs) are playing an increasingly significant role in the processes of target detection, environmental management, and mineral mapping as a result of the fast development of hyperspectral remote sensing technology. Improving classification performance is still a sig-nificant problem, however, as a result of the high dimensionality and redundancy of hyperspectral image sets (HSIs), as well as the presence of class imbalance in hyperspectral datasets. In the past few years, convolutional neural networks (CNNs) and graph convolutional networks (GCNs) have achieved good results in HSI classifi-cation, but CNNs struggle to achieve good accuracy in low samples, while GCNs have a huge computational cost. To resolve these issues, this paper proposes a Multi-Feature Fusion of 3D-CNN and Graph Attention Network MFFCG. The algorithm consists of two elements: the 3D-CNN, which produces good classification for 3D HSI cube data, and GAT-based encoder and decoder modules that help in improving the classification accuracy of the 3D -CNN. Finally, the multiple features are merged with the help of two neural network models. We further develop two optimized GAT models named GAT1 and GAT2, which are used with different layers of 3D-CNN. Algorithms after merging with 3D-CNN are named MFFCG-1 and MFFCG-2, which produce better classification results then other developed methods. Experiments on three public HSI datasets show that the proposed methods perform better than other state-of-the-art methods using the limited training samples and in low classification time.
Knowledge tracing models have gained prominence in educational data mining, with applications like the Self-Attention Knowledge Tracing model, which captures the exercise-knowledge relationship. However, conventional knowledge tracing models focus solely on static question-knowledge and knowledge-knowledge relationships, treating them with equal significance. This simplistic approach often succumbs to subjective labeling bias and lacks the depth to capture nuanced exercise-knowledge connections. In this study, we propose a novel knowledge tracing model called Knowledge Relation Rank Enhanced Heterogeneous Learning Interaction Modeling for Neural Graph Forgetting Knowledge Tracing. Our model mitigates the impact of subjective labeling by fine-tuning the skill relation matrix and Q-matrix. Additionally, we employ Graph Convolutional Networks (GCNs) to capture intricate interactions between students, exercises, and skills. Specifically, the Knowledge Relation Importance Rank Calibration method is employed to generate the skill relation matrix and Q-matrix. These calibrated matrices, alongside heterogeneous interactions, serve as input for the GCN to compute exercise and skill embeddings. Subsequently, exercise embeddings, skill embeddings, item difficulty, and contingency tables collectively contribute to an exercise relation matrix, which is then fed into an attention mechanism for predictions. Experimental evaluations on two publicly available educational datasets demonstrate the superiority of our proposed model over baseline models, evidenced by enhanced performance across three evaluation metrics.
BackgroundUltrasound plays a critical role in the early screening and diagnosis of cancers. Although deep neural networks have been widely investigated in the computer-aided diagnosis (CAD) of different medical images, diverse ultrasound devices, and image modalities pose challenges for clinical applications, especially in the recognition of thyroid nodules having various shapes and sizes. More generalized and extensible methods need to be developed for the cross-devices recognition of thyroid nodules. PurposeIn this work, a semi-supervised graph convolutional deep learning framework is proposed for the domain adaptative recognition of thyroid nodules across several ultrasound devices. A deep classification network, trained on a source domain with a specific device, can be transferred to recognize thyroid nodules on the target domain with other devices, using only few manual annotated ultrasound images. MethodsThis study presents a semi-supervised graph-convolutional-network-based domain adaptation framework, namely Semi-GCNs-DA. Based on the ResNet backbone, it is extended in three aspects for domain adaptation, that is, graph convolutional networks (GCNs) for the connection construction between source and target domains, semi-supervised GCNs for accurate target domain recognition, and pseudo labels for unlabeled target domains. Data were collected from 1498 patients comprising 12 108 images with or without thyroid nodules under three different ultrasound devices. Accuracy, Sensitivity and Specificity were used for the performance evaluation. ResultsThe proposed method was validated on six groups of data for a single source domain adaptation task, the mean Accuracy was 0.9719 +/- 0.0023, 0.9928 +/- 0.0022, 0.9353 +/- 0.0105, 0.8727 +/- 0.0021, 0.7596 +/- 0.0045, 0.8482 +/- 0.0092, which achieved better performance in comparison with the state-of-the-art. The proposed method was also validated on three groups of multiple source domain adaptation tasks. In particular, when using X60 and HS50 as the source domain data, and H60 as the target domain, it can achieve the Accuracy of 0.8829 +/- 0.0079, Sensitivity of 0.9757 +/- 0.0001, and Specificity of 0.7894 +/- 0.0164. Ablation experiments also demonstrated the effectiveness of the proposed modules. ConclusionThe developed Semi-GCNs-DA framework can effectively recognize thyroid nodules on different ultrasound devices. The developed semi-supervised GCNs can be further extended to the domain adaptation problems for other modalities of medical images.
Urban road networks have complex spatial and temporal correlations, driving a surge of research interest in spatial-temporal traffic flow prediction. However, prior approaches often overlook the temporal-scale differentiation of spatial-temporal features, limiting their ability to extract complex structural information. In this work, we design the multibranch adaptive fusion graph convolutional network (MBAF-GCN) that explicitly exploits the prior spatial-temporal characteristics at different temporal scales, and each branch is responsible for extracting spatial-temporal features at a specific scale. Besides, we design the spatial-temporal feature fusion (STFF) module to refine the prediction results. Based on the multibranch complementary features, the module adopts a coarse-to-fine fusion strategy, incorporating different spatial-temporal scale features to obtain recalibrated prediction results. Finally, we evaluate the MBAF-GCN using two real-world traffic datasets. Experimentally, the newly designed multibranch can efficaciously utilize the prior information of different temporal scales. Our MBAF-GCN achieved better performance in the comparative model, indicating its potential and validity.
Objective: HIV infection risk can be estimated based on not only individual features but also social network information. However, there have been insufficient studies using n machine learning methods that can maximize the utility of such information. Leveraging a state-of-the-art network topology modeling method, graph convolutional networks (GCN), our main objective was to include network information for the task of detecting previously unknown HIV infections. Materials and Methods: We used multiple social network data (peer referral, social, sex partners, and affiliation with social and health venues) that include 378 young men who had sex with men in Houston, TX, collected between 2014 and 2016. Due to the limited sample size, an ensemble approach was engaged by integrating GCN for modeling information flow and statistical machine learning methods, including random forest and logistic regression, to efficiently model sparse features in individual nodes. Results: Modeling network information using GCN effectively increased the prediction of HIV status in the social network. The ensemble approach achieved 96.6% on accuracy and 94.6% on F1 measure, which outperformed the baseline methods (GCN, logistic regression, and random forest: 79.0%, 90.5%, 94.4% on accuracy, respectively; and 57.7%, 80.2%, 90.4% on F1). In the networks with missing HIV status, the ensemble also produced promising results. Conclusion: Network context is a necessary component in modeling infectious disease transmissions such as HIV. GCN, when combined with traditional machine learning approaches, achieved promising performance in detecting previously unknown HIV infections, which may provide a useful tool for combatting the HIV epidemic.
The intermolecular interactions between proteins and ligands occur through site-specific amino acid residues in the proteins, and the identification of these key residues plays a critical role in both interpreting protein function and facilitating drug design based on virtual screening. In general, the information about the ligands-binding residues on proteins is unknown, and the detection of the binding residues by the biological wet experiments is time consuming. Therefore, many computational methods have been developed to identify the protein-ligand binding residues in recent years. We propose GraphPLBR, a framework based on Graph Convolutional Neural (GCN) networks, to predict protein-ligand binding residues (PLBR). The proteins are represented as a graph with residues as nodes through 3D protein structure data, such that the PLBR prediction task is transformed into a graph node classification task. A deep graph convolutional network is applied to extract information from higher-order neighbors, and initial residue connection with identity mapping is applied to cope with the over-smoothing problem caused by increasing the number of graph convolutional layers. To the best of our knowledge, this is a more unique and innovative perspective that utilizes the idea of graph node classification for protein-ligand binding residues prediction. By comparing with some state-of-the-art methods, our method performs better on several metrics.
In the field of environmental science, traditional methods for predicting PM2.5 concentrations primarily focus on singular temporal or spatial dimensions. This approach presents certain limitations when it comes to deeply mining the joint influence of multiple monitoring sites and their inherent connections with meteorological factors. To address this issue, we introduce an innovative deep-learning-based multi-graph model using Beijing as the study case. This model consists of two key modules: firstly, the 'Meteorological Factor Spatio-Temporal Feature Extraction Module'. This module deeply integrates spatio-temporal features of hourly meteorological data by employing Graph Convolutional Networks (GCN) and Long Short-Term Memory (LSTM) for spatial and temporal encoding respectively. Subsequently, through an attention mechanism, it retrieves a feature tensor associated with air pollutants. Secondly, these features are amalgamated with PM2.5 concentration values, allowing the 'PM2.5 Concentration Prediction Module' to predict with enhanced accuracy the joint influence across multiple monitoring sites. Our model exhibits significant advantages over traditional methods in processing the joint impact of multiple sites and their associated meteorological factors. By providing new perspectives and tools for the in-depth understanding of urban air pollutant distribution and optimization of air quality management, this model propels us towards a more comprehensive approach in tackling air pollution issues.
A deep learning-based multi-output prediction model is developed to better understand and more accurately estimate tunnel boring machine (TBM) performance in each segment ring during the deep excavation under complex underground environments. The novelty lies in the development of a new deep learning approach named att-GCN, which feasibly integrates the graph convolutional networks (GCN) and scaled dot-product attention mechanism to improve model performance and interpretability. It is proved that our proposed attGCN model is outstanding in significantly enhancing the prediction performance and effectively capturing the influence between monitoring points. As a case study, the proposed method is validated in a Singapore Mass Rail Transit (MRT) construction project, where seven features associated with the TBM machine are input for att-GCN training and testing. Experimental results reveal that the att-GCN model can exhibit a powerful capability in simultaneously predicting two targets named penetration rate (y1) and energy consumption (y2), reaching the mean absolute percentage error (MAPE) value at 15.475% and 15.173%, respectively. In terms of prediction accuracy, att-GCN is superior to some state-of-the-art algorithms, including deep neural network (DNN), random forest (RF), and support vector regression (SVR). Moreover, an online-learning version of att-GCN is designed. When the objective value is gradually known and fed into att-GCN during the tunneling procedure, the model can yield more impressive performance under the MAPE of 8.504% (y1) and 7.934% (y2). Accordingly, the real-time estimation of TBM performance based on the time-varying monitoring data provides valuable evidence to realize the intelligent control of TBM tunneling, which can ultimately improve construction efficiency and reliability.
MoS2/gCN/graphene ternary nanocomposites were synthesized using the ultrasonication-assisted calcination method, and different amounts of gCN were loaded to prepare the ternary nanocomposites. The hybrid MoS2/ gCN/graphene ternary nanocomposites showed significant responses to an incident light source, and electrochemical analysis indicated that the junctions of the rose-like MoS2, metal-free gC3N4, and 2D graphene positively changed the electronic structure without changing the internal crystal and electronic structures of each unary nanocomposite, thus offering an effective separation of the electron-hole pairs. Therefore, this process provides abundant photoinduced electrons for CO2/CH3OH and holes for the water oxidation reactions, which can in turn be employed for the photoreduction of CO2. In addition, the charge-carrier mechanism of the ternary nanocomposites was labeled as type-II heterojunction. The use of an aqueous solvent with a basic salt and donor scavenger enhanced the Type-II heterojunction photocatalytic CO2 reduction because of the efficient supply of hydrated CO2 molecules and the large number of electrons required for the complex reduction reaction of CO2 to alcohol. Control of the external and internal factors for photocatalytic CO2 reduction further increased the selectivity for the reduction of CO2 and CH3OH. This work demonstrates the successful integration of gCN, graphene, and rose-like MoS2 with enhanced catalytic activity. Moreover, this work is expected to be of great importance in the development of photocatalyst materials for CO2 reduction while allowing advanced tunable chemical and structural properties of the metal-free gCN and rose-like MoS2.
Tackling traffic signal control through multi-agent reinforcement learning is a widely-employed approach. However, current state-of-the-art models have drawbacks: intersections optimize their own local rewards and cause traffic to waste time and fuel with a start-stop mode at each intersection. They also lack information sharing among intersections and their specialized policy hinders the ability to adapt to new traffic scenarios. To overcome these limitations, This work presents a centralized collaborative graph network (CCGN) with the core objective of a signal-free corridor once the traffic flows have waited at the entry intersection of the traffic intersection network on either side, the subsequent intersection gives the open signal as the traffic flows arrive. CCGN combines local policy networks (LPN) and global policy networks, where LPN employed at each intersection predicts actions based on Transformer and Graph Convolutional Network (GCN). In contrast, GPN is based on GCN and Q-network that receives the LPN states, traffic flow and road information to manage intersections to provide a signal-free corridor. We developed the Deep Graph Convolution Q-Network (DGCQ) by combining Deep Q-Network (DQN) and GCN to achieve a signal-free corridor. DGCQ leverages GCN's intersection collaboration and DQN's information aggregation for traffic control decisions Proposed CCGN model is trained on the robust synthetic traffic network and evaluated on the real-world traffic networks that outperform the other state-of-the-art models. & COPY; 2023 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
Mobile CrowdSensing (MCS) has recently become a promising data acquisition paradigm, which recruits a large number of users to collect data from the target sensing areas. Obviously, with the increase of sensing scale and the decrease of sensing granularity, traditional MCS cannot fully cover the required sensing areas especially the inaccessible areas. As a variant, Sparse MCS can utilize the spatiotemporal correlations in sensing data to infer the whole sensing map only by sensing a few subareas. However, in many real-world scenarios, such as traffic congestion prediction or parking occupancy detection, inferring the current unsensed data may not be the final goal. By comparison, it is more important to get the future information through the sparse sensed data. In this paper, we turn attention from inferring the current unsensed data to predicting the future unknown data and propose an urban inference and prediction framework in Sparse MCS. To deal with the sparse sensed data, we first present a bipartite-graph-based matrix completion algorithm with spatiotemporal constraints to accurately recover the current full map. Then, by exploiting spatiotemporal correlations based on the inferred full map, we present a Graph Convolutional Networks (GCN) with spatiotemporal attention to predict the future maps. Furthermore, we design a spatiotemporal iterative method to repeatedly update the spatiotemporal attentions and constraints, in order to connect the urban inference and prediction to improve the accuracy of the whole framework. Extensive experiments have been conducted on two types of typical urban sensing tasks with four real-world data sets, which verify the effectiveness of our proposed algorithms in improving the inference and prediction accuracy with the sparse sensed data.
A plethora of information is now readily available for traffic prediction, making an effective use of them enables better traffic planning. With data coming from multiple sources, and their features spanning spatial and temporal dimensions, there is an increasing demand to exploit them for accurate traffic prediction. Existing methods, however, do not provide a solution for this, as they tend to require expertise feature engineering. In this paper, we propose a general architecture for SpatioTemporal Data Fusion (STDF) with parameter efficiency. To make heterogeneous multi-source data fusion effectiveness, we separate all data into traffic directly related data and traffic indirectly related data. With traffic indirectly related data as the input to Spatial Embedding by Temporal convolutiON (SETON) that simultaneously encodes each feature in both space and time dimensions and traffic directly related data as the input to the graph convolutional network(GCN), we designed a fine-grained feature transformer to match the ones generated by GCN. This is then followed by a fusion module to combine all features to make final prediction. Compared to using GCNs training with only traffic directly related data, experimental results show that our model can achieve a 6.1 & x0025; improvement in prediction accuracy measured by Root Mean Squared Error.
It is meaningful but challenging to teach machines to recognize handwritten Chinese characters. However, conventional approaches typically view handwritten Chinese characters as either static images or tempo-ral trajectories, which may ignore the inherent geometric semantics of characters. Instead, here we first propose to represent handwritten characters as skeleton graphs, explicitly considering the natural charac-teristics of characters (i.e., characters as graphs). Furthermore, we propose a novel Pyramid Graph Trans-former (PyGT) to specifically process the graph-structured characters, which fully integrates the advan-tages of Transformers and graph convolutional networks. Specifically, our PyGT can learn better graph fea-tures through (i) capturing the global information from all nodes with graph attention mechanism and (ii) modelling the explicit local adjacency structures of nodes with graph convolutions. Furthermore, the PyGT learns the multi-resolution features by constructing a progressive shrinking pyramid. Compared with ex-isting approaches, it is more interpretable to recognize characters as geometric graphs. Moreover, the pro-posed method is generic for both online and offline handwritten Chinese character recognition (HCCR), and it also can be feasibly extended to handwritten text recognition. Extensive experiments empirically demonstrate the superiority of PyGT over the prevalent approaches including 2D-CNN, RNN/1D-CNN, and Vision Transformer (ViT) for HCCR. The code is available at https://github.com/ganji15/PyGT-HCCR .& COPY; 2023 Elsevier Ltd. All rights reserved.
Multi-label image recognition has been an indispensable fundamental component for many real computer vision applications. However, a severe threat of privacy leakage in multi-label image recognition has been overlooked by existing studies. To fill this gap, two privacy-preserving models, Privacy-Preserving Multi-label Graph Convolutional Networks (P2-ML-GCN) and Robust P2-ML-GCN (RP2-ML-GCN), are developed in this article, where differential privacy mechanism is implemented on the model's outputs so as to defend blackbox attack and avoid large aggregated noise simultaneously. In particular, a regularization term is exploited in the loss function of RP2-ML-GCN to increase the model prediction accuracy and robustness. After that, a proper differential privacy mechanism is designed with the intention of decreasing the bias of loss function in P2-ML-GCN and increasing prediction accuracy. Besides, we analyze that a bounded global sensitivity can mitigate excessive noise's side effect and obtain a performance improvement for multi-label image recognition in our models. Theoretical proof shows that our two models can guarantee differential privacy for model's outputs, weights and input features while preserving model robustness. Finally, comprehensive experiments are conducted to validate the advantages of our proposedmodels, including the implementation of differential privacy on model's outputs, the incorporation of regularization term into loss function, and the adoption of bounded global sensitivity for multi-label image recognition.
Relations between entities evolving through discrete time-steps can be represented by discrete-time dynamic graphs. Examples include hourly interactions between social network users or daily infection spreading. In this paper, we present Dynamic Graph Echo State Network (DynGESN), a reservoir computing model for the efficient processing of discrete-time dynamic temporal graphs. We prove a sufficient condition for the echo state property, which ensures that graph embeddings are independent of initial conditions, and we briefly analyze reservoir dynamics. DynGESN is compared against temporal graph kernels (TGKs) on twelve graph classification tasks, and against ten different end-to-end trained temporal graph convolutional networks (TGNs) on four vertex regression tasks, since TGKs are limited to graph-level tasks. Compared to TGKs that need to hold the entire history of vertex interactions, our model provides a vector encoding for the dynamic graph that is updated at each time-step without requiring training. Experiments show that our model achieves accuracy in line with TGKs that have comparable computational complexity, while still offering space and time requirements better suited to scale to large-size data. Moreover, DynGESN overall achieves superior or on par accuracy with respect to TGNs, while improving efficiency by up ten times on inference and training time. (C) 2022 Elsevier B.V. All rights reserved.
Through accurate network-wide traffic prediction, network operators can agilely manage resources and improve robustness by proactively adapting to new traffic patterns, especially for traffic engineering, capacity planning and quality of service provisioning. However, due to the proliferation of backbone network traffic as well as the complexity and dynamics of network communication behavior, accurate and effective network-wide traffic prediction is challenging. To address the challenges, this paper focuses on short-term traffic matrix (TM) prediction in large-scale IP backbone networks. In order to improve the prediction performance, a novel spatiotemporal graph convolutional recurrent network (SGCRN)-a deep learning framework that incorporates both spatial and temporal dependencies of traffic flows, is proposed to implement TM prediction with high accuracy and efficiency. By learning network-wide traffic as graph-structured TM time series, SGCRN jointly utilizes graph convolutional networks (GCN) and gated recurrent units (GRU) networks to extract comprehensive spatiotemporal correlations among traffic flows. Specifically, SGCRN employs GCNs to identify structural spatial features of traffic flows by considering topological properties, and utilizes GRUs to implement temporal features learning by considering short and long-term dynamics of traffic flows. Extensive experimental results on the inter-Points of Presence network traffic data from four real IP backbone networks show that SGCRN can effectively predict short-term network-wide TM with superior accuracy compared with other four widely used traffic prediction methods.
Graph convolutional neural networks (GCN) have been widely applied to many real-world problems and have achieved better results. To improve the accuracy of GCN in the three-dimensional human pose estimation (3D HPE) task, improved semantic GCNs (SimpreRxSkip-NonCam-SemGCN and SPRA-SemGCN) are proposed. For the problem of insufficiently utilizing effective information in 3D HPE tasks, the dual- layer attention mechanism module (NonCam-attention) of extracting information is proposed. It establishes a spatial and channel-based fusion structure model by capturing the distance dependencies between different joint nodes of human poses and the associated features between different mapping channels. To reduce the training time and GPU memory for the preaggregated semantic graph convolutional networks (Pre-SemGCN) model, the simplified Pre-SemGCN module (Simpre-SemGCN) is suggested, which can accelerate the training speed of the model by eliminating the nonlinear activation layer. Further, a nested recursive expansion-based residual connection module (RxSkip + LN) is proposed to adjust the ratio of input and output with fewer parameters. To verify the effectiveness of the proposed model, we conduct experiments on the dataset Human 3.6M. The results show that the SPRA-SemGCN model proposed can effectively reduce the error of the 3D HPE task, and the mean per joint position error is finally reduced to 37.20 mm. (c) 2022 SPIE and IS&T
In recent years, privacy leakage events in large-scale social networks have become increasingly frequent. Traditional methods relying on operators have been unable to effectively curb this problem. Researchers must turn their attention to the privacy protection of users themselves. Privacy metrics are undoubtedly the most effective method. However, social networks have a substantial number of users and a complex network structure and feature set. Previous studies either considered a single aspect or measured multiple aspects separately and then artificially integrated them. The measurement procedures are complex and cannot effectively be integrated. To solve the above problems, we first propose using a deep neural network to measure the privacy status of social network users. Through a graph convolution network, we can easily and efficiently combine the user features and graph structure, determine the hidden relationships between these features, and obtain more accurate privacy scores. Given the restriction of the deep learning framework, which requires a large number of labelled samples, we incorporate a few-shot learning method, which greatly reduces the dependence on labelled data and human intervention. Our method is applicable to online social networks, such as Sina Weibo, Twitter, and Facebook, that can extract profile information, graph structure information of users' friends, and behavioural characteristics. The experiments show that our model can quickly and accurately obtain privacy scores in a whole network and eliminate traditional tedious numerical calculations and human intervention.
Graph Neural Networks (GNNs) including Graph Convolutional Networks (GCNs) have demonstrated state-ofthe-art performance in various analytical tasks. Current GNNs approaches focus on learning node representations based on the proximity similarity principle. However, they may fail to generalize to complex relations such as disassortative structure, because irrelevant information may be aggregated and generate unreasonable representations. To this end, this research introduces a novel approach - Graph neural networks via contrast between separation and aggregation for self and neighborhood, to effectively learn the node representations in the disassortative structure. To search friendly neighbor space with mitigating the unreasonable of connections, the proposed approach synthesizes the feature semantic space and the structure semantic space. To learn reasonable representations for disassortative graphs, the proposed approach stacks multiple GCNs and learns the intrinsic interrelationship between the optimal friendly aggregated information and the separated information originating from self and neighborhood by contrastive learning. At the same time, the proposed approach integrates the variational expectation maximization to train the whole framework for exploring the approximated posterior. Extensive experimental results on eight real-world graph datasets show that the proposed approach outperforms eight state-of-the-art GNN models in diverse graph mining tasks, including node classification and link prediction, demonstrating the proposed approach's superior graph representation ability.
In this paper, a new control architecture of virtual power plants (VPP) is proposed for the frequency regulation (FR) in main grid. Firstly, to address the power prediction of aggregation nodes (AN) with spatio-temporal correlation under VPP, a novel combined model based on graph convolutional networks and bi-directional long and short-term memory is established. Further, considering the effect of prediction uncertainty, a power shortage measurement method based on interval estimation is proposed to determine the effective power of AN. Secondly, a dispatch -based control strategy is introduced to enable VPP to respond to regulation commands from the main grid. Additionally, the influence of transmission line power loss on FR is considered, which can be eliminated by applying the developed power compensation design scheme based on proportional allocation. Finally, numerical simulations illustrate that the proposed method enhances prediction performance by 68.65%, taking mean absolute error as an example, while ensuring the accuracy and reliability of power prediction. Also, the adopted control strategy can effectively utilize VPP to provide FR services for the main grid. Moreover, the application results in a real scene are better than those of benchmark methods, which also demonstrates that the proposed approach has a high practical application potential in power system.
Graph-structured scene descriptions can be efficiently used in generative models to control the composition of the generated image. Previous approaches are based on the combination of graph convolutional networks and adversarial methods for layout prediction and image generation, respectively. In this work, we show how employing multi-head attention to encode the graph information, as well as using a transformer-based model in the latent space for image generation can improve the quality of the sampled data, without the need to employ adversarial models with the subsequent advantage in terms of training stability. The proposed approach, specifically, is entirely based on transformer architectures both for encoding scene graphs into intermediate object layouts and for decoding these layouts into images, passing through a lower dimensional space learned by a vector-quantized variational autoencoder. Our approach shows an improved image quality with respect to state-of-the-art methods as well as a higher degree of diversity among multiple generations from the same scene graph. We evaluate our approach on three public datasets: Visual Genome, COCO, and CLEVR. We achieve an Inception Score of 13.7 and 12.8, and an FID of 52.3 and 60.3, on COCO and Visual Genome, respectively. We perform ablation studies on our contributions to assess the impact of each component.
In this study, a novel spatiotemporal graph convolutional networks model is proposed for traffic flow prediction in urban road networks by fully considering an information geometry approach and attention-based mechanism. Accurate traffic flow prediction in real urban road networks is challenging due to the presence of dynamic spatiotemporal data and external factors in the urban environment. Moreover, the dynamic spatial and temporal dependencies of urban traffic flow data are very important for predicting traffic flow, and it has been shown that a recent attention mechanism has a relatively good ability to capture these dynamic dependencies, which are not fully considered by most existing algorithms. Therefore, in the novel model abbreviated as IGAGCN, the information geometry method is utilized to determine the dynamic data distribution difference between different sensors. The attention mechanism is employed with the information geometry method, in which a matrix is derived by analyzing the distributions of sensor data, and the spatiotemporal dynamic connections in traffic flow data features are better at capturing the spatial dependencies of traffic between different sensors in urban road networks. Furthermore, a parallel sub-model architecture is proposed to consider long time spans, where each dilated causal convolution sub-model is applied to short time spans. Two wellknown data sets were employed to demonstrate that our proposed method obtains better performance and is better at capturing the dynamic spatial dependencies of traffic than the existing only-attention based models. In addition a real-world urban road network in Shenzhen, China, was studied to test and verify the proposed model. (C) 2021 Elsevier Ltd. All rights reserved.
Knowledge graph (KG) can provide auxiliary information for recommender system to alleviate the sparsity and cold start problems, while graph convolutional networks (GCN) has recently been established as the state-of-the-art representation learning method. The combination of them is a promising perspective to improve the performance of graph-structured recommendation. However, most of GCN-based recommendations focus on homogeneous graph or user/item-similarity graph, fail to fully make use of the complex and rich semantics between entities in heterogeneous knowledge graph. In this paper, we develop Hierarchical Attention Graph Convolutional Network Incorporating Knowledge Graph for Explainable Recommendation (HAGERec) to explore users' potential preferences from the high-order connectivity structure of heterogeneous knowledge graph. To exploit semantic information, HAGERec simultaneously learn the representations of users and items via a bi-directional information propagation strategy. Specifically, the entity's representation can be aggregated through messages passing from its local proximity structure, and a hierarchical attention mechanism is developed to adaptively characterize and adjust collaborative signals. With the help of the attention mechanism, an attentive entity sampling strategy is proposed to select relevant neighbor entities, and the explainability is endowed to the model by building knowledge-aware connectivity. Experiments conducted on four real-world public datasets demonstrate the state-of-the-art performance and the strong explainability of HAGERec. (C) 2020 Elsevier B.V. All rights reserved.
Recent years have witnessed rapid progress in employing graph convolutional networks (GCNs) for various video analysis tasks where graph-based data abound. However, exploring the transferable knowledge between different graphs, which is a direction with wide and potential applications, has been rarely studied. To address this issue, we propose a graph interaction networks (GINs) model for transferring relation knowledge across two graphs. Different from conventional domain adaptation or knowledge distillation approaches, our GINs focus on a "self-learned" weight matrix, which is a higher-level representation of the input data. And each element of the weight matrix represents the pair-wise relation among different nodes within the graph. Moreover, we guide the networks to transfer the knowledge across the weight matrices by designing a task-specific loss function, so that the relation information is well preserved during transfer. We conduct experiments on two different scenarios for video analysis, including a new proposed setting for unsupervised skeleton-based action recognition across different datasets, and supervised group activity recognition with multi-modal inputs. Extensive experiments on six widely used datasets illustrate that our GINs achieve very competitive performance in comparison with the state-of-the-arts.
Skeleton-based action recognition is widely used due to its advantages of lightweight and strong anti-interference. Recently, graph convolutional networks (GCNs) have been applied to action recognition and have made breakthrough progress. The shift convolution operator can effectively replace the spatial convolution and greatly reduce the computational complexity of the algorithm. This article first applies the Conv-Shift-Conv (CSC) module and the Shift-Conv-Shift-Conv (SC2) module to replace the Shift-Conv-Shift (SCS) module in spatial graph convolution of Shift-GCN respectively. This design can reorder the shifted channels more effectively. The experimental results show that the CSC module has the best effect and effectively improves accuracy of model. After that, this article proposes to replace the shift module in the original Shift-GCN with a sparse shift module and named SparseShift-GCN. This structure can reduce the redundancy of features, prevent overfitting and improve the generality of the model. Based on the improvement in the previous step, better results have been achieved. Finally, this paper uses OHEM Loss and Weighted Loss to carefully design the loss function of the model and introduces it into the model proposed in this paper. Experimental results show that OHEM Loss further improves the accuracy of algorithm. After a series of improvements, our proposed model has improved the accuracy of 4 different streams to varying degrees, which improves the overall performance of the network. (C) 2021 Elsevier B.V. All rights reserved.
Air pollution is a significant urban issue, with practical applications for pollution control, urban environmental management planning, and urban construction. However, owing to the complexity and differences in spatiotemporal changes for various types of pollution, it is challenging to establish a framework that can capture the spatiotemporal correlations of different types of air pollution and obtain high prediction accuracy. In this paper, we proposed a deep learning framework suitable for predicting various air pollutants: a graph convolutional temporal sliding long short-term memory (GT-LSTM) model. The hybrid integrated model combines graph convolutional networks and long short-term networks based on a strategy with temporal sliding. Herein, the graph convolution networks gather neighbor information for spatial dependency modeling based on the spatial adjacency matrices of different pollutants and the graph convolution operator with parameter sharing. LSTM networks with a temporal sliding strategy are used to learn dynamic air pollution changes for temporal dependency modeling. The framework was applied to predict the average concentrations of PM2.5, PM10, O-3, CO, SO2, and NO2 in the Bejing-Tianjin-Hebei (BTH) region for the next 24 hours. Experiments demonstrated that the proposed GT-LSTM model could extract high-level spatiotemporal features and achieve higher accuracy and stability than state-of-the-art baselines. Advancement in this methodology can assist in providing decision support capabilities to mitigate air quality issues.
Generally, seismic data have discontinuity or planar fracture anomalies in the volume of rocks, commonly known as seismic faults. A large number of methods exist to interpret seismic faults, nevertheless automating the process prevails to be a practical challenge. We propose a graph representation-based approach for interpreting faults in seismic data using the graph convolutional network (GCN). We extract 2D patches of data centered around seismic data points from the 3D seismic volumes for training. Then we represent these patches in the graph domain using the k-nearest neighbor graphs followed by the application of GCN. After training the patches in the networks, we classify the patches to identify the faults. We consider both synthetic and real data for training and testing. The seismic amplitude values, the seismic attribute values, and the successive difference values are used in the networks. We compare our implementation with the state-of-the-art method, the convolutional neural networks (CNN). The results show good accuracy when applied to both synthetic and real data. Additionally, the GCN method is more time efficient than that of CNN. We process the 3D seismic section by parallel processing the 2D patches.
Public concern detection provides potential guidance to the authorities for crisis management before or during a pandemic outbreak. Detecting people's concerns and attention from online social media platforms has been widely acknowledged as an effective approach to relieve public panic and prevent a social crisis. However, detecting concerns in time from massive volumes of information in social media turns out to be a big challenge, especially when sufficient manually labelled data is in the absence during public health emergencies, e.g., COVID-19. In this paper, we propose a novel end-to-end deep learning model to identify people's concerns and the corresponding relations based on Graph Convolutional Networks and Bi-directional Long Short Term Memory integrated with Concern Graphs. Except for the sequential features from BERT embeddings, the regional features of tweets can be extracted by the Concern Graph module, which not only benefits the concern detection but also enables our model to be high noise-tolerant. Thus, our model can address the issue of insufficient manually labelled data. We conduct extensive experiments to evaluate the proposed model by using both manually labelled tweets and automatically labelled tweets. The experimental results show that our model can outperform the state-of-the-art models on real-world datasets.
Aspect-category sentiment classification of microblog comments aims to identify the sentiment polarity of different opinion aspects in microblog comments, which is meaningful for the analysis of public opinion. At present, most of aspect-category sentiment classification methods need much annotation data, and regard comments as independent samples, without using of the relationship between comments. This article proposes an aspect-category sentiment classification method based on tensor graph convolutional networks. First, the combination of a comment and its aspect category is regarded as a hybrid node, and the original representation of a hybrid node is encoded by the Bert model. Second, sentiment graph and semantic graph are constructed according to the semantic similarity and sentimental relevance between hybrid nodes, and they are stacked into a tensor. Then two convolution operations, including intra-graph convolution and inter-graph convolution, are performed for each layer of graph tensor. In this way, hybrid nodes can learn and merge the heterogeneous information of different graphs. Finally, under the supervision of few labeled comments, the sentiment classification can be completed based on the features of the hybrid nodes. Experimental results on two microblog datasets show that the proposed model can significantly improve the performance of sentiment classification compared with other baseline models.
Human trajectory prediction is an essential task for various applications such as travel recommendation, location-sensitive advertisement, and traffic planning. Most existing approaches are sequential-model based and produce a prediction by mining behavior patterns. However, the effectiveness of pattern-based methods is not as good as expected in real-life conditions, such as data sparse or data missing. Moreover, due to the technical limitations of sensors or the traffic situation at the given time, people going to the same place may produce different trajectories. Even for people traveling along the same route, the observed transit records are not exactly the same. Therefore trajectories are always diverse, and extracting user intention from trajectories is difficult. In this paper, we propose an augmented-intention recurrent neural network (AI-RNN) model to predict locations in diverse trajectories. We first propose three strategies to generate graph structures to demonstrate travel context and then leverage graph convolutional networks to augment user travel intentions under graph view. Finally, we use gated recurrent units with augmented node vectors to predict human trajectories. We experiment with two representative real-life datasets and evaluate the performance of the proposed model by comparing its results with those of other state-of-the-art models. The results demonstrate that the AI-RNN model outperforms other methods in terms of top-k accuracy, especially in scenarios with low similarity.
The abundance of energy consumption data collected by smart meters has inspired researchers to employ deep neural networks to solve the existing problems in the power industry, such as Short-Term Load Forecasting (STLF). Most studies addressing the STLF problem, focus on historical load data and to achieve higher performance, they supplement costly accessible environmental and calendar variables with data. This approach ignores the existing spatial information among the consumers which subsequently might lead into the emergence of similar consumption patterns. In this paper, we present a Graph Convolutional Recurrent Neural Network, a novel neural architecture, for STLF problem that combines Graph Convolutional Networks and Long Short-Term Memory networks to simultaneously extract spatial and temporal information from users with similar consumption patterns. Our model captures spatial information from users without prior knowledge of their geographic location and does not rely on additional environmental variables. We compared our model to traditional baseline models for STLF using two real-world electricity consumption datasets. The empirical results demonstrate a significant improvement in prediction compared with the baseline models, exhibiting a 9.5% and an 8% improvement in terms of Mean Absolute Percentage Error, in the Customer Behavior Trials and Low Carbon London datasets, respectively.
Trajectory prediction is a crucial and challenging task in many domains (e.g., autonomous driving and robot navigation). First, high-quality trajectory prediction methods need to capture the human-human interactions and human-scene interactions effectively to avoid collisions with moving agents and static obstacles. Moreover, it is indispensable for the approaches to be efficient and lightweight to reduce computing costs and economize public resources. To address these challenges, we propose a model with a Spatial-Temporal module and a heatmap module based on gated linear units. In the Spatial-Temporal module, an adaptive Graph Convolutional Network was proposed to capture the human-human interactions, which combines physical features with graph convolutional networks to speculate the agents' implicit relationships. As for the human-scene interaction, we encode the sequential local heatmap around each agent in the heatmap module. The model includes two gated linear units to capture the correlations of the agent's motion and dynamic changing trend of the surrounding scene, respectively. Compared with previous methods, our method is more lightweight and efficient with a smaller parameter size and shorter inference time. Meanwhile, our model achieves better experimental results on two publicly available datasets (ETH and UCY) and predicts more socially reasonable trajectories. (C) 2021 Elsevier B.V. All rights reserved.
As a fundamental spatiotemporal sequence forecasting problem, traffic prediction is pivotal in transportation management and urban computing. Nonetheless, the intricate and dynamic nature of spatiotemporal correlations presents significant obstacles in acquiring precise forecasts. Existing techniques utilize graph convolutional networks in conjunction with temporal modules, such as recurrent neural networks or transformer-based structures, to effectively extract spatiotemporal features. Unfortunately, current approaches struggle with outliers and fail to capture potential global correlations between different timestamps. In this study, we propose an innovative Spatio-Temporal Graph Convolution Network with Embedded location and time features (STEGCN) for traffic prediction problems, which can generate precise and prompt predictions. STEGCN effectively captures the complex interdependencies among location, time, and traffic volume by leveraging the TransD algorithm to embed their representations. For each timestamp, a graph convolution module is exploited to capture the spatial features, merged with the embeddings of location and time that serve as global external information. Then, we leverage a temporal module composed of 1-D convolutions to capture the spatiotemporal patterns. The traffic volume embedding is employed to constrain predictions within a reasonable range. Extensive experiments and rigorous analysis show that our STEGCN model outperforms state-of-the-art baselines, demonstrating exceptional performance and potential for practical application.
Water distribution Networks (WDNs) are one of the most important infrastructures for modern society. Due to accidental or malicious reasons, water contamination incidents have been repeatedly reported all over the world, which not only disrupt the water supply but also endanger public health. To ensure the safety of WDNs, water quality sensors are deployed across the WDNs for real-time contamination detection and source identification. In the literature, various methods have been employed to improve the performance of contamination source identification (CSI) and recent studies show that there is a great potential to tackle the CSI problem by deep learning models. The success of deep learning based CSI methods often requires a large size of training samples being collected. In real-world situations, the number of contamination events occurring in a single WDN is rather small, especially for a newly built WDN. However, the existing CSI methods in the literature mostly focus on the study of training and applying models on the same WDNs and the knowledge of CSI gained from one WDN cannot be reused by a different WDN. To these ends, based on the application of graph convolutional networks, this paper provides a solution for cross-network CSI that can transfer the CSI knowledge learned from one WDN to a different WDN. Empirically, based on a benchmark WDN in the task of contamination source identification, we show that the proposed cross-network CSI method can achieve comparable accuracy even trained on a different WDN. (C) 2021 Institution of Chemical Engineers. Published by Elsevier B.V. All rights reserved.
Graph learning (GL) can dynamically capture the distribution structure (graph structure) of data based on graph convolutional networks (GCN), and the learning quality of the graph structure directly influ-ences GCN for semi-supervised classification. Most existing methods combine the computational layer and the related losses into GCN for exploring the global graph (measuring graph structure from all data samples) or local graph (measuring graph structure from local data samples). The global graph empha-sizes the whole structure description of the inter-class data, while the local graph tends to the neigh-borhood structure representation of the intra-class data. However, it is difficult to simultaneously balance these learning process graphs for semi-supervised classification because of the interdependence of these graphs. To simulate the interdependence, deep graph learning (DGL) is proposed to find a better graph representation for semi-supervised classification. DGL can not only learn the global structure by the pre-vious layer metric computation updating, but also mine the local structure by next layer local weight reassignment. Furthermore, DGL can fuse the different structures by dynamically encoding the interde-pendence of these structures, and deeply mine the relationship of the different structures by hierarchical progressive learning to improve the performance of semi-supervised classification. Experiments demon-strate that the DGL outperforms state-of-the-art methods on three benchmark datasets (Citeseer, Cora, and Pubmed) for citation networks and two benchmark datasets (MNIST and Cifar10) for images. (c) 2021 Elsevier Ltd. All rights reserved.
Graph Convolutional Network (GCN) models have attracted attention given their high accuracy in interpreting graph data. One of the primary building blocks of a GCN model is aggregation, which gathers and averages the feature vectors corresponding to the vertices adjacent to each individual vertex. Aggregation works by multiplying the adjacency and feature matrices. The size of both matrices exceeds the on-chip cache capacity, and the adjacency matrix is highly sparse. These lead to little data reuse and cause numerous main-memory accesses during the aggregation process. Thus, aggregation exhibits memory-intensive characteristics. We propose GraNDe, an NDP architecture that accelerates memory-intensive aggregation operations by locating processing elements near the DRAM datapath to exploit rank-level parallelism. By exploring the data mapping of the operand matrices to DRAM ranks, we discover that the optimal mapping differs depending on the configuration of a specific GCN layer. With our optimal layer-by-layer mapping scheme, GraNDe shows a speedup up to 4.3x compared to the baseline system on open-graph benchmark datasets.
In this paper, we consider the problem of low-speed convergence in Reinforcement Learning (RL). As a solution, various potential-based reward shaping techniques were pro-posed to form the potential function. Learning a potential function is still challenging and comparable to building a value function from scratch. In this work, our main contribution is proposing a new scheme for reward shaping, which combines (1) the Graph Convolutional Recurrent Networks (GCRN), (2) augmented Krylov, and (3) look-ahead advice to form the potential function. We propose an architecture for GCRN that combines Graph Convolutional Networks (GCN) to capture spatial dependencies and Bi-Directional Gated Recurrent Units (Bi-GRUs) to account for temporal dependencies. Our definition of the loss function of GCRN incorporates the message passing technique of the Hidden Markov Models (HMM). Since the transition matrix of the environment is hard to compute, we use the Krylov basis to estimate the transition matrix, which outperforms the existing approximation bases. Unlike existing potential functions that only rely on states to perform reward shaping, we use both the states and actions through the look-ahead advice mech-anism to produce more precise advice. Our evaluations conducted on the Atari 2600 and MuJoCo games show that our solution outperforms the state-of-the-art that utilizes GCN as the potential function in most games in terms of the learning speed while reaching higher rewards.(c) 2022 Elsevier Inc. All rights reserved.
Organizing the implicit topology of a document as a graph, and further performing feature extraction via the graph convolutional network (GCN), has proven effective in document analysis. However, existing document graphs are often restricted to expressing single-level relations, which are predefined and independent of downstream learning. A set of learnable hierarchical graphs are built to explore multilevel sentence relations, assisted by a hierarchical probabilistic topic model. Based on these graphs, multiple parallel GCNs are used to extract multilevel semantic features, which are aggregated by an attention mechanism for different document-comprehension tasks. Equipped with variational inference, the graph construction and GCN are learned jointly, allowing the graphs to evolve dynamically to better match the downstream task. The effectiveness and efficiency of the proposed multilevel sentence relation graph convolutional network (MuserGCN) is demonstrated via experiments on document classification, abstractive summarization, and matching.
Prediction of the molecular compound structure-activity relationship is one of the most critical tasks in computer-assisted drug design. To accurately predict the properties of molecular compounds and explain their structure-activity relationships, we proposed a subgraph embedding model, subGE, based on reinforcement learning and mutual information mechanisms. First, molecular compounds were abstracted into graphs, and the original graphs were sampled using a breadth-first search. These subgraphs were then encoded using graph neural networks and converted into graph embeddings. Reinforcement learning was introduced to reduce the dimensionality of the subgraph embeddings and filter out significant subgraphs. A mutual information mechanism was introduced to further enhance the ability of the filtered subgraphs to characterize a full graph. SubGE was evaluated based on three open-source datasets, BBBP, Bace, and Clintox from the DeepChem package developed by MoleculeNet. The experimental results showed that subGE achieved accuracies of 86.61%, 80.49%, 95.81%, and 96.34% for four classification tasks with three datasets. These values represent improvements of 16.87%, 19.29%, 3.91%, and 3.73%, respectively, compared to that of existing graph convolutional networks, and of 8.34%, 6.64%, 5.53%, and 5.50%, respectively, compared to that of the direct encoding of subgraphs without introducing reinforcement learning and mutual information mechanisms. The subgraphs extracted by subGE could fully explain the conformational relationships of compounds through visualization.
Knowledge graph (KG) embedding encodes the entities and relations from a KG into low-dimensional vector spaces to support various applications such as KG completion, question answering, and recommender systems. In real world, knowledge graphs (KGs) are dynamic and evolve over time with addition or deletion of triples. However, most existing models focus on embedding static KGs while neglecting dynamics. To adapt to the changes in a KG, these models need to be retrained on the whole KG with a high time cost. In this paper, to tackle the aforementioned problem, we propose a new context-aware Dynamic Knowledge Graph Embedding (DKGE) method which supports the embedding learning in an online fashion. DKGE introduces two different representations (i.e., knowledge embedding and contextual element embedding) for each entity and each relation, in the joint modeling of entities and relations as well as their contexts, by employing two attentive graph convolutional networks, a gate strategy, and translation operations. This effectively helps limit the impacts of a KG update in certain regions, not in the entire graph, so that DKGE can rapidly acquire the updated KG embedding by a proposed online learning algorithm. Furthermore, DKGE can also learn KG embedding from scratch. Experiments on the tasks of link prediction and question answering in a dynamic environment demonstrate the effectiveness and efficiency of DKGE. (c) 2022 Elsevier B.V. All rights reserved.
This paper develops a novel reduced-order model called SGCNN, which combines the Graph Convolutional Networks (GCN) with the Recurrent Neural Networks (RNN), to predict sequential transient flow around cylinders using unstructured flow field data. In flow field prediction, we use GCN's unique message passing mechanism to extract and aggregate the characteristics of the flow field grid in non-Euclidean space, eliminating the pixelization process of CNN in non-Euclidean space, and significantly improving the prediction accuracy. GRU is used as the unit of the RNN network to obtain the changeable physical characteristics through the hidden layer, thereby achieving continuous prediction of the flow field. According to our literature review, this is the first investigation to estimate sequential transient flow fields around cylinders. The proposed model is initially verified with the flow around single cylinder. Taking the numerical simulation as the reference, the relative errors of the predicted sequential velocity and the pressure fields are less than 3% and 2%, respectively. Subsequently, the complexity of the investigation is increased by varying the Reynolds number and introducing additional cylinders in the flow region. The predicted physical fields consistently align well with CFD simulations, and the computational time is remarkably reduced by more than 90%.
Motivated by the powerful capability of deep neural networks in feature learning, a new graph-based neural network is proposed to learn local and global relational information on skeleton sequences represented as spatio-temporal graphs (STGs). The pipeline of our network architecture consists of three main stages. As the first stage, spatial-temporal sub-graphs (sub-STGs) are projected into a latent space in which every point is represented as a linear subspace. The second stage is based on message passing to acquire the localized correlated features of the nodes in the latent space. The third stage relies on graph convolutional networks (GCNs) to reason the long-range spatio-temporal dependencies through a graph representation of the latent space. Finally, the average pooling layer and the softmax classifier are then employed to predict the action categories based on the extracted local and global correlations. We validate our model in terms of action recognition using three challenging datasets: the NTU RGB+D, Kinetics Motion, and SBU Kinect Interaction datasets. The experimental results demonstrate the effectiveness of our approach and show that our proposed model outperforms the state-of-the-art methods.
Scaling adaptive traffic signal control involves dealing with combinatorial state and action spaces. Multi-agent reinforcement learning attempts to address this challenge by distributing control to specialized agents. However, specialization hinders generalization and transferability, and the computational graphs underlying neural-network architectures-dominating in the multi-agent setting-do not offer the flexibility to handle an arbitrary number of entities which changes both between road networks, and over time as vehicles traverse the network. We introduce Inductive Graph Reinforcement Learning (IG-RL) based on graph-convolutional networks which adapts to the structure of any road network, to learn detailed representations of traffic signal controllers and their surroundings. Our decentralized approach enables learning of a transferable-adaptive-trafficsignal-control policy. After being trained on an arbitrary set of road networks, our model can generalize to new road networks and traffic distributions, with no additional training and a constant number of parameters, enabling greater scalability compared to prior methods. Furthermore, our approach can exploit the granularity of available data by capturing the (dynamic) demand at both the lane level and the vehicle level. The proposed method is tested on both road networks and traffic settings never experienced during training. We compare IG-RL to multi-agent reinforcement learning and domain-specific baselines. In both synthetic road networks and in a larger experiment involving the control of the 3,971 traffic signals of Manhattan, we show that different instantiations of IG-RL outperform baselines.
In skeleton-based action recognition, graph convolutional networks (GCNs) have achieved remarkable success. However, there are two shortcomings of current GCN-based methods. Firstly, the computation cost is pretty heavy, typically over 15 GFLOPs for one action sample. Some recent works even reach similar to 100 GFLOPs. Secondly, the receptive fields of both spatial graph and temporal graph are inflexible. Although recent works introduce incremental adaptive modules to enhance the expressiveness of spatial graph, their efficiency is still limited by regular GCN structures. In this paper, we propose a shift graph convolutional network (ShiftGCN) to overcome both short-comings. ShiftGCN is composed of novel shift graph operations and lightweight point-wise convolutions, where the shift graph operations provide flexible receptive fields for both spatial graph and temporal graph. To further boost the efficiency, we introduce four techniques and build a more lightweight skeleton-based action recognition model named ShiftGCN++. ShiftGCN-H- is an extremely computation-efficient model, which is designed for low-power and low-cost devices with very limited computing power. On three datasets for skeleton-based action recognition, ShiftGCN notably exceeds the state-of-the-art methods with over 10x less FLOPs and 4x practical speedup. ShiftGCN-H- further boosts the efficiency of ShiftGCN, which achieves comparable performance with 6x less FLOPs and 2x practical speedup.
Graph convolutional networks (GCNs) are powerful tools for analyzing structured data with entities based on messages passing between a node and its surrounding nodes; these networks exhibit exceptional capabilities in diverse complex graph learning tasks. However, despite GCNs being capable of incorporating information from entities, they often neglect the structural connections between the entities generated by latent factors. In this study, we propose a global disentangled graph convolutional neural network based on a graph topological metric to identify these latent factors and perform graph-level disentanglement learning. In the proposed framework, a simple graph is accepted as the input and disentangled into several factorized graphs. Each factorized graph represents a latent factor and the disentangled relationship among the nodes. Specifically, our approach decouples the message passing process in GCNs into two distinct flows, feature and structural information flow. Importantly, a topological metric, named mean average distance, is introduced to promote the disentanglement among the factor graphs. Furthermore, we utilize the Jensen-Shannon MI estimator to promote disentanglement through feature information flow. Experiments on synthetic and real-world datasets demonstrated the superiority of our framework over state-of-the-art GNN networks. This work introduces a novel approach, preserving independence among latent factors while ensuring each factor maintains a consistent and interpretable meaning. We anticipate that this research can provide theoretical and technical analysis to further advance the understanding of graph disentanglement learning.
Multi-person pose tracking task aims to estimate and track person keypoints in videos. Most of the previous methods follow the general track-by-detection strategy that ignores the consistent pose information during the whole framework. Thus, they often suffer from missing detections or inaccurate human association in challenging scenes with motion blur or person occlusion. To handle those problems, we propose a pose-guided tracking-by-detection framework that fuses pose information into both video human detection and human association procedures. In the video human detection stage, we adopt the pose-guided person location prediction exploiting the temporal information to make up missing detections. Technically, pose heatmaps are utilized to cope with the person-specific intra-class distractors. Furthermore, in the human association stage, we propose an appearance discriminative model based on the hierarchical pose-guided graph convolutional networks (PoseGCN). The PoseGCN-based model exploits human structural relations to boost person representation. Extensive experiments show the superiority of our method on the challenging pose tracking benchmark. Our proposed method ranks first on the PoseTrack leaderboard. (1) (1) http://posetrack.net/leaderboard.php till the submission date (22-Aug-2019) of this paper. Our code has been publicly available at https://github.com/human-centric982/PGPT.
Information networks generally exhibit three characteristics, namely dynamicity, heterogeneity, and node attribute diversity. However, most existing network embedding approaches only consider two of the three when embedding each node into low -dimensional space. Adding to such an existing approach a technique of processing the remaining characteristic can easily cause incompatibility. One solution to process the three characteristics together is to treat the dynamic heterogeneous attributed network (DHAN) as a temporal sequence of heterogeneous attributed network (HAN) snapshots. For example, existing graph convolutional networks (GCNs)-based DHAN embedding approaches embed the HAN snapshots to get static representations offline, and then dynamically capture temporal dependencies between adjacent snapshots online to maintain fresh representations of the DHAN. However, those approaches encounter the convergence problem when stacking multiple convolutional layers to capture more topological information. Some other existing approaches dynamically update the representations of HAN snapshots online, neglecting the efficiency requirement of online scenarios and the temporal dependencies between snapshots. To address the two issues, we propose a new framework called Dynamic Heterogeneous Attributed Network Embedding (DHANE), consisting of a static model MGAT and a dynamic model NICE. MGAT captures more topological information while maintaining GCN convergence by performing metagraph-based attention in each convolutional layer. NICE preserves network freshness while reducing the computational load of the update by only examining network changes and updating their embedding representations. Extensive experiments show that DHANE achieves up to 27x speedup and 9.1-26.4% higher accuracy on several real dynamic heterogeneous attributed networks for online classification.
Knowledge tracing is a modeling method of students' knowledge mastery. The deep knowledge tracing (DKT) model uses long short-term memory (LSTM) to process the sequence data of students exercises. However, the LSTM-based model pays more attention to the short-term response status of students while ignoring the long-term learning process. Moreover, existing graph-based knowledge tracing models focus on the static relationship between exercises and skills, ignoring the dynamic graphs formed by students exercises in a session. In this work, we propose a novel knowledge tracing model which is based on an exercise session graph, named session graph based knowledge tracing (SGKT). The session graph is used to model the students' answering process. In addition, a relationship graph is used to model the relationship between exercises and skills. Then we use gated graph neural networks to obtain the students' knowledge state from the session graph and use graph convolutional networks to obtain the embedding representations of exercises and skills in the relationship graph. Next, through the interaction mechanism, multiple interaction states composed of knowledge states and embedding representations are obtained. The attention mechanism is used to find the focus from these states and make predictions. Experiments are conducted on three publicly available datasets and the results show that our approach has advantages over some existing baseline methods.
Semi-supervised short text classification is a challenging problem due to the sparsity and limited labeled data. Due to the lack of labeled data, many models focus on the generation of text samples, which is cumbersome and has poor scalability. To overcome this defi-ciency, in this paper, we propose a Self-Training Text method based on Graph Convolutional Networks (ST-Text-GCN). Differently from the previous literature, our self -training method is convenient. The labeled information is propagated to target samples along the structure of the manifold, instead of introducing the extra knowledge. Specifically, instead of adding text training samples, our method adds keywords to training set. The model will calculate the confidence of each word. Confidence indicates the degree of ambiguity of a word. Some words with high confidence are automatically marked as pseudo-labeled data. Meanwhile, word confidence is added to the calculation of the edge weights of the graph to reduce the classification error caused by word ambiguity. Our method makes full use of the keywords in short texts when labeled data is scarce. Extensive experimental results have demonstrated that our proposed method outperforms state-of-the-art models on multiple benchmark datasets.(c) 2022 Elsevier Inc. All rights reserved.
In recent years, advances in Graph Convolutional Networks (GCNs) have given new insights into the development of social recommendation. However, many existing GCN-based social recommendation methods often directly apply GCN to capture user-item and user-user interactions, which probably have two main limitations: (a) Due to the power-law property of the degree distribution, the vanilla GCN with static normalized adjacencymatrix has limitations in learning node representations, especially for the long-tail nodes; (b) multityped social relationships between users that are ubiquitous in the real world are rarely considered. In this article, we propose a novel Bilateral Filtering Heterogeneous Attention Network (BFHAN), which improves long-tail node representations and leverages multi-typed social relationships between user nodes. First, we propose a novel graph convolutional filter for the user-item bipartite network and extend it to the user-user homogeneous network. Further, we theoretically analyze the correlation between the convergence values of different graph convolutional filters and node degrees after stacking multiple layers. Second, we model multi-relational social interactions between users as the multiplex network and further propose a multiplex attention network to capture distinctive inter-layer influences for user representations. Last but not least, the experimental results demonstrate that our proposed method outperforms several state-of-the-art GCN-based methods for social recommendation tasks.
Predicting a comprehensive set of relevant labels on chest X-ray images faces great challenges towards bridging visual and textual modalities. Despite the success of Graph Convolutional Networks (GCN) on modeling label dependencies using co-occurrence matrix generated from dataset, they still suffer from inherent label imbalance in dataset and ignore the explicit relations among labels presented in external medical knowledge graph (KG). We argue that jointly exploiting both the label co-occurrence matrix in dataset and the label relations in external knowledge graph facilitates multi-label lesion annotation. To model relevant lesion labels more comprehensively, we propose a KG-augmented model via Aggregating Explicit Relations for multi-label lesion annotation, called AER-GCN. The KG-augmented model employs GCN to learn the explicit label relations in external medical KG, and aggregates the explicit relations into statistical graph built from label co-occurrence information. Specially, we present three approaches on modeling the explicit label correlations in external knowledge, and two approaches on incorporating the explicit relations into co-occurrence relations for lesion annotation. We exploit SNOMED CT as the source of external knowledge and evaluate the performance of AER-GCN on the ChestX-ray and IU X-ray datasets. Extensive experiments demonstrate that our model outperforms other state-of-the-art models.
Spatiotemporal prediction is one attractive research topic in urban computing, which is of great significance to urban planning and management. At present, there are many attempts to predict the spatiotemporal state of systems using various deep learning models. However, most existing models tend to improve prediction accuracy with larger parameter scale and time consumption, but ignoring ease of use in practice. To overcome this question, we propose a lightweight spatiotemporal graph dilated convolutional network called STGDN with satisfactory prediction accuracy and lower model complexity. More specifically, we propose a novel dilated convolution operator and integrate it into traditional causal convolutional networks and graph convolutional networks to greatly improve the efficiency of prediction. The proposed dilated convolution operator can significantly reduce the depth of the model, thereby reducing the parameter scale and improving the computational efficiency of the model. We conducted on multi experiments on three real-world spatiotemporal datasets (traffic dataset, PM2.5 dataset, and temperature dataset) to prove the effectiveness and advantage of our proposed STGDN. The experimental results show that the proposed STGDN model outperforms or achieves comparable prediction accuracy of the existing nine baselines with higher operational efficiency and fewer model parameters. Codes are available at anonymous private link on https://doi.org/10.6084/m9.figshare.23935683.
Alzheimer's disease and other types of dementia are the top cause for disabilities in later life and various types of experiments have been performed to understand the underlying mechanisms of the disease with the aim of coming up with potential drug targets. These experiments have been carried out by scientists working in different domains such as proteomics, molecular biology, clinical diagnostics and genomics. The results of such experiments are stored in the databases designed for collecting data of similar types. However, in order to get a systematic view of the disease from these independent but complementary data sets, it is necessary to combine them. In this study we describe a heterogeneous network-based data set for Alzheimer's disease (HENA). Additionally, we demonstrate the application of state-of-the-art graph convolutional networks, i.e. deep learning methods for the analysis of such large heterogeneous biological data sets. We expect HENA to allow scientists to explore and analyze their own results in the broader context of Alzheimer's disease research.
The white-matter (micro-)structural architecture of the brain promotes synchrony among neuronal populations, giving rise to richly patterned functional connections. A fundamental problem for systems neuroscience is determining the best way to relate structural and functional networks quantified by diffusion tensor imaging and resting-state functional MRI. As one of the state-of-the-art approaches for network analysis, graph convolutional networks (GCN) have been separately used to analyze functional and structural networks, but have not been applied to explore inter-network relationships. In this work, we propose to couple the two networks of an individual by adding inter-network edges between corresponding brain regions, so that the joint structure-function graph can be directly analyzed by a single GCN. The weights of inter-network edges are learnable, reflecting non-uniform structure-function coupling strength across the brain. We apply our Joint-GCN to predict age and sex of 662 participants from the public dataset of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) based on their functional and micro-structural white-matter networks. Our results support that the proposed Joint-GCN outperforms existing multi-modal graph learning approaches for analyzing structural and functional networks.
Skeleton-based human action recognition has attracted extensive attention due to the robustness of the human skeleton data in the field of computer vision. In recent years, there is a trend of using graph convolutional networks (GCNs) to model the human skeleton into a spatio-temporal graph to explore the internal connections of human joints that has achieved remarkable performance. However, the existing methods always ignore the remote dependency between joints, and fixed temporal convolution kernels will lead to inflexible temporal modeling. In this paper, we propose a multi-scale adaptive aggregate graph convolution network (MSAAGCN) for skeleton-based action recognition. First, we designed a multi-scale spatial GCN to aggregate the remote and multi-order semantic information of the skeleton data and comprehensively model the internal relations of the human body for feature learning. Then, the multi-scale temporal module adaptively selects convolution kernels of different temporal lengths to obtain a more flexible temporal map. Additionally, the attention mechanism is added to obtain more meaningful joint, frame and channel information in the skeleton sequence. Extensive experiments on three large-scale datasets (NTU RGB+D 60, NTU RGB+D 120 and Kinetics-Skeleton) demonstrate the superiority of our proposed MSAAGCN.
Aspect-based sentiment analysis(ABSA) aims to identify the sentiment polarity of specific aspects in sentences, which can more accurately mine the sentiment polarity of users towards different aspects. Most of the existing works derive the sentiment features of specific aspects by interactively learning the dependencies between different aspects of the context. However, the above work has neglected to use the external affective commonsense knowledge to augment the ability of the Graph Convolutional Networks(GCNs) to interactively capture sentiment dependencies of the inter-aspect words in different contexts. In addition, compared to the ABSA research in English, the existing research pays less attention to the Chinese-oriented research. Meanwhile, multi-head self-sttention(MHSA) is applied to extract richer context syntax and semantic interaction features. In this paper, we propose a novel knowledge-aware model in which affective knowledge augments interactive GCN for Chinese-oriented ABSA, namely AKM-IGCN. Moreover, this model can be applied to effectively analyze both Chinese and English comments simultaneously. Hence, we conducted experiments on four Chinese datasets(Camera, Phone, Notebook and Car) and six English benchmark datasets(Restaurant14, Restaurant15, Restaurant16, Twitter, MAMS, Tshirt). Experimental results illustrate that our proposed model outperforms or approaches state-of-the-art models.
With the widespread application of blockchain technology, the cyberspace security issue of phishing has also appeared in the emerging blockchain cryptocurrency ecosystem. Because phishing fraud in cryptocurrency transactions has its own unique characteristics compared to traditional phishing, many existing phishing detection algorithms are not usable. Therefore, based on graph convolutional networks, we have researched and built a high-performance model for detecting blockchain cryptocurrency phishing fraud. Our model divides the constructed blockchain cryptocurrency transaction graph into "Sender" and "Receiver" graphs, according to the sending and receiving directions. Then, the edge features in the graph are transferred. Finally, we use a double-layer graph convolution network for feature learning and send it to the classifier for fraud detection. After completing training on the actual dataset collected from Ethereum, the model achieved an accuracy of 88.02% and an F1 score of 88.14% on the test data, which had a better performance than that of the other models. Our model provides a new concept for the detection of phishing scams in blockchain cryptocurrency networks.
At present, convolutional neural networks (CNNs) have become popular in visual classification tasks because of their superior performance. However, CNN-based methods do not consider the correlation of visual data to be classified. Recently, graph convolutional networks (GCNs) have mitigated this problem by modeling the pairwise relationship in visual data. Real-world tasks of visual classification typically must address numerous complex relationships in the data, which are not fit for the modeling of the graph structure using GCNs. Therefore, it is vital to explore the underlying correlation of visual data. Regarding this issue, we propose a framework called the hypergraph-induced convolutional network to explore the high-order correlation in visual data during deep neural networks. First, a hypergraph structure is constructed to formulate the relationship in visual data. Then, the high-order correlation is optimized by a learning process based on the constructed hypergraph. The classification tasks are performed by considering the high-order correlation in the data. Thus, the convolution of the hypergraph-induced convolutional network is based on the corresponding high-order relationship, and the optimization on the network uses each data and considers the high-order correlation of the data. To evaluate the proposed hypergraph-induced convolutional network framework, we have conducted experiments on three visual data sets: the National Taiwan University 3-D model data set, Princeton Shape Benchmark, and multiview RGB-depth object data set. The experimental results and comparison in all data sets demonstrate the effectiveness of our proposed hypergraph-induced convolutional network compared with the state-of-the-art methods.
Recently, graph convolutional networks (GCNs) have been developed to explore the spatial relationship between pixels, achieving better classification performance of hyperspectral images (HSIs). However, these methods fail to sufficiently leverage the relationship between spectral bands in HSI data. As such, we propose an adaptive cross-attention-driven spatial-spectral graph convolutional network (ACSS-GCN), which is composed of a spatial GCN (Sa-GCN) subnetwork, a spectral GCN (Se-GCN) subnetwork, and a graph cross-attention fusion module (GCAFM). Specifically, Sa-GCN and Se-GCN are proposed to extract the spatial and spectral features by modeling the correlations between spatial pixels and between spectral bands, respectively. Then, by integrating attention mechanism into information aggregation of the graph, the GCAFM, including three parts, i.e., the spatial graph attention block, the spectral graph attention block, and the fusion block, is designed to fuse the spatial and spectral features, and suppress noise interference in Sa-GCN and Se-GCN. Moreover, the idea of the adaptive graph is introduced to explore an optimal graph through backpropagation during the training process. Experiments on two HSI datasets show that the proposed method achieves better performance than other classification methods.
Spatial power load forecasting is crucial for power grid planning, generation planning, dispatching, efficient power utilization, and sustainable development. The integration of new energy sources and electric vehicles has significantly altered grid loads, increasing the complexity of spatial load forecasting. However, existing techniques fail to fully consider the temporal and spatial correlation characteristics of data, leading to challenges in data identification and summarization. This reduces load forecasting accuracy and prolongs prediction time. To address these issues, a spatial electric load forecasting method based on improved scale limited dynamic time warping (LDTW) and graph convolutional network (GCN) are proposed. Firstly, the improved scale LDTW is used to improve the clustering effect of K-Mediods++, refine the type of load data, and make the subsequent model training more targeted. Secondly, the interconnections and distances of substations in a real network structure is used to build a graph model to capture the power load distribution. Finally, based on the clustering results and the graph model, GCN-LSTM is used to construct the spatio-temporal forecasting algorithm. The proposed algorithm is tested using load data from a region in Shanghai and compared with other advanced algorithms. Results show that the algorithm achieves higher prediction accuracy and efficiency. An improved scale limited dynamic time warping and graph convolutional network method, refining load data type and clustering effect, building a graph model based on real network structure, and constructing a spatio-temporal prediction algorithm using GCN-LSTM. The algorithm achieves higher prediction accuracy and efficiency in Shanghai load data.image
As the use of digital currencies, such as cryptocurrencies, increases in popularity, phishing scams and other cybercriminal activities on blockchain platforms (e.g., Ethereum) have also risen. Current methods of detecting phishing in Ethereum focus mainly on the transaction features and local network structure. However, these methods fail to account for the complexity of interactions between edges and the handling of large graphs. Additionally, these methods face significant issues due to the limited number of positive labels available. Given this, we propose a scheme that we refer to as the Bagging Multiedge Graph Convolutional Network to detect phishing scams on Ethereum. First, we extract the features from transactions and transform the complex Ethereum transaction network into three simple inter-node graphs. Then, we use graph convolution to generate node embeddings that leverage the global structural information of the inter-node graphs. Further, we apply the bagging strategy to overcome the issues of data imbalance and the Positive Unlabeled (PU) problem in transaction data. Finally, to evaluate our approach's effectiveness, we conduct experiments using actual transaction data. The results demonstrate that our Bagging Multiedge Graph Convolutional Network (0.877 AUC) outperforms all of the baseline classification methods in detecting phishing scams on Ethereum.
The online social media ecosystem is becoming more and more confused because of more and more fake information and the social media of malicious users' fake content; at the same time, unspeakable pain has been brought to mankind. Social robot detection uses supervised classification based on artificial feature extraction. However, user privacy is also involved in using these methods, and the hidden feature information is also ignored, such as semi-supervised algorithms with low utilization rates and graph features. In this work, we symmetrically combine BERT and GCN (Graph Convolutional Network, GCN) and propose a novel model that combines large scale pretraining and transductive learning for social robot detection, BGSRD. BGSRD constructs a heterogeneous graph over the dataset and represents Twitter as nodes using BERT representations. Corpus learning via text graph convolution network is a single text graph, which is mainly built for corpus-based on word co-occurrence and document word relationship. BERT and GCN modules can be jointly trained in BGSRD to achieve the best of merit, training data and unlabeled test data can spread label influence through graph convolution and can be carried out in the large-scale pre-training of massive raw data and the transduction learning of joint learning representation. The experiment shows that a better performance can also be achieved by BGSRD on a wide range of social robot detection datasets.
In silico driven optimization of compound properties related to pharmacokinetics, pharmacodynamics, and safety is a key requirement in modern drug discovery. Nowadays, large and harmonized datasets allow to implement deep neural networks (DNNs) as a framework for leveraging predictive models. Nevertheless, various available model architectures differ in their global applicability and performance in lead optimization projects, such as stability over time and interpretability of the results. Here, we describe and compare the value of established DNN-based methods for the prediction of key ADME property trends and biological activity in an industrial drug discovery environment, represented by microsomal lability, CYP3A4 inhibition and factor Xa inhibition. Three architectures are exemplified, our earlier described multilayer perceptron approach (MLP), graph convolutional network-based models (GCN) and a vector representation approach, Mol2Vec. From a statistical perspective, MLP and GCN were found to perform superior over Mol2Vec, when applied to external validation sets. Interestingly, GCN-based predictions are most stable over a longer period in a time series validation study. Apart from those statistical observations, DNN prove of value to guide local SAR. To illustrate this important aspect in pharmaceutical research projects, we discuss challenging applications in medicinal chemistry towards a more realistic picture of artificial intelligence in drug discovery.
Recently, many models based on the combination of graph convolutional networks and deep learning have attracted extensive attention for their superior performance in graph clustering tasks. However, the existing models have the following limitations: (1) Existing models are limited by the calculation method of graph convolution, and their computational cost will increase exponentially as the graph scale grows. (2) Stacking too many convolutional layers causes the over-smoothing issue and neglects the local graph structure. (3) Expanding the range of the neighborhood and the model depth together is difficult due to the orthogonal relationship between them. Inspired by personalized pagerank and auto-encoder, we conduct the node-wise graph clustering task in the undirected simple graph as the research direction and propose a Scalable Deep Network (SDN) for graph clustering via personalized pagerank. Specifically, we utilize the combination of multi-layer perceptrons and linear propagation layer based on personalized pagerank as the backbone network (i.e., the Quasi-GNN module) and employ a DNN module for auto-encoder to learn different dimensions embeddings. After that, SDN combines the two embeddings correspondingly; then, it utilizes a dual self-supervised module to constrain the training of the embedding and clustering process. Our proposed Quasi-GNN module reduces the computational costs of traditional GNN models in a decoupled approach and solves the orthogonal relationship between the model depth and the neighborhood range. Meanwhile, it also alleviates the degraded clustering effect caused by the over-smoothing issue. We conducted experiments on five widely used graph datasets. The experimental results demonstrate that our model achieves state-of-the-art performance.
Modern recommender systems (RS) work by processing a number of signals that can be inferred from large sets of user-item interaction data. The main signal to analyze stems from the raw matrix that represents interactions. However, we can increase the performance of RS by considering other kinds of signals like the context of interactions, which could be, for example, the time or date of the interaction, the user location, or sequential data corresponding to the historical interactions of the user with the system. These complex, context-based interaction signals are characterized by a rich relational structure that can be represented by a multi-partite graph. Graph Convolutional Networks (GCNs) have been used successfully in collaborative filtering with simple user-item interaction data. In this work, we generalize the use of GCNs for N-partite graphs by considering N multiple context dimensions and propose a simple way for their seamless integration in modern deep learning RS architectures. More specifically, we define a graph convolutional embedding layer for N-partite graphs that processes user-item-context interactions and constructs node embeddings by leveraging their relational structure. Experiments on several datasets show the benefits of the introduced GCN embedding layer by measuring the performance of different context-enriched tasks.
Sigma profiles are quantum-chemistry-derived molecular descriptors that encode the polarity of molecules. They have shown great performance when used as a feature in machine learning applications. To accelerate the development of these models and the construction of large sigma profile databases, this work proposes a graph convolutional network (GCN) architecture to predict sigma profiles from molecule structures. To do so, the usage of molecular mechanics (force field atom types) is explored as a computationally inexpensive node-level featurization technique to encode the local and global chemical environments of atoms in molecules. The GCN models developed in this work accurately predict the sigma profiles of assorted organic and inorganic compounds. The best GCN model here reported, obtained using Merck molecular force field (MMFF) atom types, displayed training and testing set coefficients of determination of 0.98 and 0.96, respectively, which are superior to previous methodologies reported in the literature. This performance boost is shown to be due to both the usage of a convolutional architecture and node-level features based on force field atom types. Finally, to demonstrate their practical applicability, we used GCN-predicted sigma profiles as the input to machine learning models previously developed in the literature that predict boiling temperatures and aqueous solubilities. Using the predicted sigma profiles as input, these models were able to compute both physicochemical properties using significantly less computational resources and displayed only a slight decrease in performance when compared with sigma profiles obtained from quantum chemistry methods.
Modeling the interactions between users and items to accurately predict a user preference on items is very crucial for improving the performance of recommendation. Although existing graph-based methods have achieved great progress in predicting a user preference for recommendation, they usually need additional side information which is difficultly obtained, and ignore the temporal-order associations between items (users) when constructing graphs. In this paper, we propose a temporal-order association-based dynamic graph evolution model for recommendation, which can not only capture temporal-order item associations and user relationships by recurrently constructing a temporal-order item association graph and a user similarity graph but also update and promote the embeddings and graphs by performing a novel dynamic evolution mechanism based on two graph convolutional networks (GCNs). Specifically, the proposed model consists of two main components: recurrent graph construction component and message propagation and aggregation component. The former recurrently constructs the temporal-order item association graph and the user similarity graph only from the history interactions and embeddings to capture the item-item and user-user relationships. The latter performs a novel dynamic evolution mechanism based on two GCNs on these two auxiliary graphs and interaction graph to refine user and item representations, which further helps the process of constructing two auxiliary graphs. Finally, the final embeddings of users and items are used to predict a user preference on all items the user has not interacted with. The experimental results illustrate that our method outperforms the state-of-the-art methods on five real-world datasets.
Graph convolutional networks (GCNs) have attracted increasing research attention, which merits in its strong ability to handle graph data, such as the citation network or social network. Existing models typically use first-order neighborhood information to design specific convolution operations, which aggregate the features of all adjacent nodes. However, such models ignore the high-order spatial relationship among neighboring nodes in noisy data due to its modeling complexity. In this article, we propose a novel robust graph relational network to address this issue toward modeling high-order relationships in noisy data for graph convolution. Our key innovation lies in designing a generic relation network layer, which is used to infer the underlying relations among adjacent noisy nodes. Specifically, a fixed number of adjacent nodes for each node is chosen by solving the ridge regression problem, in which the regression coefficients are used to rank the adjacent nodes of each node in a graph. Furthermore, to mine the rich features, we extract high-order information from the nodes to significantly enhance the representation ability of the GCNs for extensive applications. We conduct extensive semisupervised node classification experiments on the noisy benchmark datasets, which clearly show that our model is superior to the existing methods and can achieve state-of-the-art performance.
Network traffic forecasting is essential for efficient network management and planning. Accurate long-term forecasting models are also essential for proactive control of upcoming congestion events. Due to the complex spatial-temporal dependencies between traffic flows, traditional time series forecasting models are often unable to fully extract the spatial-temporal characteristics between the traffic flows. To address this issue, we propose a novel dual-channel based graph convolutional network (DC-STGCN) model. The proposed model consists of two temporal components that characterize the daily and weekly correlation of the network traffic. Each of these two components contains a spatial-temporal characteristics extraction module consisting of a dual-channel graph convolutional network (DCGCN) and a gated recurrent unit (GRU). The DCGCN further consists of an adjacency feature extraction module (AGCN) and a correlation feature extraction module (PGCN) to capture the connectivity between nodes and the proximity correlation, respectively. The GRU further extracts the temporal characteristics of the traffic. The experimental results based on real network data sets show that the prediction accuracy of the DC-STGCN model overperforms the existing baseline and is capable of making long-term predictions.
Detecting deceptive reviews can assist customers in grasping the real evaluation of products and services to make better purchase decisions and help companies satisfy timely to their customers' expectations. Methods based on neural networks for deceptive review detection have made significant progress in recent years. Models using attention mechanisms such as BERT have demonstrated the ability to capture contextual information in review texts. However, their ability to capture global information about the word level is limited. This latter is the strength of Graph Convolutional Networks (GCNs). In this study, we propose a detection model (SGCN-BERT) based on the combination of Semantic Graph Convolutional Network (SGCN) and pre-trained model BERT. During the construction of the heterogeneous review graph, we consider both the co-occurrence relationship and semantic relationship between words to enrich the graph information. The graph embedding of the reviews are obtained through SGCN and input to BERT together with word embeddings. Global and local information containing lexical-semantic interact through different layers of BERT, allowing them to influence and build the final classification representation jointly mutually. Comprehensive tests on four public datasets show that our method outperforms previous methods and has good generalization capability.
The higher requirements for deep neural networks are driving researchers to have a deeper understanding of the internals of neural networks. The class activation map (CAM) based methods can provide a convincing interpretation of the features extracted by the neural network from both visual and quantitative perspectives. However, the existing CAM methods do not take into account that the non-target region also contains target-related activation, which results in the generated saliency map containing noise from unrelated regions. In addition, the soft mask with continuous value not only contains more non-target regions for gradient-free CAM, but also causes the characteristics and distribution of the target region to be disturbed. This paper proposed a novel CAM method named Bipolar Information CAM (BI-CAM) to interpret convolutional neural networks (CNNs) and graph convolutional networks (GCNs). Firstly, dual-stream information is proposed to precisely quantify the relationship between the target region and the non-target region for an image/graph. Secondly, binary reformation is also proposed to generate a hard mask that can retain the original features and regions. Finally, we propose to use concise and effective Point-wise Mutual Information (PMI) to measure the quantitative relationship between the image and the local region with respect to the label. The results of the experiment show that the proposed BI-CAM achieves significantly better performance in the faithfulness evaluation from the perspectives of visualization and quantitative analysis than other competitive interpretation methods.
Monocular RGB-based 3D hand pose estimation is n is crucial for a wide range of augmented reality and human-computer interaction applications. However, this task is highly challenging due to occlusion, scale, and depth ambiguities. Most existing methods mainly focus on estimating a scale-normalized root-relative 3D pose from the cropped hand image. In this work, we propose a multi-stage GCN-based (Graph Convolutional Networks) approach to estimate the absolute 3D hand pose from a single RGB image. We exploit both the cropped hand and the global scene image, which provides clues about the hand scale and location in the camera space. Our network consists of three main stages: 2D key-points, 3D root-relative, and 3D absolute pose estimation. To achieve better performance, we propose a new loss function. It separates the extracted image features based on 3D joint locations to simplify the regression task. Extensive experiments on five public datasets show that our efficient model estimates accurate global 3D hand poses and performs favorably against several baselines and state-of-the-art methods. Also, we validate the proposed approach on a newly created dataset. It contains RGB hand images with accurate 3D pose annotations and high lighting and poses variations.
The Internet of Things (IoT) devices have limited resources and are vulnerable to attacks, so optimizing their network topology to resist random failures and malicious attacks has become a key issue. The scale-free network model has strong resistance to random attacks, but it is very vulnerable to malicious attacks. The existing studies mostly adopt heuristic algorithms to optimize the ability of scale-free networks to resist malicious attacks, but their high computational cost cannot meet the timeliness requirements of the real IoT. Therefore, this paper proposes an intelligent topology robustness optimization model based on a graph convolutional network (ROGCN). The model extracts the onion-like structural features of the highly robust network topology from the data set through supervised learning, and on this basis, different search strategies are designed to meet the needs of different IoT scenarios. The extensive experimental results demonstrate that ROGCN can more effectively improve the robustness of scale-free IoT networks against malicious attacks compared to two existing heuristic algorithms, with a lower computational cost.
Spectral unmixing is an effective tool to mine information at the subpixel level from complex hyperspectral images. To consider the spatially correlated materials distributions in the scene, many algorithms unmix the data in a spatial-spectral fashion; however, existing models are usually unable to model spectral variability simultaneously. In this article, we present a variational autoencoder-based deep generative model for spatial-spectral unmixing (DGMSSU) with endmember variability, by linking the generated endmembers to the probability distributions of endmember bundles extracted from the hyperspectral imagery via discriminators. Besides the convolutional autoencoder-like architecture that can only model the spatial information within the regular patch inputs, DGMSSU is able to alternatively choose graph convolutional networks or self-attention mechanism modules to handle the irregular but more flexible data-superpixel. Experimental results on a simulated dataset, as well as two well-known real hyperspectral images, show the superiority of our proposed approach in comparison with other state-of-the-art spatial-spectral unmixing methods. Compared to the conventional unmixing methods that consider the endmember variability, our proposed model generates more accurate endmembers on each subimage by the adversarial training process. The codes of this work will be available at https://github.com/shuaikaishi/DGMSSU for the sake of reproducibility.
Capturing global contextual representations in remote sensing images by exploiting long-range pixel-pixel dependencies has been shown to improve segmentation performance. However, how to do this efficiently is an open question as current approaches of utilizing attention schemes, or very deep models to increase the field of view, increases complexity and memory consumption. Inspired by recent work on graph neural networks, we propose the Self-Constructing Graph (SCG) module that learns a long-range dependency graph directly from the image data and uses it to capture global contextual information efficiently to improve semantic segmentation. The SCG module provides a high degree of flexibility for constructing segmentation networks that seamlessly make use of the benefits of variants of graph neural networks (GNN) and convolutional neural networks (CNN). Our SCG-GCN model, a variant of SCG-Net built upon graph convolutional networks (GCN), performs semantic segmentation in an end-to-end manner with competitive performance on the publicly available ISPRS Potsdam and Vaihingen datasets, achieving a mean F1-scores of 92.0% and 89.8%, respectively. We conclude that the SCG-Net is an attractive architecture for semantic segmentation of remote sensing images since it achieves competitive performance with much fewer parameters and lower computational cost compared to related models based on convolutional neural networks.
A protein complex is a group of associated polypeptide chains which plays essential roles in the biological process. Given a graph representing protein-protein interactions (PPI) network, it is critical but non-trivial to detect protein complexes, the subsets of proteins that are tightly coupled, from it. Network embedding is a technique to learn low-dimensional representations of vertices in networks. It has been proved quite useful for community detection in social networks in recent years. However, unlike social networks, PPI network does not contain rich metadata, so that existing network embedding methods cannot fully capture the network structure of PPI to improve the effect of protein complexes detection significantly. We propose a semi-supervised network embedding model by adopting graph convolutional networks to detect densely connected subgraphs effectively. We compare the performance of our model with state-of-the-art approaches on three popular PPI networks with various data sizes and densities. The experimental results show that our approach significantly outperforms other approaches on all three PPI networks.
Falls are a growing issue in society and has become a hot topic in the healthcare domain. Falls are more likely to occur to due to age or health problems such as cardiovascular issues and muscle weakness. In this work we focus on fall detection. The aftereffects of falls often lead to the use of prescription pain medications. We are motivated to help prevent suicide attempts by overdose in the Canadian correctional services. Most previous studies were based on hand-crafted features which limit the robustness and generality of the system. We therefore propose a general vision-based system, using Spatial Temporal Graph Convolutional Networks (ST-GCN). This system has proven its efficiency and robustness in the action recognition domain. Contrary to previous works, this model can be applied directly to new data without the need to retrain the model while offering good accuracy. Additionally, with the help of transfer learning we can solve the insufficient data problem. By using three public datasets: the NTU RGB-D dataset, the TST Fall detection dataset v2 and the Fallfree dataset to validate our method, we achieved a 100% accuracy, surpassing the state-of-the-art.
The objective imbalance between the taxi supply and demand exists in various areas of the city. Accurately predicting this imbalance helps taxi companies with dispatching, thereby increasing their profits and meeting the travel needs of residents. The application of Graph Convolutional Networks (GCNs) in traffic forecasting has inspired the development of a spatial-temporal model for grid-level prediction of the taxi demand-supply imbalance. However, spatial-temporal GCN prediction models conventionally capture only static inter-grid correlation features. This research aims to address the dynamic influences caused by taxi mobility and the variations of other transportation modes on the demand-supply dynamics between grids. To achieve this, we employ taxi trajectory data and develop a model that incorporates dynamic GCN and Gated Recurrent Units (GRUs) to predict grid-level imbalances. This model captures the dynamic inter-grid influences between neighboring grids in the spatial dimension. It also identifies trends and periodic changes in the temporal dimension. The validation of this model, using taxi trajectory data from Shenzhen city, indicates superior performance compared to classical time-series models and spatial-temporal GCN models. An ablation study is conducted to analyze the impact of various factors on the predictive accuracy. This study demonstrates the precision and applicability of the proposed model.
Driver activity engagement while driving plays a vital role that leads to negative outcomes of driving safety. To reduce traffic accidents and ensure driving safety, real-time driver activity recognition architecture is proposed in this study. Specifically, a total of eight kinds of common driving-related activities are identified, which include the normal driving, left or right checking, texting, answering the phone, using media, drinking, and picking up objects. Raw experiment videos are collected via onboard monocular cameras, which are used for the upper body skeleton information extraction of the driver. Then, the graph convolutional networks (GCN) are constructed for spatial structure feature reasoning in a single frame, which is consecutively followed by long short-term memory (LSTM) networks for temporal motion feature learning within the sequence. Moreover, the attention mechanism is further utilised to emphasise the keyframes to select discriminative sequential information. Finally, a large-scale driver activity dataset, consisting of both naturalistic driving data and simulative driving data, is collected for model training and evaluations. Experimental results show that the general recall ratio of those eight driving-related activities reaches up to 88.8% and the real-time recognition efficiency can reach up to 24 fps, which would satisfy the real-time requirements of engineering applications.
The removal of refractory contaminants such as tetracycline (TC) antibiotics from wastewater has drawn a lot of interest. Semi-ionic mesoporous F-doped g-C3N4(e.g. GCN-F0.50) photocatalysts were successfully fabricated with different doping amounts. The GCN-F0.50 shows the highest TC removal performance under visible light irradiation (lambda > 420 nm), which is 99.8% (0.0207 min(-1)) of removal in 180 min. The highest COD removal of TC was 75.9% using GCN-F0.50 photocatalyst. This is because the semi-ionic nature of the C-F bond has high polarity, which is capable of promoting good charge separation and migration. It was found that GCN-F0.50 provides a high mesoporous surface area (79.66 m(2)/g) to allow more TC pollutants to be photodegraded on the surface. In addition, the optical absorption is enhanced due to bandgap narrowing (2.55 eV). This work provides a highly efficient and good reusability photocatalyst for TC removal based on F-doped g-C3N4. (c) 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
Multi-hop machine reading comprehension is a challenging task in natural language processing as it requires more reasoning ability across multiple documents. Spectral models based on graph convolutional networks have shown good inferring abilities and lead to competitive results. However, the analysis and reasoning of some are inconsistent with those of humans. Inspired by the concept of grandmother cells in cognitive neuroscience, we propose a heterogeneous graph attention network model named ClueReader to imitate the grandmother cell concept. The model is designed to assemble the semantic features in multi-level representations and automatically concentrate or alleviate information for reasoning through the attention mechanism. The name ClueReader is a metaphor for the pattern of the model: it regards the subjects of queries as the starting points of clues, takes the reasoning entities as bridge points, considers the latent candidate entities as grandmother cells, and the clues end up in candidate entities. The proposed model enables the visualization of the reasoning graph, making it possible to analyze the importance of edges connecting entities and the selectivity in the mention and candidate nodes, which is easier to comprehend empirically. Evaluations on the open-domain multi-hop reading dataset WikiHop and drug-drug interaction dataset MedHop proved the validity of ClueReader and showed the feasibility of its application of the model in the molecular biology domain.
The application of graph convolutional networks (GCNs) to hyperspectral image (HSI) classification is a heavily researched topic. However, GCNs are based on spectral filters, which are computationally costly and fail to suppress noise effectively. In addition, the current GCN-based methods are prone to oversmoothing (the representation of each node tends to be congruent) problems. To circumvent these problems, a novel semi-supervised locality-preserving dense graph neural network (GNN) with autoregressive moving average (ARMA) filters and context-aware learning (DARMA-CAL) is proposed for HSI classification. In this work, we introduce the ARMA filter instead of a spectral filter to apply to GNNs. The ARMA filter can better capture the global graph structure and is more robust to noise. More importantly, the ARMA filter can simplify calculations compared with the spectral filter. In addition, we show that the ARMA filter can be approximated by a recursive method. Furthermore, we propose a dense structure, which not only implements the ARMA filter in the structure, but is also locality-preserving. Finally, we design a layerwise context-aware learning mechanism to extract the useful local information generated by each layer of the dense ARMA network. The experimental results on three real HSI datasets show that DARMA-CAL outperforms the compared state-of-the-art methods.
Nowadays, graph convolutional networks (GCNs) are getting more attention in hyperspectral image classification (HSIC), and various algorithms based on GCNs have been proposed. However, because of hyperspectral images' (HSIs) complex spatial texture information, the long-range graph convolution (GConv) and short-range GConv may cause inaccurate or oversmoothed feature extraction of some nodes. Thus, a multiscale short- and long range graph convolutional network (MSLGCN) is proposed for HSIC. First, MSLGCN not only extracts spatial information of ground objects at different scales but also simultaneously captures global and local spectral features, which preserves objects' fine boundaries. Then, the rich multiscale information is complementary, enabling the MSLGCN to take full advantage of texture structures of varying sizes. In addition, a method to determine the superpixel scale by the intrinsic properties of HSIs is proposed to ensure that the segmentation boundary depicts the texture structure of the object accurately. Finally, the short-long graph convolution (SLGConv) is designed to fuse the advantages of global and local features, enabling the MSLGCN to extract accurate spatial-spectral features of nodes at any location. Experiments on three HSI datasets indicate that the MSLGCN can obtain better classification performance when compared with the other 11 state-of-the-art methods.
Next point-of-interest (POI) recommendation is important for users to help them find interesting venues to visit in the near future. Most previous work on this subject has incorporated geographical and temporal information into sequential patterns to predict next POIs. However, few studies have considered the influence of important factors such as users' reviews or POIs' popularity on sequential patterns, nor distinguished between factors of different importance for prediction. In addition, the relationships between entities in location-based social networks have been ignored in most previous work. To overcome these limitations, we proposed a model called MGCAN to flexibly incorporate various influential factors into different sequential patterns for next POI recommendation. We first used multiple graph convolutional networks and independent attention networks to model multiple sequential patterns with different influential factors. Furthermore, we designed corresponding modules to simultaneously capture general preferences of users and determine the impact of different influential factors on each user. Finally, we used multiple sequential patterns and the general preferences of users in the prediction module to predict the next POI. Experimental results on two datasets showed that the MGCAN model achieved better recommendation performance than benchmark models.
Basketball is a popular sport worldwide, and many researchers have utilized various machine learning models to predict the outcome of basketball games. However, prior research has primarily focused on traditional machine learning models. Furthermore, models that rely on vector inputs tend to ignore the intricate interactions between teams and the spatial structure of the league. Therefore, this study aimed to apply graph neural networks to basketball game outcome prediction, by transforming structured data into unstructured graphs, to represent the interactions between teams in the 2012-2018 NBA season dataset. Initially, the study used a homogeneous network and undirected graph to build a team representation graph. The constructed graph was fed into a graph convolutional network, which yielded an average success rate of 66.90% in predicting the outcome of games. To improve the prediction success rate, feature extraction based on the random forest algorithm was combined with the model. The fused model yielded the best results, and the prediction accuracy was improved to 71.54%. Additionally, the study compared the results of the developed model with previous studies and the baseline model. Our proposed method considers the spatial structure of teams and the interaction between teams, resulting in superior performance in basketball game outcome prediction. The results of this study provide valuable insights for basketball performance prediction research.
Graph networks are naturally suitable for modeling multi-channel features of EEG signals. However, the existing study that attempts to utilize graph-based neural networks for EEG-based emotion recognition doesn't take the spatio-temporal redundancy of EEG features and differences in brain topology into account. In this paper, we propose EEG-GCN, a paradigm that adopts spatio-temporal and self-adaptive graph convolutional networks for single and multi-view EEG-based emotion recognition. With spatio-temporal attention mechanism employed, EEG-GCN can adaptively capture significant sequential segments and spatial location information in EEG signals. Meanwhile, a self-adaptive brain network adjacency matrix is designed to quantify the connection strength between the channels, in which way to represent the diverse activation patterns under different emotion scenarios. Additionally, we propose a multi-view EEG-based emotion recognition method, which effectively integrates the diverse features of EEG signals. Extensive experiments conducted on two benchmark datasets SEED and DEAP demonstrate that our proposed method outperforms other representative methods from both single and multiple views.
Pedestrian trajectory prediction is an increasingly important research area in applied autonomous driving and social robotics. Effectively modeling the intricate interactions between pedestrians is paramount for improving trajectory prediction accuracy. However, when using Graph Neural Networks(GNNs) to model these interactions, fixed interactions tend to remain, preventing the graph model from making adaptive adjustments and thus resulting in significant discrepancies between the predicted and true trajectories. In this study, we propose a Dynamic-Evolving Relative Graph Convolutional Network(DERGCN) to predict the future trajectories of pedestrians. The network model captures the dynamically evolving pedestrian interactions and incorporates an evolving mechanism to simulate them. In addition, with a relative temporal encoding strategy employed to improve the dynamics of the graph further, our policy network yielded an improved predictive performance when tested on two challenging datasets.
In traditional recommender systems, we often build models based on a centralized storage of user data, which however will lead to user privacy concerns and risks. In this paper, we study an emerging and important recommendation problem called federated item recommendation (FIR), in which a recommendation model is built with decentralized data of user-item interactions in a privacy-aware manner, i.e., the personal behavior data of each user does not leave the owner. Recently, graph neural network (GNN) has been widely recognized as a state-of-the-art solution for item recommendation with implicit feedback since it is able to model the high-order connectivity between users and items. However, it is very challenging to exploit the high-order connectivity information in a decentralized user-item interaction graph without compromising user privacy. To address that, we propose a GNN-based federated recommendation framework, i.e., privacy-preserving graph convolution network (P-GCN), for the studied problem of FIR. Our P-GCN can leverage the high-order connectivity information like a centralized GCN model such as LightGCN, though it is built using a decentralized user-item graph. To achieve that, we design a novel privacy-preserving graph convolution approach based on secure aggregation and employ item-based user representation to compensate for the performance loss it causes due to the protection of user privacy. Moreover, we improve a group-wise concealing strategy for protecting user privacy. Empirical studies on three datasets show that our PGCN can achieve similar or even better performance comparing with the non-federated (i.e., centralized) counterpart, and outperforms all the existing federated methods for the studied problem.& COPY; 2023 Elsevier B.V. All rights reserved.
Incorporating knowledge graphs in recommendation systems is promising as knowledge graphs can be a side information for recommendation systems to alleviate the sparsity and the cold start problems. However, existing works essentially assume that side information (i.e., knowledge graphs) is completed, which may lead to sub-optimal performance. Meanwhile, semantic hierarchies implied in applications are prevalent, and many existing approaches fail to model this semantic characteristic. Modeling the semantic structure between items in recommendation systems is a crucial challenge. Therefore, it is crucial to solve the incompleteness of knowledge graphs when integrating it into recommendation system as well as to represent the hierarchical structure contained in items. In this paper, we propose Paguridae, a framework that utilizes the item recommendation task to assist link prediction task. A core idea of the Paguridae is that two tasks automatically share the potential features between items and entities. We adopt two main structures to model the hierarchy between items and entities. In order to model the hierarchy in items, we adopt graph convolutional networks as a representation learning method. In order to model the hierarchy in entities, we use Hirec model, which maps entities into the polar coordinate system. Under the framework, users can get better recommendations and knowledge graphs can be completed as these two tasks have a mutual effect. Experiments on two real-world datasets show that the Paguridae can be trained substantially, improving F1-score by 62.51% and precision by 49.31% compared to the state-of-the-art methods.
Skeleton-based action recognition has recently achieved much attention since they can robustly convey the action information. Recently, many studies have shown that graph convolutional networks (GCNs), which generalize CNNs to more generic non-Euclidean structures, are more exactly extracts spatial feature. Nevertheless, how to effectively extract global temporal features is still a challenge. In this work, firstly, a unique feature named temporal action graph is designed. It first attempts to express timing relationship with the form of graph. Secondly, temporal adaptive graph convolution structure (T-AGCN) are proposed. Through generating global adjacency matrix for temporal action graph, it can flexibly extract global temporal features in temporal dynamics. Thirdly, we further propose a novel model named spatial-temporal adaptive graph convolutional network (ST-AGCN) for skeletons-based action recognition to extract spatial-temporal feature and improve action recognition accuracy. ST-AGCN combines T-AGCN with spatial graph convolution to make up for the shortage of T-AGCN for spatial structure. Besides, ST-AGCN uses dual features to form a two-stream network which is able to further improve action recognition accuracy for hard-to-recognition sample. Finally, comparsive experiments on the two skeleton-based action recognition datasets, NTU-RGBD and SBU, demonstrate that T-AGCN and temporal action graph can effective explore global temporal information and ST-AGCN achieves certain improvement of recognition accuracy on both datasets.
An enhanced label propagation (LP) method called GraphHop was proposed recently. It outperforms graph convolutional networks (GCNs) in the semi-supervised node classification task on various networks. Although the performance of GraphHop was explained intuitively with joint node attribute and label signal smoothening, its rigorous mathematical treatment is lacking. In this paper, we propose a label efficient regularization and propagation (LERP) framework for graph node classification, and present an alternate optimization procedure for its solution. Furthermore, we show that GraphHop only offers an approximate solution to this framework and has two drawbacks. First, it includes all nodes in the classifier training without taking the reliability of pseudo-labeled nodes into account in the label update step. Second, it provides a rough approximation to the optimum of a subproblem in the label aggregation step. Based on the LERP framework, we propose a new method, named the LERP method, to solve these two shortcomings. LERP determines reliable pseudo-labels adaptively during the alternate optimization and provides a better approximation to the optimum with computational efficiency. Theoretical convergence of LERP is guaranteed. Extensive experiments are conducted to demonstrate the effectiveness and efficiency of LERP. That is, LERP outperforms all benchmarking methods, including GraphHop, consistently on five common test datasets, two large-scale networks, and an object recognition task at extremely low label rates (i.e., 1, 2, 4, 8, 16, and 20 labeled samples per class).
Image representation is a fundamental task in computer vision. However, most of the existing approaches for image representation ignore the relations between images and consider each input image independently. Intuitively, relations between images can help to understand the images and maintain model consistency over related images, leading to better explainability. In this paper, we consider modeling the image-level relations to generate more informative image representations, and propose ImageGCN, an end-to-end graph convolutional network framework for inductive multi-relational image modeling. We apply ImageGCN to chest X-ray images where rich relational information is available for disease identification. Unlike previous image representation models, ImageGCN learns the representation of an image using both its original pixel features and its relationship with other images. Besides learning informative representations for images, ImageGCN can also be used for object detection in a weakly supervised manner. The experimental results on 3 open-source x-ray datasets, ChestX-ray14, CheXpert and MIMIC-CXR demonstrate that ImageGCN can outperform respective baselines in both disease identification and localization tasks and can achieve comparable and often better results than the state-of-the-art methods.
This work proposes the use of I-N - A (I-N: identity matrix; A: adjacency matrix), instead of I-N + A, the normalized form of which has intensively been used for the construction of graph convolutional networks (GCNs), in deep-learning chemistry. The performance of the GCN model with D-1/2(I-N - A)D-1/2 in its convolution step is at least on a par with the vanilla GCN that uses (D) over tilde (-1/2)(I-N + A)(D) over tilde (-1/2) ((D) over tilde: degree matrix of I-N + A) in various chemistry datasets, such as FreeSolv, ESOL, lipophilicity, and blood-brain barrier penetration datasets. It could be seen that the use of I-N - A might be more chemically intuitive than the use of I-N + A, potentially embracing the information on bond properties, such as dipole moment, and functional groups in a molecule. This work suggests unavoidable necessity of tackling molecular-representation problems in deep-learning chemistry from unprecedented angles of view for advanced development and construction of chemically intuitive deep-learning models.
Graph convolutional networks (GCNs) have shown great potential in recommender systems. GCN models contain multiple layers of graph convolutions to exploit signals from higher-order neighbors. In each graph convolution, the embedding of a user or item is influenced by its directly connected neighbors. Some of the main problems with this approach are as follows. First, too many graph convolutional layers make different users or items have similar embeddings. Second, the obtained interaction data have some unfavorable characteristics, such as the sparsity of the data, the noise inside the data, and the distribution skewness of the data, that may impair the model's performance. This paper proposes an interest-aware contrastive-learning-based GCN (IC-GCN) model. IC-GCN applies an interest-aware mechanism, divides users into different subgraphs according to their interests, and performs multilayer graph convolution on the subgraphs, where all collaborative signals received from multi-hop neighbors are positive. Furthermore, IC-GCN takes the contrastive learning task as an auxiliary task, where the interest-aware encoder receives two modified graphs generated by applying the node dropout operator on the full interaction graph. These two graphs generate two sets of embeddings as two additional views of the nodes. The contrastive learning loss function compares these two sets of embeddings. Extensive experiments are conducted to demonstrate the effectiveness of our model.
With the deterioration of the transportation ecosystem and traffic congestion, traffic graph representations become more complex and lack intelligibility. The deep learning method provides a new way for traffic prediction by mining the spatiotemporal relations of historical states in traffic network. Recurrent neural networks based on gate control can avoid the gradient vanishing and graph convolutional networks provide theoretical support for spatial feature extraction of traffic graph. However, in the prediction of traffic evolution behaviors, the statuses of units and groups distributed in the traffic network have strong and continuous spatiotemporal correlations. Modeling only based on the temporal or spatial perspective usually lacks comprehensiveness and semantic relevance which results in poor prediction performance. In this paper, we propose a spatiotemporal hierarchical propagation graph convolutional network(SHPGCN) to get the whole spatiotemporal evolution features of traffic graph, which can be used to predict the propagation effects and state changes of traffic flow. Considered the inadequacy of graph convolution in the learning of hierarchical features, we construct a low-dimensional propagation graph representation that projects complex node relationships into first-order neighborhoods to capture dynamic changes at different spatial and temporal scales. The SHPGCN uses graph convolution to encode the traffic propagation features and embeds them into a bidirectional recurrent sequence for traffic prediction. The experiment results show that SHPGCN can provide good prediction accuracy and robustness for the traffic evolution behaviors.
Graph convolutional networks (GCNs) and graph neural networks (GNNs) have demonstrated convincing performance on many tasks by learning the intrinsic structure of the data. However, it is still valuable and challenging to consider the complex and complete correlations of objects, i.e., high-order manifold structures, for representation learning. In this paper, we present a novel representation learning method that utilizes the optimized high-order manifold of the data for classification tasks of nonstructural data and graph-structure data. In the method, we fully explore the complicated relationship of samples by highlighting the high-order manifold information in a hypergraph. Specifically, we incorporate high-order manifold information by graph p-Laplacian into a hypergraph and propose p-Laplacian-based hypergraph neural networks (pLapHGNN) to significantly learn hidden layer representations that encode both the high-order structure of data and the high-order manifold geometrical information. Confronting the difficulties of obtaining optimized high-order manifolds of the data, we propose an effective approximate approach by graph p-Laplacian representing the relationship of hyperedges in the hypergraph. Furthermore, we study the weights of hyperedges in a hypergraph with high-order manifold information. Experiments on the ModelNet40 dataset and NTU dataset demonstrate that the proposed method is more effective than the other popular methods for 3D shape recognition. Extensive experiments on other visual classification tasks and citation networks also show the superiority of our proposed method for representation learning.
Dialogue state tracking (DST) is a significant part of prevalent task-oriented dialogue systems, which monitor the user's goals based on current and previous dialogues for effective dialogue management. However, most existing approaches train DST on a single domain, ignoring the information across domains, and thus relevant slots in each domain must learn to cooperate. This paper deals this challenge by introducing a multi-view graph convolution and multi-agent reinforcement learning (MGCRL) method to help each domain-specific slot to learn to cooperate. Specifically, first, a multi-view graph is presented to provide more related information to transfer structured features among domain-specific slots across various domains. Compared with a single-view graph, multi-view has better complementarity, incorporating additional graphs for learning multiple types of association, thus improving the cross-domain information-sharing capability of DST models. On this basis, a multi-agent reinforcement learning method is presented to train DST models. Compared to current reinforcement learning methods used in DST models, the proposed multi-agent reinforcement learning utilizing multi-view graph convolutional networks allows each agent to learn to cooperate in multi-agent environments. Experimental results on the widely-used datasets MultiWOZ (Multi-Domain Wizard-of-Oz) 2.0/2.1 demonstrate that the proposed MGCRL method achieves a higher joint goal accuracy than the existing state-of-the-art DST models.
Identifying cancer driver genes plays a curial role in the development of precision oncology and cancer therapeutics. Although a plethora of methods have been developed to tackle this problem, the complex cancer mechanisms and intricate interactions between genes still make the identification of cancer driver genes challenging. In this work, we propose a novel machine learning method of heterophilic graph diffusion convolutional networks (called HGDCs) to boost cancer-driver gene identification. Specifically, HGDC first introduces graph diffusion to generate an auxiliary network for capturing the structurally similar nodes in a biomolecular network. Then, HGDC designs an improved message aggregation and propagation scheme to adapt to the heterophilic setting of biomolecular networks, alleviating the problem of driver gene features being smoothed by its neighboring dissimilar genes. Finally, HGDC uses a layer-wise attention classifier to predict the probability of one gene being a cancer driver gene. In the comparison experiments with other existing state-of-the-art methods, our HGDC achieves outstanding performance in identifying cancer driver genes. The experimental results demonstrate that HGDC not only effectively identifies well-known driver genes on different networks but also novel candidate cancer genes. Moreover, HGDC can effectively prioritize cancer driver genes for individual patients. Particularly, HGDC can identify patient-specific additional driver genes, which work together with the well-known driver genes to cooperatively promote tumorigenesis.
Traditional recommendation systems usually use single user-item interaction information, which ignore the multiple relationships that exist for other interactions (e.g., likes, clicks). Multi-behavioral recommendation models compensate for the shortcomings of traditional models. The existing multi-behavior recommendation models focus on obtaining behavioral information by distinguishing the interaction differences of multiple user behaviors but ignore the common preferences of items related to user different interactions. In this paper, we propose a Multi-Behavior Heterogeneous Contrastive learning Recommendation (MBHCR) model. Specifically, MBHCR stresses the information fusion between different interaction behaviors and differences in the behavior view. Firstly, we design a unified heterogeneous graph based on the complexity of user multi-behavioral interaction information to distinguish behavioral differences while preserving their complete semantic information. Secondly, we propose a multi-behavior relational aggregator component to model the unified heterogeneous graph only once to capture the potential common representations of users and their different interactions and to mitigate user sparsity. Thirdly, we also design a behavior comparison learning enhancer to complement the interaction differences between the user's target behavior and auxiliary behaviors on the behavior view and extract valid information. Experiments were conducted on two real-world datasets to demonstrate the validity of MBHCR and designed ablation experiments to verify the contribution of model components.
Nowadays, individuals spend significant time on online social networks and microblogging websites, consuming news and expressing their opinions and viewpoints on various topics. It is an excellent source of data for various data mining applications, such as sentiment analysis. Mining this type of data presents several challenges, including the posts' short length and informal language. On the other hand, microblog posts contain a high degree of interdependence, which can help to improve sentiment classification based on text. This data can be represented as a graph, with nodes representing posts and edges representing the various relationships between them. By using recently developed deep learning models for graph structures, this approach enables efficient sentiment analysis of microblog posts. This paper utilizes graphs to represent microblog posts and their various relationships, such as user, friendship, hashtag, sentimental similarity, textual similarity, and common friends. It then employs graph neural networks to perform context-aware sentiment analysis. To make use of the knowledge contained in multiple graphs, we propose a stacking model that simultaneously employs multiple graph types. The findings demonstrate the relevance of sociological theories to the analysis of social media. Experimental results on HCR (a real-world Twitter sentiment analysis dataset), indicate that the proposed approach outperforms baselines and state-of-the-art models.
The main core purpose of artificial emotional intelligence is to recognize human emotions. Technologies such as facial, semantic, or brainwave recognition applications have been widely proposed. However, the abovementioned recognition techniques for emotional features require a large number of training samples to obtain high accuracy. Human behaviour pattern can be trained and recognized by the continuous movement of the Spatial Temporal Graph Convolution Network (ST-GCN). However, this technology does not distinguish between the speed of delicate emotions, and the speed of human behaviour and delicate changes of emotions cannot be effectively distinguished. This research paper proposes Spatial Temporal Variation Convolutional Network training for human emotion recognition, using skeleton detection technology to calculate the degree of skeleton point change between consecutive actions and using the nearest neighbour algorithm to classify speed levels and train the ST-GCN recognition model to obtain the emotional state. Application of the speed change recognition ability of the Spatial Temporal Variation Graph Convolution Network (STV-GCN) to artificial emotional intelligence calculation makes it possible to efficiently recognize the delicate actions of happy, sad, fear, and angry in human behaviour. The STV-GCN technology proposed in this paper is compared with ST-GCN and can effectively improve the recognition accuracy by more than 50%.
In response to the problem that current multi-city multi-pollutant prediction methods based on one-dimensional undirected graph neural network models cannot accurately reflect the two-dimensional spatial correlations and directedness, this study proposes a four-dimensional directed graph model that can capture the two-dimensional spatial directed information and node correlation information related to multiple factors, as well as extract temporal correlation information at different times. Firstly, A four-dimensional directed GCN model with directed information graph in two-dimensional space was established based on the geographical location of the city. Secondly, Spectral decomposition and tensor operations were then applied to the two-dimensional directed information graph to obtain the graph Fourier coefficients and graph Fourier basis. Thirdly, the graph filter of the four-dimensional directed GCN model was further improved and optimized. Finally, an LSTM network architecture was introduced to construct the four-dimensional directed GCN-LSTM model for synchronous extraction of spatio-temporal information and prediction of atmospheric pollutant concentrations. The study uses the 2020 atmospheric six-parameter data of the Taihu Lake city cluster and applies canonical correlation analysis to confirm the data's temporal, spatial, and multi-factor correlations. Through experimentation, it is verified that the proposed 4D-DGCN-LSTM model achieves a MAE reduction of 1.12%, 4.91%, 5.62%, and 11.67% compared with the 4D-DGCN, GCN-LSTM, GCN, and LSTM models, respectively, indicating the good performance of the 4D-DGCN-LSTM model in predicting multiple types of atmospheric pollutants in various cities.
Computational fluid dynamics (CFD) plays a critical role in many scientific and engineering applications, with aerodynamic design optimization being a primary area of interest. Recently, there has been much interest in using artificial intelligence approaches to accelerate this process. One promising method is the graph convolutional neural network (GCN), a deep learning method based on artificial neural networks (ANNs). In this paper, we propose a novel GCN-based aerodynamic design optimization acceleration framework, GCN-based aerodynamic design optimization acceleration framework. The framework significantly improves processing efficiency by optimizing data flow and data representation. We also introduce a network model called GCN4CFD that uses the GCF framework to create a compact data representation of the flow field and an encoder-decoder structure to extract features. This approach enables the model to learn underlying physical laws in a space-time efficient manner. We then evaluate the proposed method on an airfoil aerodynamic design optimization task and show that GCN4CFD provides a significant speedup compared to traditional CFD solvers while maintaining accuracy. Our experimental results demonstrate the robustness of the proposed framework and network model, achieving a speedup average of 3.0 x.
In some complex labor production and human-machine interactions, such as subway driving, to ensure both the efficient and rapid completion of work and the personal safety of staff and the integrity of operating equipment, the level of mental workload (MW) of operators is monitored at all times. In existing machine learning-based MW classification methods, the association information between neurons in different regions is almost not considered. To solve the above problem, a graph convolution network based on the squeeze-and-excitation (SE) block is proposed. For a raw electroencephalogram (EEG) signal, the principal component analysis (PCA) dimensionality reduction operation is carried out. After that, combined with the spatial distribution between brain electrodes, the dimensionality reduction data can be converted to graph structure data, carrying association information between neurons in different regions. In addition, we use graph convolution neural network (GCN) modified by SE residual to obtain final classification results. Here, to adaptively recalibrate channel-wise feature responses by explicitly modelling interdependencies between channels, the SE block is introduced. The residual connection can ease the training of networks. To discuss the performance of the proposed method, we carry out some experiments using the raw EEG signals of 10 healthy subjects, which are collected using the MATB-II platform based on multi-task aerial context manipulation. From the experiment results, the structural reasonableness and the performance superiority of the proposed method are verified. In short, the proposed GCN modified by the SE residual method is a workable plan of mental workload classification.
The radiation of adjacent field sources has a specific spatial correlation. In order to suppress electromagnetic disturbance and improve the electromagnetic compatibility of secondary equipment, the electric field's spatial coupling characteristics and distribution law should be mastered. Therefore, a method for predicting the spatial electric field generated by substation switching operation based on the Atomic Orbital Search-Graph Convolution Network- Long and Short-Term Memory (AOS-GCN-LSTM) model is presented to deal with this problem. First, the GCN is used to construct graph data according to node characteristics and topology information. The feature selection uses the Maximum Information Coefficient (MIC) to extract the spatial correlation of the adjacent field source radiation. At the same time, the LSTM is used to capture the temporal correlation characteristics of different position field strengths in space. Then, the AOS is used to optimize the model with a hyperparameter. In addition, the simulation data of the full-wave simulation model of the spatial electric field generated by switch operation in a 220 kV GIS substation is an example of verification. The results show that the prediction error of the proposed method is below 3%, and it has strong adaptability to the application environment and good prediction performance.
The possibility of using hydrogen peroxide (H2O2) as a chemical oxidizer or as a green liquid fuel to produce electricity has encouraged both the scientific and industrial communities to investigate green technologies aimed at the sustainability of the production process. In particular, the light-induced synthesis of H2O2 from water and oxygen has attracted significant attention using optical semiconductors.An exfoliated metal-free graphitic carbon nitride material (GCN-T) was prepared and tested for the photocatalytic production of H2O2 using five saccharides (arabinose, cellobiose, fructose, glucose, and sorbitol) as sacrificial electron donors. The results showed that the scavenging efficiency of the photogenerated holes rapidly increases with the number of -OH groups in the molecular structure of these sacrificial agents. Among the polyhydroxy compounds tested, the highest concentration of H2O2 was achieved using cellobiose.To develop a technological approach for H2O2 production, the GCN-T photocatalyst was immobilized on a 3D printed structure (GCN-T/3D structure), which showed high stability with both ultrapure water and seawater after several reusability runs. This innovative photocatalytic structure enables remarkable efficiency for H2O2 production, with an apparent quantum efficiency (AQE) of 17% at 412 nm radiation, compared to 12% obtained with GCN-T in suspension.
For a long time, the problems of cold start and sparse data have always been the key problems to be solved by the recommendation system. Researchers usually use auxiliary information to deal with the aforementioned problems, thereby achieving the purpose of enhancing the recommendation effect. For example, the multitask feature learning framework (MKR) uses knowledge graphs as auxiliary information to enhance recommendations. However, the MKR algorithm has the problem of insufficient semantic information representation which affect the recommendation results. Thus, a multitask recommendation algorithm based on DeepFM and graph convolutional network (DeepFM_GCN) is proposed. The graph convolution network is used to deeply mine auxiliary entity information in the knowledge graph to supplement the sparse item semantics information in the recommendation task. Through the method of cross compression unit combined with Deep Neural Network to achieve feature sharing items and entities which to make up for the impact of insufficient feature representation. Then the DeepFM_GCN model utilizes DeepFM to deeply mine the interaction feature of users and items to avoid inaccurate items recommended to users. From the analysis of the experimental results, the DeepFM_GCN model can more fully explore user and item features, accordingly avoiding semantic ambiguity and improving prediction accuracy.
The use of heterojunctions with different semiconductors has shown to be an important strategy to increase the efficiency of heterogeneous photocatalytic processes. In this regard, heterojunctions consisting of ZnO/g-C3N4 (x-Zn/gCN) and ZnFe2O4/g-C3N4 (x-ZF/gCN) were synthesized in different mass proportions of g-C3N4 (x = 10, 50 and 80%) through the following simple methods combination: mixture, sonication and thermal treatment. Ob-servations from X-ray diffractometry (XRD), Fourier-transform infrared spectra (FTIR) and field emission scan-ning electron microscope (FESEM) analyses confirmed that the materials were successfully formed. The g-C3N4 incorporation was important in the textural and optical properties modification of the heterojunctions produced. In addition, in the photoluminescence spectroscopy (PL), it was possible to observe g-C3N4 influence in the 50-Zn/gCN emission profile changing, reducing the direct recombination rate of the photogenerated charges due to a probable Z-scheme mechanism. This catalyst demonstrated greater efficiency of photocatalytic degradation when compared to the remaining materials, both for cefazolin (CFZ) and reactive black 5 (RB5), reaching 78% and 95%, respectively, after 120 min. Moreover, it also revealed good photostability after five successive cycles. 50-Zn/gCN heterojunction presents a promising character in photocatalytic reactions mediated by solar light for contaminants degradation such as pharmaceutical products and dyes and can be used as an alternative to minimize the effects of water pollution caused during the COVID-19 pandemic.
As an early stage of Alzheimer's disease (AD), mild cognitive impairment (MCI) is able to be detected by analyzing the brain connectivity networks. For this reason, we devise a new framework via multi-scale enhanced graph convolutional network (MSE-GCN) for MCI detection, which integrates the structural and functional information from the diffusion tensor imaging (DTI) and resting-state functional magnetic res-onance imaging (R-fMRI), respectively. Specifically, both information in the brain connective networks is first integrated based on the local weighted clustering coefficients (LWCC), which is concatenated as the feature vector for representing a population graph's vertice. Simultaneously, the gender and age infor-mation in each subject are integrated with the structural and functional features to construct a sparse graph. Then, various parallel graph convolutional network (GCN) layers with multiple inputs are designed from the embedding from random walk embeddings in the GCN to identify the essential MCI graph in-formation. Finally, all GCN layers' outputs are concatenated via the fully connection layer to perform dis-ease detection. The experimental results on the public Alzheimer's Disease Neuroimaging Initiative (ADNI) database show that our method is promising to detect MCI and superior to other competing algorithms, with a mean classification accuracy of 90.39% in the detection tasks. (c) 2022 Elsevier Ltd. All rights reserved.
Industrial Internet-of-Things (IIoT) networks, as the application of Internet-of-Things (IoT) networks to modern industry, are growing rapidly with the digital transformation accelerates. Mobile sensors are widely adopted in monitoring key information of massive IIoT networks in an ad hoc fashion or retrofitting on to an existing infrastructure. Hence, owing to the characteristics of scalability, unstable locations, and highly unstructured, achieving perfect prediction for mobile multisensor is a challenging problem. In this article, a dynamic space-time prediction algorithm combining temporal convolutional network and graph convolutional network (TCN-GCN) is proposed to provide reliable multiple nodes prediction for detection and maintenance in IIoT networks. In particularly, an adaptive learning graph process is exclusively designed according to the dynamic characteristics of mobile sensors. Moreover, the improved dilated time convolution network and dynamic graph convolution network (DGCN) are combined to effectively capture the time dependence and topology information. Furthermore, an advanced loss function is applied to avoid overfitting. Numerical simulations show that the proposed TCN-GCN prediction algorithm exhibits higher effectiveness in accuracy and complexity than convolutional long short-term memory (ConvLSTM), temporal graph convolutional network (T-GCN), and residual graph ConvLSTM (Graph-ResLSTM).
A novel method, Thermally Modified Non-Solvent Induced Phase Separation (T-NIPS) has been developed to fabricate translucent hollow fiber (THF) photocatalytic membrane for membrane's photodegradation efficiency enhancement. The process involves two-step temperature treatment that attacks crystalline property of polyvinylidene fluoride (PVDF). Graphitic carbon nitride in a modified morphological structure (hollow nanofiber) was used as photocatalyst to investigate the effect of translucency on membrane's photo-degradation efficiency. UV-Vis analysis coupled with FTIR highlighted different crystalline phase appearance and membrane's translucency. The membranes showed high translu-cency, ranging from 60.0% to 93.9%, with THF-PVDF/PVP-GCN (2.0) exhibiting the highest. The filtration experiment showed that membrane with GCN photocatalyst had high PWF (1200 L/m2h) and rejection (90%) OPW compared to neat THF-PVDFs. In suspended mode, GCN demonstrated an impressive photodegradation efficiency of 99.98%. When im-mobilized in opaque PVDF membrane, the photodegradation has decreased substantially to 49.40%. However, when immobilized in a translucent PVDF membrane, the photo-degradation efficiency of HN-GCN significantly improved compared to the opaque PVDF membrane, reaching 95%. Translucent membrane was subjected to five cycle regeneration test and showed 90% recovery even after the fifth cycle. The 10% reduction in the recovery was investigated using FESEM analysis revealed that there is a cake layer formation on the membrane surface. Therefore, this study proved that translucency of membrane has significant effect on immobilized photocatalyst's photocatalytic efficiency.(c) 2023 Institution of Chemical Engineers. Published by Elsevier Ltd. All rights reserved.
Heterogeneous photocatalysis is an ideal method for eco-friendly synthesis of value-added chemicals. However, due to the limited penetration depth of photons and inefficient utilization of the catalytic active sites, the scalability of heterogeneous photocatalysis is restrained. Combining heterogeneous photocatalysis and flow system is a promising solution to optimize the light absorption and mass transfer; however, an affordable, practical design of the flow system and the immobilization method of the photocatalyst is still missing. Here, we report a flow system for heterogeneous photocatalytic synthesis of azoxybenzene and its derivatives from reductive coupling of nitrobenzene at a gram-scale using anchored graphitic carbon nitride (gCN) on porous silica (gCN-SiO2). The hydrogen bonds formed between the gCN and the tetramethoxysilane (TMOS) precursor during the dehydrative condensation process prevent unwanted leaching of catalyst, enabling photocatalytic flow synthesis of azoxybenzene with high selectivity, efficiency, and durability. Mechanistic studies reveals that the gCN-SiO2 regulates the photocatalytic reduction kinetics of nitrobenzene by facilitating the generation of nitrosobenzene and N-phenylhydroxylamine intermediates while preventing the formation of unwanted 4-phenylazophenol byproducts, resulting in efficient and selective synthesis of azoxybenzene. Our work provides an alternative path towards large scale heterogeneous photocatalysis.
Parkinson's Disease (PD) is one of the most prevalent neurodegenerative diseases that affects tens of millions of Americans. PD is highly progressive and heterogeneous. Quite a few studies have been conducted in recent years on predictive or disease progression modeling of PD using clinical and biomarkers data. Neuroimaging, as another important information source for neurodegenerative disease, has also arisen considerable interests from the PD community. In this paper, we propose a deep learning method based on Graph Convolutional Networks (GCN) for fusing multiple modalities of brain images in relationship prediction which is useful for distinguishing PD cases from controls. On Parkinson's Progression Markers Initiative (PPMI) cohort, our approach achieved 0.9537±0.0587 AUC, compared with 0.6443±0.0223 AUC achieved by traditional approaches such as PCA.
Aspect-level sentiment analysis aims to predict the sentiment polarity toward a specific aspect in a sentence. Most current approaches are based on deep learning and the attention mechanism. However, these models cannot simultaneously include the context semantic information carried by local words and the global syntactic information possibly carried by remote words. In this paper, we propose a local semantic and global syntactic integration scheme, which employs a local focus mechanism over local context words and exploits improved graph convolutional networks over dependency tree to encode global syntactic information. Moreover, multi-head attention is used to capture both the semantic information and also the interactive information between semantics and syntactic features. Experimental results on five datasets show the effectiveness of our model over a series of latest models.
We present an innovative hyperspectral image (HSI) classification method addressing challenges posed by closely spaced wavelength bands. Our approach combines 3D-2D convolutional neural networks (CNNs) with multi-branch feature fusion for improved spectral-spatial feature extraction. Using segmented principal component analysis (Seg-PCA), we reduce HSIs' spectral dimensions into global and local intrinsic characteristics. The integration of 3D and 2D CNNs captures joint spectral-spatial features, while a multi-branch network extracts and merges diverse local features along the spectral dimension. Our method outperforms existing approaches, achieving remarkable accuracy of 99.27%, 100%, and 99.99% on Indian Pines, Salinas Scene, and University of Pavia datasets, respectively.
Mental-health-oriented question-answering (MH-QA) aims at retrieving an appropriate response for a question post involving mental health issues, which will be used to assist counsellors to reply to the support seeker. This task is different from the general QA task because many additional criteria such as emotions are involved. In this paper, we propose the Multi-Feature Graph Convolutional Network model (MF-GCN) to integrate not only semantic features, but also mental health related features and context features, to match question posts and responses. Different types of feature are exploited through multiple graph convolutional networks. A new dataset is constructed for MH-QA to evaluate ourmodel. Experimental results showthat our model with mental health features significantly outperforms a wide range of state-of-the-art models without them.
Graphene oxide (GO) has been intensively studied in last decades as a promising delivery nanoplatform. Although it surpasses the pristine graphene in its hydrophilic properties, variability in GO syntheses and chemical composition, its non-specific surface properties and heterogeneity in colloidal stability hamper its commercial application in general. Reliable cytotoxicity investigation of new nanotherapeutics under relevant physiological conditions represents an indispensable first step for their potential clinical translation. In the case of delivery nanoplatforms, the vasculature represents the first encounter after intravenous application. Therefore, an evaluation of interaction with endothelial and immune cells is highly desirable. Here, we performed a first comprehensive safety assessment of emerging graphene derivatives with high potential in biomedical technologies: graphene acid (GA) and cyanographene (GCN). We utilized an easy-to-use co-culture model of matured human umbilical vein endothelial cells (HUVECs) and a human monocyte/macrophage like cell line (THP-1) under dynamic flow conditions. An environment that has not been used yet to evaluate any graphene material. Our results demonstrate that well-defined synthesis/structure of GA and GCN overcome some drawbacks of graphene oxide (GO), the benchmark graphene derivative. Furthermore, applying a system mimicking a simplified blood vessel, both GA and GCN showed excellent biocompatibility without any indication of acute inflammation or dysfunction of endothelium. In summary, GA and GCN display so far all desirable properties to be potentially utilized in drug/gene delivery applications compared to the conventional GO.
Graph convolutional networks (GCNs) have achieved great success on graph-structured data. Many GCNs can be considered low-pass filters for graph signals. In this paper, we propose a more powerful GCN, named BiGCN, that extends to bidirectional filtering. Specifically, we consider the original graph structure information and the latent correlation between features. Thus BiGCN can filter the signals along with both the original graph and a latent feature-connection graph. Compared with most existing GCNs, BiGCN is more robust and has powerful capacities for feature denoising. We perform node classification and link prediction in citation networks and co-purchase networks with three settings: Noise-Rate, Noise-Level, and Structure-Mistakes. Extensive experimental results demonstrate that our model outperforms the state-of-the-art graph neural networks in both clean and artificially noisy data.
Aspect Sentiment Triplet Extraction (ASTE) is a complex and challenging task in Natural Language Processing (NLP). It aims to extract the triplet of aspect term, opinion term, and their associated sentiment polarity, which is a more fine-grained study in Aspect Based Sentiment Analysis. Furthermore, there have been a large number of approaches being proposed to handle this relevant task. However, existing methods for ASTE suffer from powerless interactions between different sources of textual features, and they usually exert an equal impact on each type of feature, which is quite unreasonable while building contextual representation. Therefore, in this paper, we propose a novel Multi-Branch GCN (MBGCN)-based ASTE model to solve this problem. Specifically, our model first generates the enhanced semantic features via the structure-biased BERT, which takes the position of tokens into the transformation of self-attention. Then, a biaffine attention module is utilized to further obtain the specific semantic feature maps. In addition, to enhance the dependency among words in the sentence, four types of linguistic relations are defined, namely part-of-speech combination, syntactic dependency type, tree-based distance, and relative position distance of each word pair, which are further embedded as adjacent matrices. Then, the widely used Graph Convolutional Network (GCN) module is utilized to complete the work of integrating the semantic feature and linguistic feature, which is operated on four types of dependency relations repeatedly. Additionally, an effective refining strategy is employed to detect whether word pairs match or not, which is conducted after the operation of each branch GCN. At last, a shallow interaction layer is designed to achieve the final textual representation by fusing the four branch features with different weights. To validate the effectiveness of MBGCNs, extensive experiments have been conducted on four public and available datasets. Furthermore, the results demonstrate the effectiveness and robustness of MBGCNs, which obviously outperform state-of-the-art approaches.
The noninvasive detection of pancreatic ductal adenocarcinoma (PDAC) remains an immense challenge. Inthis study, we proposed a robust, accurate, and noninvasive classifier, namely Multi-Omics Co-training Graph Convolutional Networks (MOCO-GCN). It achieved high accuracy (0.9 ± 0.06), F1 score (0.9± 0.07), and AUROC (0.89± 0.08), surpassing contemporary approaches. The performance of model was validated on an external cohort of German PDAC patients. Additionally, we discovered that the exposome may impact PDAC development through its complex interplay with gut microbiome by mediation analysis. For example, Fusobacterium hwasookii nucleatum, known for its ability to induce inflammatory responses, may serve as a mediator for the impact of rheumatoid arthritis on PDAC. Overall, our study sheds light on how exposome and microbiome in concert could contribute to PDAC development, and enable PDAC diagnosis with high fidelity and interpretability.
Current soil pollution prediction methods need improvement, especially with regard to accuracy in supplementing missing heavy-metal values in soil, and the accuracy and slow convergence speed of methods for predicting heavy-metal content at unknown points. To reduce costs and improve prediction accuracy, this study used two neural network models (SA-FOA-BP and SE-GCN) to supplement missing heavy-metal values and efficiently predict heavy-metal content in soil. The SA-FOA-BP model combines simulated annealing and fruit fly algorithms to optimize the parameter search method in traditional BP neural networks and improve prediction of missing heavy-metal values in soil. A spatial information fusion graph convolutional network prediction model (SE-GCN) constructs a spatial information encoder that can perceive spatial context information, and embeds it with spatial autocorrelation used for auxiliary learning to predict the heavy-metal content in soil. From the experimental results, the SE-GCN model demonstrates improved performance in terms of evaluation indicators compared with other models. Application analysis of the two improved neural network models was conducted; application scenarios and suitability were analyzed, showing that these models have practical application value for soil pollution prediction.
Graph Convolutional Networks (GCNs) derive inspiration from recent advances in computer vision, by stacking layers of first-order filters followed by a nonlinear activation function to learn entity or graph embeddings. Although GCNs have been shown to boost the performance of many network analysis tasks, they still face tremendous challenges in learning from Heterogeneous Information Networks (HINs), where relations play a decisive role in knowledge reasoning. What's more, there are multiaspect representations of entities in HINs, and a filter learned in one aspect do not necessarily apply to another. We address these challenges by proposing the Aspect-Aware Graph Attention Network (AGAT), a model that extends GCNs with alternative learnable filters to incorporate entity and relational information. Instead of focusing on learning the general entity embeddings, AGAT learns the adaptive entity embeddings based on prediction scenario. Experiments of link prediction and semi-supervised classification verify the effectiveness of our algorithm.
Evaluating the contribution of the tumour microenvironment (TME) in tumour progression has proven a complex challenge due to the intricate interactions within the TME. Multiplexed imaging is an emerging technology that allows concurrent assessment of multiple of these components simultaneously. Here we utilise a highly multiplexed dataset of 61 markers across 746 colorectal tumours to investigate how complex mTOR signalling in different tissue compartments influences patient prognosis. We found that the signalling of mTOR pathway can have heterogeneous activation patterns in tumour and immune compartments which correlate with patient prognosis. Using graph neural networks, we determined the most predictive features of mTOR activity in immune cells and identified relevant cellular subpopulations. We validated our observations using spatial transcriptomics data analysis in an independent patient cohort. Our work provides a framework for studying complex cell signalling and reveals important insights for developing mTOR-based therapies.
Multimodal models have been proven to outperform text-based models on learning semantic word representations. According to psycholinguistic theory, there is a graphical relationship among the modalities of language, and in recent years, the graph convolution network (GCN) has been proven to have substantial advantages in the extraction of non-European spatial features. This inspires us to propose a new multimodal word representation model, namely, GCNW, which uses the graph convolutional network to incorporate the phonetic and syntactic information into the word representation. We use a greedy strategy to update the modality-relation matrix in the GCN, and we train the model through unsupervised learning. We evaluated the proposed model on multiple downstream NLP tasks, and various experimental results demonstrate that the GCNW outperforms strong unimodal baselines and state-of-the-art multimodal models. We make the source code of both models available to encourage reproducible research.
Solving the supply-demand imbalance is the most crucial issue for stable implementation of a public bike-sharing system. This gap can be reduced by increasing the accuracy of demand prediction by considering spatial and temporal properties of bike demand. However, only a few attempts have been made to account for both features simultaneously. Therefore, we propose a prediction framework based on graph convolutional networks. Our framework reflects not only spatial dependencies among stations, but also various temporal patterns over different periods. Additionally, we consider the influence of global variables, such as weather and weekday/weekend to reflect non-station-level changes. We compare our framework to other baseline models using the data from Seoul's bike-sharing system. Results show that our approach has better performance than existing prediction models.
In the recent era, graph neural networks are widely used on vision-to-language tasks and achieved promising results. In particular, graph convolution network (GCN) is capable of capturing spatial and semantic relationships needed for visual question answering (VQA). But, applying GCN on VQA datasets with different subtasks can lead to varying results. Also, the training and testing size, evaluation metrics and hyperparameter used are other factors that affect VQA results. These, factors can be subjected into similar evaluation schemes in order to obtain fair evaluations of GCN based result for VQA. This study proposed a GCN framework for VQA based on fine tune word representation to solve handle reasoning type questions. The framework performance is evaluated using various performance measures. The results obtained from GQA and VQA 2.0 datasets slightly outperform most existing methods.
Graph embedding, aiming to learn low-dimensional representations (aka. embeddings) of nodes in graphs, has received significant attention. In recent years, there has been a surge of efforts, among which graph convolutional networks (GCNs) have emerged as an effective class of models. However, these methods mainly focus on the static graph embedding. In the present work, an efficient dynamic graph embedding approach is proposed, called dynamic GCN (DyGCN), which is an extension of the GCN-based methods. The embedding propagation scheme of GCN is naturally generalized to a dynamic setting in an efficient manner, which propagates the change in topological structure and neighborhood embeddings along the graph to update the node embeddings. The most affected nodes are updated first, and then their changes are propagated to further nodes, which in turn are updated. Extensive experiments on various dynamic graphs showed that the proposed model can update the node embeddings in a time-saving and performance-preserving way.
Accurate and real-time traffic flow prediction is an essential component of the Intelligent Transportation System (ITS). Balancing the prediction accuracy and time cost of prediction models is a challenging topic. This paper proposes a deep learning framework (FedAGCN) based on federated learning and asynchronous graph convolutional networks to predict traffic flow accurately in real time. FedAGCN applies asynchronous spatial-temporal graph convolution to model the spatial-temporal dependence in traffic data. In order to reduce the time cost of the deep learning model, we propose a graph federated learning strategy GraphFed to train the model. Experiments were conducted on two public traffic datasets, and the results showed that FedAGCN effectively reduced the training and inference time of the model while maintaining considerable prediction accuracy.& COPY; 2023 Elsevier B.V. All rights reserved.
Elliptic data-one of the largest Bitcoin transaction graphs-has admitted promising results in many studies using classical supervised learning and graph convolutional network models for anti-money laundering. Despite the promising results provided by these studies, only few have considered the temporal information of this dataset, wherein the results were not very satisfactory. Moreover, there is very sparse existing literature that applies active learning to this type of blockchain dataset. In this paper, we develop a classification model that combines long-short-term memory with GCN-referred to as temporal-GCN-that classifies the illicit transactions of Elliptic data using its transaction's features only. Subsequently, we present an active learning framework applied to the large-scale Bitcoin transaction graph dataset, unlike previous studies on this dataset. Uncertainties for active learning are obtained using Monte-Carlo dropout (MC-dropout) and Monte-Carlo based adversarial attack (MC-AA) which are Bayesian approximations. Active learning frameworks with these methods are compared using various acquisition functions that appeared in the literature. To the best of our knowledge, MC-AA method is the first time to be examined in the context of active learning. Our main finding is that temporal-GCN model has attained significant success in comparison to the previous studies with the same experimental settings on the same dataset. Moreover, we evaluate the performance of the provided acquisition functions using MC-AA and MC-dropout and compare the result against the baseline random sampling model.
Background Selecting and prioritizing candidate disease genes is necessary before conducting laboratory studies as identifying disease genes from a large number of candidate genes using laboratory methods, is a very costly and time-consuming task. There are many machine learning-based gene prioritization methods. These methods differ in various aspects including the feature vectors of genes, the used datasets with different structures, and the learning model. Creating a suitable feature vector for genes and an appropriate learning model on a variety of data with different and non-Euclidean structures, including graphs, as well as the lack of negative data are very important challenges of these methods. The use of graph neural networks has recently emerged in machine learning and other related fields, and they have demonstrated superior performance for a broad range of problems. Methods In this study, a new semi-supervised learning method based on graph convolutional networks is presented using the novel constructing feature vector for each gene. In the proposed method, first, we construct three feature vectors for each gene using terms from the Gene Ontology (GO) database. Then, we train a graph convolution network on these vectors using protein-protein interaction (PPI) network data to identify disease candidate genes. Our model discovers hidden layer representations encoding in both local graph structure as well as features of nodes. This method is characterized by the simultaneous consideration of topological information of the biological network (e.g., PPI) and other sources of evidence. Finally, a validation has been done to demonstrate the efficiency of our method. Results Several experiments are performed on 16 diseases to evaluate the proposed method's performance. The experiments demonstrate that our proposed method achieves the best results, in terms of precision, the area under the ROC curve (AUCs), and F1-score values, when compared with eight state-of-the-art network and machine learning-based disease gene prioritization methods. Conclusion This study shows that the proposed semi-supervised learning method appropriately classifies and ranks candidate disease genes using a graph convolutional network and an innovative method to create three feature vectors for genes based on the molecular function, cellular component, and biological process terms from GO data.
As real-world data become increasingly heterogeneous, multi-view semi-supervised learning has garnered widespread attention. Although existing studies have made efforts towards this and achieved decent performance, they are restricted to shallow models and how to mine deeper information from multiple views remains to be investigated. As a recently emerged neural network, Graph Convolutional Network (GCN) exploits graph structure to propagate label signals and has achieved encouraging performance, and it has been widely employed in various fields. Nonetheless, research on solving multi-view learning problems via GCN is limited and lacks interpretability. To address this gap, in this paper we propose a framework termed Interpretable Multi-view Graph Convolutional Network (IMvGCN). We first combine the reconstruction error and Laplacian embedding to formulate a multi-view learning problem that explores the original space from feature and topology perspectives. In light of a series of derivations, we establish a potential connection between GCN and multi-view learning, which holds significance for both domains. Furthermore, we propose an orthogonal normalization method to guarantee the mathematical connection, which solves the intractable problem of orthogonal constraints in deep learning. In addition, the proposed framework is applied to the multi-view semi-supervised learning task. Comprehensive experiments demonstrate the superiority of our proposed method over other state-of-the-art methods.
To implicitly reflect the relationship between traits and emotional expressions in a context, prevalent ways to uncover emotional configurations mostly rely on attention processes. Aspect-level sentiment analysis (ABSA) seeks to identify the emotional patterns of certain qualities in phrases while omitting the grammatical information of the Web of Things. The model includes a graph convolutional neural network (GCN) based on a dependency syntax tree and exploits syntactic structural data to directly correlate traits with their related emotional expressions, hence reducing classification interference brought to by duplicated inputs. The pretrained model BERT also picks up more grammatical knowledge by being guided by intermediary layer representations of different types of grammatical information. Each GCN layer's input is merged with the preceding layer's output and the guiding information from the BERT intermediate layer. Finally, the feature for sentiment classification is the representation of characteristics in the final layer of GCN. The experimental results on the SemEval 2014, Task4, Restaurant, Laptop, and Twitter datasets show that the proposed model provides better performance of classification accuracy than a substantial number of benchmark models.
To activate dimethyl sulfoxide (DMSO, CH3SOCH3) as a methylation agent in the C-H functionalization of (iso)quinoliniums (1), a heterogeneous photo-Fenton-like method involving the in situ generation of hydroxyl radicals by a gCN/MnO/MnO(OH) photocatalyst under visible light irradiation was realized for the first time. In the developed methodology, only a small amount of gCN/MnO/MnO(OH) photocatalysts (15 mg) was needed for the methylation of (iso)quinoliniums (1.0 mmol-scale of 1) to achieve moderate to good yields of the expected methylated-products (2) under ambient conditions. Mechanistically, hydroxyl radicals (OH) are produced when the gCN/MnO/MnO(OH) photocatalyst reacts with H2O and O-2 under visible light illumination, and then they are added to DMSO, where they subsequently fragment into CH3 radicals. The product is generated via the nucleophilic attack of the CH3 radical at the most electron-deficient position of 1, followed by deprotonation reaction. The same procedure could also be used to create trideuteromethylated (iso)quinolines (3) when DMSO-d(6) (CD3SOCD3) was used in place of DMSO. The presented novel strategy for DMSO or DMSO-d(6) activation herein is more practical, cost-effective, and risk-free compared to the conventional Fenton reagent (H2O2 and Fe2+/Fe3+) systems available in the literature. Additionally, the gCN/MnO/MnO(OH) photocatalyst is easy to prepare, practical and economical together with being easy recoverable and reusable for several runs without considerable loss in its initial activity.
With the wide application of Electronic Toll Collection (ETC) systems, the effectiveness of the operation and maintenance of gantry equipment still need to be improved. This paper proposes a dynamic anomaly detection method for gantry transactions, utilizing the contextual attention mechanism and Graph Convolutional Network-Gate Recurrent Unit (GCN-GRU) dynamic anomaly detection method for gantry transactions. In this paper, four different classes of gantry anomalies are defined and modeled, representing gantries as nodes and the connectivity between gantries as edges. First, the spatial distribution of highway ETC gantries is modeled using the GCN model to extract gantry node features. Then, the contextual attention mechanism is utilized to capture the recent patterns of the dynamic transaction graph of the gantries, and the GRU model is used to extract the time-series characteristics of the gantry nodes to dynamically update the gantry leakage. Our model is evaluated on several experimental datasets and compared with other commonly used anomaly detection methods. The experimental results show that our model outperforms other anomaly detection models in terms of accuracy, precision, and other evaluation values of 99%, proving its effectiveness and robustness. This model has a wide application potential in real gantry detection and management.
Type 2 diabetes (T2D) is a chronic condition that can lead to significant harm, such as heart disease, kidney disease, nerve damage, and blindness. Although T2D-related genes have been identified through Genome-wide association studies (GWAS) and various computational methods, the biological mechanism of T2D at the cell type level remains unclear. Exploring cell type-specific genes related to T2D is essential to understand the cellular mechanisms underlying the disease. To address this issue, we introduce DiGCellNet (predicting Disease Genes with Cell type specificity based on biological Networks), a model that integrates graph convolutional network (GCN) and multi-task learning (MTL) to predict T2D-associated cell type-specific genes based on the biological network. Our work represents the first attempt to predict cell type-specific disease genes using GCN and MTL. We evaluate our approach by predicting genes specific to four cell types and demonstrate that the proposed DiGCellNet outperforms other models that combine node embeddings with traditional machine learning algorithms. Moreover, DiGCellNet successfully identifies CALM1 as a gene specific to beta cell type in T2D cases, and this association is confirmed using an independent dataset. The code is available at https://github.com/23AIBox/23AIBox-DiGCellNet.
Context-aware recommender systems (CARS), which capture user preferences by incorporating user interactions and side information, have attracted widespread attention in today's information age. With the emergence of graph convolution networks (GCN) in recent years, graph methods have been shown effective in establishing global connections between users, items, and contexts. In this paper, we first introduce a unified graph recommendation framework to incorporate both GCN and traditional models, showing the similarities and differences between them in terms of parameter configurations and message passing styles. Then, based on the empirical analysis of existing models, we propose a novel Fused Graph Context-aware Recommender system (FGCR) model to address the identified limitations. FGCR fuses the parameter configuration of both item-based models and GCN, modeling robust node relationships in user-item-context interaction graph through a sparse item correlation matrix and dense node embeddings. In addition, FGCR applies a novel masked graph convolution strategy to refine the information aggregation process with various types of nodes. Experiments conducted on five realworld datasets show that FGCR significantly improves performance compared to the seven baseline models. Ablation study and user group analysis validate the effectiveness of each component in FGCR, especially in modeling active users and sparse contextual information.& COPY; 2023 Elsevier B.V. All rights reserved.
Accurate prediction of wind power generation is of great significance for the efficient operation of wind farms. However, traditional deep learning-based methods predict the wind power without simultaneously considering the temporal features of wind power and spatial features between variables, which leads to low prediction accuracy. This article proposes a novel wind power forecasting approach based on a graph convolution network (GCN) and a multiresolution convolution neural network (CNN), combining spatial features and temporal features. In this approach, GCN merged with maximum information coefficient (MIC) is proposed to extract the spatial correlation features between input variables, which considers the effects of multiple variables on wind power and provides interpretability for deep learning-based forecasting. On the other hand, multiresolution CNN combines multiscale convolution kernels with a new self-attention mechanism to understand local and long-term temporal features, which enables simultaneous prediction of wind power and other variables. Experiments on a real dataset prove that the proposed method is effective and accurate in short-term wind power forecasting. Comparisons with the other three state-of-the-art methods and ablation experiments also reveal the advantages of the proposed approach.
A solid state microwave (MW) assisted hydrothermal method was used to prepare S-scheme heterojunction composite Bi2S3@doped gCN (BS@CN). TC was degraded upto 99.9 % under 20 min visible light, with synergistic action of 0.2 g/L catalyst having 10 wt% Bi2S3 (BS(10)@CN) and 1.5 g/L PMS, for initial TC concentration of 50 mg/L, exhibiting first order rate constant (kapp): 0.215 min 1. The modulation of band-structure due to the generation of heterojunction, coupled with different surface-bound redox cycles, i. e.,Co2 + /Co3 +|(surf),Ce-3 + /Ce-4 +|(surf). andBi(3) + /Bi-4 +... surf., helped the charge migration, separation of excited e-/h+ and production of reactive species, like,SO4 center dot- , (OH)-O-center dot,O-2(center dot),O-2(1), etc., that played important roles towards TC degradation. Band-structure determination, XPS analysis and other characterizations revealed the formation of Sscheme configuration and corresponding surface-bound metastable complexes towards self-regeneration and excellent catalytic activity of the composite, even in the contaminated real-life surface water sources. Extensive intermediate analysis was carried out to develop a detailed TC degradation pathway. The BS@CN photocatalyst can be recycled multiple times, without significant loss of photocatalytic activity (similar to 88 % TC degradation after 5 cycles). This study demonstrated the design and fabrication of metal oxide doped gCN/metal chalcogenide-based heterojunction photocatalysts that have potential applications towards the removal of refractory contaminants in aqueous medium.
Connexin family proteins assemble into hexameric hemichannels in the cell membrane. The hemichannels dock together between two adjacent membranes to form gap junction intercellular channels (GJIChs). We report the cryo-electron microscopy structures of Cx43 GJICh, revealing the dynamic equilibrium state of various channel conformations in detergents and lipid nanodiscs. We identify three different N-terminal helix conformations of Cx43-gate-covering (GCN), pore-lining (PLN), and flexible intermediate (FIN)-that are randomly distributed in purified GJICh particles. The conformational equilibrium shifts to GCN by cholesteryl hemisuccinates and to PLN by C-terminal truncations and at varying pH. While GJIChs that mainly comprise GCN protomers are occluded by lipids, those containing conformationally heterogeneous protomers show markedly different pore sizes. We observe an alpha-to-pi-helix transition in the first transmembrane helix, which creates a side opening to the membrane in the FIN and PLN conformations. This study provides basic structural information to understand the mechanisms of action and regulation of Cx43 GJICh. Gap junction intercellular channels (GJIChs) facilitate direct communication between adjacent cells. Here, authors provide high-resolution information on dynamic structural changes in Cx43 GJICh that are necessary to understand the gating mechanism.
We study and address the multi-view crowd counting (MVCC) problem which poses more realistic challenges than single-view crowd counting for better facilitating crowd management/public safety systems. Its major challenge lies in how to fully distill and aggregate useful, complementary information among multiple camera views to create powerful ground-plane representations for wide-area crowd analysis. In this paper, we present a graph-based, multi-view learning model called Co-Communication Graph Convolutional Network (CoCo-GCN) to jointly investigate intra-view contextual dependencies and inter-view complementary relations. More specifically, CoCo-GCN builds a view-agnostic graph interaction space for each camera view to conduct efficient contextual reasoning, and extends the intra-view reasoning by using a novel Graph Communication Layer (GCL) to also take between-graph (cross-view), complementary information into account. Moreover, CoCo-GCN uses a new Co-Memory Layer (CoML) to jointly coarsen the graphs and close the 'representational gap' among them for further exploiting the compositional nature of graphs and learning more consistent representations. Finally, these jointly learned features of multiple views can be easily fused to create ground-plane representations for wide-area crowd counting. Experiments show that the proposed CoCo-GCN achieves state-of-the-art results on three MVCC datasets, i.e., PETS2009, DukeMTMC, and City Street, significantly improving the scene-level accuracy over previous models.
Unsupervised person re-identification (RE-ID) has attracted increasing attention recently due to its low costs and high application values. Currently, most of the unsupervised RE-ID approaches attempt to explore discriminative visual features based on unlabeled samples, which suffer from the label noise problem. To alleviate this problem, this paper first proposes to leverage both visual and spatial information for unsupervised person RE-ID, with a feasible assumption that the same identity has similar neighbors across different cameras. Technically, we devise an iterative Graph Convolutional Network (GCN) to alternately improve the quality of pseudo-labels and multimodal fusion features. What is more, our modal is trained based on three novel pseudo-label classes (pseudo-positive, visually similar, and pseudo-negative) instead of two to better learn discriminative features. Extensive experiments on two representative datasets (Market-1501 and DukeMTMC-reID) demonstrate the effectiveness of our approach, with 1%-2% mAP improvements as compared to the advanced approaches.
The abuse of tetracycline antibiotics (TCs) has caused serious environmental pollution problems in recent years due to excessive use of biomedicine, healthcare, animal husbandry and other fields. How to effectively remove TCs contaminants from water has been one of research emphasis on environment protection. In this work, we have successfully prepared a composite photocatalyst (P16-ZrO2/gCN) by physical mixing method and H2 plasma treatment at room temperature. The ZrO2 nanoparticles and H2 plasma treatment have synergetic effects on photocatalytic performance of gCN for degradation of TCs, and the highest degradation rate is achieved with 16 mins plasma treatment. According to BET, XPS and EPR results, more mesopores and nitrogen vacancies (NVs) are introduced by H2 plasma treatment. Furthermore, In-situ TRPL spectra illustrate that ZrO2 nanoparticles and H2 plasma treatment facilitate charge transfer process of catalysts. Overall, this work firstly reports utilizing ZrO2 nanoparticles/H2 plasma treatment together to boost photocatalytic performance of gCN and provides a low-cost approach for preparation of other photocatalysts.
In this paper, a graph convolution network prediction model based on the lioness optimization algorithm (LsOA-GCN) is proposed to predict the cumulative number of confirmed COVID-19 cases in 17 regions of Hubei Province from March 23 to March 29, 2020, according to the transmission characteristics of COVID-19. On the one hand, Spearman correlation analysis with delay days and LsOA are used to capture the dynamic changes of feature information to obtain the temporal features. On the other hand, the graph convolutional network is used to capture the topological structure of the city network, so as to obtain spatial information and finally realize the prediction task. Then, we evaluate this model through performance evaluation indicators and statistical test methods and compare the results of LsOA-GCN with 10 representative prediction methods in the current epidemic prediction study. The experimental results show that the LsOA-GCN prediction model is significantly better than other prediction methods in all indicators and can successfully capture spatio-temporal information from feature data, thereby achieving accurate prediction of epidemic trends in different regions of Hubei Province.
Previous scientific literature retrieval methods, which are based on mathematical expression, ignore the literature attributes and the association between the literature, and the retrieval accuracy was affected. In this study, literature retrieval model based on Graph Convolutional Network (GCN) is proposed. By extracting document attributes from a structured document dataset, an Attribute Relation Graph (ARG) is constructed. Using GCN to capture the dependencies among literature nodes and generate literature representations by information aggregation to realize graph-based literature modeling; Introducing the advantages of Hesitant Fuzzy Set (HFS) theory in multi-attribute decision-making to realize the similarity evaluation between mathematical query expressions and mathematical retrieval result expressions. Finally, the similarity between literature features and mathematical expressions is integrated to obtain the ordered output of scientific literature retrieval results. Experiments were conducted on the arXiv public dataset, and the average precision of the top 10 retrieval results was 0.892, and the average NDCG value of the top 10 rankings was 0.875.
The accurate classification of forest types is critical for sustainable forest management. In this study, a novel multiscale global graph convolutional neural network (MSG-GCN) was compared with random forest (RF), U-Net, and U-Net++ models in terms of the classification of natural mixed forest (NMX), natural broadleaved forest (NBL), and conifer plantation (CP) using very high-resolution aerial photographs from the University of Tokyo Chiba Forest in central Japan. Our MSG-GCN architecture is novel in the following respects: The convolutional kernel scale of the encoder is unlike those of other models; local attention replaces the conventional U-Net++ skip connection; a multiscale graph convolutional neural block is embedded into the end layer of the encoder module; and various decoding layers are spliced to preserve high- and low-level feature information and to improve the decision capacity for boundary cells. The MSG-GCN achieved higher classification accuracy than other state-of-the-art (SOTA) methods. The classification accuracy in terms of NMX was lower compared with NBL and CP. The RF method produced severe salt-and-pepper noise. The U-Net and U-Net++ methods frequently produced error patches and the edges between different forest types were rough and blurred. In contrast, the MSG-GCN method had fewer misclassification patches and showed clear edges between different forest types. Most areas misclassified by MSG-GCN were on edges, while misclassification patches were randomly distributed in internal areas for U-Net and U-Net++. We made full use of artificial intelligence and very high-resolution remote sensing data to create accurate maps to aid forest management and facilitate efficient and accurate forest resource inventory taking in Japan.
Regarding the classification of 3D point clouds, existing Graph Convolution Networks (GCN) often fail to effectively learn the correlation of visual features of different scales under the condition of multi-view (multi-domain), thus the features learnt by models are not as varied and the classification accuracy is usually limited. In view of these defects, this paper proposed a Multi-View Deep Visual Adaptive Graph Convolution Network (MVDVAGCN) which integrates the theory of visual selective attention with the graph convolution calculation method and inherits the advantages of the idea of rasterization. In the paper, the deep learning technology, the idea of multi-view, and the VAGCN were combined to establish three GCN models which were then applied to the classification of 3D point clouds and attained good results. Then the parameters set for the proposed algorithm were verified based on the ModelNet40 dataset, the recognition performance and geometrical invariance of the proposed algorithm and a few reference algorithms including VoxNeT, PointNet, PointNet++, DGCNN, KPConv3D-GCN, Dynamic Graph CNN, and 3D_RFGCN, were tested, and the results proved the feasibility, recognition performance, and geometrical invariance of the proposed algorithm.
Purpose: Accurate diagnosis of autism spectrum disorder (ASD) plays a key role in improving the condition and quality of life for patients. In this study, we mainly focus on ASD diagnosis with functional brain networks (FBNs). The major challenge for brain networks modeling is the high dimensional connectivity in brain networks and limited number of subjects, which hinders the classification capability of graph convolutional networks (GCNs). Method: To alleviate the influence of the limited data and high dimensional connectivity, we introduce a unified three-stage graph learning framework for brain network classification, involving multi-graph clustering, graph generation and graph classification. The framework combining Graph Generation, Clustering and Classification Networks (GraphCGC-Net) enhances the critical connections by multi-graph clustering (MGC) with a supervision scheme, and generates realistic brain networks by simultaneously preserving the global consistent distribution and local topology properties. Results: To demonstrate the effectiveness of our approach, we evaluate the performance of the proposed method on the Autism Brain Imaging Data Exchange (ABIDE) dataset and conduct extensive experiments on the ASD classification problem. Our proposed method achieves an average accuracy of 70.45% and an AUC of 72.76% on ABIDE. Compared with the traditional GCN model, the proposed GraphCGC-Net obtains 9.3%, and 10.64% improvement in terms of accuracy and AUC metrics, respectively. Conclusion: The comprehensive experiments demonstrate that our GraphCGC-Net is effective for graph classification in brain disorders diagnosis. Moreover, we find that MGC can generate biologically meaningful subnetworks, which is highly consistent with the previous neuroimaging-derived biomarker evidence of ASD. More importantly, the promising results suggest that applying generative adversarial networks (GANs) in brain networks to improve the classification performance is worth further investigation.(c) 2022 Published by Elsevier B.V.
Phthalate esters (PAEs) widely used as plasticizers in industrial products are a major threat to human health and water ecological security. In this work, chitin-based sponges doped with oxygen-modified graphitic carbon nitride (O-gCN) (ChCN) demonstrated adsorption-photocatalytic synergistic ability for the efficient removal of two typical PAEs, diethyl phthalate (DEP) and dibutyl phthalate (DBP). The addition of O-gCN increased the sponge mechanical strength from 0.629 to 1.39 MPa, enabling materials with interconnected pores, excellent compressibility, and mechanical durability. The saturated adsorption capacities of DEP and DBP reached 37.41-42.93 mg g-1 for ChCN sponges, wherein the driving forces were hydrophobic interactions, hydrogen bonding, and pi-pi interactions. Notably, O-gCN significantly improved PAE removal by simultaneously enhancing the adsorption and photocatalytic effect of ChCN sponges due to its high catalytic activity, leading to 100% removal of DEP and DBP within 2 h. The degradation pathway of DEP was confirmed to be de-esterification. Finally, filtration columns assembled with ChCN sponges showed 87.8-90.9% PAE removal from water under natural light, and the removal efficiency did not significantly change even after three reuses, indicating stable removal performance and good reusability with potential for practical applications. The sponges also possessed good biocompatibility and biodegradability, as demonstrated through algal toxicity experiments and biodegra-dation tests. Therefore, this research presents a convenient method for preparation of compressible and reusable sponge materials from renewable biomass for efficient PAE removal from aqueous environments and has revealed the underlying mechanisms of such removal by the adsorption-photocatalysis synergistic effect.
Emotion recognition in conversations (ERC) has gained increasing research attention in recent years due to its wide applications in a surge of emerging tasks, such as social media analysis, dialog generation, and recommender systems. Since constituent utterances in a conversation are closely semantic-related, the constituent utterances' emotional states are also closely related. In our consideration, this correlation could serve as a guide for the emotion recognition of constituent utterances. Accordingly, we propose a novel approach named Semantic-correlation Graph Convolutional Network (SC-GCN) to take advantage of this correlation for the ERC task in multimodal scenario. Specifically, we first introduce a hierarchical fusion module to model the dynamics among the textual, acoustic and visual features and fuse the multimodal information. Afterward, we construct a graph structure based on the speaker and temporal dependency of the dialog. We put forward a novel multi-loop architecture to explore the semantic correlations by the self-attention mechanism and enhance the correlation information via multiple loops. Through the graph convolution process, the proposed SC-GCN finally obtains a refined representation of each utterance, which is used for the final prediction. Extensive experiments are conducted on two benchmark datasets and the experimental results demonstrate the superiority of our SC-GCN.
Aspect-based sentiment analysis (ABSA) aims to predict the sentiment polarity of a specified aspect in a sentence. Graph neural networks (GNN) based on dependency trees have been shown to be effective for ABSA by explicitly modeling the connection between aspect and opinion terms and exploiting local semantic and syntactic information in the sentence. However, most previous works have overlooked the use of global dependency information. In this paper, we propose a novel Graph Convolutional Network (GCN) with an Interactive Memory Fusion (IMF) mechanism (IMF-GCN) that incorporates both global and local structural information for aspect-based sentiment classification. The IMF mechanism efficiently fuses global and local structural dependency information by assigning different weights to global and local dependency modules. Syntactic constraints are also imposed to prevent the graph convolution propagation unrelated to the target words, further improving the model's performance. The evaluation metrics used in the paper are accuracy and macro-average F1 scores, and the proposed approach achieves optimal results on three datasets with F1 scores of 79.60%, 82.19%, and 77.75%, which outperform the baseline model.
This paper introduces a novel surrogate model for two-dimensional adaptive steady-state thermal convection fields based on deep learning technology. The proposed model aims to overcome limitations in traditional frameworks caused by network types, such as the requirement for extensive training data, accuracy loss due to pixelated preprocessing of original data, and inability to predict information near the boundaries with precision. We propose a new framework that consists primarily of a physical-informed neural network (PINN) and a graph convolutional neural network (GCN). The GCN serves as the prediction module and predicts thermal convection in the two-dimensional computational domain by considering the mutual influence between unstructured nodes and their neighbors. On the other hand, the PINN acts as the physical constraint module of the framework by embedding the control equation of thermal convection into the loss function of the neural network, ensuring that the inference and prediction results of the GCN comply with the constraints of the control equation. The advantages of this framework lie in two aspects. First, the computation mechanism of the GCN is more in line with the actual evolution of temperature fields. Second, the PINN enhances the cognitive ability of the surrogate model toward the convection field information. It accurately describes the changes of temperature gradient information at the boundary position and reduces the model's demand for training data. To validate the advantages of the proposed model, we gradually analyzed the model's geometric adaptability and predictive accuracy from the single cylinder case to the double cylinder case. We also investigated the impact of the number of sampling points on model training and compared the model's prediction results with those of a purely data-driven model. The results show that the proposed model exhibits good geometric adaptability and stability. With only 20 training data, the mean error of the proposed model in predicting the velocity and temperature field is less than 1% and 0.6% for the single cylinder, and less than 2% and 1% for the double cylinder case, while the mean error of the purely data-driven GCN model in predicting the velocity and temperature field is 9.4% and 6.4% for the double cylinder case. These findings demonstrate the effectiveness of the proposed physics-informed graph convolutional neural network, allowing for more accurate prediction of fluid flow and heat convection using surrogate model.
In this study, we utilized calcination and simple impregnation methods to successfully fabricate bare g-C3N4 (GCN) and x% Ag/g-C3N4 (x% AgGCN) composite photocatalysts with various weight percentages (x = 1, 3, 5, and 7 wt.%). The synthesized bare and composite photocatalysts were analyzed to illustrate their phase formation, functional group, morphology, and optical properties utilizing XRD, FT-IR, UV-Vis DRS, PL, FE-SEM, and the EDS. The photodegradation rate of MO under solar light irradiation was measured, and the 5% AgGCN composite photocatalyst showed higher photocatalytic activity (99%), which is very high compared to other bare and composite photocatalysts. The MO dye degradation rate constant with the 5% AgGCN photocatalyst exhibits 14.83 times better photocatalytic activity compared to the bare GCN catalyst. This photocatalyst showed good efficiency in the degradation of MO dye and demonstrated cycling stability even in the 5th successive photocatalytic reaction cycle. The higher photocatalytic activity of the 5% AgGCN composite catalyst for the degradation of MO dye is due to the interaction of Ag with GCN and the localized surface plasmon resonance (SPR) effect of Ag. The scavenger study results indicate that O-2(?-) radicals play a major role in MO dye degradation. A possible charge-transfer mechanism is proposed to explain the solar-light-driven photocatalyst of GCN.
Atrial fibrillation (AF) is a common type of arrhythmia with a high incidence and risk, and it is difficult to monitor. Deep learning-based algorithms for AF detection have made preliminary progress, with Recurrent Convolution Neural Networks (RCNN) being widely used for AF detection. The RCNN algorithm combines electrocardiogram (ECG) morphology and rhythm information, where Convolution Neural Network (CNN) mainly processes morphological features and Recurrent Neural Network (RNN) mainly deals with rhythm information. However, a problem with this method is that direct splicing and fusion of ECG rhythm features and ECG morphological features cannot fully exploit the information of both features for AF detection because they have different representative spaces. Therefore, this paper proposes a novel AF detection algorithm based on graph convolution network, named AF-GCN. First, we transform heartbeats into a graph structure, called heartbeat diagrams. The node features of the heartbeat graph are the morphological information of each heartbeat, and the edge of the heartbeat is linked according to the time interval between heartbeats. Moreover, we calculate the edge weight according to the morphological similarity between heartbeats. Therefore, the morphological information and rhythm information of the ECG signal can be unifiedly expressed in one heartbeat. Then, using the Graph Convolution Network (GCN), the morphological and rhythmic features of the ECG signal can be effectively extracted, modeled, and fused in one network modal. We evaluated our AF-GCN method on two popular and widely recognized AF detection benchmarks, MIT-BIH AFDB and Physionet Challenge 2017 AFDB datasets. The results show that AF-GCN outperforms other existing methods.
Recommending Smart Social Network (SSN) items which are in line with user preferences is one of the significant applications in SSNs such as Event-Based Social Networks (EBSNs) and Smart object Based Social Network (SBSN). It is well acknowledged that geographical and social contextual influences play an important role in SSN item Recommender System (RS). Whereas incorporating such contextual influences into SSN item RSs is a challenging issue which needs to be addressed along with the conventional RS challenges (cold-start problem and data sparsity). To this end, a novel SSN item recommendation architecture (named as 3T-IEC*) based on Graph Convolutional Network (GCN) is proposed. Specifically, 3T-IEC* constructs an SSN item location graph based on physical distance between two SSN items and leverages a GCN-based representation learning method to capture geographical influence of SSN items; which not only incorporates the geographical preferences but also delivers a convincing idea to solve the data sparsity problem. Sequentially, 3T-IEC* deploys one more GCN to incorporate users' social associations. Furthermore, 3T-IEC* leverages self-attention technique with multiple heads to incorporate user's preferences over SSN items' multiple features. The experimental results on four real life datasets demonstrate superior performance of 3T-IEC* compared with state-of-the-art methods such as SkyLine (149%), 3T-IEC (54%), DeepWalk (38%), SORec (9%), and NGCF (7%).
In this study, a magnetic perovskite nanohybrid based on g-C3N4 (gCN) nanosheets was synthesized and developed for the efficient photodegradation of toxic environmental pollutants under short-time visible irradiation. The synthesis of this nanohybrid involved the incorporation of SrTiO3:N (STO:N) and ZnFe2O4 (ZnF) onto the g-C3N4 nanosheets through a simple reflux method. Our investigation encompassed a comprehensive suite of analytical techniques, including BET, TGA, TEM, SEM, EDX, DRS, VSM, XRD, photocurrent, and FT-IR, to elucidate the physicochemical characteristics of this nanocomposite in the context of its application in photodegradation processes. The nanohybrid displayed significantly enhanced photocatalytic activity compared to its individual components, achieving a degradation efficiency of over 90% for various pollutants, including organic dyes like Rhodamine B (Rh-B), within a short irradiation time. This enhanced activity can be attributed to the synergistic effect between gCN, STO:N, and ZnF, which promotes the generation of reactive oxygen species and facilitates the degradation process. Notably, the nanocomposite containing 20 wt% STO:N perovskite and 20 wt% ZnF demonstrated the highest Rh-B degradation rate under visible light irradiation within just 30 min. Furthermore, the nanohybrid displayed excellent stability and reusability over seven consecutive runs, retaining its high photocatalytic activity even after multiple cycles of degradation. This remarkable performance can be attributed to the strong interaction between the gCN nanosheets and the magnetic perovskite components, which prevents their aggregation and ensures their efficient utilization. Additionally, the nanohybrid exhibited excellent visible light absorption, enabling the utilization of a wider range of light for degradation. This feature is particularly advantageous, as visible light is more abundant in sunlight compared to UV light, rendering the nanohybrid suitable for practical applications under natural sunlight. In conclusion, the ternary gCN-STO:N@ZnF nanocomposite represents a promising candidate for the treatment of organic pollutants in aqueous environments, offering a versatile and efficient solution.
BACKGROUND: Accurate and timely assessment of children's developmental status is crucial for early diagnosis and intervention. More accurate and automated developmental assessments are essential due to the lack of trained health care providers and imprecise parental reporting. In various areas of development, gross motor development in toddlers is known to be predictive of subsequent childhood developments. OBJECTIVE: The purpose of this study was to develop a model to assess gross motor behavior and integrate the results to determine the overall gross motor status of toddlers. This study also aimed to identify behaviors that are important in the assessment of overall gross motor skills and detect critical moments and important body parts for the assessment of each behavior. METHODS: We used behavioral videos of toddlers aged 18-35 months. To assess gross motor development, we selected 4 behaviors (climb up the stairs, go down the stairs, throw the ball, and stand on 1 foot) that have been validated with the Korean Developmental Screening Test for Infants and Children. In the child behavior videos, we estimated each child's position as a bounding box and extracted human keypoints within the box. In the first stage, the videos with the extracted human keypoints of each behavior were evaluated separately using a graph convolutional networks (GCN)-based algorithm. The probability values obtained for each label in the first-stage model were used as input for the second-stage model, the extreme gradient boosting (XGBoost) algorithm, to predict the overall gross motor status. For interpretability, we used gradient-weighted class activation mapping (Grad-CAM) to identify important moments and relevant body parts during the movements. The Shapley additive explanations method was used for the assessment of variable importance, to determine the movements that contributed the most to the overall developmental assessment. RESULTS: Behavioral videos of 4 gross motor skills were collected from 147 children, resulting in a total of 2395 videos. The stage-1 GCN model to evaluate each behavior had an area under the receiver operating characteristic curve (AUROC) of 0.79 to 0.90. Keypoint-mapping Grad-CAM visualization identified important moments in each behavior and differences in important body parts. The stage-2 XGBoost model to assess the overall gross motor status had an AUROC of 0.90. Among the 4 behaviors, "go down the stairs" contributed the most to the overall developmental assessment. CONCLUSIONS: Using movement videos of toddlers aged 18-35 months, we developed objective and automated models to evaluate each behavior and assess each child's overall gross motor performance. We identified the important behaviors for assessing gross motor performance and developed methods to recognize important moments and body parts while evaluating gross motor performance.
N2 electrochemical reduction (NRR) suffers from weak activity and fierce competition of hydrogen evolution reaction (HER). Herein, we propose a strengthened activating strategy for N2 fixation via hydrogen bonds. To this end, amino functionalized graphitic carbon nitride (NHx-gCN) is designed. Through the N-HMIDLINE HORIZONTAL ELLIPSISN hydrogen bonds between amino groups and N2 as well as NRR intermediates of NxHy, NHx-gCN presents dramatically enhanced NRR performance, with NH3 yield rate of 56.38 mu g mg-cat 1h-1 and Faradaic efficiency of 27.00 % at-0.73 V (vs RHE). Theoretical calculations certify through hydrogen bonds the adsorption of N2 and NxHy on NHx-gCN is enhanced and the dissociation of N2 into *N2H and *N2H2 is greatly facilitated. Besides, hydrogen bonding interactions between amino groups and heptazine can suppress the HER by inhibiting adsorption of proton H. This work delivers a new hydrogen-bond strategy to optimal NRR performance with both high NH3 production and high Faradaic efficiency.
A graph convolutional network (GCN) is employed in the deep energy method (DEM) model to solve the momentum balance equation in three-dimensional space for the deformation of linear elastic and hyperelastic materials due to its ability to handle irregular domains over the traditional DEM method based on a multilayer perceptron (MLP) network. The method's accuracy and solution time are compared to the DEM model based on a MLP network. We demonstrate that the GCN-based model delivers similar accuracy while having a shorter run time through numerical examples. Two different spatial gradient computation techniques, one based on automatic differentiation (AD) and the other based on shape function (SF) gradients, are also accessed. We provide a simple example to demonstrate the strain localization instability associated with the AD-based gradient computation and show that the instability exists in more general cases by four numerical examples. The SF-based gradient computation is shown to be more robust and delivers an accurate solution even at severe deformations. Therefore, the combination of the GCN-based DEM model and SF-based gradient computation is potentially a promising candidate for solving problems involving severe material and geometric nonlinearities.
Sodium hypophosphite is a potential green source for the generation of clean elemental hydrogen without pollutants. The examination of the catalytic activity toward hydrogen production of different metallic nanoparticles supported on graphitic carbon nitride (GCN) was performed using sodium hypophosphite as hydrogen source. Four different metallic nanoparticles were assessed, namely, palladium, nickel, ruthenium, and rhodium. The Pd -based catalyst, Pd/GCN, was found to be the most active and stable of the four catalysts. The latter showed phenomenal catalytic activity of 100% conversion over five cycles hence makes this process sustainable. All four catalysts were characterized by PXRD, FTIR, XPS, TGA, TEM, and ICP-MS techniques. The blend of hypophosphite and Pd/GCN catalyst was weighed against the grouping of this catalyst with the traditional hydrogen source, po-tassium formate. We realized that the first combination is much more efficient and does not release byproducts, which makes this hydrogen source greener and more effectual.& COPY; 2023 Hydrogen Energy Publications LLC. Published by Elsevier Ltd. All rights reserved.
In recent years, there has been a significant increase in the application of graph neural networks on a wide range of different problems. A specially promising direction of research is on graph convolutional neural networks (GCN). This work focuses on the application of GCNs to graph combinatorial optimization problems (GCOPs), specifically on their decision versions. GCNs are applied on the family of GCOPs in which the objective function is directly related to the number of vertices in a graph. The selected problems are the minimum vertex cover, maximum clique, minimum dominating set and graph coloring. In this work, a framework is proposed for solving problems of this type. The performance of this approach is explored for standard multi-layer GCNs using different types of convolutional layers. On top of this, we propose a new structure that is based on graph isomorphism networks. Computational experiments show that this new structure is significantly more efficient than basic structures. To further improve the performance of this method, the use of GCN ensembles is also explored. When using GCNs to generate solution values for GCOPs, they often correspond to non-feasible solutions because they violate the problem boundaries. This issue is addressed by defining an asymmetric loss function that is used during the GCN training. The proposed method is evaluated on a large set of training data consisting of graph solution pairs that can also be accessed online.
Recently, a large number of studies have indicated that circRNAs with covalently closed loops play important roles in biological processes and have potential as diagnostic biomarkers. Therefore, research on the circRNAdisease relationship is helpful in disease diagnosis and treatment. However, traditional biological verification methods require considerable labor and time costs. In this paper, we propose a new computational method (RGCNCDA) to predict circRNA-disease associations based on relational graph convolutional networks (R-GCNs). The method first integrates the circRNA similarity network, miRNA similarity network, disease similarity network and association networks among them to construct a global heterogeneous network. Then, it employs the random walk with restart (RWR) and principal component analysis (PCA) models to learn low-dimensional and high-order information from the global heterogeneous network as the topological features. Finally, a prediction model based on an R-GCN encoder and a DistMult decoder is built to predict the potential diseaseassociated circRNA. The predicted results demonstrate that RGCNCDA performs significantly better than the other six state-of-the-art methods in a 5-fold cross validation. Furthermore, the case study illustrates that RGCNCDA can effectively discover potential circRNA-disease associations.
The sharp increase in encrypted traffic brings a huge challenge to traditional traffic classification methods. Combining deep learning with time series analysis techniques is a recent trend in solving this problem. Most of these approaches only capture the temporal correlation within a flow. The accuracy and robustness are unsatisfactory, especially in an unstable network environment with high packet loss and reordering. How to learn a representation with a strong generalization ability for each encrypted traffic flow remains a key challenge. Our detailed analysis indicates that there is a graph with particular local structures corresponding to each type of encrypted traffic flow. Inspired by this observation, we propose a novel deep learning framework called EC-GCN to classify encrypted traffic flows based on multi-scale graph convolutional neural networks. We first provide a novel lightweight layer that only relies on the metadata and encodes each encrypted traffic flow into graph representations. So that our framework can be independent of different encryption protocols. Then we design a novel graph pooling and structure learning layer to dynamically extract the multi-graph representations and improve the capabilities to adapt to complex network environments. EC-GCN is an end-to-end classification model that learns representative spatial-temporal traffic features hidden in a traffic time series and then classifies them in a unified framework. Our comprehensive experiments on three real-world datasets indicate that EC-GCN can achieve up to 5%-20% accuracy improvement and outperforms state-of-the-art methods.
Accurate pavement crack detection is important for routine maintenance of pavements and reduction of possible traffic accidents. Most existing rule-or learning-based point-level approaches cannot achieve high detection accuracy and efficiency owing to the disorderly arrangement, scattered intensities, diverse crack structures, large data volumes, and complex annotation of mobile laser scanning (MLS) point clouds. To address these issues, we developed SCL-GCN, a Stratified Contrastive Learning Graph Convolution Network with a novel dual-branch architecture for MLS-point cloud-based pavement crack detection. First, a multi-scale graph representation construction module was designed based on a stratification strategy. This module creates strengthened spaces for the raw pavement point cloud and its downsampled subset, from which adjacency matrices and initial representations are generated. The stratification strategy samples neighbors densely in the raw point clouds and sparsely in the downsampled subset to form the neighborhood for each point, utilizing long-range contexts to increase the effective receptive field while lowing the extra computation. Next, a graph feature contrastive learning module is proposed to take advantage of stratified features. This module supervises the learning process of the two branches to avoid learning bias caused by an imbalanced data distribution, promoting convergence and improving performance. The experimental results show that the developed SCL-GCN model outperforms state-of-the-art methods. With a training/testing ratio of only 1:6 and an overall training time of less than 70 min, the average precision, recall, and F1-score of the SCL-GCN reached 75.7%, 75.1%, and 75.2%, respectively.
The goal of zero-shot learning (ZSL) is to build a classifier that recognizes novel categories with no corresponding annotated training data. The typical routine is to transfer knowledge from seen classes to unseen ones by learning a visual-semantic embedding. Existing multi-label zero-shot learning approaches either ignore correlations among labels, suffer from large label combinations, or learn the embedding using only local or global visual features. In this paper, we propose a Graph Convolution Networks based Multi-label Zero-Shot Learning model, abbreviated as MZSL-GCN. Our model first constructs a label relation graph using label co-occurrences and compensates the absence of unseen labels in the training phase by semantic similarity. It then takes the graph and the word embedding of each seen (unseen) label as inputs to the GCN to learn the label semantic embedding, and to obtain a set of inter-dependent object classifiers. MZSL-GCN simultaneously trains another attention network to learn compatible local and global visual features of objects with respect to the classifiers, and thus makes the whole network end-to-end trainable. In addition, the use of unlabeled training data can reduce the bias toward seen labels and boost the generalization ability. Experimental results on benchmark datasets show that our MZSL-GCN competes with state-of-the-art approaches. (c) 2020 Elsevier Ltd. All rights reserved.
We briefly review the state-of-the-art machine learning (ML) algorithms for mineral exploration, which mainly include random forest (RF), convolutional neural network (CNN), and graph convolutional network (GCN). In recent years, RF, a representative shallow machine learning algorithm, and CNN, a representative deep learning approach, have been proved to be powerful tools for ML-based mapping for mineral exploration. In the future, GCN deserves more attention for ML-based mapping for mineral exploration because of its ability to capture the spatial anisotropy of mineralization and its applicability within irregular study areas. Finally, we summarize the original contributions of the six papers comprising this special issue.
Group activity recognition is a central theme in many domains, such as sports video analysis, CCTV surveillance, sports tactics, and social scenario understanding. However, there are still challenges in embedding actors' relations in a multi-person scenario due to occlusion, movement, and light. Current studies mainly focus on collective and individual local features from the spatial and temporal perspectives, which results in inefficiency, low robustness, and low portability. To this end, a Spatio-Temporal Attention-Based Graph Convolution Network (STAB-GCN) model is proposed to effectively embed deep complex relations between actors. Specifically, we leverage the attention mechanism to attentively explore spatio-temporal latent relations between actors. This approach captures spatio-temporal contextual information and improves individual and group embedding. Then, we feed actor relation graphs built from group activity videos into our proposed STAB-GCN for further inference, which selectively attends to the relevant features while ignoring those irrelevant to the relation extraction task. We perform experiments on three available group activity datasets, acquiring better performance than state-of-the-art methods. The results verify the validity of our proposed model and highlight the obstructive impacts of spatio-temporal attention-based graph embedding on group activity recognition.
Background: Drug response prediction is an important problem in computational personalized medicine. Many machine-learning-based methods, especially deep learning-based ones, have been proposed for this task. However, these methods often represent the drugs as strings, which are not a natural way to depict molecules. Also, interpretation (e.g., what are the mutation or copy number aberration contributing to the drug response) has not been considered thoroughly. Methods: In this study, we propose a novel method, GraphDRP, based on graph convolutional network for the problem. In GraphDRP, drugs were represented in molecular graphs directly capturing the bonds among atoms, meanwhile cell lines were depicted as binary vectors of genomic aberrations. Representative features of drugs and cell lines were learned by convolution layers, then combined to represent for each drug-cell line pair. Finally, the response value of each drug-cell line pair was predicted by a fully-connected neural network. Four variants of graph convolutional networks were used for learning the features of drugs. Results: We found that GraphDRP outperforms tCNNS in all performance measures for all experiments. Also, through saliency maps of the resulting GraphDRP models, we discovered the contribution of the genomic aberrations to the responses. Conclusion: Representing drugs as graphs can improve the performance of drug response prediction. Availability of data and materials: Data and source code can be downloaded athttps://github.com/hauldhut/ GraphDRP.
Motivation Recent advances in spatial transcriptomics technologies have enabled gene expression profiles while preserving spatial context. Accurately identifying spatial domains is crucial for downstream analysis and it requires the effective integration of gene expression profiles and spatial information. While increasingly computational methods have been developed for spatial domain detection, most of them cannot adaptively learn the complex relationship between gene expression and spatial information, leading to sub-optimal performance. Results To overcome these challenges, we propose a novel deep learning method named Spatial-MGCN for identifying spatial domains, which is a Multi-view Graph Convolutional Network (GCN) with attention mechanism. We first construct two neighbor graphs using gene expression profiles and spatial information, respectively. Then, a multi-view GCN encoder is designed to extract unique embeddings from both the feature and spatial graphs, as well as their shared embeddings by combining both graphs. Finally, a zero-inflated negative binomial decoder is used to reconstruct the original expression matrix by capturing the global probability distribution of gene expression profiles. Moreover, Spatial-MGCN incorporates a spatial regularization constraint into the features learning to preserve spatial neighbor information in an end-to-end manner. The experimental results show that Spatial-MGCN outperforms state-of-the-art methods consistently in several tasks, including spatial clustering and trajectory inference.
Graph convolutional networks (GCNs), with their powerful ability to model non-Euclidean graph data, have shown advantages in learning representations of brain networks. However, considering the complexity, multilayeredness, and spatio-temporal dynamics of brain activities, we have identified two limitations in current GCNbased research on brain networks: 1) Most studies have focused on unidirectional information transmission across brain network levels, neglecting joint learning or bidirectional information exchange among networks. 2) Most of the existing models determine node neighborhoods by thresholding or simply binarizing the brain network, which leads to the loss of edge weight information and weakens the model's sensitivity to important information in the brain network. To address the above issues, we propose a multi -level dynamic brain network joint learning architecture based on GCN for autism spectrum disorder (ASD) diagnosis. Specifically, firstly, constructing different -level dynamic brain networks. Then, utilizing joint learning based on GCN for interactive information exchange among these multi -level brain networks. Finally, designing an edge self -attention mechanism to assign different edge weights to inter -node connections, which allows us to pick out the crucial features for ASD diagnosis. Our proposed method achieves an accuracy of 81.5 %. The results demonstrate that our method enables bidirectional transfer of high -order and low -order information, facilitating information complementarity between different levels of brain networks. Additionally, the use of edge weights enhances the representation capability of ASD-related features.
The rod-fastened rotor is a critical component of heavy-duty gas turbines, and therefore, it is imperative to investigate its failure mechanisms and develop intelligent diagnostic techniques. The issue of effective cross-domain diagnosis has garnered significant interest considering the changing operating conditions of rod-fastened rotors. To mitigate the effects of limited data samples or high collection costs in the target domain, we introduce a fault diagnosis model named the task-generalization-based graph convolutional network (TG-GCN), which leverages adversarial perturbations within a meta-learning framework to enhance the robustness of prior knowledge incorporated into the graph convolutional network. Initially, the method involves generating adversarial training samples in proximity to the distribution of the source-domain data by optimizing the worst case formulation to enhance generalization to task distribution. Next, the support set and the query set are simultaneously fed into the feature extraction network, yielding corresponding feature vectors. Subsequently, similarities between feature vectors and the degree of dispersion are computed in the task space, serving as connection weights for constructing the graph network model aimed at executing fault diagnosis. The proposed TG-GCN framework employs the introduction of data augmentation during the iteration process, which helps to strengthen the vulnerable components of the network by connecting them with the worst case perturbations. Moreover, we employed a rod-fastened rotor experimental system to elucidate the underlying failure mechanisms and corroborate the superiority of the TG-GCN.
The present work entails the synthesis of thermally modified graphitic carbon nitride (GCN) using a two-step thermal treatment procedure and its subsequent use in the photocatalytic reduction of toxic pollutants such as rhodamine B dye (RhB) and chromium (VI) (Cr(VI)) from aquatic environments. The as-synthesised exfoliated GCN (GCNX) is characterised by X-ray diffraction (XRD) analysis, Fourier transform infrared (FTIR) spectros-copy, X-ray photoelectron spectroscopy (XPS), energy-dispersive X-ray spectroscopy (EDS), Bru-nauer-Emmett-Teller analysis (BET), diffuse reflectance spectroscopy (DRS), photoluminescence spectroscopy (PL), field emission scanning electron microscopy (FESEM), and transmission electron microscopy (TEM). These characterisations helped to elucidate the phase formation, chemical structure, composition, surface area, optical properties, and morphology of the sample. With assistance from a visible light source, GCNX can degrade RhB dye within 30 min in the presence of hydrogen peroxide (H2O2) and reduce Cr(VI) to Cr(III) in under 2 h in the presence of formic acid (FA/HCOOH). Variations in different catalytic parameters, including catalyst amount, pH of the solution, initial RhB or Cr(VI) concentration, and variation in H2O2 or FA concentration, are performed to inspect their effects on the photodegradation activity of GCNX. Moreover, the GCNX catalyst exhibits impressive stability and reusability. A thorough statistical evaluation follows the response surface methodology to under-stand the complex interaction between the factors contributing to the catalytic activity. The band alignment of differently functionalised GCN blocks in their pristine form and their H2O2/FA-adsorbed states is investigated using first-principles calculations to provide a further understanding of the RhB and Cr(VI) reduction mecha-nisms. The modified GCN can thus be effectively employed as a low-cost material for removing contamination from aquatic environments.
The spread of online rumor poses challenges to social peace and public order. Traditional research on rumor diffusion commences from the rumor itself, without considering the symbiosis and confrontation of anti-rumor and motivation-rumor. This study proposed a diffusion method for online rumor based on three messages: rumor, anti-rumor, and motivation-rumor. First, considering the ability of representation learning to learn unsupervised features, we decided to use representation learning method to the diversity and complexity of the content and structure feature space. In particular, we designed a new representation method-Rumor2vec-for the potential structural feature of the rumor diffusion network. Second, considering the mutual promotion and suppression of the three messages, we constructed a new network topology using the cooperative and competitive relationships based on the evolutionary game theory. Finally, considering the ability of graph convolutional network (GCN) to convolute non-Euclidean structure data such as social network, and in view of the time effectiveness of topic evolution, this study proposed a dynamic and game-GCN (evolutionary game theory GCN)-based rumor diffusion model. Experiments show that the model can not only predict the group behavior under the rumor topic but also accurately reflect the cooperation and competition among multiple messages.
Significant efforts have been made for vehicle-to-vehicle communications that now enable the Internet of Vehicles (IoV). However, current IoV solutions are unable to capture traffic data both accurately and securely. Another drawback of current IoV models that are based on deep learning is that the methods used do not tune hyperparameters efficiently. In this paper, a new system known as Secure and Intelligent System for the Internet of Vehicles (SISIV) is developed. A deep learning architecture based on graph convolutional networks and an attention mechanism are implemented. In addition, blockchain technology is used to protect data transmission between nodes in the IoV system. Moreover, the hyperparameters of the generated deep learning model are intelligently selected using a branch-and-bound technique. To validate SISIV, experiments were conducted on four networked vehicle databases dealing with prediction problems. In terms of forecasting rate (> 90%), F-measure (> 80%), and attack detection (< 75%), the results clearly show the superiority of SISIV over baseline systems. Moreover, compared to state-of-the-art solutions based on traffic prediction, SISIV enables efficient and reliable prediction of traffic flow in an IoV context.
Design space exploration in logic synthesis and parameter tuning in physical design require a massive amount of compute resources in order to meet tapeout schedules. To address this need, cloud computing provides semiconductor and electronics companies with instant access to scalable compute resources. However, deploying electronic design automation (EDA) jobs on the cloud requires EDA teams to deeply understand the characteristics of their jobs in cloud environments. Unfortunately, there has been little to no public information on these characteristics. Thus, in this article, we first formulate the problem of moving EDA jobs to the cloud. To address the problem, we characterize the performance of four EDA main applications, namely: 1) synthesis; 2) placement; 3) routing; and 4) static timing analysis. We show that different EDA jobs require different compute configurations in order to achieve the best performance. Using observations from our characterization, we propose a novel model based on graph convolutional networks to predict the total runtime of a given stage on different configurations. Our model achieves a prediction accuracy of 87%. Furthermore, we present a new formulation for optimizing cloud deployments in order to reduce costs while meeting deadline constraints. We present a pseudopolynomial optimal solution using a multichoice knapsack mapping that reduces deployment costs by 35.29%, with minimal overhead to the total runtime. In addition, we describe a cloud-ready solution, called EDA analytics central, for the continuous optimization of a design across an EDA flow. We used this system in building our runtime prediction model.
A recommendation algorithm combined with a knowledge graph enables auxiliary information on items to be obtained by using the knowledge graph to achieve better recommendations. However, the recommendation performance of existing methods relies heavily on the quality of the knowledge graph. Knowledge graphs often contain noise and irrelevant connections between items and entities in the real world. This knowledge graph sparsity and noise significantly amplifies the noise effects and hinders the accurate representation of user preferences. In response to these problems, an improved collaborative recommendation model is proposed which integrates knowledge embedding and graph contrastive learning. Specifically, we propose a knowledge contrastive learning scheme to mitigate noise within the knowledge graph during information aggregation, thereby enhancing the embedding quality of items. Simultaneously, to tackle the issue of insufficient user-side information in the knowledge graph, graph convolutional neural networks are utilized to propagate knowledge graph information from the item side to the user side, thereby enhancing the personalization capability of the recommendation system. Additionally, to resolve the over-smoothing issue in graph convolutional networks, a residual structure is employed to establish the message propagation network between adjacent layers of the same node, which expands the information propagation path. Experimental results on the Amazon-book and Yelp2018 public datasets demonstrate that the proposed model outperforms the best baseline models by 11.4% and 11.6%, respectively, in terms of the Recall@20 evaluation metric. This highlights the method's efficacy in improving the recommendation accuracy and effectiveness when incorporating knowledge graphs into the recommendation process.
Graph convolutional networks (GCNs) are important techniques for analytics tasks related to graph data. To date, most GCNs are designed for a single graph domain. They are incapable of transferring knowledge from/to different domains (graphs), due to the limitation in graph representation learning and domain adaptation across graph domains. This paper proposes a novel Graph Contrastive Learning Network (GCLN) for unsupervised domain adaptive graph learning. The key innovation is to enforce attraction and repulsion forces within each single graph domain, and across two graph domains. Within each graph, an attraction force encourages local patch node features to be similar to global representation of the entire graph, whereas a repulsion force will repel node features so they can separate network from its permutations (i.e. domain-specific graph contrastive learning). Across two graph domains, an attraction force encourages node features from two domains to be largely consistent, whereas a repulsion force ensures features are discriminative to differentiate graph domains (i.e. cross-domain graph contrastive learning). The within- and cross-domain graph contrastive learning is carried out by optimizing an objective function, which combines source classifier and target classifier loss, domain-specific contrastive loss, and cross-domain contrastive loss. As a result, feature learning from graphs is facilitated using knowledge transferred between graphs. Experiments on real-world datasets demonstrate that GCLN outperforms state-of-the-art graph neural network algorithms.
With the proliferation of multi-modal data generated by various sensors, unsupervised multi-modal hashing retrieval has been extensively studied due to its advantages in storage, retrieval efficiency, and label independence. However, there are still two obstacles to existing unsupervised methods: (1) As existing methods cannot fully capture the complementary and co-occurrence information of multi-modal data, existing methods suffer from inaccurate similarity measures. (2) Existing methods suffer from unbalanced multi-modal learning and data semantic structure being corrupted in the process of hash codes binarization. To address these obstacles, we devise an effective CLIP-based Adaptive Graph Attention Network (CAGAN) for large-scale unsupervised multi-modal hashing retrieval. Firstly, we use the multi-modal model CLIP to extract fine-grained semantic features, mine similar information from different perspectives of multi-modal data and perform similarity fusion and enhancement. In addition, this paper proposes an adaptive graph attention network to assist the learning of hash codes, which uses an attention mechanism to learn adaptive graph similarity across modalities. It further aggregates the intrinsic neighborhood information of neighboring data nodes through a graph convolutional network to generate more discriminative hash codes. Finally, this paper employs an iterative approximate optimization strategy to mitigate the information loss in the binarization process. Extensive experiments on three benchmark datasets demonstrate that the proposed method significantly outperforms several representative hashing methods in unsupervised multi-modal retrieval tasks.
The demand forecasting plays a crucial role in the predictive physical and virtualized network management in cellular networks, which can effectively reduce both the capital and operational expenditures by fully exploiting the network infrastructure. In this paper, we study the per-cell demand forecasting in cellular networks. The success of demand forecasting relies on the effective modeling of both the spatial and temporal aspects of the per-cell demand time series. However, the main challenge of the spatial relevancy modeling in the per-cell demand forecasting is the irregular spatial distribution of cells in a network, where applying grid-based models (e.g., convolutional neural networks) would lead to degradation of spatial granularity. In this paper, we propose to model the spatial relevancy among cells by a dependency graph based on spatial distances among cells without the loss of spatial granularity. Such spatial distance-based graph modeling is confirmed by the spatiotemporal analysis via semivariogram, which suggests that the relevancy between any two cells declines as their spatial distance increases. Hence, the graph convolutional networks and long short-term memory (LSTM) from deep learning are employed to model the spatial and temporal aspects, respectively. In addition, the deep graph-sequence model, graph convolutional LSTM, is further employed to simultaneously characterize both the spatial and temporal aspects of mobile demand forecasting. Experiments demonstrate that our proposed graph-sequence demand forecasting model could achieve a superior forecasting performance compared with the other two proposed models as well as the traditional auto regression integrated moving average time series model.
Accurate segmentation of anatomical structures is vital for medical image analysis. The state-of-the-art accuracy is typically achieved by supervised learning methods, where gathering the requisite expert-labeled image annotations in a scalable manner remains a main obstacle. Therefore, annotation-efficient methods that permit to produce accurate anatomical structure segmentation are highly desirable. In this work, we present Contour Transformer Network (CTN), a one-shot anatomy segmentation method with a naturally built-in human-in-the-loop mechanism. We formulate anatomy segmentation as a contour evolution process and model the evolution behavior by graph convolutional networks (GCNs). Training the CTN model requires only one labeled image exemplar and leverages additional unlabeled data through newly introduced loss functions that measure the global shape and appearance consistency of contours. On segmentation tasks of four different anatomies, we demonstrate that our one-shot learning method significantly outperforms non-learning-based methods and performs competitively to the state-of-the-art fully supervised deep learning methods. With minimal human-in-the-loop editing feedback, the segmentation performance can be further improved to surpass the fully supervised methods.
The application of graph convolutional networks (GCN) in hyperspectral image (HSI) classification has become a promising method, thanks to its flexible convolution operation in any irregular image region. For the classification of HSI, GCN can extract more superpixel-level features with a topological structure, in comparison to the traditional convolutional neural networks (CNNs) using fixed square kernels distilling pixel-level features. To fully leverage the different levels of features, this study proposes a novel deep network referred to as a CNN-combined graph residual network (C2GRN), which integrates the multilevel graph residual module and spectral-spatial features continuous learning module. During the extraction of topology information using the former module, HSI pixels are divided into superpixels and served as input nodes of the module to reduce the computational complexity and obtain the multilevel spatial relevance between adjacent superpixels. Besides, for the latter module, the spectral-spatial features are learnt continuously, which could obtain the finer pixel-level features. Finally, the captured spectral-spatial features of different levels are concatenated. This strategy could not only adequately utilize the correlation and difference of adjacent spatial but also obtain the finer and more valuable spectral-spatial information, which makes a significant boost in the HSI classification. Additionally, the experiment results demonstrate the superiority and availability of the C2GRN on three benchmark datasets of HSI, compared with the state-of-the-art methods for the classification of HSI.
Semi-supervised network representation learning is becoming a hotspot in graph mining community, which aims to learn low-dimensional vector representations of vertices using partial label information. In particular, graph neural networks integrate structural information and other side information like vertex attributes to learn node representations. Although the existing semi-supervised graph learning performs well on limited labeled data, it is still often hampered when labeled dataset is quite small. To mitigate this issue, we propose PMNRL, a pseudo-multitask learning framework for semi-supervised network representation learning to boost the expression power of graph networks such as vanilla GCN (Graph Convolutional Networks) and GAT (Graph Attention Networks). In PMNRL, by leveraging the community structures in networks, we create a pseudo task that classifies nodes' community affiliation, and conduct a joint learning of two tasks (i.e., the original task and the pseudo task). Our proposed scheme can take advantage of the inherent connection between structural proximity and label similarity to improve the performance without the need to resort to more labels. The proposed framework is implemented in two ways: two-stage method and end-to-end method. For two-stage method, communities are first detected and then the community affiliations are used as "labels" along with original labels to train the joint model. In end-to-end method, the unsupervised community learning is combined into the representation learning process by shared layers and task-specific layers, so as to encourage the common features and specific features for different tasks at the same time. The experimental results on three real-world benchmark networks demonstrate the performance improvement of the vanilla models using our framework without any additional labels, especially when there are quite few labels.
The operation of public bike sharing (PBS) programs has attracted attention again due to numerous problems encountered by free-floating bike sharing programs. These problems include malicious damage, theft, chaotic parking, large-scale deficit and bankruptcy. The short-time demand prediction is a key issue for the successful operation of PBS programs. In this study, we use a novel spatio-temporal graph convolutional network (STGCN) to predict the picking up/returning demand by exploring potential information from multi-view data. We apply graph convolutional neural networks (CNNs) to represent the spatial dependency based on the geographic information system data denoting the location of docks. Moreover, we use gated CNNs to denote the temporal dependency according to the time-series data representing the demand for picking up/returning public bikes. The STGCN and three recurrent neural network (RNN)-based competitors are trained and validated using the multi-view data from the Wenling PBS program for one month. The RNN-based competitors consist of the SimpleRNN, long short term memory and gated recurrent unit. Results show that the STGCN achieves higher prediction accuracy compared with its competitors. Although the STGCN consumes a longer training time compared with the SimpleRNN, it requires a minimal number of epochs to achieve convergence precision. The complete CNN structure in the STGCN can effectively address the spatial and temporal dependencies for PBS demand prediction.
Background Apicomplexa consist of numerous pathogenic parasitic protistan genera that invade host cells and reside and replicate within the parasitophorous vacuole (PV). Through this interface, the parasite exchanges nutrients and affects transport and immune modulation. During the intracellular life-cycle, the specialized secretory organelles of the parasite secrete an array of proteins, among which dense granule proteins (GRAs) play a major role in the modification of the PV. Despite this important role of GRAs, a large number of potential GRAs remain unidentified in Apicomplexa.Methods A multi-view attention graph convolutional network (MVA-GCN) prediction model with multiple features was constructed using a combination of machine learning and genomic datasets, and the prediction was performed on selected Neospora caninum protein data. The candidate GRAs were verified by a CRISPR/Cas9 gene editing system, and the complete NcGRA64(a,b) gene knockout strain was constructed and the phenotypes of the mutant were analyzed.Results The MVA-GCN prediction model was used to screen N. caninum candidate GRAs, and two novel GRAs (NcGRA64a and NcGRA64b) were verified by gene endogenous tagging. Knockout of complete genes of NcGRA64(a,b) in N. caninum did not affect the parasite's growth and replication in vitro and virulence in vivo.Conclusions Our study showcases the utility of the MVA-GCN deep learning model for mining Apicomplexa GRAs in genomic datasets, and the prediction model also has certain potential in mining other functional proteins of apicomplexan parasites.
Online reviews play a significant role in purchase decisions of consumers by providing feedback information from buyers of products. In order to mislead consumers, opinion spammers are hired to write fake reviews to promote or demote specific products for illegitimate benefits. Existing methods for spam review detection mainly focused on designing manual features, which highly rely on expert knowledge. Although recent works utilized deep learning methods to automatically learn the semantics of reviews through the inherent user-review-product strong relation, they fail to capture the weak relations between reviews at the content, sentiment and temporal levels, which provides various semantic information to expose fake reviews. Moreover, the imbalanced class distribution in spam detection issues makes this work even more challenging. To address the above problems, we propose a novel Weak-Strong Unified Network (WSUN) for opinion spam detection. Multi-level weak relation graphs are constructed to reveal the abnormal behavioral patterns of spammers, which aggregates the semantics of strong relations by graph convolutional networks and extracts comprehensive review representation by utilizing relation-level attention mechanism. In addition, a graph-based over-sampling method is devised to mitigate the impact of imbalanced class distribution. Extensive experimental results on real-world datasets show that our model is more effective than the state-of-the-art methods.
Nowadays, as a crucial component of intelligent transportation systems, traffic flow prediction has received extensive concern. However, most of the existing studies extracted spatial-temporal features with modules that do not differentiate with time and space, and failed to consider spatial temporal heterogeneities. Furthermore, although previous works have achieved synchronous modeling of spatial-temporal dependencies, the consideration of temporal causality is still lacking in their graph structures. To address these shortcomings, a spatial-temporal heterogeneous and synchronous graph convolution network (STHSGCN) is proposed for traffic flow prediction. To be specific, separate dilated causal spatial-temporal synchronous graph convolutional networks (DCSTSGCNs) for various node clusters are designed to reflect spatial heterogeneity, different dilated causal spatial-temporal synchronous graph convolutional modules (DCSTSGCMs) for diverse time steps are deployed to take account of temporal heterogeneity. In addition, causal spatial-temporal synchronous graph (CSTSG) is proposed to capture temporal causality in spatial temporal synchronous learning. We further conducted extensive experiments on four real-world datasets, and the results verified the consistent superiority of our proposed approach compared with various existing baselines.
