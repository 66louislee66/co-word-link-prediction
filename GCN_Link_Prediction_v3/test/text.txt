Graph convolutional networks (GCNs) have received significant attention from various research fields due to the excellent performance in learning graph representations. Although GCN performs well compared with other methods, it still faces challenges. Training a GCN model for large-scale graphs in a conventional way requires high computation and storage costs. Therefore, motivated by an urgent need in terms of efficiency and scalability in training GCN, sampling methods have been proposed and achieved a significant effect. In this paper, we categorize sampling methods based on the sampling mechanisms and provide a comprehensive survey of sampling methods for efficient training of GCN. To highlight the characteristics and differences of sampling methods, we present a detailed comparison within each category and further give an overall comparative analysis for the sampling methods in all categories. Finally, we discuss some challenges and future research directions of the sampling methods.
Recently, graph convolutional networks (GCN) have made substantial progress in semi supervised learning (SSL). However, established GCN-based methods have two major limitations. First, GCN-based methods are restricted by the oversmoothing issue that limits their ability to extract knowledge from distant but informative nodes. Second, most available GCN-based methods exploit only the feature information of unlabeled nodes, and the pseudo-labels of unlabeled nodes, which contain important information about the data distribution, are not fully utilized. To address these issues, we propose a novel end-to-end ensemble framework, which is named mixed-order graph convolutional networks (MOGCN). MOGCN consists of two modules. (1) It constructs multiple simple GCN learners with multi-order adjacency matrices, which can directly capture the high-order connectivity among the nodes to alleviate the problem of oversmoothing. (2) To efficiently combine the results from multiple GCN learners, MOGCN employs a novel ensemble module, in which the pseudo-labels of unlabeled nodes from various GCN learners are used to augment the diversity among the learners. We conduct experiments on three public benchmark datasets to evaluate the performance of MOGCN on semi-supervised node classification tasks. The experimental results demonstrate that MOGCN consistently outperforms state-of-the-art methods. (c) 2021 Published by Elsevier Inc.
The alert correlation process that aggregates computer network security alerts to the same attack scenario provides a coherent view of network status at a higher abstraction level. This letter proposes a framework called Alert-GCN to correlate alerts that belong to the same attack using graph convolutional networks (GCN). The intuition is that the stacked convolutional layers help aggregate alert information from farther neighbors in the alert graph, thus facilitating attack scenario discovery. Alert-GCN first transforms alerts into alert graph with one-hot encoding and then feeds the graph into the GCN to perform node classification. The experimental results indicate that Alert-GCN outperforms traditional classification models in correlating alerts.
Graph convolutional networks (GCNs) and their variants are excellent deep learning methods for graph-structured data. Moreover, multilayer GCNs can perform feature smoothing repeatedly, which creates considerable performance improvements. However, they may inherit unnecessary complexity and redundant computation; to make matters worse, they introduce overfitting as the number of layers increases. In this paper, we present simplified multilayer graph convolutional networks with dropout (DGCs), novel neural network architectures that successively perform nonlinearity removal and weight matrix merging between graph conventional layers, leveraging a dropout layer to achieve feature augmentation and effectively reduce overfitting. Under such circumstances, first, we extend a shallow GCN to a multilayer GCN. Then, we reduce the complexity and redundant calculations of the multilayer GCN, while improving its classification performance. Finally, we make DGCs readily applicable to inductive and transductive tasks. Extensive experiments on citation networks and social networks offer evidence that the proposed model matches or outperforms state-of-the-art methods.
In this work, we introduce multi-column graph convolutional networks (MGCNs), a deep generative model for 3D mesh surfaces that effectively learns a non-linear facial representation. We perform spectral decomposition of meshes and apply convolutions directly in the frequency domain. Our network architecture involves multiple columns of graph convolutional networks (GCNs), namely large GCN (L-GCN), medium GCN (M-GCN) and small GCN (S-GCN), with different filter sizes to extract features at different scales. L-GCN is more useful to extract large-scale features, whereas S-GCN is effective for extracting subtle and fine-grained features, and M-GCN captures information in between. Therefore, to obtain a high-quality representation, we propose a selective fusion method that adaptively integrates these three kinds of information. Spatially non-local relationships are also exploited through a self-attention mechanism to further improve the representation ability in the latent vector space. Through extensive experiments, we demonstrate the superiority of our end-to-end framework in improving the accuracy of 3D face reconstruction. Moreover, with the help of variational inference, our model has excellent generating ability.
Currently, the representation learning of a graph has been proved to be a significant technique to extract graph structured data features. In recent years, many graph representation learning (GRL) algorithms, such as Laplacian Eigenmaps (LE), Node2vec and graph convolutional networks (GCN), have been reported and have achieved great success on node classification tasks. The most representative GCN fuses the feature information and structure information of data, which aims to generalize convolutional neural networks (CNN) to learn data features with arbitrary structure. However, how to exactly express the structure information of data is still an enormous challenge. In this paper, we utilize hypergraph p-Laplacian to preserve the local geometry of samples and then propose an effective variant of GCN, i.e. hypergraph p-Laplacian graph convolutional networks (HpLapGCN). Since hypergraph p-Laplacian is a generalization of the graph Laplacian, HpLapGCN model shows great potential to learn more representative data features. In particular, we simplify and deduce a one-order approximation of spectral hypergraph p-Laplacian convolutions. Thus, we can get a more efficient layer-wise aggregate rule. Extensive experiment results on the Citeseer and Cora datasets prove that our proposed model achieves better performance compare with GCN and p-Laplacian GCN (pLapGCN). (C) 2019 Elsevier B.V. All rights reserved.
Suffering from the multi-view data diversity and complexity, most of the existing graph convolutional networks focus on the networks' architecture construction or the salient graph structure preservation for node classification in citation networks and usually ignore capturing the complete graph structure of nodes for enhancing classification performance. To mine the more complete distribution structure from multi-graph structures of multi-view data with the consideration of their specificity and the commonality, we propose structure fusion based on graph convolutional networks (SF-GCN) for improving the performance of node classification in a semi-supervised way. SF-GCN can not only exploit the special characteristic of each view datum by spectral embedding preserving multi-graph structures, but also explore the common style of multi-view data by the distance metric between multi-graph structures. Suppose the linear relationship between multi-graph structures; we can construct the optimization function of the structure fusion model by balancing the specificity loss and the commonality loss. By solving this function, we can simultaneously obtain the fusion spectral embedding from the multi-view data and the fusion structure as the adjacent matrix to input graph convolutional networks for node classification in a semi-supervised way. Furthermore, we generalize the structure fusion to structure diffusion propagation and present structure propagation fusion based on graph convolutional networks (SPF-GCN) for utilizing these structure interactions. Experiments demonstrate that the performance of SPF-GCN outperforms that of the state-of-the-art methods on three challenging datasets, which are Cora, Citeseer, and Pubmed in citation networks.
Walking is an exercise that uses muscles and joints of the human body and is essential for understanding body condition. Analyzing body movements through gait has been studied and applied in human identification, sports science, and medicine. This study investigated a spatiotemporal graph convolutional network model (ST-GCN), using attention techniques applied to pathological-gait classification from the collected skeletal information. The focus of this study was twofold. The first objective was extracting spatiotemporal features from skeletal information presented by joint connections and applying these features to graph convolutional neural networks. The second objective was developing an attention mechanism for spatiotemporal graph convolutional neural networks, to focus on important joints in the current gait. This model establishes a pathological-gait-classification system for diagnosing sarcopenia. Experiments on three datasets, namely NTU RGB+D, pathological gait of GIST, and multimodal-gait symmetry (MMGS), validate that the proposed model outperforms existing models in gait classification.
Currently, graph convolutional networks (GCN) have achieved significant progress in recommender systems, due to its remarkable capability on representation learning and the ability to integrate complex auxiliary information. However, the graph convolution operation is prone to cause over-smoothing due to the use of the graph Laplacian operator, so that the node embeddings become very similar after the multi-layer graph convolution, which leads to a decrease in recommendation performance. The recently proposed model based on simplified GCN can relieve this issue to a certain extent; however, they still only design the model from the viewpoint of GCN. Inspired by the recent developments of label propagation algorithms (LPA), in this paper, we propose a new recommender model that unifies graph convolutional networks and label propagation algorithms. Specifically, we utilize the GCN to build a basic recommendation prediction model, and unify the LPA to provide regularization of training edge weights, which has been proven to effectively alleviate the over-smoothing problem. In addition, we introduce an attention network to capture the attention weight of each user-item pair, which takes into account the fact that users attach different degrees of importance to various relationships of items. Extensive experiments on three real-world datasets demonstrate that the proposed algorithm has a significant improvement over other state-of-the-art recommendation algorithms.
With the growing applications of Graph Convolutional Networks (GCN), there is also an increasing demand for its efficient hardware acceleration. Compared with CNN tasks, GCN tasks have new challenges such as randomness, sparsity, and nonuniformity, which will lead to poor performance of previous AI accelerators. In this paper, we propose DyGA, a hardware-efficient GCN accelerator, which is featured by strategies of graph partitioning, customized storage policy, traffic-aware dynamic scheduling, and out-of-order execution. Synthesized and evaluated under TSMC 28-nm, the accelerator achieves an average throughput of over 95% of its peak performance with full utilization of hardware on representative graph data sets. Having a high area-efficiency with 0.217 GOPS/K-logic-gates and 8.06 GOPS/KB-PE-buffer, and thus an energy-efficiency of 384GOPS/W, the proposed accelerator outperforms previous state-of-the-art works in the sparse data processing.
